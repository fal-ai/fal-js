// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: "https://queue.fal.run" | (string & {});
};

/**
 * OutputParameters
 */
export type LoraOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<Image>;
  /**
   * Debug Latents
   *
   * The latents saved for debugging.
   */
  debug_latents?: File;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Debug Per Pass Latents
   *
   * The latents saved for debugging per pass.
   */
  debug_per_pass_latents?: File;
};

/**
 * File
 */
export type File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * Image
 *
 * Represents an image file.
 */
export type Image = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * TextToImageInput
 */
export type LoraInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or custom height and width
   * that **must be multiples of 8**.
   *
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Tile Height
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_height?: number;
  /**
   * Embeddings
   *
   *
   * The embeddings to use for the image generation. Only a single embedding is supported at the moment.
   * The embeddings will be used to map the tokens in the prompt to the embedding weights.
   *
   */
  embeddings?: Array<Embedding>;
  /**
   * Ic Light Model Url
   *
   *
   * The URL of the IC Light model to use for the image generation.
   *
   */
  ic_light_model_url?: string;
  /**
   * Image Encoder Weight Name
   *
   *
   * The weight name of the image encoder model to use for the image generation.
   *
   */
  image_encoder_weight_name?: string;
  /**
   * Ip Adapter
   *
   *
   * The IP adapter to use for the image generation.
   *
   */
  ip_adapter?: Array<IpAdapterType2>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler / sampler to use for the image denoising process.
   */
  scheduler?:
    | "DPM++ 2M"
    | "DPM++ 2M Karras"
    | "DPM++ 2M SDE"
    | "DPM++ 2M SDE Karras"
    | "Euler"
    | "Euler A"
    | "Euler (trailing timesteps)"
    | "LCM"
    | "LCM (trailing timesteps)"
    | "DDIM"
    | "TCD";
  /**
   * Sigmas
   *
   *
   * Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.
   * If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.
   *
   */
  sigmas?: SigmasInput;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Tile Stride Width
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_width?: number;
  /**
   * Debug Per Pass Latents
   *
   * If set to true, the latents will be saved for debugging per pass.
   */
  debug_per_pass_latents?: boolean;
  /**
   * Timesteps
   *
   *
   * Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.
   * If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.
   *
   */
  timesteps?: TimestepsInput;
  /**
   * Image Encoder Subfolder
   *
   *
   * The subfolder of the image encoder model to use for the image generation.
   *
   */
  image_encoder_subfolder?: string;
  /**
   * Prompt Weighting
   *
   *
   * If set to true, the prompt weighting syntax will be used.
   * Additionally, this will lift the 77 token limit by averaging embeddings.
   *
   */
  prompt_weighting?: boolean;
  /**
   * Variant
   *
   * The variant of the model to use for huggingface models, e.g. 'fp16'.
   */
  variant?: string;
  /**
   * Model Name
   *
   * URL or HuggingFace ID of the base model to generate the image.
   */
  model_name: string;
  /**
   * Controlnet Guess Mode
   *
   *
   * If set to true, the controlnet will be applied to only the conditional predictions.
   *
   */
  controlnet_guess_mode?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Ic Light Model Background Image Url
   *
   *
   * The URL of the IC Light model background image to use for the image generation.
   * Make sure to use a background compatible with the model.
   *
   */
  ic_light_model_background_image_url?: string;
  /**
   * Rescale Betas Snr Zero
   *
   *
   * Whether to set the rescale_betas_snr_zero option or not for the sampler
   *
   */
  rescale_betas_snr_zero?: boolean;
  /**
   * Tile Width
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_width?: number;
  /**
   * Prediction Type
   *
   *
   * The type of prediction to use for the image generation.
   * The `epsilon` is the default.
   *
   */
  prediction_type?: "v_prediction" | "epsilon";
  /**
   * Eta
   *
   * The eta value to be used for the image generation.
   */
  eta?: number;
  /**
   * Image Encoder Path
   *
   *
   * The path to the image encoder model to use for the image generation.
   *
   */
  image_encoder_path?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Image Format
   *
   * The format of the generated image.
   */
  image_format?: "jpeg" | "png";
  /**
   * Number of images
   *
   *
   * Number of images to generate in one request. Note that the higher the batch size,
   * the longer it will take to generate the images.
   *
   */
  num_images?: number;
  /**
   * Debug Latents
   *
   * If set to true, the latents will be saved for debugging.
   */
  debug_latents?: boolean;
  /**
   * Ic Light Image Url
   *
   *
   * The URL of the IC Light model image to use for the image generation.
   *
   */
  ic_light_image_url?: string;
  /**
   * Unet Name
   *
   * URL or HuggingFace ID of the custom U-Net model to use for the image generation.
   */
  unet_name?: string;
  /**
   * Clip Skip
   *
   *
   * Skips part of the image generation process, leading to slightly different results.
   * This means the image renders faster, too.
   *
   */
  clip_skip?: number;
  /**
   * Tile Stride Height
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_height?: number;
  /**
   * Controlnets
   *
   *
   * The control nets to use for the image generation. You can use any number of control nets
   * and they will be applied to the image at the specified timesteps.
   *
   */
  controlnets?: Array<ControlNetType2>;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
};

/**
 * ControlNet
 */
export type ControlNetType2 = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number;
  /**
   * Path
   *
   * URL or the path to the control net weights.
   */
  path: string;
  /**
   * Ip Adapter Index
   *
   *
   * The index of the IP adapter to be applied to the controlnet. This is only needed for InstantID ControlNets.
   *
   */
  ip_adapter_index?: number;
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number;
  /**
   * Config Url
   *
   * optional URL to the controlnet config.json file.
   */
  config_url?: string;
  /**
   * Image Url
   *
   * URL of the image to be used as the control net.
   */
  image_url: string;
  /**
   * Variant
   *
   * The optional variant if a Hugging Face repo key is used.
   */
  variant?: string;
  /**
   * Mask Url
   *
   *
   * The mask to use for the controlnet. When using a mask, the control image size and the mask size must be the same and divisible by 32.
   *
   */
  mask_url?: string;
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number;
};

/**
 * TimestepsInput
 */
export type TimestepsInput = {
  /**
   * Method
   *
   *
   * The method to use for the timesteps. If set to 'array', the timesteps will be set based
   * on the provided timesteps schedule in the `array` field.
   * Defaults to 'default' which means the scheduler will use the `num_inference_steps` parameter.
   *
   */
  method?: "default" | "array";
  /**
   * Array
   *
   *
   * Timesteps schedule to be used if 'custom' method is selected.
   *
   */
  array?: Array<number>;
};

/**
 * SigmasInput
 */
export type SigmasInput = {
  /**
   * Method
   *
   *
   * The method to use for the sigmas. If set to 'custom', the sigmas will be set based
   * on the provided sigmas schedule in the `array` field.
   * Defaults to 'default' which means the scheduler will use the sigmas of the scheduler.
   *
   */
  method?: "default" | "array";
  /**
   * Array
   *
   *
   * Sigmas schedule to be used if 'custom' method is selected.
   *
   */
  array?: Array<number>;
};

/**
 * LoraWeight
 */
export type LoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number;
};

/**
 * IPAdapter
 */
export type IpAdapterType2 = {
  /**
   * Unconditional Noising Factor
   *
   * The factor to apply to the unconditional noising of the IP adapter.
   */
  unconditional_noising_factor?: number;
  /**
   * Ip Adapter Image Url
   *
   * URL of the image to be used as the IP adapter.
   */
  ip_adapter_image_url: string | Array<string>;
  /**
   * Path
   *
   * URL or the path to the IP adapter weights.
   */
  path: string;
  /**
   * Image Projection Shortcut
   *
   *
   * The value to set the image projection shortcut to. For FaceID plus V1 models,
   * this should be set to False. For FaceID plus V2 models, this should be set to True.
   * Default is True.
   *
   */
  image_projection_shortcut?: boolean;
  /**
   * Scale Json
   *
   *
   * The scale of the IP adapter weight. This is used to scale the IP adapter weight
   * before merging it with the base model.
   *
   */
  scale_json?: {
    [key: string]: unknown;
  };
  /**
   * Ip Adapter Mask Url
   *
   *
   * The mask to use for the IP adapter. When using a mask, the ip-adapter image size and the mask size must be the same
   *
   */
  ip_adapter_mask_url?: string;
  /**
   * Model Subfolder
   *
   * Subfolder in the model directory where the IP adapter weights are stored.
   */
  model_subfolder?: string;
  /**
   * Scale
   *
   *
   * The scale of the IP adapter weight. This is used to scale the IP adapter weight
   * before merging it with the base model.
   *
   */
  scale?: number;
  /**
   * Insight Face Model Path
   *
   * URL or the path to the InsightFace model weights.
   */
  insight_face_model_path?: string;
  /**
   * Weight Name
   *
   * Name of the weight file.
   */
  weight_name?: string;
};

/**
 * Embedding
 */
export type Embedding = {
  /**
   * Tokens
   *
   * The list of tokens to use for the embedding.
   */
  tokens?: Array<string>;
  /**
   * Path
   *
   * URL or the path to the embedding weights.
   */
  path: string;
};

/**
 * ImageSize
 */
export type ImageSize = {
  /**
   * Height
   *
   * The height of the generated image.
   */
  height?: number;
  /**
   * Width
   *
   * The width of the generated image.
   */
  width?: number;
};

/**
 * FooocusOutput
 */
export type FooocusOutput = {
  /**
   * Images
   *
   * The generated image file info.
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * The time taken for the generation process.
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
};

/**
 * FooocusLegacyInput
 */
export type FooocusInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * Performance
   *
   *
   * You can choose Speed or Quality
   *
   */
  performance?: "Speed" | "Quality" | "Extreme Speed" | "Lightning";
  /**
   * Styles
   *
   *
   * The style to use.
   *
   */
  styles?: Array<
    | "Fooocus V2"
    | "Fooocus Enhance"
    | "Fooocus Sharp"
    | "Fooocus Semi Realistic"
    | "Fooocus Masterpiece"
    | "Fooocus Photograph"
    | "Fooocus Negative"
    | "Fooocus Cinematic"
    | "SAI 3D Model"
    | "SAI Analog Film"
    | "SAI Anime"
    | "SAI Cinematic"
    | "SAI Comic Book"
    | "SAI Craft Clay"
    | "SAI Digital Art"
    | "SAI Enhance"
    | "SAI Fantasy Art"
    | "SAI Isometric"
    | "SAI Line Art"
    | "SAI Lowpoly"
    | "SAI Neonpunk"
    | "SAI Origami"
    | "SAI Photographic"
    | "SAI Pixel Art"
    | "SAI Texture"
    | "MRE Cinematic Dynamic"
    | "MRE Spontaneous Picture"
    | "MRE Artistic Vision"
    | "MRE Dark Dream"
    | "MRE Gloomy Art"
    | "MRE Bad Dream"
    | "MRE Underground"
    | "MRE Surreal Painting"
    | "MRE Dynamic Illustration"
    | "MRE Undead Art"
    | "MRE Elemental Art"
    | "MRE Space Art"
    | "MRE Ancient Illustration"
    | "MRE Brave Art"
    | "MRE Heroic Fantasy"
    | "MRE Dark Cyberpunk"
    | "MRE Lyrical Geometry"
    | "MRE Sumi E Symbolic"
    | "MRE Sumi E Detailed"
    | "MRE Manga"
    | "MRE Anime"
    | "MRE Comic"
    | "Ads Advertising"
    | "Ads Automotive"
    | "Ads Corporate"
    | "Ads Fashion Editorial"
    | "Ads Food Photography"
    | "Ads Gourmet Food Photography"
    | "Ads Luxury"
    | "Ads Real Estate"
    | "Ads Retail"
    | "Artstyle Abstract"
    | "Artstyle Abstract Expressionism"
    | "Artstyle Art Deco"
    | "Artstyle Art Nouveau"
    | "Artstyle Constructivist"
    | "Artstyle Cubist"
    | "Artstyle Expressionist"
    | "Artstyle Graffiti"
    | "Artstyle Hyperrealism"
    | "Artstyle Impressionist"
    | "Artstyle Pointillism"
    | "Artstyle Pop Art"
    | "Artstyle Psychedelic"
    | "Artstyle Renaissance"
    | "Artstyle Steampunk"
    | "Artstyle Surrealist"
    | "Artstyle Typography"
    | "Artstyle Watercolor"
    | "Futuristic Biomechanical"
    | "Futuristic Biomechanical Cyberpunk"
    | "Futuristic Cybernetic"
    | "Futuristic Cybernetic Robot"
    | "Futuristic Cyberpunk Cityscape"
    | "Futuristic Futuristic"
    | "Futuristic Retro Cyberpunk"
    | "Futuristic Retro Futurism"
    | "Futuristic Sci Fi"
    | "Futuristic Vaporwave"
    | "Game Bubble Bobble"
    | "Game Cyberpunk Game"
    | "Game Fighting Game"
    | "Game Gta"
    | "Game Mario"
    | "Game Minecraft"
    | "Game Pokemon"
    | "Game Retro Arcade"
    | "Game Retro Game"
    | "Game Rpg Fantasy Game"
    | "Game Strategy Game"
    | "Game Streetfighter"
    | "Game Zelda"
    | "Misc Architectural"
    | "Misc Disco"
    | "Misc Dreamscape"
    | "Misc Dystopian"
    | "Misc Fairy Tale"
    | "Misc Gothic"
    | "Misc Grunge"
    | "Misc Horror"
    | "Misc Kawaii"
    | "Misc Lovecraftian"
    | "Misc Macabre"
    | "Misc Manga"
    | "Misc Metropolis"
    | "Misc Minimalist"
    | "Misc Monochrome"
    | "Misc Nautical"
    | "Misc Space"
    | "Misc Stained Glass"
    | "Misc Techwear Fashion"
    | "Misc Tribal"
    | "Misc Zentangle"
    | "Papercraft Collage"
    | "Papercraft Flat Papercut"
    | "Papercraft Kirigami"
    | "Papercraft Paper Mache"
    | "Papercraft Paper Quilling"
    | "Papercraft Papercut Collage"
    | "Papercraft Papercut Shadow Box"
    | "Papercraft Stacked Papercut"
    | "Papercraft Thick Layered Papercut"
    | "Photo Alien"
    | "Photo Film Noir"
    | "Photo Glamour"
    | "Photo Hdr"
    | "Photo Iphone Photographic"
    | "Photo Long Exposure"
    | "Photo Neon Noir"
    | "Photo Silhouette"
    | "Photo Tilt Shift"
    | "Cinematic Diva"
    | "Abstract Expressionism"
    | "Academia"
    | "Action Figure"
    | "Adorable 3D Character"
    | "Adorable Kawaii"
    | "Art Deco"
    | "Art Nouveau"
    | "Astral Aura"
    | "Avant Garde"
    | "Baroque"
    | "Bauhaus Style Poster"
    | "Blueprint Schematic Drawing"
    | "Caricature"
    | "Cel Shaded Art"
    | "Character Design Sheet"
    | "Classicism Art"
    | "Color Field Painting"
    | "Colored Pencil Art"
    | "Conceptual Art"
    | "Constructivism"
    | "Cubism"
    | "Dadaism"
    | "Dark Fantasy"
    | "Dark Moody Atmosphere"
    | "Dmt Art Style"
    | "Doodle Art"
    | "Double Exposure"
    | "Dripping Paint Splatter Art"
    | "Expressionism"
    | "Faded Polaroid Photo"
    | "Fauvism"
    | "Flat 2d Art"
    | "Fortnite Art Style"
    | "Futurism"
    | "Glitchcore"
    | "Glo Fi"
    | "Googie Art Style"
    | "Graffiti Art"
    | "Harlem Renaissance Art"
    | "High Fashion"
    | "Idyllic"
    | "Impressionism"
    | "Infographic Drawing"
    | "Ink Dripping Drawing"
    | "Japanese Ink Drawing"
    | "Knolling Photography"
    | "Light Cheery Atmosphere"
    | "Logo Design"
    | "Luxurious Elegance"
    | "Macro Photography"
    | "Mandola Art"
    | "Marker Drawing"
    | "Medievalism"
    | "Minimalism"
    | "Neo Baroque"
    | "Neo Byzantine"
    | "Neo Futurism"
    | "Neo Impressionism"
    | "Neo Rococo"
    | "Neoclassicism"
    | "Op Art"
    | "Ornate And Intricate"
    | "Pencil Sketch Drawing"
    | "Pop Art 2"
    | "Rococo"
    | "Silhouette Art"
    | "Simple Vector Art"
    | "Sketchup"
    | "Steampunk 2"
    | "Surrealism"
    | "Suprematism"
    | "Terragen"
    | "Tranquil Relaxing Atmosphere"
    | "Sticker Designs"
    | "Vibrant Rim Light"
    | "Volumetric Lighting"
    | "Watercolor 2"
    | "Whimsical And Playful"
    | "Mk Chromolithography"
    | "Mk Cross Processing Print"
    | "Mk Dufaycolor Photograph"
    | "Mk Herbarium"
    | "Mk Punk Collage"
    | "Mk Mosaic"
    | "Mk Van Gogh"
    | "Mk Coloring Book"
    | "Mk Singer Sargent"
    | "Mk Pollock"
    | "Mk Basquiat"
    | "Mk Andy Warhol"
    | "Mk Halftone Print"
    | "Mk Gond Painting"
    | "Mk Albumen Print"
    | "Mk Aquatint Print"
    | "Mk Anthotype Print"
    | "Mk Inuit Carving"
    | "Mk Bromoil Print"
    | "Mk Calotype Print"
    | "Mk Color Sketchnote"
    | "Mk Cibulak Porcelain"
    | "Mk Alcohol Ink Art"
    | "Mk One Line Art"
    | "Mk Blacklight Paint"
    | "Mk Carnival Glass"
    | "Mk Cyanotype Print"
    | "Mk Cross Stitching"
    | "Mk Encaustic Paint"
    | "Mk Embroidery"
    | "Mk Gyotaku"
    | "Mk Luminogram"
    | "Mk Lite Brite Art"
    | "Mk Mokume Gane"
    | "Pebble Art"
    | "Mk Palekh"
    | "Mk Suminagashi"
    | "Mk Scrimshaw"
    | "Mk Shibori"
    | "Mk Vitreous Enamel"
    | "Mk Ukiyo E"
    | "Mk Vintage Airline Poster"
    | "Mk Vintage Travel Poster"
    | "Mk Bauhaus Style"
    | "Mk Afrofuturism"
    | "Mk Atompunk"
    | "Mk Constructivism"
    | "Mk Chicano Art"
    | "Mk De Stijl"
    | "Mk Dayak Art"
    | "Mk Fayum Portrait"
    | "Mk Illuminated Manuscript"
    | "Mk Kalighat Painting"
    | "Mk Madhubani Painting"
    | "Mk Pictorialism"
    | "Mk Pichwai Painting"
    | "Mk Patachitra Painting"
    | "Mk Samoan Art Inspired"
    | "Mk Tlingit Art"
    | "Mk Adnate Style"
    | "Mk Ron English Style"
    | "Mk Shepard Fairey Style"
  >;
  /**
   * Control Type
   *
   * The type of image control
   */
  control_type?: "ImagePrompt" | "PyraCanny" | "CPDS" | "FaceSwap";
  /**
   * Mask Image Url
   *
   * The image to use as a mask for the generated image.
   */
  mask_image_url?: string | null;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 5 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Sharpness
   *
   *
   * The sharpness of the generated image. Use it to control how sharp the generated
   * image should be. Higher value means image and texture are sharper.
   *
   */
  sharpness?: number;
  /**
   * Guidance Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Inpaint Image Url
   *
   * The image to use as a reference for inpainting.
   */
  inpaint_image_url?: string | null;
  /**
   * Mixing Image Prompt And Inpaint
   */
  mixing_image_prompt_and_inpaint?: boolean;
  /**
   * Aspect Ratio
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   */
  aspect_ratio?: string;
  /**
   * Num Images
   *
   *
   * Number of images to generate in one request
   *
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Refiner Model
   *
   * Refiner (SDXL or SD 1.5)
   */
  refiner_model?: "None" | "realisticVisionV60B1_v51VAE.safetensors";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Control Image Url
   *
   * The image to use as a reference for the generated image.
   */
  control_image_url?: string | null;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | null;
  /**
   * Refiner Switch At
   *
   *
   * Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models
   * 0.8 for XL-refiners; or any value for switching two SDXL models.
   *
   */
  refiner_switch?: number;
  /**
   * Control Image Weight
   *
   *
   * The strength of the control image. Use it to control how much the generated image
   * should look like the control image.
   *
   */
  control_image_weight?: number;
  /**
   * Control Image Stop At
   *
   *
   * The stop at value of the control image. Use it to control how much the generated image
   * should look like the control image.
   *
   */
  control_image_stop_at?: number;
};

/**
 * DiffusionEdgeOutput
 */
export type DiffusionEdgeOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: ImageType4;
};

/**
 * Image
 *
 * Represents an image file.
 */
export type ImageType4 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size: number;
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type: string;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number;
};

/**
 * DiffusionEdgeInput
 */
export type DiffusionEdgeInput = {
  /**
   * Image Url
   *
   * The text prompt you would like to convert to speech.
   */
  image_url: string;
};

/**
 * LCMOutput
 */
export type LcmOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Num Inference Steps
   *
   *
   * Number of inference steps used to generate the image. It will be the same value of the one passed in the
   * input or the default one in case none was passed.
   *
   */
  num_inference_steps?: number;
  /**
   * Nsfw Content Detected
   *
   *
   * A list of booleans indicating whether the generated image contains any
   * potentially unsafe content. If the safety check is disabled, this field
   * will all will be false.
   *
   */
  nsfw_content_detected: Array<boolean>;
};

/**
 * Image
 */
export type ImageType2 = {
  /**
   * Height
   */
  height: number;
  /**
   * Content Type
   */
  content_type?: string;
  /**
   * Url
   */
  url: string;
  /**
   * Width
   */
  width: number;
};

/**
 * LCMInput
 */
export type LcmInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Controlnet Inpaint
   *
   *
   * If set to true, the inpainting pipeline will use controlnet inpainting.
   * Only effective for inpainting pipelines.
   *
   */
  controlnet_inpaint?: boolean;
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   * If not provided:
   * - For text-to-image generations, the default size is 512x512.
   * - For image-to-image generations, the default size is the same as the input image.
   * - For inpainting generations, the default size is the same as the input image.
   *
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Safety Checks
   *
   *
   * If set to true, the resulting image will be checked whether it includes any
   * potentially unsafe content. If it does, it will be replaced with a black
   * image.
   *
   */
  enable_safety_checks?: boolean;
  /**
   * Model
   *
   * The model to use for generating the image.
   */
  model?: "sdxl" | "sdv1-5";
  /**
   * Lora Url
   *
   *
   * The url of the lora server to use for image generation.
   *
   */
  lora_url?: string;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Inpaint Mask Only
   *
   *
   * If set to true, the inpainting pipeline will only inpaint the provided mask
   * area. Only effective for inpainting pipelines.
   *
   */
  inpaint_mask_only?: boolean;
  /**
   * Num Images
   *
   *
   * The number of images to generate. The function will return a list of images
   * with the same prompt and negative prompt but different seeds.
   *
   */
  num_images?: number;
  /**
   * Lora Scale
   *
   *
   * The scale of the lora server to use for image generation.
   *
   */
  lora_scale?: number;
  /**
   * Image Url
   *
   *
   * The base image to use for guiding the image generation on image-to-image
   * generations. If the either width or height of the image is larger than 1024
   * pixels, the image will be resized to 1024 pixels while keeping the aspect ratio.
   *
   */
  image_url?: string;
  /**
   * Strength
   *
   *
   * The strength of the image that is passed as `image_url`. The strength
   * determines how much the generated image will be similar to the image passed as
   * `image_url`. The higher the strength the more model gets "creative" and
   * generates an image that's different from the initial image. A strength of 1.0
   * means that the initial image is more or less ignored and the model will try to
   * generate an image that's as close as possible to the prompt.
   *
   */
  strength?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   *
   * The mask to use for guiding the image generation on image
   * inpainting. The model will focus on the mask area and try to fill it with
   * the most relevant content.
   *
   * The mask must be a black and white image where the white area is the area
   * that needs to be filled and the black area is the area that should be
   * ignored.
   *
   * The mask must have the same dimensions as the image passed as `image_url`.
   *
   */
  mask_url?: string;
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number;
};

/**
 * FooocusOutput
 */
export type FooocusInpaintOutput = {
  /**
   * Images
   *
   * The generated image file info.
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * The time taken for the generation process.
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
};

/**
 * FooocusInpaintInput
 */
export type FooocusInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * Performance
   *
   *
   * You can choose Speed or Quality
   *
   */
  performance?: "Speed" | "Quality" | "Extreme Speed" | "Lightning";
  /**
   * Styles
   *
   *
   * The style to use.
   *
   */
  styles?: Array<
    | "Fooocus V2"
    | "Fooocus Enhance"
    | "Fooocus Sharp"
    | "Fooocus Semi Realistic"
    | "Fooocus Masterpiece"
    | "Fooocus Photograph"
    | "Fooocus Negative"
    | "Fooocus Cinematic"
    | "SAI 3D Model"
    | "SAI Analog Film"
    | "SAI Anime"
    | "SAI Cinematic"
    | "SAI Comic Book"
    | "SAI Craft Clay"
    | "SAI Digital Art"
    | "SAI Enhance"
    | "SAI Fantasy Art"
    | "SAI Isometric"
    | "SAI Line Art"
    | "SAI Lowpoly"
    | "SAI Neonpunk"
    | "SAI Origami"
    | "SAI Photographic"
    | "SAI Pixel Art"
    | "SAI Texture"
    | "MRE Cinematic Dynamic"
    | "MRE Spontaneous Picture"
    | "MRE Artistic Vision"
    | "MRE Dark Dream"
    | "MRE Gloomy Art"
    | "MRE Bad Dream"
    | "MRE Underground"
    | "MRE Surreal Painting"
    | "MRE Dynamic Illustration"
    | "MRE Undead Art"
    | "MRE Elemental Art"
    | "MRE Space Art"
    | "MRE Ancient Illustration"
    | "MRE Brave Art"
    | "MRE Heroic Fantasy"
    | "MRE Dark Cyberpunk"
    | "MRE Lyrical Geometry"
    | "MRE Sumi E Symbolic"
    | "MRE Sumi E Detailed"
    | "MRE Manga"
    | "MRE Anime"
    | "MRE Comic"
    | "Ads Advertising"
    | "Ads Automotive"
    | "Ads Corporate"
    | "Ads Fashion Editorial"
    | "Ads Food Photography"
    | "Ads Gourmet Food Photography"
    | "Ads Luxury"
    | "Ads Real Estate"
    | "Ads Retail"
    | "Artstyle Abstract"
    | "Artstyle Abstract Expressionism"
    | "Artstyle Art Deco"
    | "Artstyle Art Nouveau"
    | "Artstyle Constructivist"
    | "Artstyle Cubist"
    | "Artstyle Expressionist"
    | "Artstyle Graffiti"
    | "Artstyle Hyperrealism"
    | "Artstyle Impressionist"
    | "Artstyle Pointillism"
    | "Artstyle Pop Art"
    | "Artstyle Psychedelic"
    | "Artstyle Renaissance"
    | "Artstyle Steampunk"
    | "Artstyle Surrealist"
    | "Artstyle Typography"
    | "Artstyle Watercolor"
    | "Futuristic Biomechanical"
    | "Futuristic Biomechanical Cyberpunk"
    | "Futuristic Cybernetic"
    | "Futuristic Cybernetic Robot"
    | "Futuristic Cyberpunk Cityscape"
    | "Futuristic Futuristic"
    | "Futuristic Retro Cyberpunk"
    | "Futuristic Retro Futurism"
    | "Futuristic Sci Fi"
    | "Futuristic Vaporwave"
    | "Game Bubble Bobble"
    | "Game Cyberpunk Game"
    | "Game Fighting Game"
    | "Game Gta"
    | "Game Mario"
    | "Game Minecraft"
    | "Game Pokemon"
    | "Game Retro Arcade"
    | "Game Retro Game"
    | "Game Rpg Fantasy Game"
    | "Game Strategy Game"
    | "Game Streetfighter"
    | "Game Zelda"
    | "Misc Architectural"
    | "Misc Disco"
    | "Misc Dreamscape"
    | "Misc Dystopian"
    | "Misc Fairy Tale"
    | "Misc Gothic"
    | "Misc Grunge"
    | "Misc Horror"
    | "Misc Kawaii"
    | "Misc Lovecraftian"
    | "Misc Macabre"
    | "Misc Manga"
    | "Misc Metropolis"
    | "Misc Minimalist"
    | "Misc Monochrome"
    | "Misc Nautical"
    | "Misc Space"
    | "Misc Stained Glass"
    | "Misc Techwear Fashion"
    | "Misc Tribal"
    | "Misc Zentangle"
    | "Papercraft Collage"
    | "Papercraft Flat Papercut"
    | "Papercraft Kirigami"
    | "Papercraft Paper Mache"
    | "Papercraft Paper Quilling"
    | "Papercraft Papercut Collage"
    | "Papercraft Papercut Shadow Box"
    | "Papercraft Stacked Papercut"
    | "Papercraft Thick Layered Papercut"
    | "Photo Alien"
    | "Photo Film Noir"
    | "Photo Glamour"
    | "Photo Hdr"
    | "Photo Iphone Photographic"
    | "Photo Long Exposure"
    | "Photo Neon Noir"
    | "Photo Silhouette"
    | "Photo Tilt Shift"
    | "Cinematic Diva"
    | "Abstract Expressionism"
    | "Academia"
    | "Action Figure"
    | "Adorable 3D Character"
    | "Adorable Kawaii"
    | "Art Deco"
    | "Art Nouveau"
    | "Astral Aura"
    | "Avant Garde"
    | "Baroque"
    | "Bauhaus Style Poster"
    | "Blueprint Schematic Drawing"
    | "Caricature"
    | "Cel Shaded Art"
    | "Character Design Sheet"
    | "Classicism Art"
    | "Color Field Painting"
    | "Colored Pencil Art"
    | "Conceptual Art"
    | "Constructivism"
    | "Cubism"
    | "Dadaism"
    | "Dark Fantasy"
    | "Dark Moody Atmosphere"
    | "Dmt Art Style"
    | "Doodle Art"
    | "Double Exposure"
    | "Dripping Paint Splatter Art"
    | "Expressionism"
    | "Faded Polaroid Photo"
    | "Fauvism"
    | "Flat 2d Art"
    | "Fortnite Art Style"
    | "Futurism"
    | "Glitchcore"
    | "Glo Fi"
    | "Googie Art Style"
    | "Graffiti Art"
    | "Harlem Renaissance Art"
    | "High Fashion"
    | "Idyllic"
    | "Impressionism"
    | "Infographic Drawing"
    | "Ink Dripping Drawing"
    | "Japanese Ink Drawing"
    | "Knolling Photography"
    | "Light Cheery Atmosphere"
    | "Logo Design"
    | "Luxurious Elegance"
    | "Macro Photography"
    | "Mandola Art"
    | "Marker Drawing"
    | "Medievalism"
    | "Minimalism"
    | "Neo Baroque"
    | "Neo Byzantine"
    | "Neo Futurism"
    | "Neo Impressionism"
    | "Neo Rococo"
    | "Neoclassicism"
    | "Op Art"
    | "Ornate And Intricate"
    | "Pencil Sketch Drawing"
    | "Pop Art 2"
    | "Rococo"
    | "Silhouette Art"
    | "Simple Vector Art"
    | "Sketchup"
    | "Steampunk 2"
    | "Surrealism"
    | "Suprematism"
    | "Terragen"
    | "Tranquil Relaxing Atmosphere"
    | "Sticker Designs"
    | "Vibrant Rim Light"
    | "Volumetric Lighting"
    | "Watercolor 2"
    | "Whimsical And Playful"
    | "Mk Chromolithography"
    | "Mk Cross Processing Print"
    | "Mk Dufaycolor Photograph"
    | "Mk Herbarium"
    | "Mk Punk Collage"
    | "Mk Mosaic"
    | "Mk Van Gogh"
    | "Mk Coloring Book"
    | "Mk Singer Sargent"
    | "Mk Pollock"
    | "Mk Basquiat"
    | "Mk Andy Warhol"
    | "Mk Halftone Print"
    | "Mk Gond Painting"
    | "Mk Albumen Print"
    | "Mk Aquatint Print"
    | "Mk Anthotype Print"
    | "Mk Inuit Carving"
    | "Mk Bromoil Print"
    | "Mk Calotype Print"
    | "Mk Color Sketchnote"
    | "Mk Cibulak Porcelain"
    | "Mk Alcohol Ink Art"
    | "Mk One Line Art"
    | "Mk Blacklight Paint"
    | "Mk Carnival Glass"
    | "Mk Cyanotype Print"
    | "Mk Cross Stitching"
    | "Mk Encaustic Paint"
    | "Mk Embroidery"
    | "Mk Gyotaku"
    | "Mk Luminogram"
    | "Mk Lite Brite Art"
    | "Mk Mokume Gane"
    | "Pebble Art"
    | "Mk Palekh"
    | "Mk Suminagashi"
    | "Mk Scrimshaw"
    | "Mk Shibori"
    | "Mk Vitreous Enamel"
    | "Mk Ukiyo E"
    | "Mk Vintage Airline Poster"
    | "Mk Vintage Travel Poster"
    | "Mk Bauhaus Style"
    | "Mk Afrofuturism"
    | "Mk Atompunk"
    | "Mk Constructivism"
    | "Mk Chicano Art"
    | "Mk De Stijl"
    | "Mk Dayak Art"
    | "Mk Fayum Portrait"
    | "Mk Illuminated Manuscript"
    | "Mk Kalighat Painting"
    | "Mk Madhubani Painting"
    | "Mk Pictorialism"
    | "Mk Pichwai Painting"
    | "Mk Patachitra Painting"
    | "Mk Samoan Art Inspired"
    | "Mk Tlingit Art"
    | "Mk Adnate Style"
    | "Mk Ron English Style"
    | "Mk Shepard Fairey Style"
  >;
  image_prompt_3?: ImagePrompt;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 5 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  image_prompt_4?: ImagePrompt;
  /**
   * Guidance Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Sharpness
   *
   *
   * The sharpness of the generated image. Use it to control how sharp the generated
   * image should be. Higher value means image and texture are sharper.
   *
   */
  sharpness?: number;
  /**
   * Mixing Image Prompt and Inpaint
   *
   * Mixing Image Prompt and Inpaint
   */
  mixing_image_prompt_and_inpaint?: boolean;
  /**
   * Outpaint Direction
   *
   * The directions to outpaint.
   */
  outpaint_selections?: Array<"Left" | "Right" | "Top" | "Bottom">;
  /**
   * Inpaint Image Url
   *
   * The image to use as a reference for inpainting.
   */
  inpaint_image_url: string;
  /**
   * Refiner Model
   *
   * Refiner (SDXL or SD 1.5)
   */
  refiner_model?: "None" | "realisticVisionV60B1_v51VAE.safetensors";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  image_prompt_2?: ImagePrompt;
  /**
   * Inpaint Respective Field
   *
   *
   * The area to inpaint. Value 0 is same as "Only Masked" in A1111. Value 1 is
   * same as "Whole Image" in A1111. Only used in inpaint, not used in outpaint.
   * (Outpaint always use 1.0)
   *
   */
  inpaint_respective_field?: number;
  /**
   * Inpaint Mode
   *
   * The mode to use for inpainting.
   */
  inpaint_mode?:
    | "Inpaint or Outpaint (default)"
    | "Improve Detail (face, hand, eyes, etc.)"
    | "Modify Content (add objects, change background, etc.)";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | null;
  /**
   * Refiner Switch At
   *
   *
   * Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models
   * 0.8 for XL-refiners; or any value for switching two SDXL models.
   *
   */
  refiner_switch?: number;
  /**
   * Disable Initial Latent In Inpaint
   *
   * If set to true, the initial preprocessing will be disabled.
   */
  inpaint_disable_initial_latent?: boolean;
  /**
   * Mask Image Url
   *
   * The image to use as a mask for the generated image.
   */
  mask_image_url?: string;
  /**
   * Invert Mask
   *
   * If set to true, the mask will be inverted.
   */
  invert_mask?: boolean;
  image_prompt_1?: ImagePrompt;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   *
   * Number of images to generate in one request
   *
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   */
  aspect_ratio?: string;
  /**
   * Inpaint Additional Prompt
   *
   * Describe what you want to inpaint.
   */
  inpaint_additional_prompt?: string;
  /**
   * Inpaint Denoising Strength
   *
   *
   * Same as the denoising strength in A1111 inpaint. Only used in inpaint, not
   * used in outpaint. (Outpaint always use 1.0)
   *
   */
  inpaint_strength?: number;
  /**
   * Override Inpaint Options
   *
   *
   * If set to true, the advanced inpaint options ('inpaint_disable_initial_latent',
   * 'inpaint_engine', 'inpaint_strength', 'inpaint_respective_field',
   * 'inpaint_erode_or_dilate') will be overridden.
   * Otherwise, the default values will be used.
   *
   */
  override_inpaint_options?: boolean;
  /**
   * Inpaint Engine
   *
   * Version of Fooocus inpaint model
   */
  inpaint_engine?: "None" | "v1" | "v2.5" | "v2.6";
  /**
   * Mask Erode or Dilate
   *
   *
   * Positive value will make white area in the mask larger, negative value will
   * make white area smaller. (default is 0, always process before any mask
   * invert)
   *
   */
  inpaint_erode_or_dilate?: number;
};

/**
 * ImagePrompt
 */
export type ImagePrompt = {
  /**
   * Weight
   */
  weight?: number;
  /**
   * Stop At
   */
  stop_at?: number;
  /**
   * Type
   */
  type?: "ImagePrompt" | "PyraCanny" | "CPDS" | "FaceSwap";
  /**
   * Image Url
   */
  image_url?: string;
};

/**
 * FooocusOutput
 */
export type FooocusImagePromptOutput = {
  /**
   * Images
   *
   * The generated image file info.
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * The time taken for the generation process.
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
};

/**
 * FooocusImagePromptInput
 */
export type FooocusImagePromptInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * UOV Image URL
   *
   * The image to upscale or vary.
   */
  uov_image_url?: string;
  /**
   * Performance
   *
   *
   * You can choose Speed or Quality
   *
   */
  performance?: "Speed" | "Quality" | "Extreme Speed" | "Lightning";
  image_prompt_3?: ImagePrompt;
  /**
   * Styles
   *
   *
   * The style to use.
   *
   */
  styles?: Array<
    | "Fooocus V2"
    | "Fooocus Enhance"
    | "Fooocus Sharp"
    | "Fooocus Semi Realistic"
    | "Fooocus Masterpiece"
    | "Fooocus Photograph"
    | "Fooocus Negative"
    | "Fooocus Cinematic"
    | "SAI 3D Model"
    | "SAI Analog Film"
    | "SAI Anime"
    | "SAI Cinematic"
    | "SAI Comic Book"
    | "SAI Craft Clay"
    | "SAI Digital Art"
    | "SAI Enhance"
    | "SAI Fantasy Art"
    | "SAI Isometric"
    | "SAI Line Art"
    | "SAI Lowpoly"
    | "SAI Neonpunk"
    | "SAI Origami"
    | "SAI Photographic"
    | "SAI Pixel Art"
    | "SAI Texture"
    | "MRE Cinematic Dynamic"
    | "MRE Spontaneous Picture"
    | "MRE Artistic Vision"
    | "MRE Dark Dream"
    | "MRE Gloomy Art"
    | "MRE Bad Dream"
    | "MRE Underground"
    | "MRE Surreal Painting"
    | "MRE Dynamic Illustration"
    | "MRE Undead Art"
    | "MRE Elemental Art"
    | "MRE Space Art"
    | "MRE Ancient Illustration"
    | "MRE Brave Art"
    | "MRE Heroic Fantasy"
    | "MRE Dark Cyberpunk"
    | "MRE Lyrical Geometry"
    | "MRE Sumi E Symbolic"
    | "MRE Sumi E Detailed"
    | "MRE Manga"
    | "MRE Anime"
    | "MRE Comic"
    | "Ads Advertising"
    | "Ads Automotive"
    | "Ads Corporate"
    | "Ads Fashion Editorial"
    | "Ads Food Photography"
    | "Ads Gourmet Food Photography"
    | "Ads Luxury"
    | "Ads Real Estate"
    | "Ads Retail"
    | "Artstyle Abstract"
    | "Artstyle Abstract Expressionism"
    | "Artstyle Art Deco"
    | "Artstyle Art Nouveau"
    | "Artstyle Constructivist"
    | "Artstyle Cubist"
    | "Artstyle Expressionist"
    | "Artstyle Graffiti"
    | "Artstyle Hyperrealism"
    | "Artstyle Impressionist"
    | "Artstyle Pointillism"
    | "Artstyle Pop Art"
    | "Artstyle Psychedelic"
    | "Artstyle Renaissance"
    | "Artstyle Steampunk"
    | "Artstyle Surrealist"
    | "Artstyle Typography"
    | "Artstyle Watercolor"
    | "Futuristic Biomechanical"
    | "Futuristic Biomechanical Cyberpunk"
    | "Futuristic Cybernetic"
    | "Futuristic Cybernetic Robot"
    | "Futuristic Cyberpunk Cityscape"
    | "Futuristic Futuristic"
    | "Futuristic Retro Cyberpunk"
    | "Futuristic Retro Futurism"
    | "Futuristic Sci Fi"
    | "Futuristic Vaporwave"
    | "Game Bubble Bobble"
    | "Game Cyberpunk Game"
    | "Game Fighting Game"
    | "Game Gta"
    | "Game Mario"
    | "Game Minecraft"
    | "Game Pokemon"
    | "Game Retro Arcade"
    | "Game Retro Game"
    | "Game Rpg Fantasy Game"
    | "Game Strategy Game"
    | "Game Streetfighter"
    | "Game Zelda"
    | "Misc Architectural"
    | "Misc Disco"
    | "Misc Dreamscape"
    | "Misc Dystopian"
    | "Misc Fairy Tale"
    | "Misc Gothic"
    | "Misc Grunge"
    | "Misc Horror"
    | "Misc Kawaii"
    | "Misc Lovecraftian"
    | "Misc Macabre"
    | "Misc Manga"
    | "Misc Metropolis"
    | "Misc Minimalist"
    | "Misc Monochrome"
    | "Misc Nautical"
    | "Misc Space"
    | "Misc Stained Glass"
    | "Misc Techwear Fashion"
    | "Misc Tribal"
    | "Misc Zentangle"
    | "Papercraft Collage"
    | "Papercraft Flat Papercut"
    | "Papercraft Kirigami"
    | "Papercraft Paper Mache"
    | "Papercraft Paper Quilling"
    | "Papercraft Papercut Collage"
    | "Papercraft Papercut Shadow Box"
    | "Papercraft Stacked Papercut"
    | "Papercraft Thick Layered Papercut"
    | "Photo Alien"
    | "Photo Film Noir"
    | "Photo Glamour"
    | "Photo Hdr"
    | "Photo Iphone Photographic"
    | "Photo Long Exposure"
    | "Photo Neon Noir"
    | "Photo Silhouette"
    | "Photo Tilt Shift"
    | "Cinematic Diva"
    | "Abstract Expressionism"
    | "Academia"
    | "Action Figure"
    | "Adorable 3D Character"
    | "Adorable Kawaii"
    | "Art Deco"
    | "Art Nouveau"
    | "Astral Aura"
    | "Avant Garde"
    | "Baroque"
    | "Bauhaus Style Poster"
    | "Blueprint Schematic Drawing"
    | "Caricature"
    | "Cel Shaded Art"
    | "Character Design Sheet"
    | "Classicism Art"
    | "Color Field Painting"
    | "Colored Pencil Art"
    | "Conceptual Art"
    | "Constructivism"
    | "Cubism"
    | "Dadaism"
    | "Dark Fantasy"
    | "Dark Moody Atmosphere"
    | "Dmt Art Style"
    | "Doodle Art"
    | "Double Exposure"
    | "Dripping Paint Splatter Art"
    | "Expressionism"
    | "Faded Polaroid Photo"
    | "Fauvism"
    | "Flat 2d Art"
    | "Fortnite Art Style"
    | "Futurism"
    | "Glitchcore"
    | "Glo Fi"
    | "Googie Art Style"
    | "Graffiti Art"
    | "Harlem Renaissance Art"
    | "High Fashion"
    | "Idyllic"
    | "Impressionism"
    | "Infographic Drawing"
    | "Ink Dripping Drawing"
    | "Japanese Ink Drawing"
    | "Knolling Photography"
    | "Light Cheery Atmosphere"
    | "Logo Design"
    | "Luxurious Elegance"
    | "Macro Photography"
    | "Mandola Art"
    | "Marker Drawing"
    | "Medievalism"
    | "Minimalism"
    | "Neo Baroque"
    | "Neo Byzantine"
    | "Neo Futurism"
    | "Neo Impressionism"
    | "Neo Rococo"
    | "Neoclassicism"
    | "Op Art"
    | "Ornate And Intricate"
    | "Pencil Sketch Drawing"
    | "Pop Art 2"
    | "Rococo"
    | "Silhouette Art"
    | "Simple Vector Art"
    | "Sketchup"
    | "Steampunk 2"
    | "Surrealism"
    | "Suprematism"
    | "Terragen"
    | "Tranquil Relaxing Atmosphere"
    | "Sticker Designs"
    | "Vibrant Rim Light"
    | "Volumetric Lighting"
    | "Watercolor 2"
    | "Whimsical And Playful"
    | "Mk Chromolithography"
    | "Mk Cross Processing Print"
    | "Mk Dufaycolor Photograph"
    | "Mk Herbarium"
    | "Mk Punk Collage"
    | "Mk Mosaic"
    | "Mk Van Gogh"
    | "Mk Coloring Book"
    | "Mk Singer Sargent"
    | "Mk Pollock"
    | "Mk Basquiat"
    | "Mk Andy Warhol"
    | "Mk Halftone Print"
    | "Mk Gond Painting"
    | "Mk Albumen Print"
    | "Mk Aquatint Print"
    | "Mk Anthotype Print"
    | "Mk Inuit Carving"
    | "Mk Bromoil Print"
    | "Mk Calotype Print"
    | "Mk Color Sketchnote"
    | "Mk Cibulak Porcelain"
    | "Mk Alcohol Ink Art"
    | "Mk One Line Art"
    | "Mk Blacklight Paint"
    | "Mk Carnival Glass"
    | "Mk Cyanotype Print"
    | "Mk Cross Stitching"
    | "Mk Encaustic Paint"
    | "Mk Embroidery"
    | "Mk Gyotaku"
    | "Mk Luminogram"
    | "Mk Lite Brite Art"
    | "Mk Mokume Gane"
    | "Pebble Art"
    | "Mk Palekh"
    | "Mk Suminagashi"
    | "Mk Scrimshaw"
    | "Mk Shibori"
    | "Mk Vitreous Enamel"
    | "Mk Ukiyo E"
    | "Mk Vintage Airline Poster"
    | "Mk Vintage Travel Poster"
    | "Mk Bauhaus Style"
    | "Mk Afrofuturism"
    | "Mk Atompunk"
    | "Mk Constructivism"
    | "Mk Chicano Art"
    | "Mk De Stijl"
    | "Mk Dayak Art"
    | "Mk Fayum Portrait"
    | "Mk Illuminated Manuscript"
    | "Mk Kalighat Painting"
    | "Mk Madhubani Painting"
    | "Mk Pictorialism"
    | "Mk Pichwai Painting"
    | "Mk Patachitra Painting"
    | "Mk Samoan Art Inspired"
    | "Mk Tlingit Art"
    | "Mk Adnate Style"
    | "Mk Ron English Style"
    | "Mk Shepard Fairey Style"
  >;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 5 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  image_prompt_4?: ImagePrompt;
  /**
   * Guidance Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Sharpness
   *
   *
   * The sharpness of the generated image. Use it to control how sharp the generated
   * image should be. Higher value means image and texture are sharper.
   *
   */
  sharpness?: number;
  /**
   * Mixing Image Prompt and Inpaint
   *
   * Mixing Image Prompt and Inpaint
   */
  mixing_image_prompt_and_inpaint?: boolean;
  /**
   * Outpaint Direction
   *
   * The directions to outpaint.
   */
  outpaint_selections?: Array<"Left" | "Right" | "Top" | "Bottom">;
  /**
   * Inpaint Image URL
   *
   * The image to use as a reference for inpainting.
   */
  inpaint_image_url?: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Refiner Model
   *
   * Refiner (SDXL or SD 1.5)
   */
  refiner_model?: "None" | "realisticVisionV60B1_v51VAE.safetensors";
  image_prompt_2?: ImagePrompt;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Inpaint Mode
   *
   * The mode to use for inpainting.
   */
  inpaint_mode?:
    | "Inpaint or Outpaint (default)"
    | "Improve Detail (face, hand, eyes, etc.)"
    | "Modify Content (add objects, change background, etc.)";
  /**
   * UOV Method
   *
   * The method to use for upscaling or varying.
   */
  uov_method?:
    | "Disabled"
    | "Vary (Subtle)"
    | "Vary (Strong)"
    | "Upscale (1.5x)"
    | "Upscale (2x)"
    | "Upscale (Fast 2x)";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | null;
  /**
   * Refiner Switch At
   *
   *
   * Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models
   * 0.8 for XL-refiners; or any value for switching two SDXL models.
   *
   */
  refiner_switch?: number;
  /**
   * Mixing Image Prompt and Vary/Upscale
   *
   * Mixing Image Prompt and Vary/Upscale
   */
  mixing_image_prompt_and_vary_upscale?: boolean;
  /**
   * Mask Image URL
   *
   * The image to use as a mask for the generated image.
   */
  mask_image_url?: string;
  /**
   * Image Prompt 1
   */
  image_prompt_1: ImagePrompt;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   *
   * Number of images to generate in one request
   *
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   */
  aspect_ratio?: string;
  /**
   * Inpaint Additional Prompt
   *
   * Describe what you want to inpaint.
   */
  inpaint_additional_prompt?: string;
};

/**
 * IllusionDiffusionOutput
 */
export type IllusionDiffusionOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * IllusionDiffusionInput
 */
export type IllusionDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the ControlNet.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string;
  /**
   * Scheduler
   *
   * Scheduler / sampler to use for the image denoising process.
   */
  scheduler?: "DPM++ Karras SDE" | "Euler";
  /**
   * Control Guidance Start
   */
  control_guidance_start?: number;
  /**
   * Guidance Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed?: number;
  /**
   * Control Guidance End
   */
  control_guidance_end?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FastFooocusSdxlOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageFooocusInput
 */
export type FastFooocusSdxlInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Enable Refiner
   *
   * If set to true, a smaller model will try to refine the output after it was processed.
   */
  enable_refiner?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastLcmDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageLCMInput
 */
export type FastLcmDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Model Name
   *
   * The name of the model to use.
   */
  model_name?:
    | "stabilityai/stable-diffusion-xl-base-1.0"
    | "runwayml/stable-diffusion-v1-5";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastSdxlControlnetCannyOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageControlNetInput
 */
export type FastSdxlControlnetCannyInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Deep Cache
   *
   *
   * If set to true, DeepCache will be enabled. TBD
   *
   */
  enable_deep_cache?: boolean;
};

/**
 * Output
 */
export type FastFooocusSdxlImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageFooocusInput
 */
export type FastFooocusSdxlImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Enable Refiner
   *
   * If set to true, a smaller model will try to refine the output after it was processed.
   */
  enable_refiner?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the prompt image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastLightningSdxlOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageLightningInput
 */
export type FastLightningSdxlInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: "1" | "2" | "4" | "8";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
};

/**
 * Output
 */
export type LayerDiffusionOutput = {
  /**
   * Image
   *
   * The URL of the generated image.
   */
  image: ImageType3;
  /**
   * Seed
   *
   * The seed used to generate the image.
   */
  seed: number;
};

/**
 * Image
 *
 * Represents an image file.
 */
export type ImageType3 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown;
};

/**
 * Input
 */
export type LayerDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * Guidance Scale
   *
   * The guidance scale for the model.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps for the model.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The prompt to use for generating the negative image. Be as descriptive as possible for best results.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type StableDiffusionV15Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageSD15Input
 */
export type StableDiffusionV15Input = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * LoraWeight
 */
export type LoraWeightType2 = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights. Or HF model name.
   */
  path: string;
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number;
  /**
   * Force
   *
   * If set to true, the embedding will be forced to be used.
   */
  force?: boolean;
};

/**
 * Output
 */
export type DreamshaperOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DreamshaperTextToImageInput
 */
export type DreamshaperInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want in the image.
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Model Name
   *
   * The Dreamshaper model to use.
   */
  model_name?:
    | "Lykon/dreamshaper-xl-1-0"
    | "Lykon/dreamshaper-xl-v2-turbo"
    | "Lykon/dreamshaper-8";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type RealisticVisionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * RealisticVisionTextToImageInput
 */
export type RealisticVisionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want in the image.
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Model Name
   *
   * The Realistic Vision model to use.
   */
  model_name?: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type PlaygroundV25Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImagePlaygroundv25Input
 */
export type PlaygroundV25Input = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type LightningModelsOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * LightningModelsTextToImageInput
 */
export type LightningModelsInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Scheduler
   *
   * Scheduler / sampler to use for the image denoising process.
   */
  scheduler?:
    | "DPM++ 2M"
    | "DPM++ 2M Karras"
    | "DPM++ 2M SDE"
    | "DPM++ 2M SDE Karras"
    | "DPM++ SDE"
    | "DPM++ SDE Karras"
    | "KDPM 2A"
    | "Euler"
    | "Euler (trailing timesteps)"
    | "Euler A"
    | "LCM"
    | "EDMDPMSolverMultistepScheduler"
    | "TCDScheduler";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want in the image.
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Model Name
   *
   * The Lightning model to use.
   */
  model_name?: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * T2IOutput
 */
export type LumaPhotonOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * TextToImageRequest
 */
export type LumaPhotonInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: "16:9" | "9:16" | "1:1" | "4:3" | "3:4" | "21:9" | "9:21";
};

/**
 * Output
 */
export type StableCascadeSoteDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SoteDiffusionInput
 */
export type StableCascadeSoteDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Decoder Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  second_stage_guidance_scale?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the image will be returned as base64 encoded string.
   *
   */
  sync_mode?: boolean;
  /**
   * First Stage Steps
   *
   * Number of steps to run the first stage for.
   */
  first_stage_steps?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Cascade
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Second Stage Steps
   *
   * Number of steps to run the second stage for.
   */
  second_stage_steps?: number;
};

/**
 * Output
 */
export type FastSdxlOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * TextToImageInput
 */
export type FastSdxlInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type StableCascadeOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * StableCascadeInput
 */
export type StableCascadeInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Decoder Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  second_stage_guidance_scale?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the image will be returned as base64 encoded string.
   *
   */
  sync_mode?: boolean;
  /**
   * First Stage Steps
   *
   * Number of steps to run the first stage for.
   */
  first_stage_steps?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Cascade
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Second Stage Steps
   *
   * Number of steps to run the second stage for.
   */
  second_stage_steps?: number;
};

/**
 * Output
 */
export type KolorsOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KolorsInput
 */
export type KolorsInput = {
  /**
   * Prompt
   *
   *
   * The prompt to use for generating the image. Be as descriptive as possible
   * for best results.
   *
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and
   * uploaded before returning the response. This will increase the latency of
   * the function but it allows you to get the image directly in the response
   * without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Scheduler
   *
   * The scheduler to use for the model.
   */
  scheduler?:
    | "EulerDiscreteScheduler"
    | "EulerAncestralDiscreteScheduler"
    | "DPMSolverMultistepScheduler"
    | "DPMSolverMultistepScheduler_SDE_karras"
    | "UniPCMultistepScheduler"
    | "DEISMultistepScheduler";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show
   * you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Seed
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small
   * details (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * Enable safety checker.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type SdxlControlnetUnionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageControlNetUnionInput
 */
export type SdxlControlnetUnionInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Depth Preprocess
   *
   * Whether to preprocess the depth image.
   */
  depth_preprocess?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Normal Image Url
   *
   * The URL of the control image.
   */
  normal_image_url?: string;
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Teed Image Url
   *
   * The URL of the control image.
   */
  teed_image_url?: string;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Canny Image Url
   *
   * The URL of the control image.
   */
  canny_image_url?: string;
  /**
   * Segmentation Preprocess
   *
   * Whether to preprocess the segmentation image.
   */
  segmentation_preprocess?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Segmentation Image Url
   *
   * The URL of the control image.
   */
  segmentation_image_url?: string;
  /**
   * Openpose Image Url
   *
   * The URL of the control image.
   */
  openpose_image_url?: string;
  /**
   * Canny Preprocess
   *
   * Whether to preprocess the canny image.
   */
  canny_preprocess?: boolean;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Depth Image Url
   *
   * The URL of the control image.
   */
  depth_image_url?: string;
  /**
   * Normal Preprocess
   *
   * Whether to preprocess the normal image.
   */
  normal_preprocess?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Teed Preprocess
   *
   * Whether to preprocess the teed image.
   */
  teed_preprocess?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Openpose Preprocess
   *
   * Whether to preprocess the openpose image.
   */
  openpose_preprocess?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxSubjectOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxSubjectInput
 */
export type FluxSubjectInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image of the subject
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * PixArtSigmaOutput
 */
export type PixartSigmaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * The timings of the different steps of the generation process.
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * PixArtSigmaInput
 */
export type PixartSigmaInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style
   *
   * The style to apply to the image.
   */
  style?:
    | "(No style)"
    | "Cinematic"
    | "Photographic"
    | "Anime"
    | "Manga"
    | "Digital Art"
    | "Pixel art"
    | "Fantasy art"
    | "Neonpunk"
    | "3D Model";
  /**
   * Scheduler
   *
   * The scheduler to use for the model.
   */
  scheduler?: "DPM-SOLVER" | "SA-SOLVER";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type SanaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type SanaInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style Name
   *
   * The style to generate the image in.
   */
  style_name?:
    | "(No style)"
    | "Cinematic"
    | "Photographic"
    | "Anime"
    | "Manga"
    | "Digital Art"
    | "Pixel art"
    | "Fantasy art"
    | "Neonpunk"
    | "3D Model";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * FooocusOutput
 */
export type FooocusUpscaleOrVaryOutput = {
  /**
   * Images
   *
   * The generated image file info.
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * The time taken for the generation process.
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
};

/**
 * FooocusUpscaleOrVaryInput
 */
export type FooocusUpscaleOrVaryInput = {
  /**
   * Styles
   *
   *
   * The style to use.
   *
   */
  styles?: Array<
    | "Fooocus V2"
    | "Fooocus Enhance"
    | "Fooocus Sharp"
    | "Fooocus Semi Realistic"
    | "Fooocus Masterpiece"
    | "Fooocus Photograph"
    | "Fooocus Negative"
    | "Fooocus Cinematic"
    | "SAI 3D Model"
    | "SAI Analog Film"
    | "SAI Anime"
    | "SAI Cinematic"
    | "SAI Comic Book"
    | "SAI Craft Clay"
    | "SAI Digital Art"
    | "SAI Enhance"
    | "SAI Fantasy Art"
    | "SAI Isometric"
    | "SAI Line Art"
    | "SAI Lowpoly"
    | "SAI Neonpunk"
    | "SAI Origami"
    | "SAI Photographic"
    | "SAI Pixel Art"
    | "SAI Texture"
    | "MRE Cinematic Dynamic"
    | "MRE Spontaneous Picture"
    | "MRE Artistic Vision"
    | "MRE Dark Dream"
    | "MRE Gloomy Art"
    | "MRE Bad Dream"
    | "MRE Underground"
    | "MRE Surreal Painting"
    | "MRE Dynamic Illustration"
    | "MRE Undead Art"
    | "MRE Elemental Art"
    | "MRE Space Art"
    | "MRE Ancient Illustration"
    | "MRE Brave Art"
    | "MRE Heroic Fantasy"
    | "MRE Dark Cyberpunk"
    | "MRE Lyrical Geometry"
    | "MRE Sumi E Symbolic"
    | "MRE Sumi E Detailed"
    | "MRE Manga"
    | "MRE Anime"
    | "MRE Comic"
    | "Ads Advertising"
    | "Ads Automotive"
    | "Ads Corporate"
    | "Ads Fashion Editorial"
    | "Ads Food Photography"
    | "Ads Gourmet Food Photography"
    | "Ads Luxury"
    | "Ads Real Estate"
    | "Ads Retail"
    | "Artstyle Abstract"
    | "Artstyle Abstract Expressionism"
    | "Artstyle Art Deco"
    | "Artstyle Art Nouveau"
    | "Artstyle Constructivist"
    | "Artstyle Cubist"
    | "Artstyle Expressionist"
    | "Artstyle Graffiti"
    | "Artstyle Hyperrealism"
    | "Artstyle Impressionist"
    | "Artstyle Pointillism"
    | "Artstyle Pop Art"
    | "Artstyle Psychedelic"
    | "Artstyle Renaissance"
    | "Artstyle Steampunk"
    | "Artstyle Surrealist"
    | "Artstyle Typography"
    | "Artstyle Watercolor"
    | "Futuristic Biomechanical"
    | "Futuristic Biomechanical Cyberpunk"
    | "Futuristic Cybernetic"
    | "Futuristic Cybernetic Robot"
    | "Futuristic Cyberpunk Cityscape"
    | "Futuristic Futuristic"
    | "Futuristic Retro Cyberpunk"
    | "Futuristic Retro Futurism"
    | "Futuristic Sci Fi"
    | "Futuristic Vaporwave"
    | "Game Bubble Bobble"
    | "Game Cyberpunk Game"
    | "Game Fighting Game"
    | "Game Gta"
    | "Game Mario"
    | "Game Minecraft"
    | "Game Pokemon"
    | "Game Retro Arcade"
    | "Game Retro Game"
    | "Game Rpg Fantasy Game"
    | "Game Strategy Game"
    | "Game Streetfighter"
    | "Game Zelda"
    | "Misc Architectural"
    | "Misc Disco"
    | "Misc Dreamscape"
    | "Misc Dystopian"
    | "Misc Fairy Tale"
    | "Misc Gothic"
    | "Misc Grunge"
    | "Misc Horror"
    | "Misc Kawaii"
    | "Misc Lovecraftian"
    | "Misc Macabre"
    | "Misc Manga"
    | "Misc Metropolis"
    | "Misc Minimalist"
    | "Misc Monochrome"
    | "Misc Nautical"
    | "Misc Space"
    | "Misc Stained Glass"
    | "Misc Techwear Fashion"
    | "Misc Tribal"
    | "Misc Zentangle"
    | "Papercraft Collage"
    | "Papercraft Flat Papercut"
    | "Papercraft Kirigami"
    | "Papercraft Paper Mache"
    | "Papercraft Paper Quilling"
    | "Papercraft Papercut Collage"
    | "Papercraft Papercut Shadow Box"
    | "Papercraft Stacked Papercut"
    | "Papercraft Thick Layered Papercut"
    | "Photo Alien"
    | "Photo Film Noir"
    | "Photo Glamour"
    | "Photo Hdr"
    | "Photo Iphone Photographic"
    | "Photo Long Exposure"
    | "Photo Neon Noir"
    | "Photo Silhouette"
    | "Photo Tilt Shift"
    | "Cinematic Diva"
    | "Abstract Expressionism"
    | "Academia"
    | "Action Figure"
    | "Adorable 3D Character"
    | "Adorable Kawaii"
    | "Art Deco"
    | "Art Nouveau"
    | "Astral Aura"
    | "Avant Garde"
    | "Baroque"
    | "Bauhaus Style Poster"
    | "Blueprint Schematic Drawing"
    | "Caricature"
    | "Cel Shaded Art"
    | "Character Design Sheet"
    | "Classicism Art"
    | "Color Field Painting"
    | "Colored Pencil Art"
    | "Conceptual Art"
    | "Constructivism"
    | "Cubism"
    | "Dadaism"
    | "Dark Fantasy"
    | "Dark Moody Atmosphere"
    | "Dmt Art Style"
    | "Doodle Art"
    | "Double Exposure"
    | "Dripping Paint Splatter Art"
    | "Expressionism"
    | "Faded Polaroid Photo"
    | "Fauvism"
    | "Flat 2d Art"
    | "Fortnite Art Style"
    | "Futurism"
    | "Glitchcore"
    | "Glo Fi"
    | "Googie Art Style"
    | "Graffiti Art"
    | "Harlem Renaissance Art"
    | "High Fashion"
    | "Idyllic"
    | "Impressionism"
    | "Infographic Drawing"
    | "Ink Dripping Drawing"
    | "Japanese Ink Drawing"
    | "Knolling Photography"
    | "Light Cheery Atmosphere"
    | "Logo Design"
    | "Luxurious Elegance"
    | "Macro Photography"
    | "Mandola Art"
    | "Marker Drawing"
    | "Medievalism"
    | "Minimalism"
    | "Neo Baroque"
    | "Neo Byzantine"
    | "Neo Futurism"
    | "Neo Impressionism"
    | "Neo Rococo"
    | "Neoclassicism"
    | "Op Art"
    | "Ornate And Intricate"
    | "Pencil Sketch Drawing"
    | "Pop Art 2"
    | "Rococo"
    | "Silhouette Art"
    | "Simple Vector Art"
    | "Sketchup"
    | "Steampunk 2"
    | "Surrealism"
    | "Suprematism"
    | "Terragen"
    | "Tranquil Relaxing Atmosphere"
    | "Sticker Designs"
    | "Vibrant Rim Light"
    | "Volumetric Lighting"
    | "Watercolor 2"
    | "Whimsical And Playful"
    | "Mk Chromolithography"
    | "Mk Cross Processing Print"
    | "Mk Dufaycolor Photograph"
    | "Mk Herbarium"
    | "Mk Punk Collage"
    | "Mk Mosaic"
    | "Mk Van Gogh"
    | "Mk Coloring Book"
    | "Mk Singer Sargent"
    | "Mk Pollock"
    | "Mk Basquiat"
    | "Mk Andy Warhol"
    | "Mk Halftone Print"
    | "Mk Gond Painting"
    | "Mk Albumen Print"
    | "Mk Aquatint Print"
    | "Mk Anthotype Print"
    | "Mk Inuit Carving"
    | "Mk Bromoil Print"
    | "Mk Calotype Print"
    | "Mk Color Sketchnote"
    | "Mk Cibulak Porcelain"
    | "Mk Alcohol Ink Art"
    | "Mk One Line Art"
    | "Mk Blacklight Paint"
    | "Mk Carnival Glass"
    | "Mk Cyanotype Print"
    | "Mk Cross Stitching"
    | "Mk Encaustic Paint"
    | "Mk Embroidery"
    | "Mk Gyotaku"
    | "Mk Luminogram"
    | "Mk Lite Brite Art"
    | "Mk Mokume Gane"
    | "Pebble Art"
    | "Mk Palekh"
    | "Mk Suminagashi"
    | "Mk Scrimshaw"
    | "Mk Shibori"
    | "Mk Vitreous Enamel"
    | "Mk Ukiyo E"
    | "Mk Vintage Airline Poster"
    | "Mk Vintage Travel Poster"
    | "Mk Bauhaus Style"
    | "Mk Afrofuturism"
    | "Mk Atompunk"
    | "Mk Constructivism"
    | "Mk Chicano Art"
    | "Mk De Stijl"
    | "Mk Dayak Art"
    | "Mk Fayum Portrait"
    | "Mk Illuminated Manuscript"
    | "Mk Kalighat Painting"
    | "Mk Madhubani Painting"
    | "Mk Pictorialism"
    | "Mk Pichwai Painting"
    | "Mk Patachitra Painting"
    | "Mk Samoan Art Inspired"
    | "Mk Tlingit Art"
    | "Mk Adnate Style"
    | "Mk Ron English Style"
    | "Mk Shepard Fairey Style"
  >;
  /**
   * UOV Image URL
   *
   * The image to upscale or vary.
   */
  uov_image_url: string;
  /**
   * Performance
   *
   *
   * You can choose Speed or Quality
   *
   */
  performance?: "Speed" | "Quality" | "Extreme Speed" | "Lightning";
  /**
   * Mixing Image Prompt and Vary/Upscale
   *
   * Mixing Image Prompt and Vary/Upscale
   */
  mixing_image_prompt_and_vary_upscale?: boolean;
  image_prompt_3?: ImagePrompt;
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 5 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  image_prompt_4?: ImagePrompt;
  image_prompt_1?: ImagePrompt;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Sharpness
   *
   *
   * The sharpness of the generated image. Use it to control how sharp the generated
   * image should be. Higher value means image and texture are sharper.
   *
   */
  sharpness?: number;
  /**
   * Guidance Scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Aspect Ratio
   *
   *
   * The size of the generated image. You can choose between some presets or
   * custom height and width that **must be multiples of 8**.
   *
   */
  aspect_ratio?: string;
  /**
   * Num Images
   *
   *
   * Number of images to generate in one request
   *
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Refiner Model
   *
   * Refiner (SDXL or SD 1.5)
   */
  refiner_model?: "None" | "realisticVisionV60B1_v51VAE.safetensors";
  image_prompt_2?: ImagePrompt;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * UOV Method
   *
   * The method to use for upscaling or varying.
   */
  uov_method?:
    | "Disabled"
    | "Vary (Subtle)"
    | "Vary (Strong)"
    | "Upscale (1.5x)"
    | "Upscale (2x)"
    | "Upscale (Fast 2x)";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | null;
  /**
   * Refiner Switch At
   *
   *
   * Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models
   * 0.8 for XL-refiners; or any value for switching two SDXL models.
   *
   */
  refiner_switch?: number;
};

/**
 * SD3Output
 */
export type StableDiffusionV3MediumOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Number of Images
   *
   * The number of images generated.
   */
  num_images: number;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type StableDiffusionV3MediumInput = {
  /**
   * Enhance Prompt
   *
   * If set to true, prompt will be upsampled with more details.
   */
  prompt_expansion?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FluxLoraInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintInput
 */
export type FluxLoraInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type StableDiffusionV35MediumOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type StableDiffusionV35MediumInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FluxSchnellOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SchnellTextToImageInput
 */
export type FluxSchnellInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type OmnigenV1Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type OmnigenV1Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Image Guidance scale
   *
   *
   * The Image Guidance scale is a measure of how close you want
   * the model to stick to your input image when looking for a related image to show you.
   *
   */
  img_guidance_scale?: number;
  /**
   * Input Image Urls
   *
   * URL of images to use while generating the image, Use <img><|image_1|></img> for the first image and so on.
   */
  input_image_urls?: Array<string>;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type AuraFlowOutput = {
  /**
   * Prompt
   *
   * The expanded prompt
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The seed used to generate the images
   */
  seed: number;
};

/**
 * Input
 */
export type AuraFlowInput = {
  /**
   * Prompt
   *
   * The prompt to generate images from
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate
   */
  num_images?: number;
  /**
   * Expand Prompt
   *
   * Whether to perform prompt expansion (recommended)
   */
  expand_prompt?: boolean;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Classifier free guidance scale
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to take
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for generating images
   */
  seed?: number;
};

/**
 * T2IOutput
 */
export type LumaPhotonFlashOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * TextToImageRequest
 */
export type LumaPhotonFlashInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated video
   */
  aspect_ratio?: "16:9" | "9:16" | "1:1" | "4:3" | "3:4" | "21:9" | "9:21";
};

/**
 * Output
 */
export type IdeogramV2TurboOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * File
 */
export type FileType2 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
};

/**
 * TextToImageInput
 */
export type IdeogramV2TurboInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Negative Prompt
   *
   * A negative prompt to avoid in the generated image
   */
  negative_prompt?: string;
};

/**
 * Recraft20BTextToImageOutput
 */
export type Recraft20bOutput = {
  /**
   * Images
   */
  images: Array<File>;
};

/**
 * Recraft20BTextToImageInput
 */
export type Recraft20bInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Colors
   *
   * An array of preferable colors
   */
  colors?: Array<RgbColor>;
  /**
   * Style
   *
   * The style of the generated images. Vector images cost 2X as much.
   */
  style?:
    | "any"
    | "realistic_image"
    | "digital_illustration"
    | "vector_illustration"
    | "realistic_image/b_and_w"
    | "realistic_image/enterprise"
    | "realistic_image/hard_flash"
    | "realistic_image/hdr"
    | "realistic_image/motion_blur"
    | "realistic_image/natural_light"
    | "realistic_image/studio_portrait"
    | "digital_illustration/2d_art_poster"
    | "digital_illustration/2d_art_poster_2"
    | "digital_illustration/3d"
    | "digital_illustration/80s"
    | "digital_illustration/engraving_color"
    | "digital_illustration/glow"
    | "digital_illustration/grain"
    | "digital_illustration/hand_drawn"
    | "digital_illustration/hand_drawn_outline"
    | "digital_illustration/handmade_3d"
    | "digital_illustration/infantile_sketch"
    | "digital_illustration/kawaii"
    | "digital_illustration/pixel_art"
    | "digital_illustration/psychedelic"
    | "digital_illustration/seamless"
    | "digital_illustration/voxel"
    | "digital_illustration/watercolor"
    | "vector_illustration/cartoon"
    | "vector_illustration/doodle_line_art"
    | "vector_illustration/engraving"
    | "vector_illustration/flat_2"
    | "vector_illustration/kawaii"
    | "vector_illustration/line_art"
    | "vector_illustration/line_circuit"
    | "vector_illustration/linocut"
    | "vector_illustration/seamless";
  /**
   * Style Id
   *
   * The ID of the custom style reference (optional)
   */
  style_id?: string;
};

/**
 * RGBColor
 */
export type RgbColor = {
  /**
   * R
   *
   * Red color value
   */
  r?: number;
  /**
   * B
   *
   * Blue color value
   */
  b?: number;
  /**
   * G
   *
   * Green color value
   */
  g?: number;
};

/**
 * Output
 */
export type BriaTextToImageHdOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * TextToImageRequest
 */
export type BriaTextToImageHdInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string;
  /**
   * Num Images
   *
   * How many images you would like to generate. When using any Guidance Method, Value is set to 1.
   */
  num_images?: number;
  /**
   * Prompt Enhancement
   *
   * When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.
   */
  prompt_enhancement?: boolean;
  /**
   * Guidance
   *
   * Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.
   */
  guidance?: Array<GuidanceInput>;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Medium
   *
   * Which medium should be included in your generated images. This parameter is optional.
   */
  medium?: "photography" | "art";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of iterations the model goes through to refine the generated image. This parameter is optional.
   */
  num_inference_steps?: number;
};

/**
 * GuidanceInput
 */
export type GuidanceInput = {
  /**
   * Scale
   *
   * Impact of the guidance.
   */
  scale?: number;
  /**
   * Method
   *
   * Which guidance type you would like to include in the generation. Up to 4 guidance methods can be combined during a single inference. This parameter is optional.
   */
  method?:
    | "controlnet_canny"
    | "controlnet_depth"
    | "controlnet_recoloring"
    | "controlnet_color_grid";
  /**
   * Image Url
   *
   * The image that should be used as guidance, in base64 format, with the method defined in guidance_method_1. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB. If more then one guidance method is used, all guidance images must be of the same aspect ratio, and this will be the aspect ratio of the generated results. If guidance_method_1 is selected, an image must be provided.
   */
  image_url: string;
};

/**
 * Output
 */
export type BriaTextToImageFastOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * FastTextToImageRequest
 */
export type BriaTextToImageFastInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string;
  /**
   * Num Images
   *
   * How many images you would like to generate. When using any Guidance Method, Value is set to 1.
   */
  num_images?: number;
  /**
   * Prompt Enhancement
   *
   * When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.
   */
  prompt_enhancement?: boolean;
  /**
   * Guidance
   *
   * Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.
   */
  guidance?: Array<GuidanceInput>;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Medium
   *
   * Which medium should be included in your generated images. This parameter is optional.
   */
  medium?: "photography" | "art";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of iterations the model goes through to refine the generated image. This parameter is optional.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type BriaTextToImageBaseOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * TextToImageRequest
 */
export type BriaTextToImageBaseInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string;
  /**
   * Num Images
   *
   * How many images you would like to generate. When using any Guidance Method, Value is set to 1.
   */
  num_images?: number;
  /**
   * Prompt Enhancement
   *
   * When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.
   */
  prompt_enhancement?: boolean;
  /**
   * Guidance
   *
   * Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.
   */
  guidance?: Array<GuidanceInput>;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Medium
   *
   * Which medium should be included in your generated images. This parameter is optional.
   */
  medium?: "photography" | "art";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of iterations the model goes through to refine the generated image. This parameter is optional.
   */
  num_inference_steps?: number;
};

/**
 * SwittiOutput
 */
export type Switti512Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type Switti512Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Sampling Top-k
   *
   * The number of top-k tokens to sample from.
   */
  sampling_top_k?: number;
  /**
   * Disable CFG starting scale
   *
   * Disable CFG starting scale
   */
  turn_off_cfg_start_si?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Smoothing starting scale
   *
   * Smoothing starting scale
   */
  smooth_start_si?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Temperature after disabling CFG
   *
   * Temperature after disabling CFG
   */
  last_scale_temp?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * More Diverse
   *
   * More diverse sampling
   */
  more_diverse?: boolean;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * More Smooth
   *
   * Smoothing with Gumbel softmax sampling
   */
  more_smooth?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Sampling Top-p
   *
   * The top-p probability to sample from.
   */
  sampling_top_p?: number;
};

/**
 * SwittiOutput
 */
export type SwittiOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type SwittiInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Sampling Top-k
   *
   * The number of top-k tokens to sample from.
   */
  sampling_top_k?: number;
  /**
   * Disable CFG starting scale
   *
   * Disable CFG starting scale
   */
  turn_off_cfg_start_si?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Smoothing starting scale
   *
   * Smoothing starting scale
   */
  smooth_start_si?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Temperature after disabling CFG
   *
   * Temperature after disabling CFG
   */
  last_scale_temp?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * More Diverse
   *
   * More diverse sampling
   */
  more_diverse?: boolean;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * More Smooth
   *
   * Smoothing with Gumbel softmax sampling
   */
  more_smooth?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Sampling Top-p
   *
   * The top-p probability to sample from.
   */
  sampling_top_p?: number;
};

/**
 * Output
 */
export type FluxProV11UltraFinetunedOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Image
 */
export type RegistryImageFastSdxlModelsImage = {
  /**
   * Height
   */
  height: number;
  /**
   * Content Type
   */
  content_type?: string;
  /**
   * Url
   */
  url: string;
  /**
   * Width
   */
  width: number;
};

/**
 * FluxProUltraTextToImageFinetunedInput
 */
export type FluxProV11UltraFinetunedInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Fine-tune ID
   *
   * References your specific model
   */
  finetune_id: string;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Image Prompt Strength
   *
   * The strength of the image prompt, between 0 and 1.
   */
  image_prompt_strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
  /**
   * Raw
   *
   * Generate less processed, more natural-looking images.
   */
  raw?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21"
    | string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url?: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Fine-tune Strength
   *
   *
   * Controls finetune influence.
   * Increase this value if your target concept isn't showing up strongly enough.
   * The optimal setting depends on your finetune and prompt
   *
   */
  finetune_strength: number;
};

/**
 * Output
 */
export type FluxProV11Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProPlusTextToImageInput
 */
export type FluxProV11Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type JanusOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * JanusInput
 */
export type JanusInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate in parallel.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Cfg Weight
   *
   * Classifier Free Guidance scale - how closely to follow the prompt.
   */
  cfg_weight?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Temperature
   *
   * Controls randomness in the generation. Higher values make output more random.
   */
  temperature?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
};

/**
 * ImageOutput
 */
export type LuminaImageV2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type LuminaImageV2Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Cfg Trunc Ratio
   *
   * The ratio of the timestep interval to apply normalization-based guidance scale.
   */
  cfg_trunc_ratio?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * System Prompt
   *
   * The system prompt to use.
   */
  system_prompt?: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Cfg Normalization
   *
   * Whether to apply normalization-based guidance scale.
   */
  cfg_normalization?: boolean;
};

/**
 * Output
 */
export type Imagen3Output = {
  /**
   * Images
   */
  images: Array<File>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type Imagen3Input = {
  /**
   * Prompt
   *
   * The text prompt describing what you want to see
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?: "1:1" | "16:9" | "9:16" | "3:4" | "4:3";
  /**
   * Num Images
   *
   * Number of images to generate (1-4)
   */
  num_images?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * A description of what to discourage in the generated images
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type Imagen3FastOutput = {
  /**
   * Images
   */
  images: Array<File>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type Imagen3FastInput = {
  /**
   * Prompt
   *
   * The text prompt describing what you want to see
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?: "1:1" | "16:9" | "9:16" | "3:4" | "4:3";
  /**
   * Num Images
   *
   * Number of images to generate (1-4)
   */
  num_images?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * A description of what to discourage in the generated images
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type FluxControlLoraDepthOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DepthLoraInput
 */
export type FluxControlLoraDepthInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number;
  /**
   * Preprocess Depth
   *
   *
   * If set to true, the input image will be preprocessed to extract depth information.
   * This is useful for generating depth maps from images.
   *
   */
  preprocess_depth?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FluxControlLoraCannyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type FluxControlLoraCannyInput = {
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type IdeogramV2aTurboOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * BaseTextToImageInput
 */
export type IdeogramV2aTurboInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
};

/**
 * Output
 */
export type IdeogramV2aOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * BaseTextToImageInput
 */
export type IdeogramV2aInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
};

/**
 * ImageOutput
 */
export type Cogview4Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type Cogview4Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type RundiffusionPhotoFluxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * PhotoLoraT2IInput
 */
export type RundiffusionPhotoFluxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Photo Lora Scale
   *
   * LoRA Scale of the photo lora model
   */
  photo_lora_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type JuggernautFluxProOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DevTextToImageInput
 */
export type JuggernautFluxProInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type JuggernautFluxLightningOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SchnellTextToImageInput
 */
export type JuggernautFluxLightningInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type JuggernautFluxBaseOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DevTextToImageInput
 */
export type JuggernautFluxBaseInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type JuggernautFluxLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type JuggernautFluxLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type SanaSprintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SprintInput
 */
export type SanaSprintInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style Name
   *
   * The style to generate the image in.
   */
  style_name?:
    | "(No style)"
    | "Cinematic"
    | "Photographic"
    | "Anime"
    | "Manga"
    | "Digital Art"
    | "Pixel art"
    | "Fantasy art"
    | "Neonpunk"
    | "3D Model";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type SanaV1548bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type SanaV1548bInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style Name
   *
   * The style to generate the image in.
   */
  style_name?:
    | "(No style)"
    | "Cinematic"
    | "Photographic"
    | "Anime"
    | "Manga"
    | "Digital Art"
    | "Pixel art"
    | "Fantasy art"
    | "Neonpunk"
    | "3D Model";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type SanaV1516bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type SanaV1516bInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style Name
   *
   * The style to generate the image in.
   */
  style_name?:
    | "(No style)"
    | "Cinematic"
    | "Photographic"
    | "Anime"
    | "Manga"
    | "Digital Art"
    | "Pixel art"
    | "Fantasy art"
    | "Neonpunk"
    | "3D Model";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * ImageResponse
 */
export type GptImage1TextToImageOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * ImageFile
 */
export type ImageFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Height
   *
   * The height of the image
   */
  height?: number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image
   */
  width?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * TextToImageRequest
 */
export type GptImage1TextToImageInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "auto" | "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "auto" | "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
};

/**
 * Output
 */
export type FLiteTextureOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInputTexture
 */
export type FLiteTextureInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative prompt
   *
   * Negative Prompt for generation.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FLiteStandardOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInputStandard
 */
export type FLiteStandardInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative prompt
   *
   * Negative Prompt for generation.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * OutputV3
 */
export type IdeogramV3Output = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * BaseTextToImageInputV3
 */
export type IdeogramV3Input = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "GENERAL" | "REALISTIC" | "DESIGN" | unknown;
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | "80S_ILLUSTRATION"
    | "90S_NOSTALGIA"
    | "ABSTRACT_ORGANIC"
    | "ANALOG_NOSTALGIA"
    | "ART_BRUT"
    | "ART_DECO"
    | "ART_POSTER"
    | "AURA"
    | "AVANT_GARDE"
    | "BAUHAUS"
    | "BLUEPRINT"
    | "BLURRY_MOTION"
    | "BRIGHT_ART"
    | "C4D_CARTOON"
    | "CHILDRENS_BOOK"
    | "COLLAGE"
    | "COLORING_BOOK_I"
    | "COLORING_BOOK_II"
    | "CUBISM"
    | "DARK_AURA"
    | "DOODLE"
    | "DOUBLE_EXPOSURE"
    | "DRAMATIC_CINEMA"
    | "EDITORIAL"
    | "EMOTIONAL_MINIMAL"
    | "ETHEREAL_PARTY"
    | "EXPIRED_FILM"
    | "FLAT_ART"
    | "FLAT_VECTOR"
    | "FOREST_REVERIE"
    | "GEO_MINIMALIST"
    | "GLASS_PRISM"
    | "GOLDEN_HOUR"
    | "GRAFFITI_I"
    | "GRAFFITI_II"
    | "HALFTONE_PRINT"
    | "HIGH_CONTRAST"
    | "HIPPIE_ERA"
    | "ICONIC"
    | "JAPANDI_FUSION"
    | "JAZZY"
    | "LONG_EXPOSURE"
    | "MAGAZINE_EDITORIAL"
    | "MINIMAL_ILLUSTRATION"
    | "MIXED_MEDIA"
    | "MONOCHROME"
    | "NIGHTLIFE"
    | "OIL_PAINTING"
    | "OLD_CARTOONS"
    | "PAINT_GESTURE"
    | "POP_ART"
    | "RETRO_ETCHING"
    | "RIVIERA_POP"
    | "SPOTLIGHT_80S"
    | "STYLIZED_RED"
    | "SURREAL_COLLAGE"
    | "TRAVEL_POSTER"
    | "VINTAGE_GEO"
    | "VINTAGE_POSTER"
    | "WATERCOLOR"
    | "WEIRD"
    | "WOODBLOCK_PRINT"
    | unknown;
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string;
};

/**
 * ColorPaletteMember
 */
export type ColorPaletteMember = {
  /**
   * Color Weight
   *
   * The weight of the color in the color palette
   */
  color_weight?: number | unknown;
  rgb: RgbColor;
};

/**
 * ColorPalette
 */
export type ColorPalette = {
  /**
   * Members
   *
   * A list of color palette members that define the color palette
   */
  members?: Array<ColorPaletteMember> | unknown;
  /**
   * Name
   *
   * A color palette preset value
   */
  name?:
    | "EMBER"
    | "FRESH"
    | "JUNGLE"
    | "MAGIC"
    | "MELON"
    | "MOSAIC"
    | "PASTEL"
    | "ULTRAMARINE"
    | unknown;
};

/**
 * ImageOutput
 */
export type PonyV7Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Input
 */
export type PonyV7Input = {
  /**
   * Prompt
   *
   * The prompt to generate images from
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Noise Source
   *
   *
   * The source of the noise to use for generating images.
   * If set to 'gpu', the noise will be generated on the GPU.
   * If set to 'cpu', the noise will be generated on the CPU.
   *
   */
  noise_source?: "gpu" | "cpu";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Classifier free guidance scale
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to take
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for generating images
   */
  seed?: number;
};

/**
 * MiniMaxTextToImageOutput
 */
export type MinimaxImage01Output = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<File>;
};

/**
 * MiniMaxTextToImageRequest
 */
export type MinimaxImage01Input = {
  /**
   * Prompt
   *
   * Text prompt for image generation (max 1500 characters)
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate (1-9)
   */
  num_images?: number;
  /**
   * Prompt Optimizer
   *
   * Whether to enable automatic prompt optimization
   */
  prompt_optimizer?: boolean;
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image
   */
  aspect_ratio?:
    | "1:1"
    | "16:9"
    | "4:3"
    | "3:2"
    | "2:3"
    | "3:4"
    | "9:16"
    | "21:9";
};

/**
 * Output
 */
export type FluxLoraStreamOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type FluxLoraStreamInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * DreamOOutput
 */
export type DreamoOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The URLs of the generated images.
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DreamOInput
 */
export type DreamoInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * First Reference Image URL
   *
   * URL of first reference image to use for generation.
   */
  first_image_url?: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Second Reference Image URL
   *
   * URL of second reference image to use for generation.
   */
  second_image_url?: string;
  /**
   * Second Reference Task
   *
   * Task for second reference image (ip/id/style).
   */
  second_reference_task?: "ip" | "id" | "style";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * First Reference Task
   *
   * Task for first reference image (ip/id/style).
   */
  first_reference_task?: "ip" | "id" | "style";
  /**
   * Negative Prompt
   *
   * The prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Ref Resolution
   *
   * Resolution for reference images.
   */
  ref_resolution?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * True Cfg
   *
   * The weight of the CFG loss.
   */
  true_cfg?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Imagen4TextToImageUltraOutput
 */
export type Imagen4PreviewUltraOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * Imagen4TextToImageUltraInput
 */
export type Imagen4PreviewUltraInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?: "1:1" | "16:9" | "9:16" | "4:3" | "3:4";
  /**
   * Resolution
   *
   * The resolution of the generated image.
   */
  resolution?: "1K" | "2K";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
};

/**
 * ImageOutput
 */
export type BagelOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageGenInput
 */
export type BagelInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
  /**
   * Use Thought
   *
   * Whether to use thought tokens for generation. If set to true, the model will "think" to potentially improve generation quality. Increases generation time and increases the cost by 20%.
   */
  use_thought?: boolean;
};

/**
 * Output
 */
export type FluxProKontextTextToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProTextToImageInputWithAR
 */
export type FluxProKontextTextToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxProKontextMaxTextToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProTextToImageInputWithAR
 */
export type FluxProKontextMaxTextToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type Flux1DevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseFlux1Input
 */
export type Flux1DevInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * Output
 */
export type Flux1SchnellOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SchnellFlux1TextToImageInput
 */
export type Flux1SchnellInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * SeedDreamOutput
 */
export type BytedanceSeedreamV3TextToImageOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * SeedDreamInput
 */
export type BytedanceSeedreamV3TextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the image
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Use for finer control over the output image size. Will be used over aspect_ratio, if both are provided. Width and height must be between 512 and 2048.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Controls how closely the output image aligns with the input prompt. Higher values mean stronger prompt correlation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type OmnigenV2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type OmnigenV2Input = {
  /**
   * Prompt
   *
   * The prompt to generate or edit an image. Use specific language like 'Add the bird from image 1 to the desk in image 2' for better results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Scheduler
   *
   * The scheduler to use for the diffusion process.
   */
  scheduler?: "euler" | "dpmsolver";
  /**
   * Cfg Range End
   *
   * CFG range end value.
   */
  cfg_range_end?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Negative prompt to guide what should not be in the image.
   */
  negative_prompt?: string;
  /**
   * Text Guidance scale
   *
   *
   * The Text Guidance scale controls how closely the model follows the text prompt.
   * Higher values make the model stick more closely to the prompt.
   *
   */
  text_guidance_scale?: number;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Guidance scale
   *
   *
   * The Image Guidance scale controls how closely the model follows the input images.
   * For image editing: 1.3-2.0, for in-context generation: 2.0-3.0
   *
   */
  image_guidance_scale?: number;
  /**
   * Input Image Urls
   *
   * URLs of input images to use for image editing or multi-image generation. Support up to 3 images.
   */
  input_image_urls?: Array<string>;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Cfg Range Start
   *
   * CFG range start value.
   */
  cfg_range_start?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * KontextT2IOutput
 */
export type FluxKontextLoraTextToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKontextInput
 */
export type FluxKontextLoraTextToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * SkyRaccoonResponse
 */
export type SkyRaccoonOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: File;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * SkyRaccoonRequest
 */
export type SkyRaccoonInput = {
  /**
   * Prompt
   *
   * The text prompt to guide video generation.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Turbo Mode
   *
   * If true, the video will be generated faster with no noticeable degradation in the visual quality.
   */
  turbo_mode?: boolean;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
};

/**
 * KreaOutput
 */
export type Flux1KreaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaFlux1Input
 */
export type Flux1KreaInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * KreaOutput
 */
export type FluxKreaOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaInput
 */
export type FluxKreaInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxKreaLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * TextToImageInput
 */
export type FluxKreaLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FluxKreaLoraStreamOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * TextToImageInput
 */
export type FluxKreaLoraStreamInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * QwenImageOutput
 */
export type QwenImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseQwenImageInput
 */
export type QwenImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Use Turbo
   *
   * Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).
   */
  use_turbo?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * WanT2IResponse
 */
export type WanV22A14bTextToImageOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: File;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * WanT2IRequest
 */
export type WanV22A14bTextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt to guide image generation.
   */
  prompt: string;
  /**
   * Shift
   *
   * Shift value for the image. Must be between 1.0 and 10.0.
   */
  shift?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: "none" | "regular";
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number;
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean;
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean;
};

/**
 * WanSmallT2IResponse
 */
export type WanV225bTextToImageOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: File;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * WanSmallT2IRequest
 */
export type WanV225bTextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt to guide image generation.
   */
  prompt: string;
  /**
   * Shift
   *
   * Shift value for the image. Must be between 1.0 and 10.0.
   */
  shift?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string;
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number;
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
  /**
   * Image Format
   *
   * The format of the output image.
   */
  image_format?: "png" | "jpeg";
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean;
};

/**
 * LoRAWeight
 */
export type LoRaWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number;
  /**
   * Transformer
   *
   * Specifies the transformer to load the lora weight into. 'high' loads into the high-noise transformer, 'low' loads it into the low-noise transformer, while 'both' loads the LoRA into both transformers.
   */
  transformer?: "high" | "low" | "both";
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string;
};

/**
 * WanT2IResponse
 */
export type WanV22A14bTextToImageLoraOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: File;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * WanLoRAT2IRequest
 */
export type WanV22A14bTextToImageLoraInput = {
  /**
   * Shift
   *
   * Shift value for the image. Must be between 1.0 and 10.0.
   */
  shift?: number;
  /**
   * Prompt
   *
   * The text prompt to guide image generation.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: "none" | "regular";
  /**
   * Reverse Video
   *
   * If true, the video will be reversed.
   */
  reverse_video?: boolean;
  /**
   * Loras
   *
   * LoRA weights to be used in the inference.
   */
  loras?: Array<LoRaWeight>;
  /**
   * Guidance Scale (1st Stage)
   *
   * Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string;
  /**
   * Image Format
   *
   * The format of the output image.
   */
  image_format?: "png" | "jpeg";
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean;
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
};

/**
 * DreaminaOutput
 */
export type BytedanceDreaminaV31TextToImageOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * DreaminaInput
 */
export type BytedanceDreaminaV31TextToImageInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 512 and 2048.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Prompt
   *
   * The text prompt used to generate the image
   */
  prompt: string;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to use an LLM to enhance the prompt
   */
  enhance_prompt?: boolean;
};

/**
 * NanoBananaTextToImageOutput
 */
export type NanoBananaOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaTextToImageInput
 */
export type NanoBananaInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16";
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * NanoBananaTextToImageOutput
 */
export type Gemini25FlashImageOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaTextToImageInput
 */
export type Gemini25FlashImageInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * SeedDream4T2IOutput
 */
export type BytedanceSeedreamV4TextToImageOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * SeedDream4T2IInput
 */
export type BytedanceSeedreamV4TextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the image
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Total pixels must be between 960x960 and 4096x4096.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto"
    | "auto_2K"
    | "auto_4K";
  /**
   * Enhance Prompt Mode
   *
   * The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.
   */
  enhance_prompt_mode?: "standard" | "fast";
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.
   */
  max_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
};

/**
 * HunyuanTextToImageOutput
 */
export type HunyuanImageV21TextToImageOutput = {
  /**
   * Images
   *
   * A list of the generated images.
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The base seed used for the generation process.
   */
  seed: number;
};

/**
 * HunyuanTextToImageInput
 */
export type HunyuanImageV21TextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The desired size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Use Reprompt
   *
   * Enable prompt enhancement for potentially better results.
   */
  use_reprompt?: boolean;
  /**
   * Use Refiner
   *
   * Enable the refiner model for improved image quality.
   */
  use_refiner?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Controls how much the model adheres to the prompt. Higher values mean stricter adherence.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducible results. If None, a random seed is used.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to guide the image generation away from certain concepts.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * Number of denoising steps.
   */
  num_inference_steps?: number;
};

/**
 * SRPOOutput
 */
export type Flux1SrpoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseSRPOFlux1Input
 */
export type Flux1SrpoInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * SRPOOutput
 */
export type FluxSrpoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseSRPOInput
 */
export type FluxSrpoInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * TextToImageOutput
 *
 * Output for text-to-image generation
 */
export type Wan25PreviewTextToImageOutput = {
  /**
   * Seeds
   *
   * The seeds used for each generated image
   */
  seeds: Array<number>;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Actual Prompt
   *
   * The actual prompt used if prompt rewriting was enabled
   */
  actual_prompt?: string;
};

/**
 * TextToImageInput
 *
 * Input for text-to-image generation
 */
export type Wan25PreviewTextToImageInput = {
  /**
   * Prompt
   *
   * The prompt for image generation. Supports Chinese and English, max 2000 characters.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate. Values from 1 to 4.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Can use preset names like 'square', 'landscape_16_9', etc., or specific dimensions. Total pixels must be between 768768 and 14401440, with aspect ratio between [1:4, 4:1].
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string;
};

/**
 * HunyuanTextToImageV3Output
 */
export type HunyuanImageV3TextToImageOutput = {
  /**
   * Images
   *
   * A list of the generated images.
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The base seed used for the generation process.
   */
  seed: number;
};

/**
 * HunyuanTextToImageInputV3
 */
export type HunyuanImageV3TextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt for image-to-image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The desired size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Controls how much the model adheres to the prompt. Higher values mean stricter adherence.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducible results. If None, a random seed is used.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to guide the image generation away from certain concepts.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * Number of denoising steps.
   */
  num_inference_steps?: number;
};

/**
 * ReveCreateOutput
 *
 * Output for Reve text-to-image generation
 */
export type ReveTextToImageOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
};

/**
 * ReveCreateInput
 *
 * Input for Reve text-to-image generation
 */
export type ReveTextToImageInput = {
  /**
   * Prompt
   *
   * The text description of the desired image.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the generated image.
   */
  aspect_ratio?: "16:9" | "9:16" | "3:2" | "2:3" | "4:3" | "3:4" | "1:1";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
};

/**
 * ImageResponseMini
 */
export type GptImage1MiniOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * TextToImageRequestMini
 */
export type GptImage1MiniInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "auto" | "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "auto" | "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
};

/**
 * PiQwenOutput
 */
export type PiflowOutput = {
  /**
   * Images
   *
   * The URLs of the generated images.
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * PiQwenInput
 */
export type PiflowInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or custom height and width
   * that **must be multiples of 8**.
   *
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation. If set to None, a random seed will be used.
   */
  seed?: number;
};

/**
 * GaiaOutputModel
 */
export type FiboGenerateOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<{
    [key: string]: unknown;
  }>;
  image: ImageType3;
  /**
   * Structured Prompt
   *
   * Current prompt.
   */
  structured_prompt: {
    [key: string]: unknown;
  };
};

/**
 * GaiaInputModel
 */
export type FiboGenerateInput = {
  /**
   * Prompt
   *
   * Prompt for image generation.
   */
  prompt?: string | unknown;
  /**
   * Aspect Ratio
   *
   * Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Steps Num
   *
   * Number of inference steps.
   */
  steps_num?: number;
  /**
   * Image Url
   *
   * Reference image (file or URL).
   */
  image_url?: string | unknown;
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string;
  /**
   * The structured prompt to generate an image from.
   */
  structured_prompt?: StructuredPrompt | unknown;
};

/**
 * Lighting
 */
export type Lighting = {
  /**
   * Shadows
   *
   * The shadows in the image to be generated.
   */
  shadows?: string | unknown;
  /**
   * Conditions
   *
   * The conditions of the lighting in the image to be generated.
   */
  conditions?: string | unknown;
  /**
   * Direction
   *
   * The direction of the lighting in the image to be generated.
   */
  direction?: string | unknown;
};

/**
 * Aesthetics
 */
export type Aesthetics = {
  /**
   * Composition
   *
   * The composition of the image to be generated.
   */
  composition?: string | unknown;
  /**
   * Mood Atmosphere
   *
   * The mood and atmosphere of the image to be generated.
   */
  mood_atmosphere?: string | unknown;
  /**
   * Color Scheme
   *
   * The color scheme of the image to be generated.
   */
  color_scheme?: string | unknown;
};

/**
 * PhotographicCharacteristics
 */
export type PhotographicCharacteristics = {
  /**
   * Focus
   *
   * The focus in the image to be generated.
   */
  focus?: string | unknown;
  /**
   * Lens Focal Length
   *
   * The focal length of the lens in the image to be generated.
   */
  lens_focal_length?: string | unknown;
  /**
   * Camera Angle
   *
   * The angle of the camera in the image to be generated.
   */
  camera_angle?: string | unknown;
  /**
   * Depth Of Field
   *
   * The depth of field in the image to be generated.
   */
  depth_of_field?: string | unknown;
};

/**
 * PromptObject
 */
export type PromptObject = {
  /**
   * Relative Size
   *
   * The relative size of the object in the image.
   */
  relative_size?: string | unknown;
  /**
   * Description
   *
   * A description of the object to be generated.
   */
  description?: string | unknown;
  /**
   * Skin Tone And Texture
   *
   * The skin tone and texture of the object in the image.
   */
  skin_tone_and_texture?: string | unknown;
  /**
   * Appearance Details
   *
   * The appearance details of the object.
   */
  appearance_details?: string | unknown;
  /**
   * Number Of Objects
   *
   * The number of objects in the image.
   */
  number_of_objects?: number | unknown;
  /**
   * Expression
   *
   * The expression of the object in the image.
   */
  expression?: string | unknown;
  /**
   * Pose
   *
   * The pose of the object in the image.
   */
  pose?: string | unknown;
  /**
   * Shape And Color
   *
   * The shape and color of the object.
   */
  shape_and_color?: string | unknown;
  /**
   * Relationship
   *
   * The relationship of the object to other objects in the image.
   */
  relationship: string;
  /**
   * Texture
   *
   * The texture of the object.
   */
  texture?: string | unknown;
  /**
   * Gender
   *
   * The gender of the object in the image.
   */
  gender?: string | unknown;
  /**
   * Clothing
   *
   * The clothing of the object in the image.
   */
  clothing?: string | unknown;
  /**
   * Location
   *
   * The location of the object in the image.
   */
  location?: string | unknown;
  /**
   * Orientation
   *
   * The orientation of the object in the image.
   */
  orientation?: string | unknown;
  /**
   * Action
   *
   * The action of the object in the image.
   */
  action?: string | unknown;
};

/**
 * StructuredPrompt
 */
export type StructuredPrompt = {
  /**
   * Background Setting
   *
   * The background setting of the image to be generated.
   */
  background_setting?: string | unknown;
  /**
   * Artistic Style
   *
   * The artistic style of the image to be generated.
   */
  artistic_style?: string | unknown;
  /**
   * Context
   *
   * The context of the image to be generated.
   */
  context?: string | unknown;
  /**
   * Text Render
   *
   * A list of text to be rendered in the image.
   */
  text_render?: Array<unknown> | unknown;
  /**
   * Objects
   *
   * A list of objects in the image to be generated, along with their attributes and relationships to other objects in the image.
   */
  objects?: Array<PromptObject> | unknown;
  /**
   * Style Medium
   *
   * The style medium of the image to be generated.
   */
  style_medium?: string | unknown;
  /**
   * The photographic characteristics of the image to be generated.
   */
  photographic_characteristics?: PhotographicCharacteristics | unknown;
  /**
   * The aesthetics of the image to be generated.
   */
  aesthetics?: Aesthetics | unknown;
  /**
   * The lighting of the image to be generated.
   */
  lighting?: Lighting | unknown;
  /**
   * Short Description
   *
   * A short description of the image to be generated.
   */
  short_description?: string | unknown;
};

/**
 * Emu35Output
 */
export type Emu35ImageTextToImageOutput = {
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * Emu35ImageInput
 */
export type Emu35ImageTextToImageInput = {
  /**
   * Prompt
   *
   * The prompt to create the image.
   */
  prompt: string;
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: "480p" | "720p";
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
};

/**
 * Image
 *
 * Represents an image file.
 */
export type ImageOutput = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number | unknown;
};

/**
 * ImagineArt_1_5_Output
 */
export type Imagineart15PreviewTextToImageOutput = {
  /**
   * Images
   *
   * Generated image
   */
  images: Array<ImageOutput>;
};

/**
 * ImagineArt_1_5_Input
 */
export type Imagineart15PreviewTextToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * Image aspect ratio: 1:1, 3:1, 1:3, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3
   */
  aspect_ratio?:
    | "1:1"
    | "16:9"
    | "9:16"
    | "4:3"
    | "3:4"
    | "3:1"
    | "1:3"
    | "3:2"
    | "2:3";
  /**
   * Seed
   *
   * Seed for the image generation
   */
  seed?: number;
};

/**
 * NanoBananaTextToImageOutput
 */
export type NanoBananaProOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFileType2>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * ImageFile
 */
export type ImageFileType2 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * Height
   *
   * The height of the image
   */
  height?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image
   */
  width?: number | unknown;
};

/**
 * NanoBananaTextToImageInput
 */
export type NanoBananaProInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: "1K" | "2K" | "4K";
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16";
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * NanoBananaTextToImageOutput
 */
export type Gemini3ProImagePreviewOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFileType2>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaTextToImageInput
 */
export type Gemini3ProImagePreviewInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean;
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: "1K" | "2K" | "4K";
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image. Use "auto" to let the model decide based on the prompt.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16"
    | unknown;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * Flux2FlexOutput
 */
export type Flux2FlexOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2FlexTextToImageInput
 */
export type Flux2FlexInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Prompt Expansion
   *
   * Whether to expand the prompt using the model's own knowledge.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the generation.
   */
  guidance_scale?: number;
};

/**
 * BallpointPenSketchOutput
 */
export type Flux2LoraGalleryBallpointPenSketchOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated ballpoint pen sketch style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * BallpointPenSketchInput
 *
 * Input model for Ballpoint Pen Sketch endpoint - Generate ballpoint pen sketch style images
 */
export type Flux2LoraGalleryBallpointPenSketchInput = {
  /**
   * Prompt
   *
   * The prompt to generate a ballpoint pen sketch style image. Use 'b4llp01nt' trigger word for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the ballpoint pen sketch effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * DigitalComicArtOutput
 */
export type Flux2LoraGalleryDigitalComicArtOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated digital comic art style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * DigitalComicArtInput
 *
 * Input model for Digital Comic Art endpoint - Generate digital comic art style images
 */
export type Flux2LoraGalleryDigitalComicArtInput = {
  /**
   * Prompt
   *
   * The prompt to generate a digital comic art style image. Use 'd1g1t4l' trigger word for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the digital comic art effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * HdrStyleOutput
 */
export type Flux2LoraGalleryHdrStyleOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated HDR style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * HdrStyleInput
 *
 * Input model for HDR Style endpoint - Generate HDR style images with vibrant colors
 */
export type Flux2LoraGalleryHdrStyleInput = {
  /**
   * Prompt
   *
   * The prompt to generate an HDR style image. The trigger word 'Hyp3rRe4list1c' will be automatically prepended.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the HDR style effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * RealismOutput
 */
export type Flux2LoraGalleryRealismOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated realistic style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * RealismInput
 *
 * Input model for Realism endpoint - Generate realistic style images
 */
export type Flux2LoraGalleryRealismInput = {
  /**
   * Prompt
   *
   * The prompt to generate a realistic image with natural lighting and authentic details.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the realism effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * SatelliteViewStyleOutput
 */
export type Flux2LoraGallerySatelliteViewStyleOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated satellite view style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * SatelliteViewStyleInput
 *
 * Input model for Satellite View Style endpoint - Generate satellite/aerial view style images
 */
export type Flux2LoraGallerySatelliteViewStyleInput = {
  /**
   * Prompt
   *
   * The prompt to generate a satellite/aerial view style image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the satellite view style effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * SepiaVintageOutput
 */
export type Flux2LoraGallerySepiaVintageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated sepia vintage photography style images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * SepiaVintageInput
 *
 * Input model for Sepia Vintage Photography endpoint - Generate vintage sepia style images
 */
export type Flux2LoraGallerySepiaVintageInput = {
  /**
   * Prompt
   *
   * The prompt to generate a sepia vintage photography style image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the sepia vintage photography effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ZImageTurboOutput
 */
export type ZImageTurboOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboTextToImageInput
 */
export type ZImageTurboInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * OvisImageOutput
 */
export type OvisImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * TextToImageInput
 */
export type OvisImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ZImageTurboOutput
 */
export type ZImageTurboLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboTextToImageLoRAInput
 */
export type ZImageTurboLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export type LoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number;
};

/**
 * TextToImageOutput
 */
export type ViduQ2TextToImageOutput = {
  /**
   * Image
   *
   * The edited image
   */
  image: Image;
};

/**
 * TextToImageRequest
 */
export type ViduQ2TextToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: "16:9" | "9:16" | "1:1";
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number;
};

/**
 * SeedDream45T2IOutput
 */
export type BytedanceSeedreamV45TextToImageOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * SeedDream45T2IInput
 */
export type BytedanceSeedreamV45TextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt used to generate the image
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 1920 and 4096, or total number of pixels must be between 2560*1440 and 4096*4096.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto_2K"
    | "auto_4K";
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.
   */
  max_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
};

/**
 * TextToImageOutput
 */
export type LongcatImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type LongcatImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Flux2MaxOutput
 */
export type Flux2MaxOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2MaxTextToImageInput
 */
export type Flux2MaxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
};

/**
 * Flux2TurboT2IOutput
 */
export type Flux2TurboOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2TurboTextToImageInput
 */
export type Flux2TurboInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * GaiaOutputModel
 */
export type FiboLiteGenerateOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<{
    [key: string]: unknown;
  }>;
  image: ImageType3;
  /**
   * Structured Prompt
   *
   * Current prompt.
   */
  structured_prompt: {
    [key: string]: unknown;
  };
};

/**
 * GaiaLiteInputModel
 */
export type FiboLiteGenerateInput = {
  /**
   * Prompt
   *
   * Prompt for image generation.
   */
  prompt?: string | unknown;
  /**
   * Steps Num
   *
   * Number of inference steps for Fibo Lite.
   */
  steps_num?: number;
  /**
   * Aspect Ratio
   *
   * Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Image Url
   *
   * Reference image (file or URL).
   */
  image_url?: string | unknown;
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * The structured prompt to generate an image from.
   */
  structured_prompt?: StructuredPrompt | unknown;
};

/**
 * ImageResponse
 */
export type GptImage15Output = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * TextToImageRequest
 */
export type GptImage15Input = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
};

/**
 * Flux2FlashT2IOutput
 */
export type Flux2FlashOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2FlashTextToImageInput
 */
export type Flux2FlashInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * TextToImageWanOutput
 *
 * Output for Wan 2.6 text-to-image (can include generated text in mixed mode)
 */
export type V26TextToImageOutput = {
  /**
   * Images
   *
   * Generated images in PNG format
   */
  images: Array<File>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
  /**
   * Generated Text
   *
   * Generated text content (in mixed text-and-image mode). May be None if only images were generated.
   */
  generated_text?: string;
};

/**
 * TextToImageWanInput
 *
 * Input for Wan 2.6 text-to-image or mixed text-and-image generation (enable_interleave=true)
 */
export type V26TextToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters.
   */
  prompt: string;
  /**
   * Image Size
   *
   * Output image size. If not set: matches input image size (up to 1280*1280). Use presets like 'square_hd', 'landscape_16_9', or specify exact dimensions.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Max Images
   *
   * Maximum number of images to generate (1-5). Actual count may be less depending on model inference.
   */
  max_images?: number;
  /**
   * Image Url
   *
   * Optional reference image (0 or 1). When provided, can be used for style guidance. Resolution: 384-5000px each dimension. Max size: 10MB. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP.
   */
  image_url?: string;
  /**
   * Enable Safety Checker
   *
   * Enable content moderation for input and output.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility (0-2147483647).
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Content to avoid in the generated image. Max 500 characters.
   */
  negative_prompt?: string;
};

/**
 * QwenImage2512Output
 */
export type QwenImage2512Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type QwenImage2512Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * QwenImage2512Output
 */
export type QwenImage2512LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * LoraInput
 */
export type QwenImage2512LoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * GlmImageOutput
 */
export type GlmImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * List of URLs to the generated images.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * GlmImageInput
 */
export type GlmImageInput = {
  /**
   * Prompt
   *
   * Text prompt for image generation.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Output image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "portrait_3_2"
    | "landscape_3_2"
    | "portrait_hd"
    | "landscape_hd";
  /**
   * Output Format
   *
   * Output image format.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If True, the image will be returned as a base64 data URI instead of a URL.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values make the model follow the prompt more closely.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. The same seed with the same prompt will produce the same image.
   */
  seed?: number;
  /**
   * Enable Prompt Expansion
   *
   * If True, the prompt will be enhanced using an LLM for more detailed and higher quality results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Num Inference Steps
   *
   * Number of diffusion denoising steps. More steps generally produce higher quality images.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Enable NSFW safety checking on the generated images.
   */
  enable_safety_checker?: boolean;
};

/**
 * ImagineArt_1_5_Output
 */
export type Imagineart15ProPreviewTextToImageOutput = {
  /**
   * Images
   *
   * Generated image
   */
  images: Array<ImageType3>;
};

/**
 * ImagineArt_1_5_Input
 */
export type Imagineart15ProPreviewTextToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * Image aspect ratio: 1:1, 3:1, 1:3, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3
   */
  aspect_ratio?:
    | "1:1"
    | "16:9"
    | "9:16"
    | "4:3"
    | "3:4"
    | "3:1"
    | "1:3"
    | "3:2"
    | "2:3";
  /**
   * Seed
   *
   * Seed for the image generation
   */
  seed?: number;
};

/**
 * Klein4BDistilledT2IOutput
 */
export type Flux2Klein4bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinDistilledInput
 */
export type Flux2Klein4bInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * Klein9BDistilledT2IOutput
 */
export type Flux2Klein9bOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein9BDistilledInput
 */
export type Flux2Klein9bInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * Klein4BT2IOutput
 */
export type Flux2Klein4bBaseOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein4BBaseInput
 */
export type Flux2Klein4bBaseInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
};

/**
 * Klein9BT2IOutput
 */
export type Flux2Klein9bBaseOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein9BBaseInput
 */
export type Flux2Klein9bBaseInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
};

/**
 * KleinT2IOutput
 */
export type Flux2Klein4bBaseLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinBaseLoRAInput
 */
export type Flux2Klein4bBaseLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<FalAiFlux2KleinLoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
};

/**
 * LoRAInput
 */
export type FalAiFlux2KleinLoRaInput = {
  /**
   * Path
   *
   * URL, HuggingFace repo ID (owner/repo), or local path to LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   * Scale factor for LoRA application (0.0 to 4.0).
   */
  scale?: number;
};

/**
 * KleinT2IOutput
 */
export type Flux2Klein9bBaseLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinBaseLoRAInput
 */
export type Flux2Klein9bBaseLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<FalAiFlux2KleinLoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
};

/**
 * ZImageBaseOutput
 */
export type ZImageBaseOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageBaseTextToImageInput
 */
export type ZImageBaseInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the image generation.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ZImageBaseOutput
 */
export type ZImageBaseLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageBaseTextToImageLoRAInput
 */
export type ZImageBaseLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to use for the image generation.
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * QwenImageMaxTextToImageOutput
 */
export type QwenImageMaxTextToImageOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images: Array<File>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * QwenImageMaxTextToImageInput
 */
export type QwenImageMaxTextToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image. Supports Chinese and English. Max 800 characters.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Prompt Expansion
   *
   * Enable LLM prompt optimization for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility (0-2147483647).
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * Enable content moderation for input and output.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Content to avoid in the generated image. Max 500 characters.
   */
  negative_prompt?: string;
};

/**
 * HunyuanImageTextToImageResponse
 */
export type HunyuanImageV3InstructTextToImageOutput = {
  /**
   * Images
   *
   * A list of the generated images.
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The base seed used for the generation process.
   */
  seed: number;
};

/**
 * HunyuanImageRequest
 */
export type HunyuanImageV3InstructTextToImageInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The desired size of the generated image. If auto, image size will be determined by the model.
   */
  image_size?:
    | ImageSize
    | "auto"
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducible results. If None, a random seed is used.
   */
  seed?: number;
  /**
   * Guidance Scale
   *
   * Controls how much the model adheres to the prompt. Higher values mean stricter adherence.
   */
  guidance_scale?: number;
};

/**
 * XAIImageOutput
 */
export type GrokImagineImageOutput = {
  /**
   * Images
   *
   * The URL of the generated image.
   */
  images: Array<ImageFile>;
  /**
   * Revised Prompt
   *
   * The enhanced prompt that was used to generate the image.
   */
  revised_prompt: string;
};

/**
 * XAIImageInput
 */
export type GrokImagineImageInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Prompt
   *
   * Text description of the desired image.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "2:1"
    | "20:9"
    | "19.5:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:19.5"
    | "9:20"
    | "1:2";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
};

/**
 * Output
 */
export type FluxLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type FluxLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FluxGeneralOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type FluxGeneralInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Proportion of steps to apply NAG
   *
   *
   * The proportion of steps to apply NAG. After the specified proportion
   * of steps has been iterated, the remaining steps will use original
   * attention processors in FLUX.
   *
   */
  nag_end?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Control Loras
   *
   *
   * The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  control_loras?: Array<ControlLoraWeight>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler for the denoising process.
   */
  scheduler?: "euler" | "dpmpp_2m";
  /**
   * Easycontrols
   *
   *
   * EasyControl Inputs to use for image generation.
   *
   */
  easycontrols?: Array<EasyControlWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Real CFG scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  real_cfg_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Use CFG-Zero-Init
   *
   *
   * Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.
   *
   */
  use_cfg_zero?: boolean;
  /**
   * Fill Image
   *
   * Use an image input to influence the generation. Can be used to fill images in masked areas.
   */
  fill_image?: ImageFillInput;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Sigma Schedule
   *
   * Sigmas schedule for the denoising process.
   */
  sigma_schedule?: "sgm_uniform";
  /**
   * Reference End
   *
   *
   * The percentage of the total timesteps when the reference guidance is to be ended.
   *
   */
  reference_end?: number;
  /**
   * Reference Strength
   *
   * Strength of reference_only generation. Only used if a reference image is provided.
   */
  reference_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * NAG scale
   *
   *
   * The scale for NAG. Higher values will result in a image that is more distant
   * to the negative prompt.
   *
   */
  nag_scale?: number;
  /**
   * Reference Image Url
   *
   * URL of Image for Reference-Only
   */
  reference_image_url?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Controlnet Unions
   *
   *
   * The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnet_unions?: Array<ControlNetUnion>;
  /**
   * Negative Prompt
   *
   *
   * Negative prompt to steer the image generation away from unwanted features.
   * By default, we will be using NAG for processing the negative prompt.
   *
   */
  negative_prompt?: string;
  /**
   * NAG Tau
   *
   *
   * The tau for NAG. Controls the normalization of the hidden state.
   * Higher values will result in a less aggressive normalization,
   * but may also lead to unexpected changes with respect to the original image.
   * Not recommended to change this value.
   *
   */
  nag_tau?: number;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Use Beta Schedule
   *
   * Specifies whether beta sigmas ought to be used.
   */
  use_beta_schedule?: boolean;
  /**
   * Ip Adapters
   *
   *
   * IP-Adapter to use for image generation.
   *
   */
  ip_adapters?: Array<IpAdapter>;
  /**
   * Base Shift
   *
   * Base shift for the scheduled timesteps
   */
  base_shift?: number;
  /**
   * NAG alpha
   *
   *
   * The alpha value for NAG. This value is used as a final weighting
   * factor for steering the normalized guidance (positive and negative prompts)
   * in the direction of the positive prompt. Higher values will result in less
   * steering on the normalized guidance where lower values will result in
   * considering the positive prompt guidance more.
   *
   */
  nag_alpha?: number;
  /**
   * Use Real CFG
   *
   *
   * Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.
   * If using XLabs IP-Adapter v1, this will be turned on!.
   *
   */
  use_real_cfg?: boolean;
  /**
   * Max Shift
   *
   * Max shift for the scheduled timesteps
   */
  max_shift?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Controlnets
   *
   *
   * The controlnets to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnets?: Array<ControlNet>;
  /**
   * Reference Start
   *
   *
   * The percentage of the total timesteps when the reference guidance is to bestarted.
   *
   */
  reference_start?: number;
};

/**
 * ControlNet
 */
export type ControlNet = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number;
  /**
   * Path
   *
   * URL or the path to the control net weights.
   */
  path: string;
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number;
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number;
  /**
   * Config Url
   *
   * optional URL to the controlnet config.json file.
   */
  config_url?: string;
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null;
  /**
   * Variant
   *
   * The optional variant if a Hugging Face repo key is used.
   */
  variant?: string;
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string;
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number;
};

/**
 * IPAdapter
 */
export type IpAdapter = {
  /**
   * Path
   *
   * Hugging Face path to the IP-Adapter
   */
  path: string;
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number;
  /**
   * Image Encoder Weight Name
   *
   * Name of the image encoder.
   */
  image_encoder_weight_name?: string;
  /**
   * Image Encoder Subfolder
   *
   * Subfolder in which the image encoder weights exist.
   */
  image_encoder_subfolder?: string;
  /**
   * Image Url
   *
   * URL of Image for IP-Adapter conditioning.
   */
  image_url: string;
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string;
  /**
   * Subfolder
   *
   * Subfolder in which the ip_adapter weights exist
   */
  subfolder?: string;
  /**
   * Scale
   *
   * Scale for ip adapter.
   */
  scale: number;
  /**
   * Image Encoder Path
   *
   * Path to the Image Encoder for the IP-Adapter, for example 'openai/clip-vit-large-patch14'
   */
  image_encoder_path: string;
  /**
   * Weight Name
   *
   * Name of the safetensors file containing the ip-adapter weights
   */
  weight_name?: string;
};

/**
 * ControlNetUnionInput
 */
export type ControlNetUnionInput = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number;
  /**
   * Mask Threshold
   *
   * Threshold for mask.
   */
  mask_threshold?: number;
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number;
  /**
   * Mask Image Url
   *
   * URL of the mask for the control image.
   */
  mask_image_url?: string | null;
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string;
  /**
   * Control Mode
   *
   * Control Mode for Flux Controlnet Union. Supported values are:
   * - canny: Uses the edges for guided generation.
   * - tile: Uses the tiles for guided generation.
   * - depth: Utilizes a grayscale depth map for guided generation.
   * - blur: Adds a blur to the image.
   * - pose: Uses the pose of the image for guided generation.
   * - gray: Converts the image to grayscale.
   * - low-quality: Converts the image to a low-quality image.
   */
  control_mode:
    | "canny"
    | "tile"
    | "depth"
    | "blur"
    | "pose"
    | "gray"
    | "low-quality";
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number;
};

/**
 * ControlNetUnion
 */
export type ControlNetUnion = {
  /**
   * Controls
   *
   * The control images and modes to use for the control net.
   */
  controls: Array<ControlNetUnionInput>;
  /**
   * Path
   *
   * URL or the path to the control net weights.
   */
  path: string;
  /**
   * Variant
   *
   * The optional variant if a Hugging Face repo key is used.
   */
  variant?: string;
  /**
   * Config Url
   *
   * optional URL to the controlnet config.json file.
   */
  config_url?: string;
};

/**
 * ImageFillInput
 */
export type ImageFillInput = {
  /**
   * Fill Image Url
   *
   * URLs of images to be filled for redux prompting
   */
  fill_image_url?: string | Array<string>;
};

/**
 * EasyControlWeight
 */
export type EasyControlWeight = {
  /**
   * Scale
   *
   * Scale for the control method.
   */
  scale?: number;
  /**
   * Image Control Type
   *
   * Control type of the image. Must be one of `spatial` or `subject`.
   */
  image_control_type: "subject" | "spatial";
  /**
   * Control Method Url
   *
   * URL to safetensor weights of control method to be applied. Can also be one of `canny`, `depth`, `hedsketch`, `inpainting`, `pose`, `seg`, `subject`, `ghibli`
   */
  control_method_url: string;
  /**
   * Image Url
   *
   * URL of an image to use as a control
   */
  image_url: string;
};

/**
 * ControlLoraWeight
 */
export type ControlLoraWeight = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model. Providing a dictionary as {"layer_name":layer_scale} allows per-layer lora scale settings. Layers with no scale provided will have scale 1.0.
   *
   */
  scale?:
    | {
        [key: string]: unknown;
      }
    | number;
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string;
  /**
   * Preprocess
   *
   * Type of preprocessing to apply to the input image.
   */
  preprocess?: "canny" | "depth" | "None";
};

/**
 * Output
 */
export type StableDiffusionV35LargeOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * TextToImageInput
 */
export type StableDiffusionV35LargeInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Defaults to landscape_4_3 if no controlnet has been passed, otherwise defaults to the size of the controlnet conditioning image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Controlnet
   *
   *
   * ControlNet for inference.
   *
   */
  controlnet?: ControlNetType3;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Ip Adapter
   *
   *
   * IP-Adapter to use during inference.
   *
   */
  ip_adapter?: IpAdapter;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ControlNet
 */
export type ControlNetType3 = {
  /**
   * Conditioning Scale
   *
   *
   * The scale of the control net weight. This is used to scale the control net weight
   * before merging it with the base model.
   *
   */
  conditioning_scale?: number;
  /**
   * Path
   *
   * URL or the path to the control net weights.
   */
  path: string;
  /**
   * Control Image Url
   *
   * URL of the image to be used as the control image.
   */
  control_image_url: string;
  /**
   * Start Percentage
   *
   *
   * The percentage of the image to start applying the controlnet in terms of the total timesteps.
   *
   */
  start_percentage?: number;
  /**
   * End Percentage
   *
   *
   * The percentage of the image to end applying the controlnet in terms of the total timesteps.
   *
   */
  end_percentage?: number;
};

/**
 * Output
 */
export type IdeogramV2Output = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type IdeogramV2Input = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Negative Prompt
   *
   * A negative prompt to avoid in the generated image
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type FluxDevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseInput
 */
export type FluxDevInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type HidreamI1FastOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FastInput
 */
export type HidreamI1FastInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type HidreamI1DevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DevInput
 */
export type HidreamI1DevInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
};

export type HidreamI1FullOutput = unknown;

/**
 * TextToImageInput
 */
export type HidreamI1FullInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.
   */
  loras?: Array<LoraWeightType3>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * LoraWeight
 */
export type LoraWeightType3 = {
  /**
   * Path
   *
   * URL or the path to the LoRA weights.
   */
  path: string;
  /**
   * Scale
   *
   *
   * The scale of the LoRA weight. This is used to scale the LoRA weight
   * before merging it with the base model.
   *
   */
  scale?: number;
  /**
   * Weight Name
   *
   * Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.
   */
  weight_name?: string;
};

/**
 * Imagen4TextToImageFastOutput
 */
export type Imagen4PreviewFastOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * Imagen4TextToImageFastInput
 */
export type Imagen4PreviewFastInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?: "1:1" | "16:9" | "9:16" | "4:3" | "3:4";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
};

/**
 * OutputModel
 */
export type TextToImage32Output = {
  image: ImageType3;
};

/**
 * InputModel
 */
export type TextToImage32Input = {
  /**
   * Prompt
   *
   * Prompt for image generation.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Prompt Enhancer
   *
   * Whether to improve the prompt.
   */
  prompt_enhancer?: boolean;
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Truncate Prompt
   *
   * Whether to truncate the prompt.
   */
  truncate_prompt?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string;
};

/**
 * Flux2ProOutput
 */
export type Flux2ProOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2ProTextToImageInput
 */
export type Flux2ProInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
};

/**
 * Flux2T2IOutput
 */
export type Flux2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2TextToImageInput
 */
export type Flux2Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for the image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Flux2T2ILoRAOutput
 */
export type Flux2LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2TextToImageLoRAInput
 */
export type Flux2LoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for the image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3). Each LoRA can be a URL, HuggingFace repo ID, or local path.
   */
  loras?: Array<LoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * TextToImageOutput
 */
export type RecraftV3TextToImageOutput = {
  /**
   * Images
   */
  images: Array<File>;
};

/**
 * TextToImageInput
 */
export type RecraftV3TextToImageInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Colors
   *
   * An array of preferable colors
   */
  colors?: Array<RgbColor>;
  /**
   * Style
   *
   * The style of the generated images. Vector images cost 2X as much.
   */
  style?:
    | "any"
    | "realistic_image"
    | "digital_illustration"
    | "vector_illustration"
    | "realistic_image/b_and_w"
    | "realistic_image/hard_flash"
    | "realistic_image/hdr"
    | "realistic_image/natural_light"
    | "realistic_image/studio_portrait"
    | "realistic_image/enterprise"
    | "realistic_image/motion_blur"
    | "realistic_image/evening_light"
    | "realistic_image/faded_nostalgia"
    | "realistic_image/forest_life"
    | "realistic_image/mystic_naturalism"
    | "realistic_image/natural_tones"
    | "realistic_image/organic_calm"
    | "realistic_image/real_life_glow"
    | "realistic_image/retro_realism"
    | "realistic_image/retro_snapshot"
    | "realistic_image/urban_drama"
    | "realistic_image/village_realism"
    | "realistic_image/warm_folk"
    | "digital_illustration/pixel_art"
    | "digital_illustration/hand_drawn"
    | "digital_illustration/grain"
    | "digital_illustration/infantile_sketch"
    | "digital_illustration/2d_art_poster"
    | "digital_illustration/handmade_3d"
    | "digital_illustration/hand_drawn_outline"
    | "digital_illustration/engraving_color"
    | "digital_illustration/2d_art_poster_2"
    | "digital_illustration/antiquarian"
    | "digital_illustration/bold_fantasy"
    | "digital_illustration/child_book"
    | "digital_illustration/child_books"
    | "digital_illustration/cover"
    | "digital_illustration/crosshatch"
    | "digital_illustration/digital_engraving"
    | "digital_illustration/expressionism"
    | "digital_illustration/freehand_details"
    | "digital_illustration/grain_20"
    | "digital_illustration/graphic_intensity"
    | "digital_illustration/hard_comics"
    | "digital_illustration/long_shadow"
    | "digital_illustration/modern_folk"
    | "digital_illustration/multicolor"
    | "digital_illustration/neon_calm"
    | "digital_illustration/noir"
    | "digital_illustration/nostalgic_pastel"
    | "digital_illustration/outline_details"
    | "digital_illustration/pastel_gradient"
    | "digital_illustration/pastel_sketch"
    | "digital_illustration/pop_art"
    | "digital_illustration/pop_renaissance"
    | "digital_illustration/street_art"
    | "digital_illustration/tablet_sketch"
    | "digital_illustration/urban_glow"
    | "digital_illustration/urban_sketching"
    | "digital_illustration/vanilla_dreams"
    | "digital_illustration/young_adult_book"
    | "digital_illustration/young_adult_book_2"
    | "vector_illustration/bold_stroke"
    | "vector_illustration/chemistry"
    | "vector_illustration/colored_stencil"
    | "vector_illustration/contour_pop_art"
    | "vector_illustration/cosmics"
    | "vector_illustration/cutout"
    | "vector_illustration/depressive"
    | "vector_illustration/editorial"
    | "vector_illustration/emotional_flat"
    | "vector_illustration/infographical"
    | "vector_illustration/marker_outline"
    | "vector_illustration/mosaic"
    | "vector_illustration/naivector"
    | "vector_illustration/roundish_flat"
    | "vector_illustration/segmented_colors"
    | "vector_illustration/sharp_contrast"
    | "vector_illustration/thin"
    | "vector_illustration/vector_photo"
    | "vector_illustration/vivid_shapes"
    | "vector_illustration/engraving"
    | "vector_illustration/line_art"
    | "vector_illustration/line_circuit"
    | "vector_illustration/linocut";
  /**
   * Style Id
   *
   * The ID of the custom style reference (optional)
   */
  style_id?: string;
};

/**
 * Output
 */
export type FluxProV11UltraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProUltraTextToImageInput
 */
export type FluxProV11UltraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21"
    | string;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url?: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Image Prompt Strength
   *
   * The strength of the image prompt, between 0 and 1.
   */
  image_prompt_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Raw
   *
   * Generate less processed, more natural-looking images.
   */
  raw?: boolean;
};

/**
 * Imagen4TextToImageOutput
 */
export type Imagen4PreviewOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * Imagen4TextToImageInput
 */
export type Imagen4PreviewInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?: "1:1" | "16:9" | "9:16" | "4:3" | "3:4";
  /**
   * Resolution
   *
   * The resolution of the generated image.
   */
  resolution?: "1K" | "2K";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
};

/**
 * RemoveBackgroundOutput
 */
export type ImageutilsRembgOutput = {
  /**
   * Image
   *
   * Background removed image.
   */
  image: Image;
};

/**
 * RemoveBackgroundInput
 */
export type ImageutilsRembgInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Crop To Bbox
   *
   *
   * If set to true, the resulting image be cropped to a bounding box around the subject
   *
   */
  crop_to_bbox?: boolean;
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string;
};

/**
 * UpscaleOutput
 */
export type EsrganOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: Image;
};

/**
 * UpscaleInput
 */
export type EsrganInput = {
  /**
   * Model
   *
   * Model to use for upscaling
   */
  model?:
    | "RealESRGAN_x4plus"
    | "RealESRGAN_x2plus"
    | "RealESRGAN_x4plus_anime_6B"
    | "RealESRGAN_x4_v3"
    | "RealESRGAN_x4_wdn_v3"
    | "RealESRGAN_x4_anime_v3";
  /**
   * Face
   *
   * Upscaling a face
   */
  face?: boolean;
  /**
   * Scale
   *
   * Rescaling factor
   */
  scale?: number;
  /**
   * Tile
   *
   * Tile size. Default is 0, that is no tile. When encountering the out-of-GPU-memory issue, please specify it, e.g., 400 or 200
   */
  tile?: number;
  /**
   * Output Format
   *
   * Output image format (png or jpeg)
   */
  output_format?: "png" | "jpeg";
  /**
   * Image Url
   *
   * Url to input image
   */
  image_url: string;
};

/**
 * InpaintOutput
 */
export type InpaintOutput = {
  /**
   * Image
   *
   * The generated image files info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintInput
 */
export type InpaintInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Url
   *
   * Input image for img2img or inpaint mode
   */
  image_url: string;
  /**
   * Model Name
   *
   * URL or HuggingFace ID of the base model to generate the image.
   */
  model_name: string;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   * Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.
   */
  mask_url: string;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * LCMOutput
 */
export type LcmSd15I2iOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Num Inference Steps
   *
   *
   * Number of inference steps used to generate the image. It will be the same value of the one passed in the
   * input or the default one in case none was passed.
   *
   */
  num_inference_steps?: number;
  /**
   * Nsfw Content Detected
   *
   *
   * A list of booleans indicating whether the generated image contains any
   * potentially unsafe content. If the safety check is disabled, this field
   * will have a false for each generated image.
   *
   */
  nsfw_content_detected: Array<boolean>;
};

/**
 * LCMI2IInput
 */
export type LcmSd15I2iInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   *
   * The number of images to generate. The function will return a list of images
   * with the same prompt and negative prompt but different seeds.
   *
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The image to use as a base.
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength of the image.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checks
   *
   *
   * If set to true, the resulting image will be checked whether it includes any
   * potentially unsafe content. If it does, it will be replaced with a black
   * image.
   *
   */
  enable_safety_checks?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FastSdxlControlnetCannyInpaintingOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintingControlNetInput
 */
export type FastSdxlControlnetCannyInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FastSdxlControlnetCannyImageToImageOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageControlNetInput
 */
export type FastSdxlControlnetCannyImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ReferenceFace
 */
export type ReferenceFace = {
  /**
   * Image Url
   *
   * URL of the reference face image
   */
  image_url: string;
};

/**
 * OutputModel
 */
export type PulidOutput = {
  /**
   * Images
   *
   * List of generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Random seed used for reproducibility
   */
  seed: number;
};

/**
 * InputModel
 */
export type PulidInput = {
  /**
   * Prompt
   *
   * Prompt to generate the face from
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Size of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Id Scale
   *
   * ID scale
   */
  id_scale?: number;
  /**
   * Mode
   *
   * Mode of generation
   */
  mode?: "fidelity" | "extreme style";
  /**
   * Id Mix
   *
   * if you want to mix two ID image, please turn this on, otherwise, turn this off
   */
  id_mix?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance scale
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of steps to take
   */
  num_inference_steps?: number;
  /**
   * Reference Images
   *
   * List of reference faces, ideally 4 images.
   */
  reference_images: Array<ReferenceFace>;
  /**
   * Negative Prompt
   *
   * Negative prompt to generate the face from
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * Random seed for reproducibility
   */
  seed?: number;
};

/**
 * MarigoldDepthMapOutput
 */
export type ImageutilsMarigoldDepthOutput = {
  /**
   * Image
   *
   * The depth map.
   */
  image: Image;
};

/**
 * MarigoldDepthMapInput
 */
export type ImageutilsMarigoldDepthInput = {
  /**
   * Ensemble Size
   *
   * Number of predictions to average over. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.
   */
  ensemble_size?: number;
  /**
   * Num Inference Steps
   *
   * Number of denoising steps. Defaults to `10`. The higher the number, the more accurate the result, but the slower the inference.
   */
  num_inference_steps?: number;
  /**
   * Processing Res
   *
   * Maximum processing resolution. Defaults `0` which means it uses the size of the input image.
   */
  processing_res?: number;
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string;
};

/**
 * DepthMapOutput
 */
export type ImageutilsDepthOutput = {
  /**
   * Image
   *
   * The depth map.
   */
  image: Image;
};

/**
 * DepthMapInput
 */
export type ImageutilsDepthInput = {
  /**
   * Bg Th
   *
   * bg_th
   */
  bg_th?: number;
  /**
   * A
   *
   * a
   */
  a?: number;
  /**
   * Depth And Normal
   *
   * depth_and_normal
   */
  depth_and_normal?: boolean;
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string;
};

/**
 * RetoucherOutput
 */
export type RetoucherOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * RetoucherInput
 */
export type RetoucherInput = {
  /**
   * Seed
   *
   * Seed for reproducibility. Different seeds will make slightly different results.
   */
  seed?: number;
  /**
   * Image Url
   *
   * The URL of the image to be retouched.
   */
  image_url: string;
};

/**
 * Output
 */
export type FastLcmDiffusionImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageLCMInput
 */
export type FastLcmDiffusionImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Model Name
   *
   * The name of the model to use.
   */
  model_name?:
    | "stabilityai/stable-diffusion-xl-base-1.0"
    | "runwayml/stable-diffusion-v1-5";
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastLcmDiffusionInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintingLCMInput
 */
export type FastLcmDiffusionInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Model Name
   *
   * The name of the model to use.
   */
  model_name?:
    | "stabilityai/stable-diffusion-xl-base-1.0"
    | "runwayml/stable-diffusion-v1-5";
};

/**
 * Output
 */
export type PlaygroundV25InpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintingPlaygroundv25Input
 */
export type PlaygroundV25InpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FastLightningSdxlInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintingLightningInput
 */
export type FastLightningSdxlInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: "1" | "2" | "4" | "8";
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastLightningSdxlImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageLightningInput
 */
export type FastLightningSdxlImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean;
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: "1" | "2" | "4" | "8";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type PlaygroundV25ImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImagePlaygroundv25Input
 */
export type PlaygroundV25ImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Guidance Rescale
   *
   * The rescale factor for the CFG.
   */
  guidance_rescale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type BirefnetOutput = {
  /**
   * Image
   *
   * Image with background removed
   */
  image: ImageFile;
  /**
   * Mask Image
   *
   * Mask used to remove the background
   */
  mask_image?: ImageFile;
};

/**
 * Input
 */
export type BirefnetInput = {
  /**
   * Operating Resolution
   *
   * The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images.
   */
  operating_resolution?: "1024x1024" | "2048x2048";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "webp" | "png" | "gif";
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string;
  /**
   * Model
   *
   *
   * Model to use for background removal.
   * The 'General Use (Light)' model is the original model used in the BiRefNet repository.
   * The 'General Use (Heavy)' model is a slower but more accurate model.
   * The 'Portrait' model is a model trained specifically for portrait images.
   * The 'General Use (Light)' model is recommended for most use cases.
   *
   * The corresponding models are as follows:
   * - 'General Use (Light)': BiRefNet-DIS_ep580.pth
   * - 'General Use (Heavy)': BiRefNet-massive-epoch_240.pth
   * - 'Portrait': BiRefNet-portrait-TR_P3M_10k-epoch_120.pth
   *
   */
  model?: "General Use (Light)" | "General Use (Heavy)" | "Portrait";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Mask
   *
   * Whether to output the mask used to remove the background
   */
  output_mask?: boolean;
  /**
   * Refine Foreground
   *
   * Whether to refine the foreground using the estimated mask
   */
  refine_foreground?: boolean;
};

/**
 * CreativeUpscalerOutput
 */
export type CreativeUpscalerOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * CreativeUpscalerInput
 */
export type CreativeUpscalerInput = {
  /**
   * Shape Preservation
   *
   * How much to preserve the shape of the original image
   */
  shape_preservation?: number;
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results. If no prompt is provide BLIP2 will be used to generate a prompt.
   */
  prompt?: string | null;
  /**
   * Additional Embedding Url
   *
   * The URL to the additional embeddings to use for the upscaling. Default is None
   */
  additional_embedding_url?: string;
  /**
   * Enable Safety Checks
   *
   *
   * If set to true, the resulting image will be checked whether it includes any
   * potentially unsafe content. If it does, it will be replaced with a black
   * image.
   *
   */
  enable_safety_checks?: boolean;
  /**
   * Additional Lora Url
   *
   * The URL to the additional LORA model to use for the upscaling. Default is None
   */
  additional_lora_url?: string;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Scale
   *
   * The scale of the output image. The higher the scale, the bigger the output image will be.
   */
  scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Skip Ccsr
   *
   *
   * If set to true, the image will not be processed by the CCSR model before
   * being processed by the creativity model.
   *
   */
  skip_ccsr?: boolean;
  /**
   * Additional Lora Scale
   *
   * The scale of the additional LORA model to use for the upscaling. Default is 1.0
   */
  additional_lora_scale?: number;
  /**
   * Detail
   *
   * How much detail to add
   */
  detail?: number;
  /**
   * Base Model Url
   *
   * The URL to the base model to use for the upscaling
   */
  base_model_url?: string;
  /**
   * Image Url
   *
   * The image to upscale.
   */
  image_url: string;
  /**
   * Creativity
   *
   * How much the output can deviate from the original
   */
  creativity?: number;
  /**
   * Override Size Limits
   *
   *
   * Allow for large uploads that could take a very long time.
   *
   */
  override_size_limits?: boolean;
  /**
   * Prompt Suffix
   *
   * The suffix to add to the prompt. This is useful to add a common ending to all prompts such as 'high quality' etc or embedding tokens.
   */
  prompt_suffix?: string;
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number;
  /**
   * Model Type
   *
   * The type of model to use for the upscaling. Default is SD_1_5
   */
  model_type?: "SD_1_5" | "SDXL";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * PhotoMakerOutput
 */
export type PhotomakerOutput = {
  /**
   * Images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * PhotoMakerInput
 */
export type PhotomakerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Number of images
   *
   *
   * Number of images to generate in one request. Note that the higher the batch size,
   * the longer it will take to generate the images.
   *
   */
  num_images?: number;
  /**
   * Style strength (in %)
   */
  style_strength?: number;
  /**
   * Style
   */
  style?:
    | "(No style)"
    | "Cinematic"
    | "Disney Character"
    | "Digital Art"
    | "Photographic"
    | "Fantasy art"
    | "Neonpunk"
    | "Enhance"
    | "Comic book"
    | "Lowpoly"
    | "Line art";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image Archive Url
   *
   * The URL of the image archive containing the images you want to use.
   */
  image_archive_url: string;
  /**
   * Initial Image Url
   *
   * Optional initial image for img2img
   */
  initial_image_url?: string;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
  /**
   * Initial Image Strength
   *
   * How much noise to add to the latent image. O for no noise, 1 for maximum noise.
   */
  initial_image_strength?: number;
  /**
   * Base Pipeline
   *
   * The base pipeline to use for generating the image.
   */
  base_pipeline?: "photomaker" | "photomaker-style";
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
};

/**
 * FaceToStickerOutput
 */
export type FaceToStickerOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<Image>;
  /**
   * Sticker Image
   *
   * The generated face sticker image.
   */
  sticker_image: Image;
  /**
   * Sticker Image Background Removed
   *
   * The generated face sticker image with the background removed.
   */
  sticker_image_background_removed: Image;
  /**
   * Seed
   *
   * Seed used during the inference.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   *
   * Whether the generated images contain NSFW concepts.
   * The key is the image type and the value is a boolean.
   *
   */
  has_nsfw_concepts: {
    [key: string]: boolean;
  };
};

/**
 * FaceToStickerInput
 */
export type FaceToStickerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * IP adapter weight
   *
   * The weight of the IP adapter.
   */
  ip_adapter_weight?: number;
  /**
   * Image Url
   *
   * URL of the video.
   */
  image_url: string;
  /**
   * Upscale steps
   *
   * The number of steps to use for upscaling. Only used if `upscale` is `true`.
   */
  upscale_steps?: number;
  /**
   * Instant ID strength
   *
   * The strength of the instant ID.
   */
  instant_id_strength?: number;
  /**
   * Upscale
   *
   * Whether to upscale the image 2x.
   */
  upscale?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * IP adapter noise
   *
   * The amount of noise to add to the IP adapter.
   */
  ip_adapter_noise?: number;
};

/**
 * Output
 */
export type FastSdxlInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * InpaintingInput
 */
export type FastSdxlInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FastSdxlImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ImageToImageInput
 */
export type FastSdxlImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * OutputParameters
 */
export type LoraImageToImageOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<Image>;
  /**
   * Debug Latents
   *
   * The latents saved for debugging.
   */
  debug_latents?: File;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Debug Per Pass Latents
   *
   * The latents saved for debugging per pass.
   */
  debug_per_pass_latents?: File;
};

/**
 * ImageToImageInput
 */
export type LoraImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Noise Strength
   *
   * The amount of noise to add to noise image for image. Only used if the image_url is provided. 1.0 is complete noise and 0 is no noise.
   */
  noise_strength?: number;
  /**
   * Tile Height
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_height?: number;
  /**
   * Embeddings
   *
   *
   * The embeddings to use for the image generation. Only a single embedding is supported at the moment.
   * The embeddings will be used to map the tokens in the prompt to the embedding weights.
   *
   */
  embeddings?: Array<Embedding>;
  /**
   * Ic Light Model Url
   *
   *
   * The URL of the IC Light model to use for the image generation.
   *
   */
  ic_light_model_url?: string;
  /**
   * Image Encoder Weight Name
   *
   *
   * The weight name of the image encoder model to use for the image generation.
   *
   */
  image_encoder_weight_name?: string;
  /**
   * Ip Adapter
   *
   *
   * The IP adapter to use for the image generation.
   *
   */
  ip_adapter?: Array<IpAdapterType2>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler / sampler to use for the image denoising process.
   */
  scheduler?:
    | "DPM++ 2M"
    | "DPM++ 2M Karras"
    | "DPM++ 2M SDE"
    | "DPM++ 2M SDE Karras"
    | "Euler"
    | "Euler A"
    | "Euler (trailing timesteps)"
    | "LCM"
    | "LCM (trailing timesteps)"
    | "DDIM"
    | "TCD";
  /**
   * Sigmas
   *
   *
   * Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.
   * If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.
   *
   */
  sigmas?: SigmasInput;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Tile Stride Width
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_width?: number;
  /**
   * Debug Per Pass Latents
   *
   * If set to true, the latents will be saved for debugging per pass.
   */
  debug_per_pass_latents?: boolean;
  /**
   * Timesteps
   *
   *
   * Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.
   * If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.
   *
   */
  timesteps?: TimestepsInput;
  /**
   * Model Name
   *
   * URL or HuggingFace ID of the base model to generate the image.
   */
  model_name: string;
  /**
   * Prompt Weighting
   *
   *
   * If set to true, the prompt weighting syntax will be used.
   * Additionally, this will lift the 77 token limit by averaging embeddings.
   *
   */
  prompt_weighting?: boolean;
  /**
   * Variant
   *
   * The variant of the model to use for huggingface models, e.g. 'fp16'.
   */
  variant?: string;
  /**
   * Image Url
   *
   * URL of image to use for image to image/inpainting.
   */
  image_url?: string;
  /**
   * Controlnet Guess Mode
   *
   *
   * If set to true, the controlnet will be applied to only the conditional predictions.
   *
   */
  controlnet_guess_mode?: boolean;
  /**
   * Image Encoder Subfolder
   *
   *
   * The subfolder of the image encoder model to use for the image generation.
   *
   */
  image_encoder_subfolder?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Ic Light Model Background Image Url
   *
   *
   * The URL of the IC Light model background image to use for the image generation.
   * Make sure to use a background compatible with the model.
   *
   */
  ic_light_model_background_image_url?: string;
  /**
   * Rescale Betas Snr Zero
   *
   *
   * Whether to set the rescale_betas_snr_zero option or not for the sampler
   *
   */
  rescale_betas_snr_zero?: boolean;
  /**
   * Tile Width
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_width?: number;
  /**
   * Prediction Type
   *
   *
   * The type of prediction to use for the image generation.
   * The `epsilon` is the default.
   *
   */
  prediction_type?: "v_prediction" | "epsilon";
  /**
   * Eta
   *
   * The eta value to be used for the image generation.
   */
  eta?: number;
  /**
   * Image Encoder Path
   *
   *
   * The path to the image encoder model to use for the image generation.
   *
   */
  image_encoder_path?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Image Format
   *
   * The format of the generated image.
   */
  image_format?: "jpeg" | "png";
  /**
   * Number of images
   *
   *
   * Number of images to generate in one request. Note that the higher the batch size,
   * the longer it will take to generate the images.
   *
   */
  num_images?: number;
  /**
   * Debug Latents
   *
   * If set to true, the latents will be saved for debugging.
   */
  debug_latents?: boolean;
  /**
   * Ic Light Image Url
   *
   *
   * The URL of the IC Light model image to use for the image generation.
   *
   */
  ic_light_image_url?: string;
  /**
   * Unet Name
   *
   * URL or HuggingFace ID of the custom U-Net model to use for the image generation.
   */
  unet_name?: string;
  /**
   * Clip Skip
   *
   *
   * Skips part of the image generation process, leading to slightly different results.
   * This means the image renders faster, too.
   *
   */
  clip_skip?: number;
  /**
   * Tile Stride Height
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_height?: number;
  /**
   * Controlnets
   *
   *
   * The control nets to use for the image generation. You can use any number of control nets
   * and they will be applied to the image at the specified timesteps.
   *
   */
  controlnets?: Array<ControlNetType2>;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
};

/**
 * OutputParameters
 */
export type LoraInpaintOutput = {
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<Image>;
  /**
   * Debug Latents
   *
   * The latents saved for debugging.
   */
  debug_latents?: File;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Debug Per Pass Latents
   *
   * The latents saved for debugging per pass.
   */
  debug_per_pass_latents?: File;
};

/**
 * InpaintInput
 */
export type LoraInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Noise Strength
   *
   * The amount of noise to add to noise image for image. Only used if the image_url is provided. 1.0 is complete noise and 0 is no noise.
   */
  noise_strength?: number;
  /**
   * Tile Height
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_height?: number;
  /**
   * Embeddings
   *
   *
   * The embeddings to use for the image generation. Only a single embedding is supported at the moment.
   * The embeddings will be used to map the tokens in the prompt to the embedding weights.
   *
   */
  embeddings?: Array<Embedding>;
  /**
   * Ic Light Model Url
   *
   *
   * The URL of the IC Light model to use for the image generation.
   *
   */
  ic_light_model_url?: string;
  /**
   * Image Encoder Weight Name
   *
   *
   * The weight name of the image encoder model to use for the image generation.
   *
   */
  image_encoder_weight_name?: string;
  /**
   * Ip Adapter
   *
   *
   * The IP adapter to use for the image generation.
   *
   */
  ip_adapter?: Array<IpAdapterType2>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler / sampler to use for the image denoising process.
   */
  scheduler?:
    | "DPM++ 2M"
    | "DPM++ 2M Karras"
    | "DPM++ 2M SDE"
    | "DPM++ 2M SDE Karras"
    | "Euler"
    | "Euler A"
    | "Euler (trailing timesteps)"
    | "LCM"
    | "LCM (trailing timesteps)"
    | "DDIM"
    | "TCD";
  /**
   * Sigmas
   *
   *
   * Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.
   * If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.
   *
   */
  sigmas?: SigmasInput;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Tile Stride Width
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_width?: number;
  /**
   * Debug Per Pass Latents
   *
   * If set to true, the latents will be saved for debugging per pass.
   */
  debug_per_pass_latents?: boolean;
  /**
   * Timesteps
   *
   *
   * Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.
   * Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.
   * If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.
   *
   */
  timesteps?: TimestepsInput;
  /**
   * Model Name
   *
   * URL or HuggingFace ID of the base model to generate the image.
   */
  model_name: string;
  /**
   * Prompt Weighting
   *
   *
   * If set to true, the prompt weighting syntax will be used.
   * Additionally, this will lift the 77 token limit by averaging embeddings.
   *
   */
  prompt_weighting?: boolean;
  /**
   * Variant
   *
   * The variant of the model to use for huggingface models, e.g. 'fp16'.
   */
  variant?: string;
  /**
   * Image Url
   *
   * URL of image to use for image to image/inpainting.
   */
  image_url?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   * URL of black-and-white image to use as mask during inpainting.
   */
  mask_url?: string;
  /**
   * Image Encoder Subfolder
   *
   *
   * The subfolder of the image encoder model to use for the image generation.
   *
   */
  image_encoder_subfolder?: string;
  /**
   * Ic Light Model Background Image Url
   *
   *
   * The URL of the IC Light model background image to use for the image generation.
   * Make sure to use a background compatible with the model.
   *
   */
  ic_light_model_background_image_url?: string;
  /**
   * Rescale Betas Snr Zero
   *
   *
   * Whether to set the rescale_betas_snr_zero option or not for the sampler
   *
   */
  rescale_betas_snr_zero?: boolean;
  /**
   * Tile Width
   *
   * The size of the tiles to be used for the image generation.
   */
  tile_width?: number;
  /**
   * Controlnet Guess Mode
   *
   *
   * If set to true, the controlnet will be applied to only the conditional predictions.
   *
   */
  controlnet_guess_mode?: boolean;
  /**
   * Prediction Type
   *
   *
   * The type of prediction to use for the image generation.
   * The `epsilon` is the default.
   *
   */
  prediction_type?: "v_prediction" | "epsilon";
  /**
   * Eta
   *
   * The eta value to be used for the image generation.
   */
  eta?: number;
  /**
   * Image Encoder Path
   *
   *
   * The path to the image encoder model to use for the image generation.
   *
   */
  image_encoder_path?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Image Format
   *
   * The format of the generated image.
   */
  image_format?: "jpeg" | "png";
  /**
   * Number of images
   *
   *
   * Number of images to generate in one request. Note that the higher the batch size,
   * the longer it will take to generate the images.
   *
   */
  num_images?: number;
  /**
   * Debug Latents
   *
   * If set to true, the latents will be saved for debugging.
   */
  debug_latents?: boolean;
  /**
   * Ic Light Image Url
   *
   *
   * The URL of the IC Light model image to use for the image generation.
   *
   */
  ic_light_image_url?: string;
  /**
   * Unet Name
   *
   * URL or HuggingFace ID of the custom U-Net model to use for the image generation.
   */
  unet_name?: string;
  /**
   * Clip Skip
   *
   *
   * Skips part of the image generation process, leading to slightly different results.
   * This means the image renders faster, too.
   *
   */
  clip_skip?: number;
  /**
   * Tile Stride Height
   *
   * The stride of the tiles to be used for the image generation.
   */
  tile_stride_height?: number;
  /**
   * Controlnets
   *
   *
   * The control nets to use for the image generation. You can use any number of control nets
   * and they will be applied to the image at the specified timesteps.
   *
   */
  controlnets?: Array<ControlNetType2>;
  /**
   * Number of inference steps
   *
   *
   * Increasing the amount of steps tells Stable Diffusion that it should take more steps
   * to generate your final result which can increase the amount of detail in your image.
   *
   */
  num_inference_steps?: number;
};

/**
 * IpAdapterFaceIdOutput
 */
export type IpAdapterFaceIdOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * IpAdapterFaceIdInput
 */
export type IpAdapterFaceIdInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Face Image Url
   *
   * An image of a face to match. If an image with a size of 640x640 is not provided, it will be scaled and cropped to that size.
   */
  face_image_url?: string;
  /**
   * Width
   *
   *
   * The width of the generated image.
   *
   */
  width?: number;
  /**
   * Face Id Det Size
   *
   *
   * The size of the face detection model. The higher the number the more accurate
   * the detection will be but it will also take longer to run. The higher the number the more
   * likely it will fail to find a face as well. Lower it if you are having trouble
   * finding a face in the image.
   *
   */
  face_id_det_size?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Height
   *
   *
   * The height of the generated image.
   *
   */
  height?: number;
  /**
   * Num Samples
   *
   *
   * The number of samples for face id. The more samples the better the image will
   * be but it will also take longer to generate. Default is 4.
   *
   */
  num_samples?: number;
  /**
   * Base Sdxl Model Repo
   *
   * The URL to the base SDXL model. Default is SG161222/RealVisXL_V3.0
   */
  base_sdxl_model_repo?: string;
  /**
   * Base 1 5 Model Repo
   *
   * The URL to the base 1.5 model. Default is SG161222/Realistic_Vision_V4.0_noVAE
   */
  base_1_5_model_repo?: string;
  /**
   * Num Inference Steps
   *
   *
   * The number of inference steps to use for generating the image. The more steps
   * the better the image will be but it will also take longer to generate.
   *
   */
  num_inference_steps?: number;
  /**
   * Model Type
   *
   * The model type to use. 1_5 is the default and is recommended for most use cases.
   */
  model_type?:
    | "1_5-v1"
    | "1_5-v1-plus"
    | "1_5-v2-plus"
    | "SDXL-v1"
    | "SDXL-v2-plus"
    | "1_5-auraface-v1";
  /**
   * Face Images Data Url
   *
   *
   * URL to zip archive with images of faces. The images embedding will be averaged to
   * create a more accurate face id.
   *
   */
  face_images_data_url?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * OmniZeroOutput
 */
export type OmniZeroOutput = {
  /**
   * Image
   *
   * The generated image.
   */
  image: Image;
};

/**
 * OmniZeroInput
 */
export type OmniZeroInput = {
  /**
   * Prompt
   *
   * Prompt to guide the image generation.
   */
  prompt: string;
  /**
   * Identity Image Url
   *
   * Identity image url.
   */
  identity_image_url: string;
  /**
   * Identity Strength
   *
   * Identity strength.
   */
  identity_strength?: number;
  /**
   * Number Of Images
   *
   * Number of images.
   */
  number_of_images?: number;
  /**
   * Guidance Scale
   *
   * Guidance scale.
   */
  guidance_scale?: number;
  /**
   * Image Strength
   *
   * Image strength.
   */
  image_strength?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt to guide the image generation.
   */
  negative_prompt?: string;
  /**
   * Composition Image Url
   *
   * Composition image url.
   */
  composition_image_url: string;
  /**
   * Depth Strength
   *
   * Depth strength.
   */
  depth_strength?: number;
  /**
   * Composition Strength
   *
   * Composition strength.
   */
  composition_strength?: number;
  /**
   * Image Url
   *
   * Input image url.
   */
  image_url: string;
  /**
   * Style Image Url
   *
   * Style image url.
   */
  style_image_url: string;
  /**
   * Face Strength
   *
   * Face strength.
   */
  face_strength?: number;
  /**
   * Style Strength
   *
   * Style strength.
   */
  style_strength?: number;
  /**
   * Seed
   *
   * Seed.
   */
  seed?: number;
};

/**
 * CCSROutput
 */
export type CcsrOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * CCSRInput
 */
export type CcsrInput = {
  /**
   * Color Fix Type
   *
   * Type of color correction for samples.
   */
  color_fix_type?: "none" | "wavelet" | "adain";
  /**
   * Tile Diffusion Size
   *
   * Size of patch.
   */
  tile_diffusion_size?: number;
  /**
   * Tile Vae Decoder Size
   *
   * Size of VAE patch.
   */
  tile_vae_decoder_size?: number;
  /**
   * Tile Vae Encoder Size
   *
   * Size of latent image
   */
  tile_vae_encoder_size?: number;
  /**
   * T Min
   *
   * The starting point of uniform sampling strategy.
   */
  t_min?: number;
  /**
   * Image Url
   *
   * The URL or data URI of the image to upscale.
   */
  image_url: string;
  /**
   * Tile Diffusion Stride
   *
   * Stride of sliding patch.
   */
  tile_diffusion_stride?: number;
  /**
   * Tile Vae
   *
   * If specified, a patch-based sampling strategy will be used for VAE decoding.
   */
  tile_vae?: boolean;
  /**
   * Scale
   *
   * The scale of the output image. The higher the scale, the bigger the output image will be.
   */
  scale?: number;
  /**
   * Seed
   *
   * Seed for reproducibility. Different seeds will make slightly different results.
   */
  seed?: number;
  /**
   * T Max
   *
   * The ending point of uniform sampling strategy.
   */
  t_max?: number;
  /**
   * Steps
   *
   * The number of steps to run the model for. The higher the number the better the quality and longer it will take to generate.
   */
  steps?: number;
  /**
   * Tile Diffusion
   *
   * If specified, a patch-based sampling strategy will be used for sampling.
   */
  tile_diffusion?: "none" | "mix" | "gaussian";
};

/**
 * Output
 */
export type Sd15DepthControlnetOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageControlNetInput
 */
export type Sd15DepthControlnetInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Control Image Url
   *
   * The URL of the control image.
   */
  control_image_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Deep Cache
   *
   *
   * If set to true, DeepCache will be enabled. TBD
   *
   */
  enable_deep_cache?: boolean;
};

/**
 * DWPoseOutput
 */
export type DwposeOutput = {
  /**
   * Image
   *
   * The predicted pose image
   */
  image: Image;
};

/**
 * DWPoseInput
 */
export type DwposeInput = {
  /**
   * Draw Mode
   *
   * Mode of drawing the pose on the image. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.
   */
  draw_mode?:
    | "full-pose"
    | "body-pose"
    | "face-pose"
    | "hand-pose"
    | "face-hand-mask"
    | "face-mask"
    | "hand-mask";
  /**
   * Image Url
   *
   * URL of the image to be processed
   */
  image_url: string;
};

/**
 * SD3Output
 */
export type StableDiffusionV3MediumImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Number of Images
   *
   * The number of images generated.
   */
  num_images: number;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type StableDiffusionV3MediumImageToImageInput = {
  /**
   * Enhance Prompt
   *
   * If set to true, prompt will be upsampled with more details.
   */
  prompt_expansion?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Defaults to the conditioning image's size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength of the image-to-image transformation.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Region
 */
export type Region = {
  /**
   * Y1
   *
   * Y-coordinate of the top-left corner
   */
  y1: number;
  /**
   * X2
   *
   * X-coordinate of the bottom-right corner
   */
  x2: number;
  /**
   * X1
   *
   * X-coordinate of the top-left corner
   */
  x1: number;
  /**
   * Y2
   *
   * Y-coordinate of the bottom-right corner
   */
  y2: number;
};

/**
 * PolygonOutputWithLabels
 */
export type Florence2LargeRegionToSegmentationOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: PolygonOutput;
};

/**
 * Polygon
 */
export type Polygon = {
  /**
   * Points
   *
   * List of points
   */
  points: Array<{
    [key: string]: number;
  }>;
  /**
   * Label
   *
   * Label of the polygon
   */
  label: string;
};

/**
 * PolygonOutput
 */
export type PolygonOutput = {
  /**
   * Polygons
   *
   * List of polygons
   */
  polygons: Array<Polygon>;
};

/**
 * ImageWithUserCoordinatesInput
 */
export type Florence2LargeRegionToSegmentationInput = {
  /**
   * Region
   *
   * The user input coordinates
   */
  region: Region;
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * OCRBoundingBoxSingle
 */
export type OcrBoundingBoxSingle = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number;
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string;
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number;
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number;
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number;
};

/**
 * OCRBoundingBox
 */
export type OcrBoundingBox = {
  /**
   * Quad Boxes
   *
   * List of quadrilateral boxes
   */
  quad_boxes: Array<OcrBoundingBoxSingle>;
};

/**
 * OCRBoundingBoxOutputWithLabels
 */
export type Florence2LargeOcrWithRegionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: OcrBoundingBox;
};

/**
 * ImageInput
 */
export type Florence2LargeOcrWithRegionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeRegionProposalOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes;
};

/**
 * BoundingBox
 */
export type BoundingBox = {
  /**
   * Y
   *
   * Y-coordinate of the top-left corner
   */
  y: number;
  /**
   * Label
   *
   * Label of the bounding box
   */
  label: string;
  /**
   * H
   *
   * Height of the bounding box
   */
  h: number;
  /**
   * W
   *
   * Width of the bounding box
   */
  w: number;
  /**
   * X
   *
   * X-coordinate of the top-left corner
   */
  x: number;
};

/**
 * BoundingBoxes
 */
export type BoundingBoxes = {
  /**
   * Bboxes
   *
   * List of bounding boxes
   */
  bboxes: Array<BoundingBox>;
};

/**
 * ImageInput
 */
export type Florence2LargeRegionProposalInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeCaptionToPhraseGroundingOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes;
};

/**
 * ImageWithTextInput
 */
export type Florence2LargeCaptionToPhraseGroundingInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string;
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeOpenVocabularyDetectionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes;
};

/**
 * ImageWithTextInput
 */
export type Florence2LargeOpenVocabularyDetectionInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string;
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeObjectDetectionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes;
};

/**
 * ImageInput
 */
export type Florence2LargeObjectDetectionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * PolygonOutputWithLabels
 */
export type Florence2LargeReferringExpressionSegmentationOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: PolygonOutput;
};

/**
 * ImageWithTextInput
 */
export type Florence2LargeReferringExpressionSegmentationInput = {
  /**
   * Text Input
   *
   * Text input for the task
   */
  text_input: string;
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * BoundingBoxOutputWithLabels
 */
export type Florence2LargeDenseRegionCaptionOutput = {
  /**
   * Image
   *
   * Processed image
   */
  image?: Image;
  /**
   * Results
   *
   * Results from the model
   */
  results: BoundingBoxes;
};

/**
 * ImageInput
 */
export type Florence2LargeDenseRegionCaptionInput = {
  /**
   * Image Url
   *
   * The URL of the image to be processed.
   */
  image_url: string;
};

/**
 * Era3DOutput
 */
export type Era3dOutput = {
  /**
   * Images
   *
   * Images with background removed
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number;
  /**
   * Normal Images
   *
   * Normal images with background removed
   */
  normal_images: Array<ImageType3>;
};

/**
 * Era3DInput
 */
export type Era3dInput = {
  /**
   * Cfg
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  cfg?: number;
  /**
   * Background Removal
   *
   * Background removal
   */
  background_removal?: boolean;
  /**
   * Steps
   *
   * Number of steps to run the model for
   */
  steps?: number;
  /**
   * Crop Size
   *
   * Size of the image to crop to
   */
  crop_size?: number;
  /**
   * Seed
   *
   * Seed for random number generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string;
};

/**
 * Output
 */
export type SdxlControlnetUnionImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageControlNetUnionInput
 */
export type SdxlControlnetUnionImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Depth Preprocess
   *
   * Whether to preprocess the depth image.
   */
  depth_preprocess?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Normal Image Url
   *
   * The URL of the control image.
   */
  normal_image_url?: string;
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Teed Image Url
   *
   * The URL of the control image.
   */
  teed_image_url?: string;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Canny Image Url
   *
   * The URL of the control image.
   */
  canny_image_url?: string;
  /**
   * Segmentation Preprocess
   *
   * Whether to preprocess the segmentation image.
   */
  segmentation_preprocess?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Segmentation Image Url
   *
   * The URL of the control image.
   */
  segmentation_image_url?: string;
  /**
   * Openpose Image Url
   *
   * The URL of the control image.
   */
  openpose_image_url?: string;
  /**
   * Canny Preprocess
   *
   * Whether to preprocess the canny image.
   */
  canny_preprocess?: boolean;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Depth Image Url
   *
   * The URL of the control image.
   */
  depth_image_url?: string;
  /**
   * Normal Preprocess
   *
   * Whether to preprocess the normal image.
   */
  normal_preprocess?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Preserve Aspect Ratio
   *
   *
   * If set to true, the aspect ratio of the generated image will be preserved even
   * if the image size is too large. However, if the image is not a multiple of 32
   * in width or height, it will be resized to the nearest multiple of 32. By default,
   * this snapping to the nearest multiple of 32 will not preserve the aspect ratio.
   * Set crop_output to True, to crop the output to the proper aspect ratio
   * after generating.
   *
   */
  preserve_aspect_ratio?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Crop Output
   *
   *
   * If set to true, the output cropped to the proper aspect ratio after generating.
   *
   */
  crop_output?: boolean;
  /**
   * Teed Preprocess
   *
   * Whether to preprocess the teed image.
   */
  teed_preprocess?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Openpose Preprocess
   *
   * Whether to preprocess the openpose image.
   */
  openpose_preprocess?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type SdxlControlnetUnionInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintingControlNetUnionInput
 */
export type SdxlControlnetUnionInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt: string;
  /**
   * Depth Preprocess
   *
   * Whether to preprocess the depth image.
   */
  depth_preprocess?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image. Leave it none to automatically infer from the control image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Normal Image Url
   *
   * The URL of the control image.
   */
  normal_image_url?: string;
  /**
   * Embeddings
   *
   * The list of embeddings to use.
   */
  embeddings?: Array<Embedding>;
  /**
   * Teed Image Url
   *
   * The URL of the control image.
   */
  teed_image_url?: string;
  /**
   * Loras
   *
   * The list of LoRA weights to use.
   */
  loras?: Array<LoraWeightType2>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Canny Image Url
   *
   * The URL of the control image.
   */
  canny_image_url?: string;
  /**
   * Segmentation Preprocess
   *
   * Whether to preprocess the segmentation image.
   */
  segmentation_preprocess?: boolean;
  /**
   * Format
   *
   * The format of the generated image.
   */
  format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * The URL of the image to use as a starting point for the generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Request Id
   *
   *
   * An id bound to a request, can be used with response to identify the request
   * itself.
   *
   */
  request_id?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   * The URL of the mask to use for inpainting.
   */
  mask_url: string;
  /**
   * Segmentation Image Url
   *
   * The URL of the control image.
   */
  segmentation_image_url?: string;
  /**
   * Openpose Image Url
   *
   * The URL of the control image.
   */
  openpose_image_url?: string;
  /**
   * Canny Preprocess
   *
   * Whether to preprocess the canny image.
   */
  canny_preprocess?: boolean;
  /**
   * Expand Prompt
   *
   * If set to true, the prompt will be expanded with additional prompts.
   */
  expand_prompt?: boolean;
  /**
   * Depth Image Url
   *
   * The URL of the control image.
   */
  depth_image_url?: string;
  /**
   * Normal Preprocess
   *
   * Whether to preprocess the normal image.
   */
  normal_preprocess?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use.Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Teed Preprocess
   *
   * Whether to preprocess the teed image.
   */
  teed_preprocess?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Controlnet Conditioning Scale
   *
   * The scale of the controlnet conditioning.
   */
  controlnet_conditioning_scale?: number;
  /**
   * Strength
   *
   * determines how much the generated image resembles the initial image
   */
  strength?: number;
  /**
   * Safety Checker Version
   *
   * The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.
   */
  safety_checker_version?: "v1" | "v2";
  /**
   * Openpose Preprocess
   *
   * Whether to preprocess the openpose image.
   */
  openpose_preprocess?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxLoraImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type FluxLoraImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FluxGeneralDifferentialDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DifferentialDiffusionInput
 */
export type FluxGeneralDifferentialDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Proportion of steps to apply NAG
   *
   *
   * The proportion of steps to apply NAG. After the specified proportion
   * of steps has been iterated, the remaining steps will use original
   * attention processors in FLUX.
   *
   */
  nag_end?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Control Loras
   *
   *
   * The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  control_loras?: Array<ControlLoraWeight>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler for the denoising process.
   */
  scheduler?: "euler" | "dpmpp_2m";
  /**
   * Easycontrols
   *
   *
   * EasyControl Inputs to use for image generation.
   *
   */
  easycontrols?: Array<EasyControlWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Real CFG scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  real_cfg_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Use CFG-Zero-Init
   *
   *
   * Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.
   *
   */
  use_cfg_zero?: boolean;
  /**
   * Fill Image
   *
   * Use an image input to influence the generation. Can be used to fill images in masked areas.
   */
  fill_image?: ImageFillInput;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Sigma Schedule
   *
   * Sigmas schedule for the denoising process.
   */
  sigma_schedule?: "sgm_uniform";
  /**
   * Reference End
   *
   *
   * The percentage of the total timesteps when the reference guidance is to be ended.
   *
   */
  reference_end?: number;
  /**
   * Reference Strength
   *
   * Strength of reference_only generation. Only used if a reference image is provided.
   */
  reference_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image URL
   *
   * URL of image to use as initial image.
   */
  image_url: string;
  /**
   * NAG scale
   *
   *
   * The scale for NAG. Higher values will result in a image that is more distant
   * to the negative prompt.
   *
   */
  nag_scale?: number;
  /**
   * Reference Image Url
   *
   * URL of Image for Reference-Only
   */
  reference_image_url?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Controlnet Unions
   *
   *
   * The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnet_unions?: Array<ControlNetUnion>;
  /**
   * Negative Prompt
   *
   *
   * Negative prompt to steer the image generation away from unwanted features.
   * By default, we will be using NAG for processing the negative prompt.
   *
   */
  negative_prompt?: string;
  /**
   * NAG Tau
   *
   *
   * The tau for NAG. Controls the normalization of the hidden state.
   * Higher values will result in a less aggressive normalization,
   * but may also lead to unexpected changes with respect to the original image.
   * Not recommended to change this value.
   *
   */
  nag_tau?: number;
  /**
   * Change Map URL
   *
   * URL of change map.
   */
  change_map_image_url: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Use Beta Schedule
   *
   * Specifies whether beta sigmas ought to be used.
   */
  use_beta_schedule?: boolean;
  /**
   * Ip Adapters
   *
   *
   * IP-Adapter to use for image generation.
   *
   */
  ip_adapters?: Array<IpAdapter>;
  /**
   * Base Shift
   *
   * Base shift for the scheduled timesteps
   */
  base_shift?: number;
  /**
   * NAG alpha
   *
   *
   * The alpha value for NAG. This value is used as a final weighting
   * factor for steering the normalized guidance (positive and negative prompts)
   * in the direction of the positive prompt. Higher values will result in less
   * steering on the normalized guidance where lower values will result in
   * considering the positive prompt guidance more.
   *
   */
  nag_alpha?: number;
  /**
   * Strength
   *
   * The strength to use for differential diffusion. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Max Shift
   *
   * Max shift for the scheduled timesteps
   */
  max_shift?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Controlnets
   *
   *
   * The controlnets to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnets?: Array<ControlNet>;
  /**
   * Reference Start
   *
   *
   * The percentage of the total timesteps when the reference guidance is to bestarted.
   *
   */
  reference_start?: number;
  /**
   * Use Real CFG
   *
   *
   * Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.
   * If using XLabs IP-Adapter v1, this will be turned on!.
   *
   */
  use_real_cfg?: boolean;
};

/**
 * Output
 */
export type FluxGeneralImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type FluxGeneralImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Proportion of steps to apply NAG
   *
   *
   * The proportion of steps to apply NAG. After the specified proportion
   * of steps has been iterated, the remaining steps will use original
   * attention processors in FLUX.
   *
   */
  nag_end?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Control Loras
   *
   *
   * The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  control_loras?: Array<ControlLoraWeight>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler for the denoising process.
   */
  scheduler?: "euler" | "dpmpp_2m";
  /**
   * Easycontrols
   *
   *
   * EasyControl Inputs to use for image generation.
   *
   */
  easycontrols?: Array<EasyControlWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Real CFG scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  real_cfg_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Use CFG-Zero-Init
   *
   *
   * Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.
   *
   */
  use_cfg_zero?: boolean;
  /**
   * Fill Image
   *
   * Use an image input to influence the generation. Can be used to fill images in masked areas.
   */
  fill_image?: ImageFillInput;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Sigma Schedule
   *
   * Sigmas schedule for the denoising process.
   */
  sigma_schedule?: "sgm_uniform";
  /**
   * Reference End
   *
   *
   * The percentage of the total timesteps when the reference guidance is to be ended.
   *
   */
  reference_end?: number;
  /**
   * Reference Strength
   *
   * Strength of reference_only generation. Only used if a reference image is provided.
   */
  reference_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * NAG scale
   *
   *
   * The scale for NAG. Higher values will result in a image that is more distant
   * to the negative prompt.
   *
   */
  nag_scale?: number;
  /**
   * Reference Image Url
   *
   * URL of Image for Reference-Only
   */
  reference_image_url?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Controlnet Unions
   *
   *
   * The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnet_unions?: Array<ControlNetUnion>;
  /**
   * Negative Prompt
   *
   *
   * Negative prompt to steer the image generation away from unwanted features.
   * By default, we will be using NAG for processing the negative prompt.
   *
   */
  negative_prompt?: string;
  /**
   * NAG Tau
   *
   *
   * The tau for NAG. Controls the normalization of the hidden state.
   * Higher values will result in a less aggressive normalization,
   * but may also lead to unexpected changes with respect to the original image.
   * Not recommended to change this value.
   *
   */
  nag_tau?: number;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Use Beta Schedule
   *
   * Specifies whether beta sigmas ought to be used.
   */
  use_beta_schedule?: boolean;
  /**
   * Ip Adapters
   *
   *
   * IP-Adapter to use for image generation.
   *
   */
  ip_adapters?: Array<IpAdapter>;
  /**
   * Base Shift
   *
   * Base shift for the scheduled timesteps
   */
  base_shift?: number;
  /**
   * NAG alpha
   *
   *
   * The alpha value for NAG. This value is used as a final weighting
   * factor for steering the normalized guidance (positive and negative prompts)
   * in the direction of the positive prompt. Higher values will result in less
   * steering on the normalized guidance where lower values will result in
   * considering the positive prompt guidance more.
   *
   */
  nag_alpha?: number;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Max Shift
   *
   * Max shift for the scheduled timesteps
   */
  max_shift?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Controlnets
   *
   *
   * The controlnets to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnets?: Array<ControlNet>;
  /**
   * Reference Start
   *
   *
   * The percentage of the total timesteps when the reference guidance is to bestarted.
   *
   */
  reference_start?: number;
  /**
   * Use Real CFG
   *
   *
   * Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.
   * If using XLabs IP-Adapter v1, this will be turned on!.
   *
   */
  use_real_cfg?: boolean;
};

/**
 * Output
 */
export type FluxGeneralInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintInput
 */
export type FluxGeneralInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Proportion of steps to apply NAG
   *
   *
   * The proportion of steps to apply NAG. After the specified proportion
   * of steps has been iterated, the remaining steps will use original
   * attention processors in FLUX.
   *
   */
  nag_end?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Control Loras
   *
   *
   * The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  control_loras?: Array<ControlLoraWeight>;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Scheduler
   *
   * Scheduler for the denoising process.
   */
  scheduler?: "euler" | "dpmpp_2m";
  /**
   * Easycontrols
   *
   *
   * EasyControl Inputs to use for image generation.
   *
   */
  easycontrols?: Array<EasyControlWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Real CFG scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  real_cfg_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Use CFG-Zero-Init
   *
   *
   * Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.
   *
   */
  use_cfg_zero?: boolean;
  /**
   * Fill Image
   *
   * Use an image input to influence the generation. Can be used to fill images in masked areas.
   */
  fill_image?: ImageFillInput;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Sigma Schedule
   *
   * Sigmas schedule for the denoising process.
   */
  sigma_schedule?: "sgm_uniform";
  /**
   * Reference End
   *
   *
   * The percentage of the total timesteps when the reference guidance is to be ended.
   *
   */
  reference_end?: number;
  /**
   * Reference Strength
   *
   * Strength of reference_only generation. Only used if a reference image is provided.
   */
  reference_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string;
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * NAG scale
   *
   *
   * The scale for NAG. Higher values will result in a image that is more distant
   * to the negative prompt.
   *
   */
  nag_scale?: number;
  /**
   * Reference Image Url
   *
   * URL of Image for Reference-Only
   */
  reference_image_url?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Controlnet Unions
   *
   *
   * The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnet_unions?: Array<ControlNetUnion>;
  /**
   * Negative Prompt
   *
   *
   * Negative prompt to steer the image generation away from unwanted features.
   * By default, we will be using NAG for processing the negative prompt.
   *
   */
  negative_prompt?: string;
  /**
   * NAG Tau
   *
   *
   * The tau for NAG. Controls the normalization of the hidden state.
   * Higher values will result in a less aggressive normalization,
   * but may also lead to unexpected changes with respect to the original image.
   * Not recommended to change this value.
   *
   */
  nag_tau?: number;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Use Beta Schedule
   *
   * Specifies whether beta sigmas ought to be used.
   */
  use_beta_schedule?: boolean;
  /**
   * Ip Adapters
   *
   *
   * IP-Adapter to use for image generation.
   *
   */
  ip_adapters?: Array<IpAdapter>;
  /**
   * Base Shift
   *
   * Base shift for the scheduled timesteps
   */
  base_shift?: number;
  /**
   * NAG alpha
   *
   *
   * The alpha value for NAG. This value is used as a final weighting
   * factor for steering the normalized guidance (positive and negative prompts)
   * in the direction of the positive prompt. Higher values will result in less
   * steering on the normalized guidance where lower values will result in
   * considering the positive prompt guidance more.
   *
   */
  nag_alpha?: number;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Max Shift
   *
   * Max shift for the scheduled timesteps
   */
  max_shift?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Controlnets
   *
   *
   * The controlnets to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnets?: Array<ControlNet>;
  /**
   * Reference Start
   *
   *
   * The percentage of the total timesteps when the reference guidance is to bestarted.
   *
   */
  reference_start?: number;
  /**
   * Use Real CFG
   *
   *
   * Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.
   * If using XLabs IP-Adapter v1, this will be turned on!.
   *
   */
  use_real_cfg?: boolean;
};

/**
 * SAM2ImageOutput
 */
export type Sam2ImageOutput = {
  /**
   * Image
   *
   * Segmented image.
   */
  image: Image;
};

/**
 * SAM2ImageInput
 */
export type Sam2ImageInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Prompts
   *
   * List of prompts to segment the image
   */
  prompts?: Array<PointPromptType2>;
  /**
   * Box Prompts
   *
   * Coordinates for boxes
   */
  box_prompts?: Array<BoxPromptType2>;
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean;
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string;
};

/**
 * BoxPrompt
 */
export type BoxPromptType2 = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number;
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number;
  /**
   * X Max
   *
   * X Max Coordinate of the prompt
   */
  x_max?: number;
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number;
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt
   */
  y_max?: number;
};

/**
 * PointPrompt
 */
export type PointPromptType2 = {
  /**
   * Y
   *
   * Y Coordinate of the prompt
   */
  y?: number;
  /**
   * Label
   *
   * Label of the prompt. 1 for foreground, 0 for background
   */
  label?: 0 | 1;
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number;
  /**
   * X
   *
   * X Coordinate of the prompt
   */
  x?: number;
};

/**
 * PiDiOutput
 */
export type ImagePreprocessorsPidiOutput = {
  image: ImageType3;
};

/**
 * PiDiInput
 */
export type ImagePreprocessorsPidiInput = {
  /**
   * Safe
   *
   * Whether to use the safe version of the Pidi detector
   */
  safe?: boolean;
  /**
   * Apply Filter
   *
   * Whether to apply the filter to the image.
   */
  apply_filter?: boolean;
  /**
   * Scribble
   *
   * Whether to use the scribble version of the Pidi detector
   */
  scribble?: boolean;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * ZoeOutput
 */
export type ImagePreprocessorsZoeOutput = {
  image: ImageType3;
};

/**
 * ZoeInput
 */
export type ImagePreprocessorsZoeInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * LineartOutput
 */
export type ImagePreprocessorsLineartOutput = {
  image: ImageType3;
};

/**
 * LineartInput
 */
export type ImagePreprocessorsLineartInput = {
  /**
   * Coarse
   *
   * Whether to use the coarse model
   */
  coarse?: boolean;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * TeeDOutput
 */
export type ImagePreprocessorsTeedOutput = {
  image: ImageType3;
};

/**
 * TeeDInput
 */
export type ImagePreprocessorsTeedInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * MiDaSOutput
 */
export type ImagePreprocessorsMidasOutput = {
  normal_map: ImageType3;
  depth_map: ImageType3;
};

/**
 * MiDaSInput
 */
export type ImagePreprocessorsMidasInput = {
  /**
   * A
   *
   * A parameter for the MiDaS detector
   */
  a?: number;
  /**
   * Background Threshold
   *
   * Background threshold for the MiDaS detector
   */
  background_threshold?: number;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * SamOutput
 */
export type ImagePreprocessorsSamOutput = {
  image: ImageType3;
};

/**
 * SamInput
 */
export type ImagePreprocessorsSamInput = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * MLSDOutput
 */
export type ImagePreprocessorsMlsdOutput = {
  image: ImageType3;
};

/**
 * MLSDInput
 */
export type ImagePreprocessorsMlsdInput = {
  /**
   * Distance Threshold
   *
   * Distance threshold for the MLSD detector
   */
  distance_threshold?: number;
  /**
   * Score Threshold
   *
   * Score threshold for the MLSD detector
   */
  score_threshold?: number;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * ScribbleOutput
 */
export type ImagePreprocessorsScribbleOutput = {
  image: ImageType3;
};

/**
 * ScribbleInput
 */
export type ImagePreprocessorsScribbleInput = {
  /**
   * Model
   *
   * The model to use for the Scribble detector
   */
  model?: "HED" | "PiDi";
  /**
   * Safe
   *
   * Whether to use the safe version of the Scribble detector
   */
  safe?: boolean;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * DepthAnythingV2Output
 */
export type ImagePreprocessorsDepthAnythingV2Output = {
  image: ImageType3;
};

/**
 * DepthAnythingV2Input
 */
export type ImagePreprocessorsDepthAnythingV2Input = {
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * HEDOutput
 */
export type ImagePreprocessorsHedOutput = {
  image: ImageType3;
};

/**
 * HEDInput
 */
export type ImagePreprocessorsHedInput = {
  /**
   * Safe
   *
   * Whether to use the safe version of the HED detector
   */
  safe?: boolean;
  /**
   * Scribble
   *
   * Whether to use the scribble version of the HED detector
   */
  scribble?: boolean;
  /**
   * Image Url
   *
   * URL of the image to process
   */
  image_url: string;
};

/**
 * Output
 */
export type FluxGeneralRfInversionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * RFInversionInput
 */
export type FluxGeneralRfInversionInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with
   */
  prompt: string;
  /**
   * Proportion of steps to apply NAG
   *
   *
   * The proportion of steps to apply NAG. After the specified proportion
   * of steps has been iterated, the remaining steps will use original
   * attention processors in FLUX.
   *
   */
  nag_end?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | null;
  /**
   * Control Loras
   *
   *
   * The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  control_loras?: Array<ControlLoraWeight>;
  /**
   * Controller Guidance Reverse
   *
   * The controller guidance (eta) used in the denoising process.Using values closer to 1 will result in an image closer to input.
   */
  controller_guidance_reverse?: number;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Reverse Guidance Start
   *
   * Timestep to start guidance during reverse process.
   */
  reverse_guidance_start?: number;
  /**
   * Easycontrols
   *
   *
   * EasyControl Inputs to use for image generation.
   *
   */
  easycontrols?: Array<EasyControlWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Scheduler
   *
   * Scheduler for the denoising process.
   */
  scheduler?: "euler" | "dpmpp_2m";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Use CFG-Zero-Init
   *
   *
   * Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.
   *
   */
  use_cfg_zero?: boolean;
  /**
   * Reference Strength
   *
   * Strength of reference_only generation. Only used if a reference image is provided.
   */
  reference_strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Sigma Schedule
   *
   * Sigmas schedule for the denoising process.
   */
  sigma_schedule?: "sgm_uniform";
  /**
   * Reference End
   *
   *
   * The percentage of the total timesteps when the reference guidance is to be ended.
   *
   */
  reference_end?: number;
  /**
   * Controller Guidance Forward
   *
   * The controller guidance (gamma) used in the creation of structured noise.
   */
  controller_guidance_forward?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be edited
   */
  image_url: string;
  /**
   * Fill Image
   *
   * Use an image input to influence the generation. Can be used to fill images in masked areas.
   */
  fill_image?: ImageFillInput;
  /**
   * NAG scale
   *
   *
   * The scale for NAG. Higher values will result in a image that is more distant
   * to the negative prompt.
   *
   */
  nag_scale?: number;
  /**
   * Reverse Guidance Schedule
   *
   * Scheduler for applying reverse guidance.
   */
  reverse_guidance_schedule?:
    | "constant"
    | "linear_increase"
    | "linear_decrease";
  /**
   * Reference Image Url
   *
   * URL of Image for Reference-Only
   */
  reference_image_url?: string;
  /**
   * Reverse Guidance End
   *
   * Timestep to stop guidance during reverse process.
   */
  reverse_guidance_end?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Controlnet Unions
   *
   *
   * The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnet_unions?: Array<ControlNetUnion>;
  /**
   * Negative Prompt
   *
   *
   * Negative prompt to steer the image generation away from unwanted features.
   * By default, we will be using NAG for processing the negative prompt.
   *
   */
  negative_prompt?: string;
  /**
   * NAG Tau
   *
   *
   * The tau for NAG. Controls the normalization of the hidden state.
   * Higher values will result in a less aggressive normalization,
   * but may also lead to unexpected changes with respect to the original image.
   * Not recommended to change this value.
   *
   */
  nag_tau?: number;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Use Beta Schedule
   *
   * Specifies whether beta sigmas ought to be used.
   */
  use_beta_schedule?: boolean;
  /**
   * NAG alpha
   *
   *
   * The alpha value for NAG. This value is used as a final weighting
   * factor for steering the normalized guidance (positive and negative prompts)
   * in the direction of the positive prompt. Higher values will result in less
   * steering on the normalized guidance where lower values will result in
   * considering the positive prompt guidance more.
   *
   */
  nag_alpha?: number;
  /**
   * Base Shift
   *
   * Base shift for the scheduled timesteps
   */
  base_shift?: number;
  /**
   * Max Shift
   *
   * Max shift for the scheduled timesteps
   */
  max_shift?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Reference Start
   *
   *
   * The percentage of the total timesteps when the reference guidance is to bestarted.
   *
   */
  reference_start?: number;
  /**
   * Controlnets
   *
   *
   * The controlnets to use for the image generation. Only one controlnet is supported at the moment.
   *
   */
  controlnets?: Array<ControlNet>;
};

/**
 * LivePortraitImageOutput
 */
export type LivePortraitImageOutput = {
  /**
   * Image
   *
   * The generated image file.
   */
  image: Image;
};

/**
 * LivePortraitImageInput
 */
export type LivePortraitImageInput = {
  /**
   * Smile
   *
   * Amount to smile
   */
  smile?: number;
  /**
   * Eyebrow
   *
   * Amount to raise or lower eyebrows
   */
  eyebrow?: number;
  /**
   * Rotate Roll
   *
   * Amount to rotate the face in roll
   */
  rotate_roll?: number;
  /**
   * Wink
   *
   * Amount to wink
   */
  wink?: number;
  /**
   * Rotate Pitch
   *
   * Amount to rotate the face in pitch
   */
  rotate_pitch?: number;
  /**
   * Blink
   *
   * Amount to blink the eyes
   */
  blink?: number;
  /**
   * Dsize
   *
   * Size of the output image.
   */
  dsize?: number;
  /**
   * Vy Ratio
   *
   * Vertical offset ratio for face crop. Positive values move up, negative values move down.
   */
  vy_ratio?: number;
  /**
   * Scale
   *
   * Scaling factor for the face crop.
   */
  scale?: number;
  /**
   * Pupil X
   *
   * Amount to move pupils horizontally
   */
  pupil_x?: number;
  /**
   * Flag Pasteback
   *
   * Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.
   */
  flag_pasteback?: boolean;
  /**
   * Eee
   *
   * Amount to shape mouth in 'eee' position
   */
  eee?: number;
  /**
   * Enable Safety Checker
   *
   *
   * Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.
   * The safety checker will process the input image
   *
   */
  enable_safety_checker?: boolean;
  /**
   * Vx Ratio
   *
   * Horizontal offset ratio for face crop.
   */
  vx_ratio?: number;
  /**
   * Pupil Y
   *
   * Amount to move pupils vertically
   */
  pupil_y?: number;
  /**
   * Output Format
   *
   * Output format
   */
  output_format?: "jpeg" | "png";
  /**
   * Rotate Yaw
   *
   * Amount to rotate the face in yaw
   */
  rotate_yaw?: number;
  /**
   * Flag Do Rot
   *
   * Whether to conduct the rotation when flag_do_crop is True.
   */
  flag_do_rot?: boolean;
  /**
   * Woo
   *
   * Amount to shape mouth in 'woo' position
   */
  woo?: number;
  /**
   * Aaa
   *
   * Amount to open mouth in 'aaa' shape
   */
  aaa?: number;
  /**
   * Image Url
   *
   * URL of the image to be animated
   */
  image_url: string;
  /**
   * Flag Do Crop
   *
   * Whether to crop the source portrait to the face-cropping space.
   */
  flag_do_crop?: boolean;
  /**
   * Flag Lip Zero
   *
   * Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.
   */
  flag_lip_zero?: boolean;
};

/**
 * Output
 */
export type BirefnetV2Output = {
  /**
   * Image
   *
   * Image with background removed
   */
  image: ImageFile;
  /**
   * Mask Image
   *
   * Mask used to remove the background
   */
  mask_image?: ImageFile;
};

/**
 * InputV2
 */
export type BirefnetV2Input = {
  /**
   * Operating Resolution
   *
   * The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.
   */
  operating_resolution?: "1024x1024" | "2048x2048" | "2304x2304";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "webp" | "png" | "gif";
  /**
   * Image Url
   *
   * URL of the image to remove background from
   */
  image_url: string;
  /**
   * Model
   *
   *
   * Model to use for background removal.
   * The 'General Use (Light)' model is the original model used in the BiRefNet repository.
   * The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.
   * The 'General Use (Heavy)' model is a slower but more accurate model.
   * The 'Matting' model is a model trained specifically for matting images.
   * The 'Portrait' model is a model trained specifically for portrait images.
   * The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.
   * The 'General Use (Light)' model is recommended for most use cases.
   *
   * The corresponding models are as follows:
   * - 'General Use (Light)': BiRefNet
   * - 'General Use (Light 2K)': BiRefNet_lite-2K
   * - 'General Use (Heavy)': BiRefNet_lite
   * - 'Matting': BiRefNet-matting
   * - 'Portrait': BiRefNet-portrait
   * - 'General Use (Dynamic)': BiRefNet_dynamic
   *
   */
  model?:
    | "General Use (Light)"
    | "General Use (Light 2K)"
    | "General Use (Heavy)"
    | "Matting"
    | "Portrait"
    | "General Use (Dynamic)";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Mask
   *
   * Whether to output the mask used to remove the background
   */
  output_mask?: boolean;
  /**
   * Refine Foreground
   *
   * Whether to refine the foreground using the estimated mask
   */
  refine_foreground?: boolean;
};

/**
 * Output
 */
export type FluxPulidOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxPulidInput
 */
export type FluxPulidInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Id Weight
   *
   * The weight of the ID loss.
   */
  id_weight?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Start Step
   *
   * The number of steps to start the CFG from.
   */
  start_step?: number;
  /**
   * Reference Image URL
   *
   * URL of image to use for inpainting.
   */
  reference_image_url: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Max Sequence Length
   *
   * The maximum sequence length for the model.
   */
  max_sequence_length?: "128" | "256" | "512";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * True Cfg
   *
   * The weight of the CFG loss.
   */
  true_cfg?: number;
};

/**
 * Output
 */
export type FluxDifferentialDiffusionOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * DiffInput
 */
export type FluxDifferentialDiffusionInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image URL
   *
   * URL of image to use as initial image.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Change Map URL
   *
   * URL of change map.
   */
  change_map_image_url: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type IclightV2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseInput
 */
export type IclightV2Input = {
  /**
   * Initial Latent
   *
   *
   * Provide lighting conditions for the model
   *
   */
  initial_latent?: "None" | "Left" | "Right" | "Top" | "Bottom";
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Background Threshold
   *
   * Threshold for the background removal algorithm. A high threshold will produce sharper masks. Note: This parameter is currently deprecated and has no effect on the output.
   */
  background_threshold?: number;
  /**
   * Mask Image Url
   *
   * URL of mask to be used for ic-light conditioning image
   */
  mask_image_url?: string;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Lowres Denoise
   *
   * Strength for low-resolution pass.
   */
  lowres_denoise?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * Negative Prompt for the image
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Hr Downscale
   */
  hr_downscale?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Highres Denoise
   *
   * Strength for high-resolution pass. Only used if enable_hr_fix is True.
   */
  highres_denoise?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Hr Fix
   *
   * Use HR fix
   */
  enable_hr_fix?: boolean;
  /**
   * Cfg
   *
   * The real classifier-free-guidance scale for the generation.
   */
  cfg?: number;
};

/**
 * Output
 */
export type KolorsImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KolorsImg2ImgInput
 */
export type KolorsImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for image to image
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and
   * uploaded before returning the response. This will increase the latency of
   * the function but it allows you to get the image directly in the response
   * without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Scheduler
   *
   * The scheduler to use for the model.
   */
  scheduler?:
    | "EulerDiscreteScheduler"
    | "EulerAncestralDiscreteScheduler"
    | "DPMSolverMultistepScheduler"
    | "DPMSolverMultistepScheduler_SDE_karras"
    | "UniPCMultistepScheduler"
    | "DEISMultistepScheduler";
  /**
   * Strength
   *
   * The strength to use for image-to-image. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show
   * you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Seed
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small
   * details (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * Enable safety checker.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type FluxDevReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseReduxInput
 */
export type FluxDevReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxProV1FillOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProFillInput
 */
export type FluxProV1FillInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxProV11UltraReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProUltraTextToImageInputRedux
 */
export type FluxProV11UltraReduxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21"
    | string;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Image Prompt Strength
   *
   * The strength of the image prompt, between 0 and 1.
   */
  image_prompt_strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Raw
   *
   * Generate less processed, more natural-looking images.
   */
  raw?: boolean;
};

/**
 * Output
 */
export type FluxLoraDepthOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DepthInput
 */
export type FluxLoraDepthInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for depth input
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * Output
 */
export type FluxProV11ReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProRedux
 */
export type FluxProV11ReduxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxSchnellReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SchnellReduxInput
 */
export type FluxSchnellReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type IdeogramV2TurboRemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * RemixImageInput
 */
export type IdeogramV2TurboRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * Output
 */
export type IdeogramV2TurboEditOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * EditImageInput
 */
export type IdeogramV2TurboEditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string;
};

/**
 * Output
 */
export type IdeogramV2RemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * RemixImageInput
 */
export type IdeogramV2RemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * Output
 */
export type IdeogramV2EditOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * EditImageInput
 */
export type IdeogramV2EditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string;
};

/**
 * VTONOutput
 */
export type LeffaVirtualTryonOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: Image;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the image contains NSFW concepts.
   */
  has_nsfw_concepts: boolean;
};

/**
 * VTONInput
 */
export type LeffaVirtualTryonInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string;
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Garment Type
   *
   * The type of the garment used for virtual try-on.
   */
  garment_type: "upper_body" | "lower_body" | "dresses";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your input when generating the image.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * PoseTransferOutput
 */
export type LeffaPoseTransferOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: Image;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the image contains NSFW concepts.
   */
  has_nsfw_concepts: boolean;
};

/**
 * PoseTransferInput
 */
export type LeffaPoseTransferInput = {
  /**
   * Pose Image Url
   *
   * Url for the human image.
   */
  pose_image_url: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your input when generating the image.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Person Image Url
   *
   * Url to the garment image.
   */
  person_image_url: string;
};

/**
 * CATVTONOutput
 */
export type CatVtonOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: Image;
};

/**
 * CATVTONInput
 */
export type CatVtonInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string;
  /**
   * Cloth Type
   *
   *
   * Type of the Cloth to be tried on.
   *
   * Options:
   * upper: Upper body cloth
   * lower: Lower body cloth
   * overall: Full body cloth
   * inner: Inner cloth, like T-shirt inside a jacket
   * outer: Outer cloth, like a jacket over a T-shirt
   *
   */
  cloth_type: "upper" | "lower" | "overall" | "inner" | "outer";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same input given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ImageFillInput
 */
export type ImageFillInputType2 = {
  /**
   * In Context Fill
   *
   * Uses the provided fill image in context with the base image to fill in more faithfully. Will increase price.
   */
  in_context_fill?: boolean;
  /**
   * Use Prompt
   *
   * Whether to use the prompt as well in the generation, along with the redux image.
   */
  use_prompt?: boolean;
  /**
   * Fill Image Url
   *
   * URLs of images to be filled into the masked area.
   */
  fill_image_url?: Array<string> | string;
};

/**
 * Output
 */
export type FluxLoraFillOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * FillInput
 */
export type FluxLoraFillInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string;
  /**
   * Resize To Original
   *
   * Resizes the image back to the original size. Use when you wish to preserve the exact image size as the originally provided image.
   */
  resize_to_original?: boolean;
  /**
   * Paste Back
   *
   * Specifies whether to paste-back the original image onto to the non-inpainted areas of the output
   */
  paste_back?: boolean;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for fill operation
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Fill Image
   *
   * Use an image fill input to fill in particular images into the masked area.
   */
  fill_image?: ImageFillInputType2;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * BGReplaceOutput
 */
export type BriaBackgroundReplaceOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * BGReplaceInput
 */
export type BriaBackgroundReplaceInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of Images to generate.
   */
  num_images?: number;
  /**
   * Ref Image Url
   *
   * The URL of the reference image to be used for generating the new background. Use "" to leave empty. Either ref_image_url or bg_prompt has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.
   */
  ref_image_url?: string;
  /**
   * Refine Prompt
   *
   * Whether to refine prompt
   */
  refine_prompt?: boolean;
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
};

/**
 * BGRemoveOutput
 */
export type BriaBackgroundRemoveOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: Image;
};

/**
 * BGRemoveInput
 */
export type BriaBackgroundRemoveInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string;
};

/**
 * ProductShotOutput
 */
export type BriaProductShotOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
};

/**
 * ProductShotInput
 */
export type BriaProductShotInput = {
  /**
   * Ref Image Url
   *
   * The URL of the reference image to be used for generating the new scene or background for the product shot. Use "" to leave empty.Either ref_image_url or scene_description has to be provided but not both. If both ref_image_url and ref_image_file are provided, ref_image_url will be used. Accepted formats are jpeg, jpg, png, webp.
   */
  ref_image_url?: string;
  /**
   * Manual Placement Selection
   *
   * If you've selected placement_type=manual_placement, you should use this parameter to specify which placements/positions you would like to use from the list. You can select more than one placement in one request.
   */
  manual_placement_selection?:
    | "upper_left"
    | "upper_right"
    | "bottom_left"
    | "bottom_right"
    | "right_center"
    | "left_center"
    | "upper_center"
    | "bottom_center"
    | "center_vertical"
    | "center_horizontal";
  /**
   * Num Results
   *
   * The number of lifestyle product shots you would like to generate. You will get num_results x 10 results when placement_type=automatic and according to the number of required placements x num_results if placement_type=manual_placement.
   */
  num_results?: number;
  /**
   * Padding Values
   *
   * The desired padding in pixels around the product, when using placement_type=manual_padding. The order of the values is [left, right, top, bottom]. For optimal results, the total number of pixels, including padding, should be around 1,000,000. It is recommended to first use the product cutout API, get the cutout and understand the size of the result, and then define the required padding and use the cutout as an input for this API.
   */
  padding_values?: Array<number>;
  /**
   * Shot Size
   *
   * The desired size of the final product shot. For optimal results, the total number of pixels should be around 1,000,000. This parameter is only relevant when placement_type=automatic or placement_type=manual_placement.
   */
  shot_size?: Array<number>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Placement Type
   *
   * This parameter allows you to control the positioning of the product in the image. Choosing 'original' will preserve the original position of the product in the image. Choosing 'automatic' will generate results with the 10 recommended positions for the product. Choosing 'manual_placement' will allow you to select predefined positions (using the parameter 'manual_placement_selection'). Selecting 'manual_padding' will allow you to control the position and size of the image by defining the desired padding in pixels around the product.
   */
  placement_type?:
    | "original"
    | "automatic"
    | "manual_placement"
    | "manual_padding";
  /**
   * Original Quality
   *
   * This flag is only relevant when placement_type=original. If true, the output image retains the original input image's size; otherwise, the image is scaled to 1 megapixel (1MP) while preserving its aspect ratio.
   */
  original_quality?: boolean;
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean;
  /**
   * Optimize Description
   *
   * Whether to optimize the scene description
   */
  optimize_description?: boolean;
  /**
   * Scene Description
   *
   * Text description of the new scene or background for the provided product shot. Bria currently supports prompts in English only, excluding special characters.
   */
  scene_description?: string;
  /**
   * Image Url
   *
   * The URL of the product shot to be placed in a lifestyle shot. If both image_url and image_file are provided, image_url will be used. Accepted formats are jpeg, jpg, png, webp. Maximum file size 12MB.
   */
  image_url: string;
};

/**
 * GenFillOutput
 */
export type BriaGenfillOutput = {
  /**
   * Images
   *
   * Generated Images
   */
  images: Array<Image>;
};

/**
 * GenFillInput
 */
export type BriaGenfillInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of Images to generate.
   */
  num_images?: number;
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask Url
   *
   * The URL of the binary mask image that represents the area that will be cleaned.
   */
  mask_url: string;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
};

/**
 * ImageExpansionOutput
 */
export type BriaExpandOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: Image;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * ImageExpansionInput
 */
export type BriaExpandInput = {
  /**
   * Prompt
   *
   * Text on which you wish to base the image expansion. This parameter is optional. Bria currently supports prompts in English only, excluding special characters.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the final image. Will be used over original_image_size and original_image_location if provided.
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Original Image Location
   *
   * The desired location of the original image, inside the full canvas. Provide the location of the upper left corner of the original image. The location can also be outside the canvas (the original image will be cropped). Will be ignored if aspect_ratio is provided.
   */
  original_image_location?: Array<number>;
  /**
   * Image Url
   *
   * The URL of the input image.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Original Image Size
   *
   * The desired size of the original image, inside the full canvas. Ensure that the ratio of input image foreground or main subject to the canvas area is greater than 15% to achieve optimal results. Will be ignored if aspect_ratio is provided.
   */
  original_image_size?: Array<number>;
  /**
   * Canvas Size
   *
   * The desired size of the final image, after the expansion. should have an area of less than 5000x5000 pixels.
   */
  canvas_size: Array<number>;
  /**
   * Seed
   *
   * You can choose whether you want your generated expension to be random or predictable. You can recreate the same result in the future by using the seed value of a result from the response. You can exclude this parameter if you are not interested in recreating your results. This parameter is optional.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt you would like to use to generate images.
   */
  negative_prompt?: string;
};

/**
 * EraserOutput
 */
export type BriaEraserOutput = {
  /**
   * Image
   *
   * The generated image
   */
  image: Image;
};

/**
 * EraserInput
 */
export type BriaEraserInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Preserve Alpha
   *
   *
   * If set to true, attempts to preserve the alpha channel of the input image.
   *
   */
  preserve_alpha?: boolean;
  /**
   * Mask Url
   *
   * The URL of the binary mask image that represents the area that will be cleaned.
   */
  mask_url: string;
  /**
   * Mask Type
   *
   * You can use this parameter to specify the type of the input mask from the list. 'manual' opttion should be used in cases in which the mask had been generated by a user (e.g. with a brush tool), and 'automatic' mask type should be used when mask had been generated by an algorithm like 'SAM'.
   */
  mask_type?: "manual" | "automatic";
  /**
   * Image Url
   *
   * Input Image to erase from
   */
  image_url: string;
};

/**
 * DetectionOutput
 */
export type MoondreamNextDetectionOutput = {
  /**
   * Output Image
   *
   * Output image with detection visualization
   */
  image?: Image;
  /**
   * Text Output
   *
   * Detection results as text
   */
  text_output: string;
};

/**
 * DetectionInput
 */
export type MoondreamNextDetectionInput = {
  /**
   * Detection Prompt
   *
   * Text description of what to detect
   */
  detection_prompt: string;
  /**
   * Use Ensemble
   *
   * Whether to use ensemble for gaze detection
   */
  use_ensemble?: boolean;
  /**
   * Task Type
   *
   * Type of detection to perform
   */
  task_type: "bbox_detection" | "point_detection" | "gaze_detection";
  /**
   * Show Visualization
   *
   * Whether to show visualization for detection
   */
  show_visualization?: boolean;
  /**
   * Combine Points
   *
   * Whether to combine points into a single point for point detection. This has no effect for bbox detection or gaze detection.
   */
  combine_points?: boolean;
  /**
   * Image URL
   *
   * Image URL to be processed
   */
  image_url: string;
};

/**
 * Output
 */
export type FluxProV1FillFinetunedOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxProFillFinetunedInput
 */
export type FluxProV1FillFinetunedInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Fine-tune Strength
   *
   *
   * Controls finetune influence.
   * Increase this value if your target concept isn't showing up strongly enough.
   * The optimal setting depends on your finetune and prompt
   *
   */
  finetune_strength: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Fine-tune ID
   *
   * References your specific model
   */
  finetune_id: string;
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. Needs to match the dimensions of the input image.
   */
  mask_url: string;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxLoraCannyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * CannyInput
 */
export type FluxLoraCannyInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for canny input
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * TryOnOutput
 */
export type KlingV15KolorsVirtualTryOnOutput = {
  /**
   * Image
   *
   * The output image.
   */
  image: Image;
};

/**
 * TryOnRequest
 */
export type KlingV15KolorsVirtualTryOnInput = {
  /**
   * Garment Image Url
   *
   * Url to the garment image.
   */
  garment_image_url: string;
  /**
   * Sync Mode
   *
   * If true, the function will return the image in the response.
   */
  sync_mode?: boolean;
  /**
   * Human Image Url
   *
   * Url for the human image.
   */
  human_image_url: string;
};

/**
 * ConformerOutput
 */
export type CodeformerOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * CodeformerInput
 */
export type CodeformerInput = {
  /**
   * Aligned
   *
   * Should faces etc should be aligned.
   */
  aligned?: boolean;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
  /**
   * Upscale Factor
   *
   * Upscaling factor
   */
  upscale_factor?: number;
  /**
   * Fidelity
   *
   * Weight of the fidelity factor.
   */
  fidelity?: number;
  /**
   * Face Upscale
   *
   * Should faces be upscaled
   */
  face_upscale?: boolean;
  /**
   * Only Center Face
   *
   * Should only center face be restored
   */
  only_center_face?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
};

/**
 * UpscaleOutput
 */
export type IdeogramUpscaleOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * UpscaleImageInput
 */
export type IdeogramUpscaleInput = {
  /**
   * Prompt
   *
   * The prompt to upscale the image with
   */
  prompt?: string | unknown;
  /**
   * Detail
   *
   * The detail of the upscaled image
   */
  detail?: number;
  /**
   * Resemblance
   *
   * The resemblance of the upscaled image to the original image
   */
  resemblance?: number;
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to upscale
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * Output
 */
export type FluxControlLoraDepthImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type FluxControlLoraDepthImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FluxControlLoraCannyImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type FluxControlLoraCannyImageToImageInput = {
  /**
   * Control Lora Strength
   *
   * The strength of the control lora.
   */
  control_lora_strength?: number;
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Control Lora Image Url
   *
   *
   * The image to use for control lora. This is used to control the style of the generated image.
   *
   */
  control_lora_image_url?: string;
};

/**
 * Ben2OutputImage
 */
export type BenV2ImageOutput = {
  /**
   * Image
   *
   * The output image after background removal.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Ben2InputImage
 */
export type BenV2ImageInput = {
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for background removal
   */
  image_url: string;
};

/**
 * FlowEditOutput
 */
export type FloweditOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FlowEditInput
 */
export type FloweditInput = {
  /**
   * Source Guidance scale (CFG)
   *
   * Guidance scale for the source.
   */
  src_guidance_scale?: number;
  /**
   * N Min
   *
   * Minimum step for improved style edits
   */
  n_min?: number;
  /**
   * N Max
   *
   * Control the strength of the edit
   */
  n_max?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
  /**
   * Source Prompt
   *
   * Prompt of the image to be used.
   */
  source_prompt: string;
  /**
   * Target Guidance scale (CFG)
   *
   * Guidance scale for target.
   */
  tar_guidance_scale?: number;
  /**
   * Target Prompt
   *
   * Prompt of the image to be made.
   */
  target_prompt: string;
  /**
   * Seed
   *
   * Random seed for reproducible generation. If set none, a random seed will be used.
   */
  seed?: number;
  /**
   * Steps
   *
   * Steps for which the model should run.
   */
  num_inference_steps?: number;
  /**
   * N Avg
   *
   * Average step count
   */
  n_avg?: number;
};

/**
 * ProcessedOutput
 */
export type PostProcessingOutput = {
  /**
   * Images
   *
   * The processed images
   */
  images: Array<Image>;
};

/**
 * ImageProcessingInput
 */
export type PostProcessingInput = {
  /**
   * Blue Shift
   *
   * Blue channel shift amount
   */
  blue_shift?: number;
  /**
   * Vertex Y
   *
   * Vertex Y position
   */
  vertex_y?: number;
  /**
   * Green Direction
   *
   * Green channel shift direction
   */
  green_direction?: "horizontal" | "vertical";
  /**
   * Enable Glow
   *
   * Enable glow effect
   */
  enable_glow?: boolean;
  /**
   * Dodge Burn Mode
   *
   * Dodge and burn mode
   */
  dodge_burn_mode?:
    | "dodge"
    | "burn"
    | "dodge_and_burn"
    | "burn_and_dodge"
    | "color_dodge"
    | "color_burn"
    | "linear_dodge"
    | "linear_burn";
  /**
   * Glow Intensity
   *
   * Glow intensity
   */
  glow_intensity?: number;
  /**
   * Blur Sigma
   *
   * Sigma for Gaussian blur
   */
  blur_sigma?: number;
  /**
   * Desaturate Method
   *
   * Desaturation method
   */
  desaturate_method?:
    | "luminance (Rec.709)"
    | "luminance (Rec.601)"
    | "average"
    | "lightness";
  /**
   * Enable Blur
   *
   * Enable blur effect
   */
  enable_blur?: boolean;
  /**
   * Blur Radius
   *
   * Blur radius
   */
  blur_radius?: number;
  /**
   * Grain Style
   *
   * Style of film grain to apply
   */
  grain_style?:
    | "modern"
    | "analog"
    | "kodak"
    | "fuji"
    | "cinematic"
    | "newspaper";
  /**
   * Cas Amount
   *
   * CAS sharpening amount
   */
  cas_amount?: number;
  /**
   * Gamma
   *
   * Gamma adjustment
   */
  gamma?: number;
  /**
   * Tint Mode
   *
   * Tint color mode
   */
  tint_mode?:
    | "sepia"
    | "red"
    | "green"
    | "blue"
    | "cyan"
    | "magenta"
    | "yellow"
    | "purple"
    | "orange"
    | "warm"
    | "cool"
    | "lime"
    | "navy"
    | "vintage"
    | "rose"
    | "teal"
    | "maroon"
    | "peach"
    | "lavender"
    | "olive";
  /**
   * Blur Type
   *
   * Type of blur to apply
   */
  blur_type?: "gaussian" | "kuwahara";
  /**
   * Enable Vignette
   *
   * Enable vignette effect
   */
  enable_vignette?: boolean;
  /**
   * Dissolve Image Url
   *
   * URL of second image for dissolve
   */
  dissolve_image_url?: string;
  /**
   * Red Shift
   *
   * Red channel shift amount
   */
  red_shift?: number;
  /**
   * Enable Desaturate
   *
   * Enable desaturation effect
   */
  enable_desaturate?: boolean;
  /**
   * Grain Intensity
   *
   * Film grain intensity (when enabled)
   */
  grain_intensity?: number;
  /**
   * Dodge Burn Intensity
   *
   * Dodge and burn intensity
   */
  dodge_burn_intensity?: number;
  /**
   * Smart Sharpen Strength
   *
   * Smart sharpen strength
   */
  smart_sharpen_strength?: number;
  /**
   * Red Direction
   *
   * Red channel shift direction
   */
  red_direction?: "horizontal" | "vertical";
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
  /**
   * Vertex X
   *
   * Vertex X position
   */
  vertex_x?: number;
  /**
   * Tint Strength
   *
   * Tint strength
   */
  tint_strength?: number;
  /**
   * Enable Dissolve
   *
   * Enable dissolve effect
   */
  enable_dissolve?: boolean;
  /**
   * Enable Parabolize
   *
   * Enable parabolize effect
   */
  enable_parabolize?: boolean;
  /**
   * Enable Grain
   *
   * Enable film grain effect
   */
  enable_grain?: boolean;
  /**
   * Solarize Threshold
   *
   * Solarize threshold
   */
  solarize_threshold?: number;
  /**
   * Enable Sharpen
   *
   * Enable sharpen effect
   */
  enable_sharpen?: boolean;
  /**
   * Enable Dodge Burn
   *
   * Enable dodge and burn effect
   */
  enable_dodge_burn?: boolean;
  /**
   * Glow Radius
   *
   * Glow blur radius
   */
  glow_radius?: number;
  /**
   * Sharpen Alpha
   *
   * Sharpen strength (for basic mode)
   */
  sharpen_alpha?: number;
  /**
   * Enable Color Correction
   *
   * Enable color correction
   */
  enable_color_correction?: boolean;
  /**
   * Contrast
   *
   * Contrast adjustment
   */
  contrast?: number;
  /**
   * Enable Solarize
   *
   * Enable solarize effect
   */
  enable_solarize?: boolean;
  /**
   * Noise Radius
   *
   * Noise radius for smart sharpen
   */
  noise_radius?: number;
  /**
   * Grain Scale
   *
   * Film grain scale (when enabled)
   */
  grain_scale?: number;
  /**
   * Temperature
   *
   * Color temperature adjustment
   */
  temperature?: number;
  /**
   * Brightness
   *
   * Brightness adjustment
   */
  brightness?: number;
  /**
   * Blue Direction
   *
   * Blue channel shift direction
   */
  blue_direction?: "horizontal" | "vertical";
  /**
   * Dissolve Factor
   *
   * Dissolve blend factor
   */
  dissolve_factor?: number;
  /**
   * Sharpen Mode
   *
   * Type of sharpening to apply
   */
  sharpen_mode?: "basic" | "smart" | "cas";
  /**
   * Vignette Strength
   *
   * Vignette strength (when enabled)
   */
  vignette_strength?: number;
  /**
   * Sharpen Radius
   *
   * Sharpen radius (for basic mode)
   */
  sharpen_radius?: number;
  /**
   * Parabolize Coeff
   *
   * Parabolize coefficient
   */
  parabolize_coeff?: number;
  /**
   * Saturation
   *
   * Saturation adjustment
   */
  saturation?: number;
  /**
   * Enable Tint
   *
   * Enable color tint effect
   */
  enable_tint?: boolean;
  /**
   * Green Shift
   *
   * Green channel shift amount
   */
  green_shift?: number;
  /**
   * Preserve Edges
   *
   * Edge preservation factor
   */
  preserve_edges?: number;
  /**
   * Desaturate Factor
   *
   * Desaturation factor
   */
  desaturate_factor?: number;
  /**
   * Smart Sharpen Ratio
   *
   * Smart sharpen blend ratio
   */
  smart_sharpen_ratio?: number;
  /**
   * Enable Chromatic
   *
   * Enable chromatic aberration
   */
  enable_chromatic?: boolean;
};

/**
 * NafnetOutputDenoise
 */
export type NafnetDenoiseOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * NafnetInputDenoise
 */
export type NafnetDenoiseInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * NafnetOutput
 */
export type NafnetDeblurOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * NafnetInput
 */
export type NafnetDeblurInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * Output
 */
export type DrctSuperResolutionOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: Image;
};

/**
 * Input
 */
export type DrctSuperResolutionInput = {
  /**
   * Upscaling Factor (Xs)
   *
   * Upscaling factor.
   */
  upscale_factor?: 4;
  /**
   * Image URL
   *
   * URL of the image to upscale.
   */
  image_url: string;
};

/**
 * SAM2AutomaticSegmentationOutput
 */
export type Sam2AutoSegmentOutput = {
  /**
   * Combined Mask
   *
   * Combined segmentation mask.
   */
  combined_mask: Image;
  /**
   * Individual Masks
   *
   * Individual segmentation masks.
   */
  individual_masks: Array<Image>;
};

/**
 * SAM2AutomaticSegmentationInput
 */
export type Sam2AutoSegmentInput = {
  /**
   * Points Per Side
   *
   * Number of points to sample along each side of the image.
   */
  points_per_side?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Min Mask Region Area
   *
   * Minimum area of a mask region.
   */
  min_mask_region_area?: number;
  /**
   * Image Url
   *
   * URL of the image to be automatically segmented
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Pred Iou Thresh
   *
   * Threshold for predicted IOU score.
   */
  pred_iou_thresh?: number;
  /**
   * Stability Score Thresh
   *
   * Threshold for stability score.
   */
  stability_score_thresh?: number;
};

/**
 * DDColorOutput
 */
export type DdcolorOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * DDColorInput
 */
export type DdcolorInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * ImageOutput
 */
export type EvfSamOutput = {
  /**
   * Image
   *
   * The segmented output image
   */
  image: File;
};

/**
 * ImageInput
 */
export type EvfSamInput = {
  /**
   * Prompt
   *
   * The prompt to generate segmentation from.
   */
  prompt: string;
  /**
   * Use Grounding Dino
   *
   * Use GroundingDINO instead of SAM for segmentation
   */
  use_grounding_dino?: boolean;
  /**
   * Semantic Type
   *
   * Enable semantic level segmentation for body parts, background or multi objects
   */
  semantic_type?: boolean;
  /**
   * Fill Holes
   *
   * Fill holes in the mask using morphological operations
   */
  fill_holes?: boolean;
  /**
   * Expand Mask
   *
   * Expand/dilate the mask by specified pixels
   */
  expand_mask?: number;
  /**
   * Mask Only
   *
   * Output only the binary mask instead of masked image
   */
  mask_only?: boolean;
  /**
   * Revert Mask
   *
   * Invert the mask (background becomes foreground and vice versa)
   */
  revert_mask?: boolean;
  /**
   * Blur Mask
   *
   * Apply Gaussian blur to the mask. Value determines kernel size (must be odd number)
   */
  blur_mask?: number;
  /**
   * Negative Prompt
   *
   * Areas to exclude from segmentation (will be subtracted from prompt results)
   */
  negative_prompt?: string;
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string;
};

/**
 * Output
 */
export type IdeogramV2aTurboRemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * RemixImageInput
 */
export type IdeogramV2aTurboRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * Output
 */
export type IdeogramV2aRemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * RemixImageInput
 */
export type IdeogramV2aRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image
   */
  aspect_ratio?:
    | "10:16"
    | "16:10"
    | "9:16"
    | "16:9"
    | "4:3"
    | "3:4"
    | "1:1"
    | "1:3"
    | "3:1"
    | "3:2"
    | "2:3";
  /**
   * Style
   *
   * The style of the generated image
   */
  style?: "auto" | "general" | "realistic" | "design" | "render_3D" | "anime";
  /**
   * Expand Prompt
   *
   * Whether to expand the prompt with MagicPrompt functionality.
   */
  expand_prompt?: boolean;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * SwinSrOutput
 */
export type Swin2SrOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * SwinSrInput
 */
export type Swin2SrInput = {
  /**
   * Task
   *
   * Task to perform
   */
  task?: "classical_sr" | "compressed_sr" | "real_sr";
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for image enhancement
   */
  image_url: string;
};

/**
 * DocResOutput
 */
export type DocresOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * DocResInput
 */
export type DocresInput = {
  /**
   * Task
   *
   * Task to perform
   */
  task: "deshadowing" | "appearance" | "deblurring" | "binarization";
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * DocResOutput
 */
export type DocresDewarpOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * DocResInputDewarp
 */
export type DocresDewarpInput = {
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * Output
 */
export type JuggernautFluxProImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DevImageToImageInput
 */
export type JuggernautFluxProImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type JuggernautFluxBaseImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * DevImageToImageInput
 */
export type JuggernautFluxBaseImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * WatermarkOutput
 */
export type InvisibleWatermarkOutput = {
  /**
   * Image
   *
   * The watermarked image file info (when encoding)
   */
  image?: Image;
  /**
   * Extracted Watermark
   *
   * The extracted watermark text (when decoding)
   */
  extracted_watermark?: string;
  /**
   * Length
   *
   * Length of the watermark bits used (helpful for future decoding)
   */
  length?: number;
};

/**
 * WatermarkInput
 */
export type InvisibleWatermarkInput = {
  /**
   * Decode
   *
   * Whether to decode a watermark from the image instead of encoding
   */
  decode?: boolean;
  /**
   * Watermark
   *
   * Text to use as watermark (for encoding only)
   */
  watermark?: string;
  /**
   * Length
   *
   * Length of watermark bits to decode (required when decode=True)
   */
  length?: number;
  /**
   * Image Url
   *
   * URL of image to be watermarked or decoded
   */
  image_url: string;
};

/**
 * GeminiImageOutput
 */
export type GeminiFlashEditMultiOutput = {
  /**
   * Description
   *
   * Text description or response from Gemini
   */
  description: string;
  image: ImageType3;
};

/**
 * GeminiMultiImageRequest
 */
export type GeminiFlashEditMultiInput = {
  /**
   * Prompt
   *
   * The prompt for image generation or editing
   */
  prompt: string;
  /**
   * Input Image Urls
   *
   * List of URLs of input images for editing
   */
  input_image_urls: Array<string>;
};

/**
 * GeminiImageOutput
 */
export type GeminiFlashEditOutput = {
  /**
   * Description
   *
   * Text description or response from Gemini
   */
  description: string;
  image: ImageType3;
};

/**
 * GeminiImageRequest
 */
export type GeminiFlashEditInput = {
  /**
   * Prompt
   *
   * The prompt for image generation or editing
   */
  prompt: string;
  /**
   * Image Url
   *
   * Optional URL of an input image for editing. If not provided, generates a new image.
   */
  image_url: string;
};

/**
 * MixDehazeNetOutput
 */
export type MixDehazeNetOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
};

/**
 * MixDehazeNetInput
 */
export type MixDehazeNetInput = {
  /**
   * Model
   *
   * Model to be used for dehazing
   */
  model?: "indoor" | "outdoor";
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for image enhancement
   */
  image_url: string;
};

/**
 * TheraOutput
 */
export type TheraOutput = {
  /**
   * Image
   *
   * The generated image file info.
   */
  image: Image;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TheraInput
 */
export type TheraInput = {
  /**
   * Upscale Factor
   *
   * The upscaling factor for the image.
   */
  upscale_factor?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
  /**
   * Backbone
   *
   * Backbone to use for upscaling
   */
  backbone: "edsr" | "rdn";
  /**
   * Image Url
   *
   * URL of image to be used for upscaling
   */
  image_url: string;
};

/**
 * Output
 */
export type GhiblifyOutput = {
  /**
   * The URL of the generated image.
   */
  image: ImageType3;
};

/**
 * Input
 */
export type GhiblifyInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the upscale. If not provided, a random seed will be used.
   */
  seed?: number | unknown;
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string;
};

/**
 * StarVectorOutput
 */
export type StarVectorOutput = {
  image: FileType2;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * StarVectorInput
 */
export type StarVectorInput = {
  /**
   * Seed
   *
   * seed to be used for generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of image to be used for relighting
   */
  image_url: string;
};

/**
 * EraseOutput
 */
export type FinegrainEraserOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: File;
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number;
};

/**
 * PromptEraseRequest
 */
export type FinegrainEraserInput = {
  /**
   * Prompt
   *
   * Text description of what to erase
   */
  prompt: string;
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: "express" | "standard" | "premium";
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number;
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string;
};

/**
 * BoxPromptBase
 */
export type BoxPromptBase = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number;
  /**
   * X Max
   *
   * X Max Coordinate of the prompt
   */
  x_max?: number;
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number;
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt
   */
  y_max?: number;
};

/**
 * EraseOutput
 */
export type FinegrainEraserBboxOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: File;
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number;
};

/**
 * BBoxEraseRequest
 */
export type FinegrainEraserBboxInput = {
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: "express" | "standard" | "premium";
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number;
  /**
   * Box Prompts
   *
   * List of bounding box coordinates to erase (only one box prompt is supported)
   */
  box_prompts: Array<BoxPromptBase>;
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string;
};

/**
 * EraseOutput
 */
export type FinegrainEraserMaskOutput = {
  /**
   * Image
   *
   * The edited image with content erased
   */
  image: File;
  /**
   * Used Seed
   *
   * Seed used for generation
   */
  used_seed: number;
};

/**
 * MaskEraseRequest
 */
export type FinegrainEraserMaskInput = {
  /**
   * Mode
   *
   * Erase quality mode
   */
  mode?: "express" | "standard" | "premium";
  /**
   * Seed
   *
   * Random seed for reproducible generation
   */
  seed?: number;
  /**
   * Mask Url
   *
   * URL of the mask image. Should be a binary mask where white (255) indicates areas to erase
   */
  mask_url: string;
  /**
   * Image Url
   *
   * URL of the image to edit
   */
  image_url: string;
};

/**
 * Output
 */
export type CartoonifyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * CartoonifyInput
 */
export type CartoonifyInput = {
  /**
   * Use Cfg Zero
   *
   * Whether to use CFG zero
   */
  use_cfg_zero?: boolean;
  /**
   * Image Url
   *
   * URL of the image to apply Pixar style to
   */
  image_url: string;
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number;
  /**
   * Scale
   *
   * Scale factor for the Pixar effect
   */
  scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed for image generation. Same seed with same parameters will generate same image.
   */
  seed?: number;
};

/**
 * ImageOutput
 */
export type InstantCharacterOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type InstantCharacterInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Scale
   *
   * The scale of the subject image. Higher values will make the subject image more prominent in the generated image.
   */
  scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type PlushifyOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * PlushifyInput
 */
export type PlushifyInput = {
  /**
   * Prompt
   *
   * Prompt for the generation. Default is empty which is usually best, but sometimes it can help to add a description of the subject.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Use Cfg Zero
   *
   * Whether to use CFG zero
   */
  use_cfg_zero?: boolean;
  /**
   * Image Url
   *
   * URL of the image to apply cartoon style to
   */
  image_url: string;
  /**
   * Scale
   *
   * Scale factor for the Cartoon effect
   */
  scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed for image generation. Same seed with same parameters will generate same image.
   */
  seed?: number;
};

/**
 * Output
 */
export type FashnTryonV15Output = {
  /**
   * Images
   */
  images: Array<File>;
};

/**
 * Input
 */
export type FashnTryonV15Input = {
  /**
   * Model Image
   *
   * URL or base64 of the model image
   */
  model_image: string;
  /**
   * Moderation Level
   *
   * Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.
   */
  moderation_level?: "none" | "permissive" | "conservative";
  /**
   * Garment Photo Type
   *
   * Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.
   */
  garment_photo_type?: "auto" | "model" | "flat-lay";
  /**
   * Garment Image
   *
   * URL or base64 of the garment image
   */
  garment_image: string;
  /**
   * Category
   *
   * Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.
   */
  category?: "tops" | "bottoms" | "one-pieces" | "auto";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Segmentation Free
   *
   * Disables human parsing on the model image.
   */
  segmentation_free?: boolean;
  /**
   * Num Samples
   *
   * Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.
   */
  num_samples?: number;
  /**
   * Mode
   *
   * Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.
   */
  mode?: "performance" | "balanced" | "quality";
  /**
   * Seed
   *
   * Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.
   */
  seed?: number;
  /**
   * Output Format
   *
   * Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster
   */
  output_format?: "png" | "jpeg";
};

/**
 * Output
 */
export type JuggernautFluxLoraInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * InpaintInput
 */
export type JuggernautFluxLoraInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * EditImageResponse
 */
export type GptImage1EditImageOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * EditImageRequest
 */
export type GptImage1EditImageInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "auto" | "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "auto" | "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Input Fidelity
   *
   * Input fidelity for the generated image
   */
  input_fidelity?: "low" | "high";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>;
};

/**
 * UNOOutput
 */
export type UnoOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The URLs of the generated images.
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * UNOInput
 */
export type UnoInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   *
   * The size of the generated image. You can choose between some presets or custom height and width
   * that **must be multiples of 8**.
   *
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Input Image Urls
   *
   * URL of images to use while generating the image.
   */
  input_image_urls: Array<string>;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation. If set none, a random seed will be used.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Image2SVGOutput
 */
export type Image2SvgOutput = {
  /**
   * Images
   *
   * The converted SVG file
   */
  images: Array<File>;
};

/**
 * Image2SVGInput
 */
export type Image2SvgInput = {
  /**
   * Splice Threshold
   *
   * Splice threshold for joining paths
   */
  splice_threshold?: number;
  /**
   * Hierarchical
   *
   * Hierarchical mode: stacked or cutout
   */
  hierarchical?: "stacked" | "cutout";
  /**
   * Color Precision
   *
   * Color quantization level
   */
  color_precision?: number;
  /**
   * Colormode
   *
   * Choose between color or binary (black and white) output
   */
  colormode?: "color" | "binary";
  /**
   * Max Iterations
   *
   * Maximum number of iterations for optimization
   */
  max_iterations?: number;
  /**
   * Length Threshold
   *
   * Length threshold for curves/lines
   */
  length_threshold?: number;
  /**
   * Image Url
   *
   * The image to convert to SVG
   */
  image_url: string;
  /**
   * Mode
   *
   * Mode: spline (curved) or polygon (straight lines)
   */
  mode?: "spline" | "polygon";
  /**
   * Corner Threshold
   *
   * Corner detection threshold in degrees
   */
  corner_threshold?: number;
  /**
   * Path Precision
   *
   * Decimal precision for path coordinates
   */
  path_precision?: number;
  /**
   * Filter Speckle
   *
   * Filter out small speckles and noise
   */
  filter_speckle?: number;
  /**
   * Layer Difference
   *
   * Layer difference threshold for hierarchical mode
   */
  layer_difference?: number;
};

/**
 * ImageOutput
 */
export type Step1xEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type Step1xEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * EditOutputV3
 */
export type IdeogramV3EditOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * EditImageInputV3
 */
export type IdeogramV3EditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | "80S_ILLUSTRATION"
    | "90S_NOSTALGIA"
    | "ABSTRACT_ORGANIC"
    | "ANALOG_NOSTALGIA"
    | "ART_BRUT"
    | "ART_DECO"
    | "ART_POSTER"
    | "AURA"
    | "AVANT_GARDE"
    | "BAUHAUS"
    | "BLUEPRINT"
    | "BLURRY_MOTION"
    | "BRIGHT_ART"
    | "C4D_CARTOON"
    | "CHILDRENS_BOOK"
    | "COLLAGE"
    | "COLORING_BOOK_I"
    | "COLORING_BOOK_II"
    | "CUBISM"
    | "DARK_AURA"
    | "DOODLE"
    | "DOUBLE_EXPOSURE"
    | "DRAMATIC_CINEMA"
    | "EDITORIAL"
    | "EMOTIONAL_MINIMAL"
    | "ETHEREAL_PARTY"
    | "EXPIRED_FILM"
    | "FLAT_ART"
    | "FLAT_VECTOR"
    | "FOREST_REVERIE"
    | "GEO_MINIMALIST"
    | "GLASS_PRISM"
    | "GOLDEN_HOUR"
    | "GRAFFITI_I"
    | "GRAFFITI_II"
    | "HALFTONE_PRINT"
    | "HIGH_CONTRAST"
    | "HIPPIE_ERA"
    | "ICONIC"
    | "JAPANDI_FUSION"
    | "JAZZY"
    | "LONG_EXPOSURE"
    | "MAGAZINE_EDITORIAL"
    | "MINIMAL_ILLUSTRATION"
    | "MIXED_MEDIA"
    | "MONOCHROME"
    | "NIGHTLIFE"
    | "OIL_PAINTING"
    | "OLD_CARTOONS"
    | "PAINT_GESTURE"
    | "POP_ART"
    | "RETRO_ETCHING"
    | "RIVIERA_POP"
    | "SPOTLIGHT_80S"
    | "STYLIZED_RED"
    | "SURREAL_COLLAGE"
    | "TRAVEL_POSTER"
    | "VINTAGE_GEO"
    | "VINTAGE_POSTER"
    | "WATERCOLOR"
    | "WEIRD"
    | "WOODBLOCK_PRINT"
    | unknown;
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Image URL
   *
   * The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.
   */
  mask_url: string;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
};

/**
 * RemixOutputV3
 */
export type IdeogramV3RemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * RemixImageInputV3
 */
export type IdeogramV3RemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "GENERAL" | "REALISTIC" | "DESIGN" | unknown;
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * ReplaceBackgroundOutputV3
 */
export type IdeogramV3ReplaceBackgroundOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * ReplaceBackgroundInputV3
 */
export type IdeogramV3ReplaceBackgroundInput = {
  /**
   * Prompt
   *
   * Cyber punk city with neon lights and skyscrappers
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "GENERAL" | "REALISTIC" | "DESIGN" | unknown;
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | "80S_ILLUSTRATION"
    | "90S_NOSTALGIA"
    | "ABSTRACT_ORGANIC"
    | "ANALOG_NOSTALGIA"
    | "ART_BRUT"
    | "ART_DECO"
    | "ART_POSTER"
    | "AURA"
    | "AVANT_GARDE"
    | "BAUHAUS"
    | "BLUEPRINT"
    | "BLURRY_MOTION"
    | "BRIGHT_ART"
    | "C4D_CARTOON"
    | "CHILDRENS_BOOK"
    | "COLLAGE"
    | "COLORING_BOOK_I"
    | "COLORING_BOOK_II"
    | "CUBISM"
    | "DARK_AURA"
    | "DOODLE"
    | "DOUBLE_EXPOSURE"
    | "DRAMATIC_CINEMA"
    | "EDITORIAL"
    | "EMOTIONAL_MINIMAL"
    | "ETHEREAL_PARTY"
    | "EXPIRED_FILM"
    | "FLAT_ART"
    | "FLAT_VECTOR"
    | "FOREST_REVERIE"
    | "GEO_MINIMALIST"
    | "GLASS_PRISM"
    | "GOLDEN_HOUR"
    | "GRAFFITI_I"
    | "GRAFFITI_II"
    | "HALFTONE_PRINT"
    | "HIGH_CONTRAST"
    | "HIPPIE_ERA"
    | "ICONIC"
    | "JAPANDI_FUSION"
    | "JAZZY"
    | "LONG_EXPOSURE"
    | "MAGAZINE_EDITORIAL"
    | "MINIMAL_ILLUSTRATION"
    | "MIXED_MEDIA"
    | "MONOCHROME"
    | "NIGHTLIFE"
    | "OIL_PAINTING"
    | "OLD_CARTOONS"
    | "PAINT_GESTURE"
    | "POP_ART"
    | "RETRO_ETCHING"
    | "RIVIERA_POP"
    | "SPOTLIGHT_80S"
    | "STYLIZED_RED"
    | "SURREAL_COLLAGE"
    | "TRAVEL_POSTER"
    | "VINTAGE_GEO"
    | "VINTAGE_POSTER"
    | "WATERCOLOR"
    | "WEIRD"
    | "WOODBLOCK_PRINT"
    | unknown;
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Image URL
   *
   * The image URL whose background needs to be replaced
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
};

/**
 * ReframeOutputV3
 */
export type IdeogramV3ReframeOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * ReframeImageInputV3
 */
export type IdeogramV3ReframeInput = {
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The resolution for the reframed output image
   */
  image_size:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "GENERAL" | "REALISTIC" | "DESIGN" | unknown;
  /**
   * Style Preset
   *
   * Style preset for generation. The chosen style preset will guide the generation.
   */
  style_preset?:
    | "80S_ILLUSTRATION"
    | "90S_NOSTALGIA"
    | "ABSTRACT_ORGANIC"
    | "ANALOG_NOSTALGIA"
    | "ART_BRUT"
    | "ART_DECO"
    | "ART_POSTER"
    | "AURA"
    | "AVANT_GARDE"
    | "BAUHAUS"
    | "BLUEPRINT"
    | "BLURRY_MOTION"
    | "BRIGHT_ART"
    | "C4D_CARTOON"
    | "CHILDRENS_BOOK"
    | "COLLAGE"
    | "COLORING_BOOK_I"
    | "COLORING_BOOK_II"
    | "CUBISM"
    | "DARK_AURA"
    | "DOODLE"
    | "DOUBLE_EXPOSURE"
    | "DRAMATIC_CINEMA"
    | "EDITORIAL"
    | "EMOTIONAL_MINIMAL"
    | "ETHEREAL_PARTY"
    | "EXPIRED_FILM"
    | "FLAT_ART"
    | "FLAT_VECTOR"
    | "FOREST_REVERIE"
    | "GEO_MINIMALIST"
    | "GLASS_PRISM"
    | "GOLDEN_HOUR"
    | "GRAFFITI_I"
    | "GRAFFITI_II"
    | "HALFTONE_PRINT"
    | "HIGH_CONTRAST"
    | "HIPPIE_ERA"
    | "ICONIC"
    | "JAPANDI_FUSION"
    | "JAZZY"
    | "LONG_EXPOSURE"
    | "MAGAZINE_EDITORIAL"
    | "MINIMAL_ILLUSTRATION"
    | "MIXED_MEDIA"
    | "MONOCHROME"
    | "NIGHTLIFE"
    | "OIL_PAINTING"
    | "OLD_CARTOONS"
    | "PAINT_GESTURE"
    | "POP_ART"
    | "RETRO_ETCHING"
    | "RIVIERA_POP"
    | "SPOTLIGHT_80S"
    | "STYLIZED_RED"
    | "SURREAL_COLLAGE"
    | "TRAVEL_POSTER"
    | "VINTAGE_GEO"
    | "VINTAGE_POSTER"
    | "WATERCOLOR"
    | "WEIRD"
    | "WOODBLOCK_PRINT"
    | unknown;
  /**
   * Image URL
   *
   * The image URL to reframe
   */
  image_url: string;
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
};

/**
 * Img2ImgOutput
 */
export type HidreamI1FullImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type HidreamI1FullImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Setting to None uses the input image's size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.
   */
  loras?: Array<LoraWeightType3>;
  /**
   * Strength
   *
   * Denoising strength for image-to-image generation.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * MiniMaxTextToImageWithReferenceOutput
 */
export type MinimaxImage01SubjectReferenceOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<File>;
};

/**
 * MiniMaxTextToImageWithReferenceRequest
 */
export type MinimaxImage01SubjectReferenceInput = {
  /**
   * Prompt
   *
   * Text prompt for image generation (max 1500 characters)
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate (1-9)
   */
  num_images?: number;
  /**
   * Prompt Optimizer
   *
   * Whether to enable automatic prompt optimization
   */
  prompt_optimizer?: boolean;
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image
   */
  aspect_ratio?:
    | "1:1"
    | "16:9"
    | "4:3"
    | "3:2"
    | "2:3"
    | "3:4"
    | "9:16"
    | "21:9";
  /**
   * Image Url
   *
   * URL of the subject reference image to use for consistent character appearance
   */
  image_url: string;
};

/**
 * ImageToImageOutput
 */
export type RecraftV3ImageToImageOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<File>;
};

/**
 * ImageToImageInput
 */
export type RecraftV3ImageToImageInput = {
  /**
   * Prompt
   *
   * A text description of areas to change.
   */
  prompt: string;
  /**
   * Style
   *
   * The style of the generated images. Vector images cost 2X as much.
   */
  style?:
    | "any"
    | "realistic_image"
    | "digital_illustration"
    | "vector_illustration"
    | "realistic_image/b_and_w"
    | "realistic_image/hard_flash"
    | "realistic_image/hdr"
    | "realistic_image/natural_light"
    | "realistic_image/studio_portrait"
    | "realistic_image/enterprise"
    | "realistic_image/motion_blur"
    | "realistic_image/evening_light"
    | "realistic_image/faded_nostalgia"
    | "realistic_image/forest_life"
    | "realistic_image/mystic_naturalism"
    | "realistic_image/natural_tones"
    | "realistic_image/organic_calm"
    | "realistic_image/real_life_glow"
    | "realistic_image/retro_realism"
    | "realistic_image/retro_snapshot"
    | "realistic_image/urban_drama"
    | "realistic_image/village_realism"
    | "realistic_image/warm_folk"
    | "digital_illustration/pixel_art"
    | "digital_illustration/hand_drawn"
    | "digital_illustration/grain"
    | "digital_illustration/infantile_sketch"
    | "digital_illustration/2d_art_poster"
    | "digital_illustration/handmade_3d"
    | "digital_illustration/hand_drawn_outline"
    | "digital_illustration/engraving_color"
    | "digital_illustration/2d_art_poster_2"
    | "digital_illustration/antiquarian"
    | "digital_illustration/bold_fantasy"
    | "digital_illustration/child_book"
    | "digital_illustration/child_books"
    | "digital_illustration/cover"
    | "digital_illustration/crosshatch"
    | "digital_illustration/digital_engraving"
    | "digital_illustration/expressionism"
    | "digital_illustration/freehand_details"
    | "digital_illustration/grain_20"
    | "digital_illustration/graphic_intensity"
    | "digital_illustration/hard_comics"
    | "digital_illustration/long_shadow"
    | "digital_illustration/modern_folk"
    | "digital_illustration/multicolor"
    | "digital_illustration/neon_calm"
    | "digital_illustration/noir"
    | "digital_illustration/nostalgic_pastel"
    | "digital_illustration/outline_details"
    | "digital_illustration/pastel_gradient"
    | "digital_illustration/pastel_sketch"
    | "digital_illustration/pop_art"
    | "digital_illustration/pop_renaissance"
    | "digital_illustration/street_art"
    | "digital_illustration/tablet_sketch"
    | "digital_illustration/urban_glow"
    | "digital_illustration/urban_sketching"
    | "digital_illustration/vanilla_dreams"
    | "digital_illustration/young_adult_book"
    | "digital_illustration/young_adult_book_2"
    | "vector_illustration/bold_stroke"
    | "vector_illustration/chemistry"
    | "vector_illustration/colored_stencil"
    | "vector_illustration/contour_pop_art"
    | "vector_illustration/cosmics"
    | "vector_illustration/cutout"
    | "vector_illustration/depressive"
    | "vector_illustration/editorial"
    | "vector_illustration/emotional_flat"
    | "vector_illustration/infographical"
    | "vector_illustration/marker_outline"
    | "vector_illustration/mosaic"
    | "vector_illustration/naivector"
    | "vector_illustration/roundish_flat"
    | "vector_illustration/segmented_colors"
    | "vector_illustration/sharp_contrast"
    | "vector_illustration/thin"
    | "vector_illustration/vector_photo"
    | "vector_illustration/vivid_shapes"
    | "vector_illustration/engraving"
    | "vector_illustration/line_art"
    | "vector_illustration/line_circuit"
    | "vector_illustration/linocut";
  /**
   * Style Id
   *
   * The ID of the custom style reference (optional)
   */
  style_id?: string;
  /**
   * Image Url
   *
   * The URL of the image to modify. Must be less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity
   */
  strength?: number;
  /**
   * Colors
   *
   * An array of preferable colors
   */
  colors?: Array<RgbColor>;
  /**
   * Negative Prompt
   *
   * A text description of undesired elements on an image
   */
  negative_prompt?: string;
};

/**
 * UpscaleOutput
 */
export type RecraftUpscaleCrispOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: File;
};

/**
 * UpscaleInput
 */
export type RecraftUpscaleCrispInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Image Url
   *
   * The URL of the image to be upscaled. Must be in PNG format.
   */
  image_url: string;
};

/**
 * UpscaleOutput
 */
export type RecraftUpscaleCreativeOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: File;
};

/**
 * UpscaleInput
 */
export type RecraftUpscaleCreativeInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Image Url
   *
   * The URL of the image to be upscaled. Must be in PNG format.
   */
  image_url: string;
};

/**
 * ImageOutput
 */
export type RembgEnhanceOutput = {
  image: FileType2;
};

/**
 * ImageInput
 */
export type RembgEnhanceInput = {
  /**
   * Image Url
   *
   * URL of the input image
   */
  image_url: string;
};

/**
 * ImageEditOutput
 */
export type BagelEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<Image>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageEditInput
 */
export type BagelEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
  /**
   * Use Thought
   *
   * Whether to use thought tokens for generation. If set to true, the model will "think" to potentially improve generation quality. Increases generation time and increases the cost by 20%.
   */
  use_thought?: boolean;
  /**
   * Image Url
   *
   * The image to edit.
   */
  image_url: string;
};

/**
 * KontextEditOutput
 */
export type FluxKontextDevOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseKontextEditInput
 */
export type FluxKontextDevInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Resolution Mode
   *
   *
   * Determines how the output resolution is set for image editing.
   * - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.
   * - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).
   * Apart from these, a few aspect ratios are also supported.
   *
   */
  resolution_mode?:
    | "auto"
    | "match_input"
    | "1:1"
    | "16:9"
    | "21:9"
    | "3:2"
    | "2:3"
    | "4:5"
    | "5:4"
    | "3:4"
    | "4:3"
    | "9:16"
    | "9:21";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * Output format
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FluxKontextOutput
 */
export type FluxProKontextMaxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalToolkitImageImageImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Image
 *
 * Represents an image file.
 */
export type FalToolkitImageImageImage = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Height
   *
   * The height of the image in pixels.
   */
  height?: number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the image in pixels.
   */
  width?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * FluxKontextInput
 */
export type FluxProKontextMaxInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxProKontextMultiOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxKontextMultiInput
 */
export type FluxProKontextMultiInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_urls: Array<string>;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * Output
 */
export type FluxProKontextMaxMultiOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<RegistryImageFastSdxlModelsImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxKontextMultiInput
 */
export type FluxProKontextMaxMultiInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_urls: Array<string>;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

/**
 * AgeProgressionOutput
 */
export type ImageEditingAgeProgressionOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * AgeProgressionInput
 */
export type ImageEditingAgeProgressionInput = {
  /**
   * Age Change
   *
   * The age change to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * BackgroundChangeOutput
 */
export type ImageEditingBackgroundChangeOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BackgroundChangeInput
 */
export type ImageEditingBackgroundChangeInput = {
  /**
   * Background Prompt
   *
   * The desired background to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * CartoonifyOutput
 */
export type ImageEditingCartoonifyOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BaseInput
 */
export type ImageEditingCartoonifyInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ColorCorrectionOutput
 */
export type ImageEditingColorCorrectionOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BaseInput
 */
export type ImageEditingColorCorrectionInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ExpressionChangeOutput
 */
export type ImageEditingExpressionChangeOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * ExpressionChangeInput
 */
export type ImageEditingExpressionChangeInput = {
  /**
   * Expression Prompt
   *
   * The desired facial expression to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * FaceEnhancementOutput
 */
export type ImageEditingFaceEnhancementOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BaseInput
 */
export type ImageEditingFaceEnhancementInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * HairChangeOutput
 */
export type ImageEditingHairChangeOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * HairChangeInput
 */
export type ImageEditingHairChangeInput = {
  /**
   * Hair Style Prompt
   *
   * The desired hair style to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ObjectRemovalOutput
 */
export type ImageEditingObjectRemovalOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * ObjectRemovalInput
 */
export type ImageEditingObjectRemovalInput = {
  /**
   * Objects to Remove
   *
   * Specify which objects to remove from the image.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ProfessionalPhotoOutput
 */
export type ImageEditingProfessionalPhotoOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BaseInput
 */
export type ImageEditingProfessionalPhotoInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * SceneCompositionOutput
 */
export type ImageEditingSceneCompositionOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * SceneCompositionInput
 */
export type ImageEditingSceneCompositionInput = {
  /**
   * Scene Description
   *
   * Describe the scene where you want to place the subject.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * StyleTransferOutput
 */
export type ImageEditingStyleTransferOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * StyleTransferInput
 */
export type ImageEditingStyleTransferInput = {
  /**
   * Style Prompt
   *
   * The artistic style to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * TimeOfDayOutput
 */
export type ImageEditingTimeOfDayOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * TimeOfDayInput
 */
export type ImageEditingTimeOfDayInput = {
  /**
   * Time of Day
   *
   * The time of day to transform the scene to.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * WeatherEffectOutput
 */
export type ImageEditingWeatherEffectOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * WeatherEffectInput
 */
export type ImageEditingWeatherEffectInput = {
  /**
   * Weather Effect
   *
   * The weather effect to apply.
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * PhotoRestorationOutput
 */
export type ImageEditingPhotoRestorationOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * PhotoRestorationInput
 *
 * Input model for photo restoration endpoint.
 */
export type ImageEditingPhotoRestorationInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * URL of the old or damaged photo to restore.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * TextRemovalOutput
 */
export type ImageEditingTextRemovalOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * TextRemovalInput
 *
 * Input model for text removal endpoint.
 */
export type ImageEditingTextRemovalInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * URL of the image containing text to be removed.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * Output
 */
export type Flux1DevImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseFlux1ImageToInput
 */
export type Flux1DevImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * Output
 */
export type Flux1DevReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseFlux1ReduxInput
 */
export type Flux1DevReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * Output
 */
export type Flux1SchnellReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * SchnellFlux1ReduxInput
 */
export type Flux1SchnellReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
};

/**
 * T2IOutput
 */
export type LumaPhotonReframeOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * ReframeImageRequest
 */
export type LumaPhotonReframeInput = {
  /**
   * Prompt
   *
   * Optional prompt for reframing
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: "1:1" | "16:9" | "9:16" | "4:3" | "3:4" | "21:9" | "9:21";
  /**
   * Y Start
   *
   * Start Y coordinate for reframing
   */
  y_start?: number;
  /**
   * X End
   *
   * End X coordinate for reframing
   */
  x_end?: number;
  /**
   * Y End
   *
   * End Y coordinate for reframing
   */
  y_end?: number;
  /**
   * Grid Position Y
   *
   * Y position of the grid for reframing
   */
  grid_position_y?: number;
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string;
  /**
   * Grid Position X
   *
   * X position of the grid for reframing
   */
  grid_position_x?: number;
  /**
   * X Start
   *
   * Start X coordinate for reframing
   */
  x_start?: number;
};

/**
 * T2IOutput
 */
export type LumaPhotonFlashReframeOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * ReframeImageRequest
 */
export type LumaPhotonFlashReframeInput = {
  /**
   * Prompt
   *
   * Optional prompt for reframing
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: "1:1" | "16:9" | "9:16" | "4:3" | "3:4" | "21:9" | "9:21";
  /**
   * Y Start
   *
   * Start Y coordinate for reframing
   */
  y_start?: number;
  /**
   * X End
   *
   * End X coordinate for reframing
   */
  x_end?: number;
  /**
   * Y End
   *
   * End Y coordinate for reframing
   */
  y_end?: number;
  /**
   * Grid Position Y
   *
   * Y position of the grid for reframing
   */
  grid_position_y?: number;
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string;
  /**
   * Grid Position X
   *
   * X position of the grid for reframing
   */
  grid_position_x?: number;
  /**
   * X Start
   *
   * Start X coordinate for reframing
   */
  x_start?: number;
};

/**
 * BabyVersionOutput
 */
export type ImageEditingBabyVersionOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BabyVersionInput
 *
 * Input model for baby version endpoint.
 */
export type ImageEditingBabyVersionInput = {
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * URL of the image to transform into a baby version.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ReframeOutput
 */
export type ImageEditingReframeOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * ReframeInput
 */
export type ImageEditingReframeInput = {
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio for the reframed image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * URL of the old or damaged photo to restore.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 6 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * T2IOutput
 */
export type LumaPhotonModifyOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * ModifyImageRequest
 */
export type LumaPhotonModifyInput = {
  /**
   * Prompt
   *
   * Instruction for modifying the image
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: "1:1" | "16:9" | "9:16" | "4:3" | "3:4" | "21:9" | "9:21";
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.
   */
  strength: number;
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string;
};

/**
 * T2IOutput
 */
export type LumaPhotonFlashModifyOutput = {
  /**
   * Images
   *
   * The generated image
   */
  images: Array<File>;
};

/**
 * ModifyImageRequest
 */
export type LumaPhotonFlashModifyInput = {
  /**
   * Prompt
   *
   * Instruction for modifying the image
   */
  prompt?: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the reframed image
   */
  aspect_ratio: "1:1" | "16:9" | "9:16" | "4:3" | "3:4" | "21:9" | "9:21";
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are corresponding to more influence of the initial image on the output.
   */
  strength: number;
  /**
   * Image Url
   *
   * URL of the input image to reframe
   */
  image_url: string;
};

/**
 * FrameOutput
 */
export type FfmpegApiExtractFrameOutput = {
  /**
   * Images
   */
  images: Array<ImageType3>;
};

/**
 * FrameInput
 */
export type FfmpegApiExtractFrameInput = {
  /**
   * Video Url
   *
   * URL of the video file to use as the video track
   */
  video_url: string;
  /**
   * Frame Type
   *
   * Type of frame to extract: first, middle, or last frame of the video
   */
  frame_type?: "first" | "middle" | "last";
};

/**
 * VectorizeOutput
 */
export type RecraftVectorizeOutput = {
  /**
   * Image
   *
   * The vectorized image.
   */
  image: File;
};

/**
 * VectorizeInput
 */
export type RecraftVectorizeInput = {
  /**
   * Image Url
   *
   * The URL of the image to be vectorized. Must be in PNG, JPG or WEBP format, less than 5 MB in size, have resolution less than 16 MP and max dimension less than 4096 pixels, min dimension more than 256 pixels.
   */
  image_url: string;
};

/**
 * Output
 */
export type ObjectRemovalOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<Image>;
};

/**
 * PromptInput
 */
export type ObjectRemovalInput = {
  /**
   * Prompt
   *
   * Text description of the object to remove.
   */
  prompt: string;
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number;
  /**
   * Model
   */
  model?: "low_quality" | "medium_quality" | "high_quality" | "best_quality";
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string;
};

/**
 * Output
 */
export type ObjectRemovalMaskOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<Image>;
};

/**
 * MaskInput
 */
export type ObjectRemovalMaskInput = {
  /**
   * Model
   */
  model?: "low_quality" | "medium_quality" | "high_quality" | "best_quality";
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number;
  /**
   * Mask Url
   *
   * The URL of the mask image. White pixels (255) indicate areas to remove.
   */
  mask_url: string;
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string;
};

/**
 * BBoxPromptBase
 */
export type BBoxPromptBase = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box (0-1)
   */
  y_min?: number;
  /**
   * X Max
   *
   * X Max Coordinate of the prompt (0-1)
   */
  x_max?: number;
  /**
   * X Min
   *
   * X Min Coordinate of the box (0-1)
   */
  x_min?: number;
  /**
   * Y Max
   *
   * Y Max Coordinate of the prompt (0-1)
   */
  y_max?: number;
};

/**
 * Output
 */
export type ObjectRemovalBboxOutput = {
  /**
   * Images
   *
   * The generated images with objects removed.
   */
  images: Array<Image>;
};

/**
 * BboxInput
 */
export type ObjectRemovalBboxInput = {
  /**
   * Model
   */
  model?: "low_quality" | "medium_quality" | "high_quality" | "best_quality";
  /**
   * Mask Expansion
   *
   * Amount of pixels to expand the mask by. Range: 0-50
   */
  mask_expansion?: number;
  /**
   * Box Prompts
   *
   * List of bounding box coordinates to erase (only one box prompt is supported)
   */
  box_prompts?: Array<BBoxPromptBase>;
  /**
   * Image Url
   *
   * The URL of the image to remove objects from.
   */
  image_url: string;
};

/**
 * Output
 */
export type PasdOutput = {
  /**
   * Images
   *
   * The generated super-resolved images
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * Timing information for different processing stages
   */
  timings?: {
    [key: string]: number;
  };
};

/**
 * Input
 */
export type PasdInput = {
  /**
   * Conditioning Scale
   *
   * ControlNet conditioning scale (0.1-1.0)
   */
  conditioning_scale?: number;
  /**
   * Prompt
   *
   * Additional prompt to guide super-resolution
   */
  prompt?: string;
  /**
   * Image Url
   *
   * Input image to super-resolve
   */
  image_url: string;
  /**
   * Steps
   *
   * Number of inference steps (10-50)
   */
  steps?: number;
  /**
   * Scale
   *
   * Upscaling factor (1-4x)
   */
  scale?: number;
  /**
   * Guidance Scale
   *
   * Guidance scale for diffusion (1.0-20.0)
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt to avoid unwanted artifacts
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type ChainOfZoomOutput = {
  /**
   * Images
   *
   * List of intermediate images
   */
  images: Array<ImageType2>;
  /**
   * Zoom Center
   *
   * Center coordinates used for zoom
   */
  zoom_center: Array<number>;
  /**
   * Scale
   *
   * Actual linear zoom scale applied
   */
  scale: number;
};

/**
 * Input
 */
export type ChainOfZoomInput = {
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Center Y
   *
   * Y coordinate of zoom center (0-1)
   */
  center_y?: number;
  /**
   * Scale
   *
   * Zoom scale in powers of 2
   */
  scale?: number;
  /**
   * Center X
   *
   * X coordinate of zoom center (0-1)
   */
  center_x?: number;
  /**
   * User Prompt
   *
   * Additional prompt text to guide the zoom enhancement
   */
  user_prompt?: string;
  /**
   * Image Url
   *
   * Input image to zoom into
   */
  image_url: string;
};

/**
 * V16Output
 */
export type FashnTryonV16Output = {
  /**
   * Images
   */
  images: Array<File>;
};

/**
 * V16Input
 */
export type FashnTryonV16Input = {
  /**
   * Model Image
   *
   * URL or base64 of the model image
   */
  model_image: string;
  /**
   * Moderation Level
   *
   * Content moderation level for garment images. 'none' disables moderation, 'permissive' blocks only explicit content, 'conservative' also blocks underwear and swimwear.
   */
  moderation_level?: "none" | "permissive" | "conservative";
  /**
   * Garment Photo Type
   *
   * Specifies the type of garment photo to optimize internal parameters for better performance. 'model' is for photos of garments on a model, 'flat-lay' is for flat-lay or ghost mannequin images, and 'auto' attempts to automatically detect the photo type.
   */
  garment_photo_type?: "auto" | "model" | "flat-lay";
  /**
   * Garment Image
   *
   * URL or base64 of the garment image
   */
  garment_image: string;
  /**
   * Category
   *
   * Category of the garment to try-on. 'auto' will attempt to automatically detect the category of the garment.
   */
  category?: "tops" | "bottoms" | "one-pieces" | "auto";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Segmentation Free
   *
   * Disables human parsing on the model image.
   */
  segmentation_free?: boolean;
  /**
   * Num Samples
   *
   * Number of images to generate in a single run. Image generation has a random element in it, so trying multiple images at once increases the chances of getting a good result.
   */
  num_samples?: number;
  /**
   * Mode
   *
   * Specifies the mode of operation. 'performance' mode is faster but may sacrifice quality, 'balanced' mode is a balance between speed and quality, and 'quality' mode is slower but produces higher quality results.
   */
  mode?: "performance" | "balanced" | "quality";
  /**
   * Seed
   *
   * Sets random operations to a fixed state. Use the same seed to reproduce results with the same inputs, or different seed to force different results.
   */
  seed?: number;
  /**
   * Output Format
   *
   * Output format of the generated images. 'png' is highest quality, while 'jpeg' is faster
   */
  output_format?: "png" | "jpeg";
};

/**
 * KontextEditOutput
 */
export type FluxKontextLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKontextEditInput
 */
export type FluxKontextLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Resolution Mode
   *
   *
   * Determines how the output resolution is set for image editing.
   * - `auto`: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.
   * - `match_input`: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits).
   * Apart from these, a few aspect ratios are also supported.
   *
   */
  resolution_mode?:
    | "auto"
    | "match_input"
    | "1:1"
    | "16:9"
    | "21:9"
    | "3:2"
    | "2:3"
    | "4:5"
    | "5:4"
    | "3:4"
    | "4:3"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   *
   * Max width: 14142px, Max height: 14142px, Timeout: 20s
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * PlushieStyleOutput
 */
export type ImageEditingPlushieStyleOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * PlushieStyleInput
 *
 * Input model for plushie style endpoint.
 */
export type ImageEditingPlushieStyleInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to convert to plushie style.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * WojakStyleOutput
 */
export type ImageEditingWojakStyleOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * WojakStyleInput
 *
 * Input model for wojak style endpoint.
 */
export type ImageEditingWojakStyleInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to convert to wojak style.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * BroccoliHaircutOutput
 */
export type ImageEditingBroccoliHaircutOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * BroccoliHaircutInput
 *
 * Input model for broccoli haircut endpoint.
 */
export type ImageEditingBroccoliHaircutInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to apply broccoli haircut style.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ImageUpscaleOutput
 */
export type TopazUpscaleImageOutput = {
  /**
   * Image
   *
   * The upscaled image.
   */
  image: File;
};

/**
 * ImageUpscaleRequest
 */
export type TopazUpscaleImageInput = {
  /**
   * Face Enhancement Creativity
   *
   * Creativity level for face enhancement. 0.0 means no creativity, 1.0 means maximum creativity. Ignored if face ehnancement is disabled.
   */
  face_enhancement_creativity?: number;
  /**
   * Face Enhancement Strength
   *
   * Strength of the face enhancement. 0.0 means no enhancement, 1.0 means maximum enhancement. Ignored if face ehnancement is disabled.
   */
  face_enhancement_strength?: number;
  /**
   * Output Format
   *
   * Output format of the upscaled image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Face Enhancement
   *
   * Whether to apply face enhancement to the image.
   */
  face_enhancement?: boolean;
  /**
   * Image Url
   *
   * Url of the image to be upscaled
   */
  image_url: string;
  /**
   * Model
   *
   * Model to use for image enhancement.
   */
  model?:
    | "Low Resolution V2"
    | "Standard V2"
    | "CGI"
    | "High Fidelity V2"
    | "Text Refine"
    | "Recovery"
    | "Redefine"
    | "Recovery V2";
  /**
   * Subject Detection
   *
   * Subject detection mode for the image enhancement.
   */
  subject_detection?: "All" | "Foreground" | "Background";
  /**
   * Crop To Fill
   */
  crop_to_fill?: boolean;
  /**
   * Upscale Factor
   *
   * Factor to upscale the video by (e.g. 2.0 doubles width and height)
   */
  upscale_factor?: number;
};

/**
 * YouTubeThumbnailsOutput
 */
export type ImageEditingYoutubeThumbnailsOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * YouTubeThumbnailsInput
 *
 * Input model for YouTube thumbnails endpoint.
 */
export type ImageEditingYoutubeThumbnailsInput = {
  /**
   * Thumbnail Text
   *
   * The text to include in the YouTube thumbnail.
   */
  prompt?: string;
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to convert to YouTube thumbnail style.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
};

/**
 * BlurOutput
 */
export type PostProcessingBlurOutput = {
  /**
   * Images
   *
   * The processed images with blur effect
   */
  images: Array<Image>;
};

/**
 * BlurInput
 */
export type PostProcessingBlurInput = {
  /**
   * Blur Sigma
   *
   * Sigma for Gaussian blur
   */
  blur_sigma?: number;
  /**
   * Blur Radius
   *
   * Blur radius
   */
  blur_radius?: number;
  /**
   * Blur Type
   *
   * Type of blur to apply
   */
  blur_type?: "gaussian" | "kuwahara";
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * ChromaticAberrationOutput
 */
export type PostProcessingChromaticAberrationOutput = {
  /**
   * Images
   *
   * The processed images with chromatic aberration effect
   */
  images: Array<Image>;
};

/**
 * ChromaticAberrationInput
 */
export type PostProcessingChromaticAberrationInput = {
  /**
   * Blue Shift
   *
   * Blue channel shift amount
   */
  blue_shift?: number;
  /**
   * Red Shift
   *
   * Red channel shift amount
   */
  red_shift?: number;
  /**
   * Green Direction
   *
   * Green channel shift direction
   */
  green_direction?: "horizontal" | "vertical";
  /**
   * Blue Direction
   *
   * Blue channel shift direction
   */
  blue_direction?: "horizontal" | "vertical";
  /**
   * Red Direction
   *
   * Red channel shift direction
   */
  red_direction?: "horizontal" | "vertical";
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
  /**
   * Green Shift
   *
   * Green channel shift amount
   */
  green_shift?: number;
};

/**
 * ColorCorrectionOutput
 */
export type PostProcessingColorCorrectionOutput = {
  /**
   * Images
   *
   * The processed images with color correction
   */
  images: Array<Image>;
};

/**
 * ColorCorrectionInput
 */
export type PostProcessingColorCorrectionInput = {
  /**
   * Gamma
   *
   * Gamma adjustment
   */
  gamma?: number;
  /**
   * Saturation
   *
   * Saturation adjustment
   */
  saturation?: number;
  /**
   * Temperature
   *
   * Color temperature adjustment
   */
  temperature?: number;
  /**
   * Brightness
   *
   * Brightness adjustment
   */
  brightness?: number;
  /**
   * Contrast
   *
   * Contrast adjustment
   */
  contrast?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * ColorTintOutput
 */
export type PostProcessingColorTintOutput = {
  /**
   * Images
   *
   * The processed images with color tint effect
   */
  images: Array<Image>;
};

/**
 * ColorTintInput
 */
export type PostProcessingColorTintInput = {
  /**
   * Tint Strength
   *
   * Tint strength
   */
  tint_strength?: number;
  /**
   * Tint Mode
   *
   * Tint color mode
   */
  tint_mode?:
    | "sepia"
    | "red"
    | "green"
    | "blue"
    | "cyan"
    | "magenta"
    | "yellow"
    | "purple"
    | "orange"
    | "warm"
    | "cool"
    | "lime"
    | "navy"
    | "vintage"
    | "rose"
    | "teal"
    | "maroon"
    | "peach"
    | "lavender"
    | "olive";
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * DesaturateOutput
 */
export type PostProcessingDesaturateOutput = {
  /**
   * Images
   *
   * The processed images with desaturation effect
   */
  images: Array<Image>;
};

/**
 * DesaturateInput
 */
export type PostProcessingDesaturateInput = {
  /**
   * Desaturate Method
   *
   * Desaturation method
   */
  desaturate_method?:
    | "luminance (Rec.709)"
    | "luminance (Rec.601)"
    | "average"
    | "lightness";
  /**
   * Desaturate Factor
   *
   * Desaturation factor
   */
  desaturate_factor?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * DissolveOutput
 */
export type PostProcessingDissolveOutput = {
  /**
   * Images
   *
   * The processed images with dissolve effect
   */
  images: Array<Image>;
};

/**
 * DissolveInput
 */
export type PostProcessingDissolveInput = {
  /**
   * Dissolve Factor
   *
   * Dissolve blend factor
   */
  dissolve_factor?: number;
  /**
   * Dissolve Image Url
   *
   * URL of second image for dissolve
   */
  dissolve_image_url: string;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * DodgeBurnOutput
 */
export type PostProcessingDodgeBurnOutput = {
  /**
   * Images
   *
   * The processed images with dodge and burn effect
   */
  images: Array<Image>;
};

/**
 * DodgeBurnInput
 */
export type PostProcessingDodgeBurnInput = {
  /**
   * Dodge Burn Mode
   *
   * Dodge and burn mode
   */
  dodge_burn_mode?:
    | "dodge"
    | "burn"
    | "dodge_and_burn"
    | "burn_and_dodge"
    | "color_dodge"
    | "color_burn"
    | "linear_dodge"
    | "linear_burn";
  /**
   * Dodge Burn Intensity
   *
   * Dodge and burn intensity
   */
  dodge_burn_intensity?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * GrainOutput
 */
export type PostProcessingGrainOutput = {
  /**
   * Images
   *
   * The processed images with grain effect
   */
  images: Array<Image>;
};

/**
 * GrainInput
 */
export type PostProcessingGrainInput = {
  /**
   * Grain Style
   *
   * Style of film grain to apply
   */
  grain_style?:
    | "modern"
    | "analog"
    | "kodak"
    | "fuji"
    | "cinematic"
    | "newspaper";
  /**
   * Grain Intensity
   *
   * Film grain intensity
   */
  grain_intensity?: number;
  /**
   * Grain Scale
   *
   * Film grain scale
   */
  grain_scale?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * ParabolizeOutput
 */
export type PostProcessingParabolizeOutput = {
  /**
   * Images
   *
   * The processed images with parabolize effect
   */
  images: Array<Image>;
};

/**
 * ParabolizeInput
 */
export type PostProcessingParabolizeInput = {
  /**
   * Parabolize Coeff
   *
   * Parabolize coefficient
   */
  parabolize_coeff?: number;
  /**
   * Vertex Y
   *
   * Vertex Y position
   */
  vertex_y?: number;
  /**
   * Vertex X
   *
   * Vertex X position
   */
  vertex_x?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * SharpenOutput
 */
export type PostProcessingSharpenOutput = {
  /**
   * Images
   *
   * The processed images with sharpen effect
   */
  images: Array<Image>;
};

/**
 * SharpenInput
 */
export type PostProcessingSharpenInput = {
  /**
   * Sharpen Mode
   *
   * Type of sharpening to apply
   */
  sharpen_mode?: "basic" | "smart" | "cas";
  /**
   * Sharpen Alpha
   *
   * Sharpen strength (for basic mode)
   */
  sharpen_alpha?: number;
  /**
   * Noise Radius
   *
   * Noise radius for smart sharpen
   */
  noise_radius?: number;
  /**
   * Sharpen Radius
   *
   * Sharpen radius (for basic mode)
   */
  sharpen_radius?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
  /**
   * Smart Sharpen Strength
   *
   * Smart sharpen strength
   */
  smart_sharpen_strength?: number;
  /**
   * Cas Amount
   *
   * CAS sharpening amount
   */
  cas_amount?: number;
  /**
   * Preserve Edges
   *
   * Edge preservation factor
   */
  preserve_edges?: number;
  /**
   * Smart Sharpen Ratio
   *
   * Smart sharpen blend ratio
   */
  smart_sharpen_ratio?: number;
};

/**
 * SolarizeOutput
 */
export type PostProcessingSolarizeOutput = {
  /**
   * Images
   *
   * The processed images with solarize effect
   */
  images: Array<Image>;
};

/**
 * SolarizeInput
 */
export type PostProcessingSolarizeInput = {
  /**
   * Solarize Threshold
   *
   * Solarize threshold
   */
  solarize_threshold?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * VignetteOutput
 */
export type PostProcessingVignetteOutput = {
  /**
   * Images
   *
   * The processed images with vignette effect
   */
  images: Array<Image>;
};

/**
 * VignetteInput
 */
export type PostProcessingVignetteInput = {
  /**
   * Vignette Strength
   *
   * Vignette strength
   */
  vignette_strength?: number;
  /**
   * Image Url
   *
   * URL of image to process
   */
  image_url: string;
};

/**
 * RealismOutput
 */
export type ImageEditingRealismOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * RealismInput
 *
 * Input model for realism enhancement endpoint.
 */
export type ImageEditingRealismInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to enhance with realism details.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ReimagineOutput
 */
export type BriaReimagineOutput = {
  /**
   * Images
   *
   * The generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed value used for generation.
   */
  seed: number;
};

/**
 * ReimagineInput
 */
export type BriaReimagineInput = {
  /**
   * Prompt
   *
   * The prompt you would like to use to generate images.
   */
  prompt: string;
  /**
   * Num Results
   *
   * How many images you would like to generate. When using any Guidance Method, Value is set to 1.
   */
  num_results?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Structure Ref Influence
   *
   * The influence of the structure reference on the generated image.
   */
  structure_ref_influence?: number;
  /**
   * Fast
   *
   * Whether to use the fast model
   */
  fast?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of iterations the model goes through to refine the generated image. This parameter is optional.
   */
  num_inference_steps?: number;
  /**
   * Structure Image Url
   *
   * The URL of the structure reference image. Use "" to leave empty. Accepted formats are jpeg, jpg, png, webp.
   */
  structure_image_url?: string;
};

/**
 * Output
 */
export type CalligrapherOutput = {
  /**
   * Images
   */
  images: Array<Image>;
};

/**
 * Input
 */
export type CalligrapherInput = {
  /**
   * Use Context
   *
   * Whether to prepend context reference to the input
   */
  use_context?: boolean;
  /**
   * Num Images
   *
   * How many images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Target image size for generation
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Auto Mask Generation
   *
   * Whether to automatically generate mask from detected text
   */
  auto_mask_generation?: boolean;
  /**
   * Reference Image Url
   *
   * Optional base64 reference image for style
   */
  reference_image_url?: string;
  /**
   * Source Image Url
   *
   * Base64-encoded source image with drawn mask layers
   */
  source_image_url: string;
  /**
   * Prompt
   *
   * Text prompt to inpaint or customize
   */
  prompt: string;
  /**
   * Mask Image Url
   *
   * Base64-encoded mask image (optional if using auto_mask_generation)
   */
  mask_image_url?: string;
  /**
   * Source Text
   *
   * Source text to replace (if empty, masks all detected text)
   */
  source_text?: string;
  /**
   * Num Inference Steps
   *
   * Number of inference steps (1-100)
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility
   */
  seed?: number;
  /**
   * Cfg Scale
   *
   * Guidance or strength scale for the model
   */
  cfg_scale?: number;
};

/**
 * VideoFile
 */
export type VideoFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Duration
   *
   * The duration of the video
   */
  duration?: number;
  /**
   * Height
   *
   * The height of the video
   */
  height?: number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * Width
   *
   * The width of the video
   */
  width?: number;
  /**
   * Fps
   *
   * The FPS of the video
   */
  fps?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Num Frames
   *
   * The number of frames in the video
   */
  num_frames?: number;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * FILMImageOutput
 */
export type FilmOutput = {
  /**
   * Images
   *
   * The generated frames as individual images.
   */
  images?: Array<ImageFile>;
  /**
   * Video
   *
   * The generated video file, if output_type is 'video'.
   */
  video?: VideoFile;
};

/**
 * FILMImageInput
 */
export type FilmInput = {
  /**
   * Video Write Mode
   *
   * The write mode of the output video. Only applicable if output_type is 'video'.
   */
  video_write_mode?: "fast" | "balanced" | "small";
  /**
   * Number of Frames
   *
   * The number of frames to generate between the input images.
   */
  num_frames?: number;
  /**
   * Include Start
   *
   * Whether to include the start image in the output.
   */
  include_start?: boolean;
  /**
   * Video Quality
   *
   * The quality of the output video. Only applicable if output_type is 'video'.
   */
  video_quality?: "low" | "medium" | "high" | "maximum";
  /**
   * Include End
   *
   * Whether to include the end image in the output.
   */
  include_end?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Frames Per Second
   *
   * Frames per second for the output video. Only applicable if output_type is 'video'.
   */
  fps?: number;
  /**
   * Start Image URL
   *
   * The URL of the first image to use as the starting point for interpolation.
   */
  start_image_url: string;
  /**
   * End Image URL
   *
   * The URL of the second image to use as the ending point for interpolation.
   */
  end_image_url: string;
  /**
   * Image Format
   *
   * The format of the output images. Only applicable if output_type is 'images'.
   */
  image_format?: "png" | "jpeg";
  /**
   * Output Type
   *
   * The type of output to generate; either individual images or a video.
   */
  output_type?: "images" | "video";
};

/**
 * RIFEImageOutput
 */
export type RifeOutput = {
  /**
   * Images
   *
   * The generated frames as individual images.
   */
  images?: Array<Image>;
  /**
   * Video
   *
   * The generated video file, if output_type is 'video'.
   */
  video?: File;
};

/**
 * RIFEImageInput
 */
export type RifeInput = {
  /**
   * Output Format
   *
   * The format of the output images. Only applicable if output_type is 'images'.
   */
  output_format?: "png" | "jpeg";
  /**
   * Frames Per Second
   *
   * Frames per second for the output video. Only applicable if output_type is 'video'.
   */
  fps?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Include End
   *
   * Whether to include the end image in the output.
   */
  include_end?: boolean;
  /**
   * Include Start
   *
   * Whether to include the start image in the output.
   */
  include_start?: boolean;
  /**
   * Number of Frames
   *
   * The number of frames to generate between the input images.
   */
  num_frames?: number;
  /**
   * End Image URL
   *
   * The URL of the second image to use as the ending point for interpolation.
   */
  end_image_url: string;
  /**
   * Output Type
   *
   * The type of output to generate; either individual images or a video.
   */
  output_type?: "images" | "video";
  /**
   * Start Image URL
   *
   * The URL of the first image to use as the starting point for interpolation.
   */
  start_image_url: string;
};

/**
 * Output
 */
export type HidreamE11Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseInput
 */
export type HidreamE11Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt?: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Guidance Scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your initial image when looking for a related image to show you.
   *
   */
  image_guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * URL of an input image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Target Image Description
   *
   * The description of the target image after your edits have been made. Leave this blank to allow the model to use its own imagination.
   */
  target_image_description?: string;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * RetouchOutput
 */
export type ImageEditingRetouchOutput = {
  /**
   * Images
   */
  images: Array<Image>;
  /**
   * Seed
   */
  seed: number;
};

/**
 * RetouchInput
 *
 * Input model for retouch endpoint.
 */
export type ImageEditingRetouchInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Image URL
   *
   * URL of the image to retouch.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ImageToPanoramaResponse
 */
export type HunyuanWorldOutput = {
  /**
   * Image
   *
   * The generated panorama image.
   */
  image: Image;
};

/**
 * ImageToPanoramaRequest
 */
export type HunyuanWorldInput = {
  /**
   * Prompt
   *
   * The prompt to use for the panorama generation.
   */
  prompt: string;
  /**
   * Image Url
   *
   * The URL of the image to convert to a panorama.
   */
  image_url: string;
};

/**
 * KontextInpaintOutput
 */
export type FluxKontextLoraInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKontextInpaintInput
 */
export type FluxKontextLoraInpaintInput = {
  /**
   * Prompt
   *
   * The prompt for the image to image task.
   */
  prompt: string;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Reference Image URL
   *
   * The URL of the reference image for inpainting.
   */
  reference_image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to be inpainted.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URL
   *
   * The URL of the mask for inpainting.
   */
  mask_url: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * KreaReduxOutput
 */
export type Flux1KreaReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaFlux1ReduxInput
 */
export type Flux1KreaReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * KreaOutput
 */
export type Flux1KreaImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaFlux1ImageToInput
 */
export type Flux1KreaImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * KreaReduxOutput
 */
export type FluxKreaReduxOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaReduxInput
 */
export type FluxKreaReduxInput = {
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxKreaImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseKreaImageToInput
 */
export type FluxKreaImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Output
 */
export type FluxKreaLoraImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ImageToImageInput
 */
export type FluxKreaLoraImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * Output
 */
export type FluxKreaLoraInpaintingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * InpaintInput
 */
export type FluxKreaLoraInpaintingInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate. This is always set to 1 for streaming output.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * URL of image to use for inpainting. or img2img
   */
  image_url: string;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use any number of LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.
   */
  strength?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   *
   * The mask to area to Inpaint in.
   *
   */
  mask_url: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * CharacterRemixOutputV3
 */
export type IdeogramCharacterRemixOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * CharacterRemixInputV3
 */
export type IdeogramCharacterRemixInput = {
  /**
   * Prompt
   *
   * The prompt to remix the image with
   */
  prompt: string;
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "REALISTIC" | "FICTION";
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>;
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image URL
   *
   * The image URL to remix
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * Strength
   *
   * Strength of the input image in the remix
   */
  strength?: number;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * CharacterOutputV3
 */
export type IdeogramCharacterOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * BaseCharacterInputV3
 */
export type IdeogramCharacterInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The resolution of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "REALISTIC" | "FICTION";
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
  /**
   * Negative Prompt
   *
   * Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
};

/**
 * CharacterEditOutputV3
 */
export type IdeogramCharacterEditOutput = {
  /**
   * Images
   */
  images: Array<FileType2>;
  /**
   * Seed
   *
   * Seed used for the random number generator
   */
  seed: number;
};

/**
 * CharacterEditInputV3
 */
export type IdeogramCharacterEditInput = {
  /**
   * Prompt
   *
   * The prompt to fill the masked part of the image.
   */
  prompt: string;
  /**
   * Style
   *
   * The style type to generate with. Cannot be used with style_codes.
   */
  style?: "AUTO" | "REALISTIC" | "FICTION";
  /**
   * Expand Prompt
   *
   * Determine if MagicPrompt should be used in generating the request or not.
   */
  expand_prompt?: boolean;
  /**
   * Rendering Speed
   *
   * The rendering speed to use.
   */
  rendering_speed?: "TURBO" | "BALANCED" | "QUALITY";
  /**
   * Reference Mask Urls
   *
   * A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format
   */
  reference_mask_urls?: Array<string>;
  /**
   * Reference Image Urls
   *
   * A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format
   */
  reference_image_urls: Array<string>;
  /**
   * Image Urls
   *
   * A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format
   */
  image_urls?: Array<string> | unknown;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image URL
   *
   * The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image.
   */
  image_url: string;
  /**
   * Style Codes
   *
   * A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style
   */
  style_codes?: Array<string> | unknown;
  /**
   * A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)
   */
  color_palette?: ColorPalette | unknown;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Seed for the random number generator
   */
  seed?: number | unknown;
  /**
   * Mask URL
   *
   * The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image.
   */
  mask_url: string;
};

/**
 * QwenImageOutput
 */
export type QwenImageEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseQwenEditImageInput
 */
export type QwenImageEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * NextStepResponse
 */
export type Nextstep1Output = {
  /**
   * Image
   *
   * Generated image
   */
  image: {
    /**
     * File Size
     *
     * The size of the file in bytes.
     */
    file_size?: number | unknown;
    /**
     * Height
     *
     * The height of the image in pixels.
     */
    height?: number | unknown;
    /**
     * File Name
     *
     * The name of the file. It will be auto-generated if not provided.
     */
    file_name?: string | unknown;
    /**
     * Content Type
     *
     * The mime type of the file.
     */
    content_type?: string | unknown;
    /**
     * Url
     *
     * The URL where the file can be downloaded from.
     */
    url: string;
    /**
     * Width
     *
     * The width of the image in pixels.
     */
    width?: number | unknown;
  };
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number;
};

/**
 * NextStepEditRequest
 */
export type Nextstep1Input = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   *
   */
  negative_prompt: string;
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
};

/**
 * NanoBananaImageToImageOutput
 */
export type NanoBananaEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaImageToImageInput
 */
export type NanoBananaEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16";
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * OutputModel
 */
export type Reimagine32Output = {
  image: ImageType3;
};

/**
 * InputModel
 */
export type Reimagine32Input = {
  /**
   * Prompt
   *
   * Prompt for image generation.
   */
  prompt: string;
  /**
   * Depth Preprocess
   *
   * Depth image preprocess.
   */
  depth_preprocess?: boolean;
  /**
   * Canny Preprocess
   *
   * Canny image preprocess.
   */
  canny_preprocess?: boolean;
  /**
   * Depth Image Url
   *
   * Depth control image (file or URL).
   */
  depth_image_url?: string | unknown;
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number;
  /**
   * Canny Image Url
   *
   * Canny edge control image (file or URL).
   */
  canny_image_url?: string | unknown;
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string;
  /**
   * Depth Scale
   *
   * Depth control strength (0.0 to 1.0).
   */
  depth_scale?: number;
  /**
   * Aspect Ratio
   *
   * Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9
   */
  aspect_ratio?:
    | "1:1"
    | "2:3"
    | "3:2"
    | "3:4"
    | "4:3"
    | "4:5"
    | "5:4"
    | "9:16"
    | "16:9";
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Prompt Enhancer
   *
   * Whether to improve the prompt.
   */
  prompt_enhancer?: boolean;
  /**
   * Truncate Prompt
   *
   * Whether to truncate the prompt.
   */
  truncate_prompt?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Canny Scale
   *
   * Canny edge control strength (0.0 to 1.0).
   */
  canny_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps.
   */
  num_inference_steps?: number;
};

/**
 * QwenImageI2IOutput
 */
export type QwenImageImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * QwenImageI2IInput
 */
export type QwenImageImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Image Size
   *
   * The size of the generated image. By default, we will use the provided image for determining the image_size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Use Turbo
   *
   * Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).
   */
  use_turbo?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image Url
   *
   * The reference image to guide the generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Denoising strength. 1.0 = fully remake; 0.0 = preserve original.
   */
  strength?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * NanoBananaImageToImageOutput
 */
export type Gemini25FlashImageEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<ImageFile>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaImageToImageInput
 */
export type Gemini25FlashImageEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16";
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * USOOutputImage
 */
export type UsoOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images with applied style and/or subject customization
   */
  images: Array<Image>;
  /**
   * Timings
   *
   * Performance timings for different stages
   */
  timings: {
    [key: string]: unknown;
  };
  /**
   * Has Nsfw Concepts
   *
   * NSFW detection results for each generated image
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * USOInputImage
 */
export type UsoInput = {
  /**
   * Prompt
   *
   * Text prompt for generation. Can be empty for pure style transfer.
   */
  prompt?: string;
  /**
   * Number of Images
   *
   * Number of images to generate in parallel.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * Output image format. PNG preserves transparency, JPEG is smaller.
   */
  output_format?: "jpeg" | "png";
  /**
   * Keep Input Size
   *
   * Preserve the layout and dimensions of the input content image. Useful for style transfer.
   */
  keep_size?: boolean;
  /**
   * Reference Images
   *
   * List of image URLs in order: [content_image, style_image, extra_style_image].
   */
  input_image_urls: Array<string>;
  /**
   * Sync Mode
   *
   * If true, wait for generation and upload before returning. Increases latency but provides immediate access to images.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale (CFG)
   *
   * How closely to follow the prompt. Higher values stick closer to the prompt.
   */
  guidance_scale?: number;
  /**
   * Inference Steps
   *
   * Number of denoising steps. More steps can improve quality but increase generation time.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducible generation. Use same seed for consistent results.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * What you don't want in the image. Use it to exclude unwanted elements, styles, or artifacts.
   */
  negative_prompt?: string;
  /**
   * Safety Checker
   *
   * Enable NSFW content detection and filtering.
   */
  enable_safety_checker?: boolean;
};

/**
 * WanI2IResponse
 */
export type WanV22A14bImageToImageOutput = {
  /**
   * Prompt
   *
   * The text prompt used for image generation.
   */
  prompt?: string;
  /**
   * Image
   *
   * The generated image file.
   */
  image: File;
  /**
   * Seed
   *
   * The seed used for generation.
   */
  seed: number;
};

/**
 * WanI2IRequest
 */
export type WanV22A14bImageToImageInput = {
  /**
   * Shift
   */
  shift?: number;
  /**
   * Prompt
   *
   * The text prompt to guide image generation.
   */
  prompt: string;
  /**
   * Image Size
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.
   */
  acceleration?: "none" | "regular";
  /**
   * Enable Safety Checker
   *
   * If set to true, input data will be checked for safety before processing.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale.
   */
  guidance_scale?: number;
  /**
   * Image Format
   *
   * The format of the output image.
   */
  image_format?: "png" | "jpeg";
  /**
   * Negative Prompt
   *
   * Negative prompt for video generation.
   */
  negative_prompt?: string;
  /**
   * Aspect Ratio
   *
   * Aspect ratio of the generated image. If 'auto', the aspect ratio will be determined automatically based on the input image.
   */
  aspect_ratio?: "auto" | "16:9" | "9:16" | "1:1";
  /**
   * Enable Output Safety Checker
   *
   * If set to true, output video will be checked for safety after generation.
   */
  enable_output_safety_checker?: boolean;
  /**
   * Image URL
   *
   * URL of the input image.
   */
  image_url: string;
  /**
   * Strength
   *
   * Denoising strength. 1.0 = fully remake; 0.0 = preserve original.
   */
  strength?: number;
  /**
   * Guidance Scale (2nd Stage)
   *
   * Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.
   */
  guidance_scale_2?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
};

/**
 * SeedDream4EditOutput
 */
export type BytedanceSeedreamV4EditOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * Seed used for generation
   */
  seed: number;
};

/**
 * SeedDream4EditInput
 */
export type BytedanceSeedreamV4EditInput = {
  /**
   * Prompt
   *
   * The text prompt used to edit the image
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. The minimum total image area is 921600 pixels. Failing this, the image size will be adjusted to by scaling it up, while maintaining the aspect ratio.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto"
    | "auto_2K"
    | "auto_4K";
  /**
   * Enhance Prompt Mode
   *
   * The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.
   */
  enhance_prompt_mode?: "standard" | "fast";
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15
   */
  max_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.
   */
  image_urls: Array<string>;
};

/**
 * ReferenceToImageOutput
 */
export type ViduReferenceToImageOutput = {
  /**
   * Image
   *
   * The edited image
   */
  image: Image;
};

/**
 * ReferenceToImageRequest
 */
export type ViduReferenceToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: "16:9" | "9:16" | "1:1";
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>;
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number;
};

/**
 * QwenImageOutput
 */
export type QwenImageEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseQwenEditImageLoRAInput
 */
export type QwenImageEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   *
   * If set to true, the function will wait for the image to be generated and uploaded
   * before returning the response. This will increase the latency of the function but
   * it allows you to get the image directly in the response without going through the CDN.
   *
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type Flux1SrpoImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseSRPOFlux1ImageToInput
 */
export type Flux1SrpoImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
};

/**
 * Output
 */
export type FluxSrpoImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseSRPOImageToInput
 */
export type FluxSrpoImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * QwenImageInpaintOutput
 */
export type QwenImageEditInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseQwenEditInpaintImageInput
 */
export type QwenImageEditInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of noising process for inpainting
   */
  strength?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Mask URL
   *
   * The URL of the mask for inpainting
   */
  mask_url: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * MakeupApplicationOutput
 */
export type ImageAppsV2MakeupApplicationOutput = {
  /**
   * Images
   *
   * Portrait with applied makeup
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * MakeupApplicationInput
 */
export type ImageAppsV2MakeupApplicationInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Intensity
   */
  intensity?: "light" | "medium" | "heavy" | "dramatic";
  /**
   * Makeup Style
   */
  makeup_style?:
    | "natural"
    | "glamorous"
    | "smoky_eyes"
    | "bold_lips"
    | "no_makeup"
    | "remove_makeup"
    | "dramatic"
    | "bridal"
    | "professional"
    | "korean_style"
    | "artistic";
  /**
   * Image Url
   *
   * Portrait image URL for makeup application
   */
  image_url: string;
};

/**
 * AspectRatio
 *
 * Aspect ratio model that calculates 4K resolution dimensions
 */
export type AspectRatio = {
  /**
   * Ratio
   *
   * Aspect ratio for 4K resolution output
   */
  ratio?: "1:1" | "16:9" | "9:16" | "4:3" | "3:4";
};

/**
 * AgeModifyOutput
 */
export type ImageAppsV2AgeModifyOutput = {
  /**
   * Images
   *
   * Portrait with modified age
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * AgeModifyInput
 */
export type ImageAppsV2AgeModifyInput = {
  /**
   * Image Url
   *
   * Portrait image URL for age modification
   */
  image_url: string;
  aspect_ratio?: AspectRatio;
  /**
   * Preserve Identity
   */
  preserve_identity?: boolean;
  /**
   * Target Age
   */
  target_age?: number;
};

/**
 * CityTeleportOutput
 */
export type ImageAppsV2CityTeleportOutput = {
  /**
   * Images
   *
   * Person teleported to city location
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * CityTeleportInput
 */
export type ImageAppsV2CityTeleportInput = {
  /**
   * City Image Url
   *
   * Optional city background image URL. When provided, the person will be blended into this custom scene.
   */
  city_image_url?: string | unknown;
  aspect_ratio?: AspectRatio;
  /**
   * City Name
   *
   * City name (used when city_image_url is not provided)
   */
  city_name: string;
  /**
   * Photo Shot
   *
   * Type of photo shot
   */
  photo_shot?:
    | "extreme_close_up"
    | "close_up"
    | "medium_close_up"
    | "medium_shot"
    | "medium_long_shot"
    | "long_shot"
    | "extreme_long_shot"
    | "full_body";
  /**
   * Camera Angle
   *
   * Camera angle for the shot
   */
  camera_angle?:
    | "eye_level"
    | "low_angle"
    | "high_angle"
    | "dutch_angle"
    | "birds_eye_view"
    | "worms_eye_view"
    | "overhead"
    | "side_angle";
  /**
   * Person Image Url
   *
   * Person photo URL
   */
  person_image_url: string;
};

/**
 * ExpressionChangeOutput
 */
export type ImageAppsV2ExpressionChangeOutput = {
  /**
   * Images
   *
   * Portrait with changed expression
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * ExpressionChangeInput
 */
export type ImageAppsV2ExpressionChangeInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Target Expression
   */
  target_expression?:
    | "smile"
    | "surprise"
    | "glare"
    | "panic"
    | "shyness"
    | "laugh"
    | "cry"
    | "angry"
    | "sad"
    | "happy"
    | "excited"
    | "shocked"
    | "confused"
    | "focused"
    | "dreamy"
    | "serious"
    | "playful"
    | "mysterious"
    | "confident"
    | "thoughtful";
  /**
   * Image Url
   *
   * Portrait image URL for expression change
   */
  image_url: string;
};

/**
 * HairChangeOutput
 */
export type ImageAppsV2HairChangeOutput = {
  /**
   * Images
   *
   * Portrait with changed hair
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * HairChangeInput
 */
export type ImageAppsV2HairChangeInput = {
  /**
   * Target Hairstyle
   */
  target_hairstyle?:
    | "short_hair"
    | "medium_long_hair"
    | "long_hair"
    | "curly_hair"
    | "wavy_hair"
    | "high_ponytail"
    | "bun"
    | "bob_cut"
    | "pixie_cut"
    | "braids"
    | "straight_hair"
    | "afro"
    | "dreadlocks"
    | "buzz_cut"
    | "mohawk"
    | "bangs"
    | "side_part"
    | "middle_part";
  aspect_ratio?: AspectRatio;
  /**
   * Hair Color
   */
  hair_color?:
    | "black"
    | "dark_brown"
    | "light_brown"
    | "blonde"
    | "platinum_blonde"
    | "red"
    | "auburn"
    | "gray"
    | "silver"
    | "blue"
    | "green"
    | "purple"
    | "pink"
    | "rainbow"
    | "natural"
    | "highlights"
    | "ombre"
    | "balayage";
  /**
   * Image Url
   *
   * Portrait image URL for hair change
   */
  image_url: string;
};

/**
 * HeadshotOutput
 */
export type ImageAppsV2HeadshotPhotoOutput = {
  /**
   * Images
   *
   * Professional headshot image
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * HeadshotInput
 */
export type ImageAppsV2HeadshotPhotoInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Background Style
   */
  background_style?: "professional" | "corporate" | "clean" | "gradient";
  /**
   * Image Url
   *
   * Portrait image URL to convert to professional headshot
   */
  image_url: string;
};

/**
 * ObjectRemovalOutput
 */
export type ImageAppsV2ObjectRemovalOutput = {
  /**
   * Images
   *
   * Image with object removed
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * ObjectRemovalInput
 */
export type ImageAppsV2ObjectRemovalInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Object To Remove
   *
   * Object to remove
   */
  object_to_remove: string;
  /**
   * Image Url
   *
   * Image URL containing object to remove
   */
  image_url: string;
};

/**
 * PerspectiveOutput
 */
export type ImageAppsV2PerspectiveOutput = {
  /**
   * Images
   *
   * Image with changed perspective
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * PerspectiveInput
 */
export type ImageAppsV2PerspectiveInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Target Perspective
   */
  target_perspective?:
    | "front"
    | "left_side"
    | "right_side"
    | "back"
    | "top_down"
    | "bottom_up"
    | "birds_eye"
    | "three_quarter_left"
    | "three_quarter_right";
  /**
   * Image Url
   *
   * Image URL for perspective change
   */
  image_url: string;
};

/**
 * PhotographyEffectsOutput
 */
export type ImageAppsV2PhotographyEffectsOutput = {
  /**
   * Images
   *
   * Image with photography effects
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * PhotographyEffectsInput
 */
export type ImageAppsV2PhotographyEffectsInput = {
  /**
   * Effect Type
   */
  effect_type?:
    | "film"
    | "vintage_film"
    | "portrait_photography"
    | "fashion_photography"
    | "street_photography"
    | "sepia_tone"
    | "film_grain"
    | "light_leaks"
    | "vignette_effect"
    | "instant_camera"
    | "golden_hour"
    | "dramatic_lighting"
    | "soft_focus"
    | "bokeh_effect"
    | "high_contrast"
    | "double_exposure";
  aspect_ratio?: AspectRatio;
  /**
   * Image Url
   *
   * Image URL for photography effects
   */
  image_url: string;
};

/**
 * PortraitOutput
 */
export type ImageAppsV2PortraitEnhanceOutput = {
  /**
   * Images
   *
   * Enhanced portrait
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * PortraitInput
 */
export type ImageAppsV2PortraitEnhanceInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Image Url
   *
   * Portrait image URL to enhance
   */
  image_url: string;
};

/**
 * PhotoRestorationOutput
 */
export type ImageAppsV2PhotoRestorationOutput = {
  /**
   * Images
   *
   * Restored photo
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * PhotoRestorationInput
 */
export type ImageAppsV2PhotoRestorationInput = {
  /**
   * Enhance Resolution
   */
  enhance_resolution?: boolean;
  aspect_ratio?: AspectRatio;
  /**
   * Remove Scratches
   */
  remove_scratches?: boolean;
  /**
   * Fix Colors
   */
  fix_colors?: boolean;
  /**
   * Image Url
   *
   * Old or damaged photo URL to restore
   */
  image_url: string;
};

/**
 * StyleTransferOutput
 */
export type ImageAppsV2StyleTransferOutput = {
  /**
   * Images
   *
   * Image with transferred style
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * StyleTransferInput
 */
export type ImageAppsV2StyleTransferInput = {
  /**
   * Target Style
   */
  target_style?:
    | "anime_character"
    | "cartoon_3d"
    | "hand_drawn_animation"
    | "cyberpunk_future"
    | "anime_game_style"
    | "comic_book_animation"
    | "animated_series"
    | "cartoon_animation"
    | "lofi_aesthetic"
    | "cottagecore"
    | "dark_academia"
    | "y2k"
    | "vaporwave"
    | "liminal_space"
    | "weirdcore"
    | "dreamcore"
    | "synthwave"
    | "outrun"
    | "photorealistic"
    | "hyperrealistic"
    | "digital_art"
    | "concept_art"
    | "impressionist"
    | "anime"
    | "pixel_art"
    | "claymation";
  aspect_ratio?: AspectRatio;
  /**
   * Style Reference Image Url
   *
   * Optional reference image URL. When provided, the style will be inferred from this image instead of the selected preset style.
   */
  style_reference_image_url?: string | unknown;
  /**
   * Image Url
   *
   * Image URL for style transfer
   */
  image_url: string;
};

/**
 * RelightingOutput
 */
export type ImageAppsV2RelightingOutput = {
  /**
   * Images
   *
   * Image with new lighting
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * RelightingInput
 */
export type ImageAppsV2RelightingInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Lighting Style
   */
  lighting_style?:
    | "natural"
    | "studio"
    | "golden_hour"
    | "blue_hour"
    | "dramatic"
    | "soft"
    | "hard"
    | "backlight"
    | "side_light"
    | "front_light"
    | "rim_light"
    | "sunset"
    | "sunrise"
    | "neon"
    | "candlelight"
    | "moonlight"
    | "spotlight"
    | "ambient";
  /**
   * Image Url
   *
   * Image URL for relighting
   */
  image_url: string;
};

/**
 * TextureTransformOutput
 */
export type ImageAppsV2TextureTransformOutput = {
  /**
   * Images
   *
   * Image with transformed texture
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * TextureTransformInput
 */
export type ImageAppsV2TextureTransformInput = {
  /**
   * Target Texture
   */
  target_texture?:
    | "cotton"
    | "denim"
    | "wool"
    | "felt"
    | "wood"
    | "leather"
    | "velvet"
    | "stone"
    | "marble"
    | "ceramic"
    | "concrete"
    | "brick"
    | "clay"
    | "foam"
    | "glass"
    | "metal"
    | "silk"
    | "fabric"
    | "crystal"
    | "rubber"
    | "plastic"
    | "lace";
  aspect_ratio?: AspectRatio;
  /**
   * Image Url
   *
   * Image URL for texture transformation
   */
  image_url: string;
};

/**
 * VirtualTryOnOutput
 */
export type ImageAppsV2VirtualTryOnOutput = {
  /**
   * Images
   *
   * Person wearing the virtual clothing
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * VirtualTryOnInput
 */
export type ImageAppsV2VirtualTryOnInput = {
  /**
   * Preserve Pose
   */
  preserve_pose?: boolean;
  aspect_ratio?: AspectRatio;
  /**
   * Clothing Image Url
   *
   * Clothing photo URL
   */
  clothing_image_url: string;
  /**
   * Person Image Url
   *
   * Person photo URL
   */
  person_image_url: string;
};

/**
 * ProductPhotographyOutput
 */
export type ImageAppsV2ProductPhotographyOutput = {
  /**
   * Images
   *
   * Professional studio product photography
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * ProductPhotographyInput
 */
export type ImageAppsV2ProductPhotographyInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Product Image Url
   *
   * Image URL of the product to create professional studio photography
   */
  product_image_url: string;
};

/**
 * ProductHoldingOutput
 */
export type ImageAppsV2ProductHoldingOutput = {
  /**
   * Images
   *
   * Person holding the product naturally
   */
  images: Array<ImageType3>;
  /**
   * Inference Time Ms
   *
   * Total inference time in milliseconds
   */
  inference_time_ms: number;
};

/**
 * ProductHoldingInput
 */
export type ImageAppsV2ProductHoldingInput = {
  aspect_ratio?: AspectRatio;
  /**
   * Product Image Url
   *
   * Image URL of the product to be held by the person
   */
  product_image_url: string;
  /**
   * Person Image Url
   *
   * Image URL of the person who will hold the product
   */
  person_image_url: string;
};

/**
 * SeedVRImageOutput
 */
export type SeedvrUpscaleImageOutput = {
  image: ImageFileType2;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
};

/**
 * SeedVRImageInput
 */
export type SeedvrUpscaleImageInput = {
  /**
   * Upscale Mode
   *
   * The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.
   */
  upscale_mode?: "target" | "factor";
  /**
   * Noise Scale
   *
   * The noise scale to use for the generation process.
   */
  noise_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "png" | "jpg" | "webp";
  /**
   * Target Resolution
   *
   * The target resolution to upscale to when `upscale_mode` is `target`.
   */
  target_resolution?: "720p" | "1080p" | "1440p" | "2160p";
  /**
   * Image Url
   *
   * The input image to be processed
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Upscale Factor
   *
   * Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.
   */
  upscale_factor?: number;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed?: number | unknown;
};

/**
 * QwenImageOutput
 */
export type QwenImageEditPlusOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseQwenEditImagePlusInput
 */
export type QwenImageEditPlusInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ImageToImageOutput
 *
 * Output for image editing
 */
export type Wan25PreviewImageToImageOutput = {
  /**
   * Seeds
   *
   * The seeds used for each generated image
   */
  seeds: Array<number>;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Actual Prompt
   *
   * The original prompt (prompt expansion is not available for image editing)
   */
  actual_prompt?: string;
};

/**
 * ImageToImageInput
 *
 * Input for image editing
 */
export type Wan25PreviewImageToImageInput = {
  /**
   * Prompt
   *
   * The text prompt describing how to edit the image. Max 2000 characters.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate. Values from 1 to 4.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 384 and 1440 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed is chosen.
   */
  seed?: number;
  /**
   * Image Urls
   *
   * URLs of images to edit. For single-image editing, provide 1 URL. For multi-reference generation, provide up to 2 URLs. If more than 2 URLs are provided, only the first 2 will be used.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Negative prompt to describe content to avoid. Max 500 characters.
   */
  negative_prompt?: string;
};

/**
 * QwenImageOutput
 */
export type QwenImageEditImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseQwenEditImg2ImgInput
 */
export type QwenImageEditImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * Strength of the image-to-image transformation. Lower values preserve more of the original image.
   */
  strength?: number;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * LucidFluxResponse
 */
export type LucidfluxOutput = {
  /**
   * Image
   *
   * Generated image
   */
  image: Image;
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed: number;
};

/**
 * LucidFluxRequest
 */
export type LucidfluxInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Guidance
   *
   * The guidance to use for the diffusion process.
   */
  guidance?: number;
  /**
   * Target Height
   *
   * The height of the output image.
   */
  target_height?: number;
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Target Width
   *
   * The width of the output image.
   */
  target_width?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for sampling. Higher values give better quality but take longer.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Seed used for random number generation
   */
  seed?: number;
};

/**
 * QwenImageOutput
 */
export type QwenImageEditPlusLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export type QwenImageEditPlusLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * DreamOmni2Response
 */
export type Dreamomni2EditOutput = {
  /**
   * Image
   *
   * Generated image
   */
  image: Image;
};

/**
 * DreamOmni2Request
 */
export type Dreamomni2EditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * You can use only with to 2 images.
   *
   * List of URLs of input images for editing.
   */
  image_urls: Array<string>;
};

/**
 * Image2PixelOutput
 */
export type Image2PixelOutput = {
  /**
   * Images
   *
   * The processed pixel-art image (PNG) and the scaled image (PNG).
   */
  images: Array<ImageFile>;
  /**
   * Num Colors
   *
   * The number of colors in the processed media.
   */
  num_colors: number;
  /**
   * Palette
   *
   * The palette of the processed media.
   */
  palette: Array<string>;
  /**
   * Pixel Scale
   *
   * The detected pixel scale of the input.
   */
  pixel_scale: number;
};

/**
 * Image2PixelInput
 */
export type Image2PixelInput = {
  /**
   * Cleanup Morph
   *
   * Apply morphological operations to remove noise.
   */
  cleanup_morph?: boolean;
  /**
   * Auto Color Detect
   *
   * Enable automatic detection of optimal number of colors.
   */
  auto_color_detect?: boolean;
  /**
   * Alpha Threshold
   *
   * Alpha binarization threshold (0-255).
   */
  alpha_threshold?: number;
  /**
   * Snap Grid
   *
   * Align output to the pixel grid.
   */
  snap_grid?: boolean;
  /**
   * Fixed Palette
   *
   * Optional fixed color palette as hex strings (e.g., ['#000000', '#ffffff']).
   */
  fixed_palette?: Array<string>;
  /**
   * Scale
   *
   * Force a specific pixel scale. If None, auto-detect.
   */
  scale?: number;
  /**
   * Cleanup Jaggy
   *
   * Remove isolated diagonal pixels (jaggy edge cleanup).
   */
  cleanup_jaggy?: boolean;
  /**
   * Trim Borders
   *
   * Trim borders of the image.
   */
  trim_borders?: boolean;
  /**
   * Background Tolerance
   *
   * Background tolerance (0-255).
   */
  background_tolerance?: number;
  /**
   * Detect Method
   *
   * Scale detection method to use.
   */
  detect_method?: "auto" | "runs" | "edge";
  /**
   * Transparent Background
   *
   * Remove background of the image. This will check for contiguous color regions from the edges after correction and make them transparent.
   */
  transparent_background?: boolean;
  /**
   * Downscale Method
   *
   * Downscaling method to produce the pixel-art output.
   */
  downscale_method?:
    | "dominant"
    | "median"
    | "mode"
    | "mean"
    | "content-adaptive";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image Url
   *
   * The image URL to process into improved pixel art
   */
  image_url: string;
  /**
   * Background Mode
   *
   * Controls where to flood-fill from when removing the background.
   */
  background_mode?: "edges" | "corners" | "midpoints";
  /**
   * Max Colors
   *
   * Maximum number of colors in the output palette. Set None to disable limit.
   */
  max_colors?: number;
  /**
   * Dominant Color Threshold
   *
   * Dominant color threshold (0.0-1.0).
   */
  dominant_color_threshold?: number;
};

/**
 * ReveEditOutput
 *
 * Output for Reve image editing
 */
export type ReveEditOutput = {
  /**
   * Images
   *
   * The edited images
   */
  images: Array<Image>;
};

/**
 * ReveEditInput
 *
 * Input for Reve image editing
 */
export type ReveEditInput = {
  /**
   * Prompt
   *
   * The text description of how to edit the provided image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Reference Image URL
   *
   * URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string;
};

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export type ReveRemixOutput = {
  /**
   * Images
   *
   * The remixed images
   */
  images: Array<Image>;
};

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export type ReveRemixInput = {
  /**
   * Prompt
   *
   * The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.
   */
  aspect_ratio?: "16:9" | "9:16" | "3:2" | "2:3" | "4:3" | "3:4" | "1:1";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Reference Image URLs
   *
   * List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_urls: Array<string>;
};

/**
 * EditImageResponseMini
 */
export type GptImage1MiniEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * EditImageRequestMini
 */
export type GptImage1MiniEditInput = {
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "auto" | "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "auto" | "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>;
};

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * ChronoEditInput
 *
 * Input model for ChronoEdit standard editing operations
 */
export type ChronoEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: "480p" | "720p";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string;
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use for faster inference.
   */
  turbo_mode?: boolean;
  /**
   * Number of Temporal Reasoning Steps
   *
   * The number of temporal reasoning steps to perform.
   */
  num_temporal_reasoning_steps?: number;
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Enable Temporal Reasoning
   *
   * Whether to enable temporal reasoning.
   */
  enable_temporal_reasoning?: boolean;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
};

/**
 * Emu35EditOutput
 */
export type Emu35ImageEditImageOutput = {
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * Emu35ImageEditInput
 */
export type Emu35ImageEditImageInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: "480p" | "720p";
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output image.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
};

/**
 * Output
 */
export type FluxVisionUpscalerOutput = {
  /**
   * The URL of the generated image.
   */
  image: ImageType3;
  /**
   * Caption
   *
   * The VLM-generated caption describing the upscaled image.
   */
  caption: string;
  /**
   * Seed
   *
   * The seed used to generate the image.
   */
  seed: number;
  /**
   * Timings
   *
   * The timings of the different steps in the workflow.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Input
 */
export type FluxVisionUpscalerInput = {
  /**
   * Guidance
   *
   * CFG/guidance scale (1-4). Controls how closely the model follows the prompt.
   */
  guidance?: number;
  /**
   * Creativity
   *
   * The creativity of the model. The higher the creativity, the more the model will deviate from the original. Refers to the denoise strength of the sampling.
   */
  creativity?: number;
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string;
  /**
   * Upscale Factor
   *
   * The upscale factor (1-4x).
   */
  upscale_factor?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the upscale. If not provided, a random seed will be used.
   */
  seed?: number | unknown;
  /**
   * Steps
   *
   * Number of inference steps (4-50).
   */
  steps?: number;
};

/**
 * OutpaintOutput
 */
export type ImageAppsV2OutpaintOutput = {
  /**
   * Images
   *
   * Outpainted image with extended scene
   */
  images: Array<ImageType3>;
};

/**
 * OutpaintInput
 */
export type ImageAppsV2OutpaintInput = {
  /**
   * Prompt
   *
   * Optional prompt to guide the outpainting. If provided, it will be appended to the base outpaint instruction. Example: 'with a beautiful sunset in the background'
   */
  prompt?: string;
  /**
   * Expand Right
   *
   * Number of pixels to add as black margin on the right side (0-700).
   */
  expand_right?: number;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Zoom Out Percentage
   *
   * Percentage to zoom out the image. If set, the image will be scaled down by this percentage and black margins will be added to maintain original size. Example: 50 means the image will be 50% of original size with black margins filling the rest.
   */
  zoom_out_percentage?: number;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "png" | "jpeg" | "jpg" | "webp";
  /**
   * Image Url
   *
   * Image URL to outpaint
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If True, the function will wait for the image to be generated and uploaded before returning the response. If False, the function will return immediately and the image will be generated asynchronously.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Expand Left
   *
   * Number of pixels to add as black margin on the left side (0-700).
   */
  expand_left?: number;
  /**
   * Expand Bottom
   *
   * Number of pixels to add as black margin on the bottom side (0-700).
   */
  expand_bottom?: number;
  /**
   * Expand Top
   *
   * Number of pixels to add as black margin on the top side (0-700).
   */
  expand_top?: number;
};

/**
 * ReveFastEditOutput
 *
 * Output for Reve fast image editing
 */
export type ReveFastEditOutput = {
  /**
   * Images
   *
   * The edited images
   */
  images: Array<Image>;
};

/**
 * ReveFastEditInput
 *
 * Input for Reve fast image editing
 */
export type ReveFastEditInput = {
  /**
   * Prompt
   *
   * The text description of how to edit the provided image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Reference Image URL
   *
   * URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_url: string;
};

/**
 * ReveRemixOutput
 *
 * Output for Reve image remixing
 */
export type ReveFastRemixOutput = {
  /**
   * Images
   *
   * The remixed images
   */
  images: Array<Image>;
};

/**
 * ReveRemixInput
 *
 * Input for Reve image remixing
 */
export type ReveFastRemixInput = {
  /**
   * Prompt
   *
   * The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model.
   */
  aspect_ratio?: "16:9" | "9:16" | "3:2" | "2:3" | "4:3" | "3:4" | "1:1";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Output Format
   *
   * Output format for the generated image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Reference Image URLs
   *
   * List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.
   */
  image_urls: Array<string>;
};

/**
 * AddBackgroundOutput
 */
export type QwenImageEditPlusLoraGalleryAddBackgroundOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export type QwenImageEditPlusLoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to edit. Provide an image with a white or clean background.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FaceToFullPortraitOutput
 */
export type QwenImageEditPlusLoraGalleryFaceToFullPortraitOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export type QwenImageEditPlusLoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the cropped face image. Provide a close-up face photo.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * GroupPhotoOutput
 */
export type QwenImageEditPlusLoraGalleryGroupPhotoOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export type QwenImageEditPlusLoraGalleryGroupPhotoInput = {
  /**
   * Prompt
   *
   * Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * IntegrateProductOutput
 */
export type QwenImageEditPlusLoraGalleryIntegrateProductOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export type QwenImageEditPlusLoraGalleryIntegrateProductInput = {
  /**
   * Prompt
   *
   * Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image with product to integrate into background.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * NextSceneOutput
 */
export type QwenImageEditPlusLoraGalleryNextSceneOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export type QwenImageEditPlusLoraGalleryNextSceneInput = {
  /**
   * Prompt
   *
   * Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image to create the next scene from.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * RemoveElementOutput
 */
export type QwenImageEditPlusLoraGalleryRemoveElementOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export type QwenImageEditPlusLoraGalleryRemoveElementInput = {
  /**
   * Prompt
   *
   * Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image containing elements to remove.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * RemoveLightingOutput
 */
export type QwenImageEditPlusLoraGalleryRemoveLightingOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export type QwenImageEditPlusLoraGalleryRemoveLightingInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image with lighting/shadows to remove.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ShirtDesignOutput
 */
export type QwenImageEditPlusLoraGalleryShirtDesignOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export type QwenImageEditPlusLoraGalleryShirtDesignInput = {
  /**
   * Prompt
   *
   * Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * MultipleAnglesOutput
 */
export type QwenImageEditPlusLoraGalleryMultipleAnglesOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export type QwenImageEditPlusLoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Wide-Angle Lens
   *
   * Enable wide-angle lens effect
   */
  wide_angle_lens?: boolean;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Vertical Angle (Bird  Worm)
   *
   * Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)
   */
  vertical_angle?: number;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Move Forward  Close-Up
   *
   * Move camera forward (0=no movement, 10=close-up)
   */
  move_forward?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Rotate Right-Left (degrees )
   *
   * Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.
   */
  rotate_right_left?: number;
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * NanoBananaImageToImageOutput
 */
export type NanoBananaProEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<ImageFileType2>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaImageToImageInput
 */
export type NanoBananaProEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16"
    | unknown;
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: "1K" | "2K" | "4K";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * NanoBananaImageToImageOutput
 */
export type Gemini3ProImagePreviewEditOutput = {
  /**
   * Images
   *
   * The edited images.
   */
  images: Array<ImageFileType2>;
  /**
   * Description
   *
   * The description of the generated images.
   */
  description: string;
};

/**
 * NanoBananaImageToImageInput
 */
export type Gemini3ProImagePreviewEditInput = {
  /**
   * Prompt
   *
   * The prompt for image editing.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Enable Web Search
   *
   * Enable web search for the image generation task. This will allow the model to use the latest information from the web to generate the image.
   */
  enable_web_search?: boolean;
  /**
   * Resolution
   *
   * The resolution of the image to generate.
   */
  resolution?: "1K" | "2K" | "4K";
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "auto"
    | "21:9"
    | "16:9"
    | "3:2"
    | "4:3"
    | "5:4"
    | "1:1"
    | "4:5"
    | "3:4"
    | "2:3"
    | "9:16"
    | unknown;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * The seed for the random number generator.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to use for image-to-image generation or image editing.
   */
  image_urls: Array<string>;
  /**
   * Limit Generations
   *
   * Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.
   */
  limit_generations?: boolean;
};

/**
 * SAM3ImageOutput
 */
export type Sam3ImageOutput = {
  /**
   * Image
   *
   * Primary segmented mask preview.
   */
  image?: Image;
  /**
   * Metadata
   *
   * Per-mask metadata including scores and boxes.
   */
  metadata?: Array<MaskMetadata>;
  /**
   * Masks
   *
   * Segmented mask images.
   */
  masks: Array<Image>;
  /**
   * Scores
   *
   * Per-mask confidence scores when requested.
   */
  scores?: Array<number>;
  /**
   * Boxes
   *
   * Per-mask normalized bounding boxes [cx, cy, w, h] when requested.
   */
  boxes?: Array<Array<number>>;
};

/**
 * MaskMetadata
 */
export type MaskMetadata = {
  /**
   * Box
   *
   * Bounding box for the mask in normalized cxcywh coordinates.
   */
  box?: Array<number>;
  /**
   * Score
   *
   * Score for this mask.
   */
  score?: number;
  /**
   * Index
   *
   * Index of the mask inside the model output.
   */
  index: number;
};

/**
 * SAM3ImageInput
 */
export type Sam3ImageInput = {
  /**
   * Prompt
   *
   * Text prompt for segmentation
   */
  prompt?: string;
  /**
   * Include Boxes
   *
   * Whether to include bounding boxes for each mask (when available).
   */
  include_boxes?: boolean;
  /**
   * Box Prompts
   *
   * Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.
   */
  box_prompts?: Array<BoxPrompt>;
  /**
   * Return Multiple Masks
   *
   * If True, upload and return multiple generated masks as defined by `max_masks`.
   */
  return_multiple_masks?: boolean;
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Point Prompts
   *
   * List of point prompts
   */
  point_prompts?: Array<PointPrompt>;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Max Masks
   *
   * Maximum number of masks to return when `return_multiple_masks` is enabled.
   */
  max_masks?: number;
  /**
   * Include Scores
   *
   * Whether to include mask confidence scores.
   */
  include_scores?: boolean;
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean;
  /**
   * Text Prompt
   *
   * [DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.
   *
   * @deprecated
   */
  text_prompt?: string;
};

/**
 * PointPrompt
 */
export type PointPrompt = {
  /**
   * Y
   *
   * Y Coordinate of the prompt
   */
  y?: number;
  /**
   * X
   *
   * X Coordinate of the prompt
   */
  x?: number;
  /**
   * Object Id
   *
   * Optional object identifier. Prompts sharing an object id refine the same object.
   */
  object_id?: number;
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number;
  /**
   * Label
   *
   * 1 for foreground, 0 for background
   */
  label?: 0 | 1;
};

/**
 * BoxPrompt
 */
export type BoxPrompt = {
  /**
   * Y Min
   *
   * Y Min Coordinate of the box
   */
  y_min?: number;
  /**
   * Object Id
   *
   * Optional object identifier. Boxes sharing an object id refine the same object.
   */
  object_id?: number;
  /**
   * Frame Index
   *
   * The frame index to interact with.
   */
  frame_index?: number;
  /**
   * X Max
   *
   * X Max Coordinate of the box
   */
  x_max?: number;
  /**
   * X Min
   *
   * X Min Coordinate of the box
   */
  x_min?: number;
  /**
   * Y Max
   *
   * Y Max Coordinate of the box
   */
  y_max?: number;
};

/**
 * SAM3RLEOutput
 */
export type Sam3ImageRleOutput = {
  /**
   * Rle
   *
   * Run Length Encoding of the mask.
   */
  rle: string | Array<string>;
  /**
   * Metadata
   *
   * Per-mask metadata when multiple RLEs are returned.
   */
  metadata?: Array<MaskMetadata>;
  /**
   * Scores
   *
   * Per-mask confidence scores when requested.
   */
  scores?: Array<number>;
  /**
   * Boundingbox Frames Zip
   *
   * Zip file containing per-frame bounding box overlays.
   */
  boundingbox_frames_zip?: File;
  /**
   * Boxes
   *
   * Per-mask normalized bounding boxes [cx, cy, w, h] when requested.
   */
  boxes?: Array<Array<number>>;
};

/**
 * SAM3ImageInput
 */
export type Sam3ImageRleInput = {
  /**
   * Prompt
   *
   * Text prompt for segmentation
   */
  prompt?: string;
  /**
   * Include Boxes
   *
   * Whether to include bounding boxes for each mask (when available).
   */
  include_boxes?: boolean;
  /**
   * Box Prompts
   *
   * Box prompt coordinates (x_min, y_min, x_max, y_max). Multiple boxes supported - use object_id to group boxes for the same object or leave empty for separate objects.
   */
  box_prompts?: Array<BoxPrompt>;
  /**
   * Return Multiple Masks
   *
   * If True, upload and return multiple generated masks as defined by `max_masks`.
   */
  return_multiple_masks?: boolean;
  /**
   * Image Url
   *
   * URL of the image to be segmented
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Point Prompts
   *
   * List of point prompts
   */
  point_prompts?: Array<PointPrompt>;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Max Masks
   *
   * Maximum number of masks to return when `return_multiple_masks` is enabled.
   */
  max_masks?: number;
  /**
   * Include Scores
   *
   * Whether to include mask confidence scores.
   */
  include_scores?: boolean;
  /**
   * Apply Mask
   *
   * Apply the mask on the image.
   */
  apply_mask?: boolean;
  /**
   * Text Prompt
   *
   * [DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.
   *
   * @deprecated
   */
  text_prompt?: string;
};

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraGalleryUpscalerOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * ChronoEditUpscalerInput
 *
 * Input for upscaler mode
 */
export type ChronoEditLoraGalleryUpscalerInput = {
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA adapter.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image Url
   *
   * The image to upscale.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * Optional additional LoRAs to merge (max 3).
   */
  loras?: Array<ChronoLoraWeight>;
  /**
   * Upscale Factor
   *
   * Target scale factor for the output resolution.
   */
  upscale_factor?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of inference steps for the upscaling pass.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
};

/**
 * ChronoLoraWeight
 */
export type ChronoLoraWeight = {
  /**
   * Path
   *
   * URL or path to the LoRA weights (Safetensors).
   */
  path: string;
  /**
   * Scale
   *
   * Scale factor controlling LoRA strength.
   */
  scale?: number;
};

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraGalleryPaintbrushOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * ChronoEditPaintBrushInput
 *
 * Input for paintbrush mode
 */
export type ChronoEditLoraGalleryPaintbrushInput = {
  /**
   * Prompt
   *
   * Describe how to transform the sketched regions.
   */
  prompt: string;
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: "480p" | "720p";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA adapter.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image Url
   *
   * The image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use faster inference.
   */
  turbo_mode?: boolean;
  /**
   * Loras
   *
   * Optional additional LoRAs to merge (max 3).
   */
  loras?: Array<ChronoLoraWeight>;
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * Number of denoising steps to run.
   */
  num_inference_steps?: number;
  /**
   * Mask Url
   *
   * Optional mask image where black areas indicate regions to sketch/paint.
   */
  mask_url?: string;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
};

/**
 * ChronoEditOutput
 *
 * Unified output model for all ChronoEdit operations
 */
export type ChronoEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for the inference.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited image.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed: number;
};

/**
 * ChronoEditLoRAInput
 *
 * ChronoEdit input with optional custom LoRAs.
 */
export type ChronoEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Loras
   *
   * Optional additional LoRAs to merge for this request (max 3).
   */
  loras?: Array<ChronoLoraWeight>;
  /**
   * Turbo Mode
   *
   * Enable turbo mode to use for faster inference.
   */
  turbo_mode?: boolean;
  /**
   * Enable Temporal Reasoning
   *
   * Whether to enable temporal reasoning.
   */
  enable_temporal_reasoning?: boolean;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Guidance Scale
   *
   * The guidance scale for the inference.
   */
  guidance_scale?: number;
  /**
   * Resolution
   *
   * The resolution of the output image.
   */
  resolution?: "480p" | "720p";
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Number of Temporal Reasoning Steps
   *
   * The number of temporal reasoning steps to perform.
   */
  num_temporal_reasoning_steps?: number;
  /**
   * Sync Mode
   *
   * Whether to return the image in sync mode.
   */
  sync_mode?: boolean;
  /**
   * Image URL
   *
   * The image to edit.
   */
  image_url: string;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * The seed for the inference.
   */
  seed?: number;
};

/**
 * Flux2FlexEditOutput
 */
export type Flux2FlexEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2FlexImageEditInput
 */
export type Flux2FlexEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the generation.
   */
  guidance_scale?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | ImageSize
    | "auto"
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Prompt Expansion
   *
   * Whether to expand the prompt using the model's own knowledge.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
};

/**
 * CrystalUpscaleOutput
 */
export type CrystalUpscalerOutput = {
  /**
   * Images
   *
   * List of upscaled images
   */
  images: Array<Image>;
};

/**
 * CrystalUpscaleInput
 */
export type CrystalUpscalerInput = {
  /**
   * Creativity
   *
   * Creativity level for upscaling
   */
  creativity?: number;
  /**
   * Scale Factor
   *
   * Scale factor
   */
  scale_factor?: number;
  /**
   * Image Url
   *
   * URL to the input image
   */
  image_url: string;
};

/**
 * AddBackgroundOutput
 */
export type Flux2LoraGalleryAddBackgroundOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images with added background
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Add background to images
 */
export type Flux2LoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * The prompt describing the background to add. Must start with 'Add Background' followed by your description.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the add background effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images. Provide an image with a white or clean background.
   */
  image_urls: Array<string>;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ApartmentStagingOutput
 */
export type Flux2LoraGalleryApartmentStagingOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated furnished room images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * ApartmentStagingInput
 *
 * Input model for Apartment Staging endpoint - Furnish rooms
 */
export type Flux2LoraGalleryApartmentStagingInput = {
  /**
   * Prompt
   *
   * The prompt to generate a furnished room. Use 'furnish this room' for best results.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the apartment staging effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the empty room image to furnish.
   */
  image_urls: Array<string>;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FaceToFullPortraitOutput
 */
export type Flux2LoraGalleryFaceToFullPortraitOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated full portrait images from face
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from face
 */
export type Flux2LoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * The prompt describing the full portrait to generate from the face.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the face to full portrait effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the cropped face image.
   */
  image_urls: Array<string>;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * MultipleAnglesOutput
 */
export type Flux2LoraGalleryMultipleAnglesOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images with multiple camera angles
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word. Prompt is built automatically from slider values.
 */
export type Flux2LoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation.
   */
  acceleration?: "none" | "regular";
  /**
   * Horizontal Angle (Azimuth )
   *
   * Horizontal rotation angle around the object in degrees. 0=front view, 90=right side, 180=back view, 270=left side, 360=front view again.
   */
  horizontal_angle?: number;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>;
  /**
   * Zoom (Distance)
   *
   * Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).
   */
  zoom?: number;
  /**
   * Vertical Angle (Elevation )
   *
   * Vertical camera angle in degrees. 0=eye-level shot, 30=elevated shot, 60=high-angle shot (looking down from above).
   */
  vertical_angle?: number;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Lora Scale
   *
   * The strength of the multiple angles effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image.
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If True, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number | unknown;
};

/**
 * VirtualTryonOutput
 */
export type Flux2LoraGalleryVirtualTryonOutput = {
  /**
   * Prompt
   *
   * The prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated virtual try-on images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * VirtualTryonInput
 *
 * Input model for Virtual Try-on endpoint - Generate virtual try-on images
 */
export type Flux2LoraGalleryVirtualTryonInput = {
  /**
   * Prompt
   *
   * The prompt to generate a virtual try-on image.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The strength of the virtual try-on effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images for virtual try-on. Provide person image and clothing image.
   */
  image_urls: Array<string>;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * OmniImageElementInput
 */
export type OmniImageElementInput = {
  /**
   * Reference Image Urls
   *
   * Additional reference images from different angles. 1-3 images supported. At least one image is required.
   */
  reference_image_urls?: Array<string>;
  /**
   * Frontal Image Url
   *
   * The frontal image of the element (main view).
   */
  frontal_image_url: string;
};

/**
 * OmniImageOutput
 */
export type KlingImageO1Output = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
};

/**
 * OmniImageRequest
 */
export type KlingImageO1Input = {
  /**
   * Prompt
   *
   * Text prompt for image generation. Reference images using @Image1, @Image2, etc. (or @Image if only one image). Max 2500 characters.
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * Aspect ratio of generated images. 'auto' intelligently determines based on input content.
   */
  aspect_ratio?:
    | "auto"
    | "16:9"
    | "9:16"
    | "1:1"
    | "4:3"
    | "3:4"
    | "3:2"
    | "2:3"
    | "21:9";
  /**
   * Num Images
   *
   * Number of images to generate (1-9).
   */
  num_images?: number;
  /**
   * Resolution
   *
   * Image generation resolution. 1K: standard, 2K: high-res.
   */
  resolution?: "1K" | "2K";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Elements
   *
   * Elements (characters/objects) to include in the image. Reference in prompt as @Element1, @Element2, etc. Maximum 10 total (elements + reference images).
   */
  elements?: Array<OmniImageElementInput>;
  /**
   * Image Urls
   *
   * List of reference images. Reference images in prompt using @Image1, @Image2, etc. (1-indexed). Max 10 images.
   */
  image_urls: Array<string>;
};

/**
 * ReferenceToImageOutput
 */
export type ViduQ2ReferenceToImageOutput = {
  /**
   * Image
   *
   * The edited image
   */
  image: Image;
};

/**
 * ReferenceToImageRequest
 */
export type ViduQ2ReferenceToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for video generation, max 1500 characters
   */
  prompt: string;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the output video
   */
  aspect_ratio?: "16:9" | "9:16" | "1:1";
  /**
   * Reference Image Urls
   *
   * URLs of the reference images to use for consistent subject appearance
   */
  reference_image_urls: Array<string>;
  /**
   * Seed
   *
   * Random seed for generation
   */
  seed?: number;
};

/**
 * SeedDream45EditOutput
 */
export type BytedanceSeedreamV45EditOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<Image>;
};

/**
 * SeedDream45EditInput
 */
export type BytedanceSeedreamV45EditInput = {
  /**
   * Prompt
   *
   * The text prompt used to edit the image
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of separate model generations to be run with the prompt.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. Width and height must be between 1920 and 4096, or total number of pixels must be between 2560*1440 and 4096*4096.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto_2K"
    | "auto_4K";
  /**
   * Max Images
   *
   * If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15
   */
  max_images?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed to control the stochasticity of image generation.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.
   */
  image_urls: Array<string>;
};

/**
 * ImageToImageOutput
 */
export type LongcatImageEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * EditImageInput
 */
export type LongcatImageEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * The URL of the image to edit.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ZImageTurboImageToImageOutput
 */
export type ZImageTurboImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboImageToImageInput
 */
export type ZImageTurboImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for Image-to-Image generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the image-to-image conditioning.
   */
  strength?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ZImageTurboImageToImageOutput
 */
export type ZImageTurboImageToImageLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboImageToImageLoRAInput
 */
export type ZImageTurboImageToImageLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for Image-to-Image generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Strength
   *
   * The strength of the image-to-image conditioning.
   */
  strength?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ZImageTurboControlNetOutput
 */
export type ZImageTurboControlnetOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboControlNetInput
 */
export type ZImageTurboControlnetInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number;
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for ControlNet generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Preprocess
   *
   * What kind of preprocessing to apply to the image, if any.
   */
  preprocess?: "none" | "canny" | "depth" | "pose";
};

/**
 * ZImageTurboControlNetOutput
 */
export type ZImageTurboControlnetLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboControlNetLoRAInput
 */
export type ZImageTurboControlnetLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number;
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for ControlNet generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Preprocess
   *
   * What kind of preprocessing to apply to the image, if any.
   */
  preprocess?: "none" | "canny" | "depth" | "pose";
};

/**
 * ImageOutput
 */
export type StepxEdit2Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Best Info
   *
   * Reflection analysis (only available when reflection mode is enabled).
   */
  best_info?: Array<{
    [key: string]: unknown;
  }>;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Reformat Prompt
   *
   * The model's interpretation of your instruction (only available when thinking mode is enabled).
   */
  reformat_prompt?: string;
  /**
   * Think Info
   *
   * Reasoning process details (only available when thinking mode is enabled).
   */
  think_info?: Array<string>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * ImageToImageInput
 */
export type StepxEdit2Input = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enable Reflection Mode
   *
   * Enable reflection mode. Reviews outputs, corrects unintended changes, and determines when editing is complete.
   */
  enable_reflection_mode?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The image URL to generate an image from. Needs to match the dimensions of the mask.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * True CFG scale
   *
   *
   * The true CFG scale. Controls how closely the model follows the prompt.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform. Recommended: 50.
   */
  num_inference_steps?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Negative Prompt
   *
   *
   * The negative prompt to use. Use it to address details that you don't want
   * in the image. This could be colors, objects, scenery and even the small details
   * (e.g. moustache, blurry, low resolution).
   *
   */
  negative_prompt?: string;
  /**
   * Enable Thinking Mode
   *
   * Enable thinking mode. Uses multimodal language model knowledge to interpret abstract editing instructions.
   */
  enable_thinking_mode?: boolean;
};

/**
 * Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)
 */
export type Point = {
  [key: string]: unknown;
};

/**
 * UsageInfo
 */
export type UsageInfo = {
  /**
   * Output Tokens
   *
   * Number of output tokens generated
   */
  output_tokens: number;
  /**
   * Decode Time Ms
   *
   * Time taken for decoding in milliseconds
   */
  decode_time_ms: number;
  /**
   * Input Tokens
   *
   * Number of input tokens processed
   */
  input_tokens: number;
  /**
   * Ttft Ms
   *
   * Time to first token in milliseconds
   */
  ttft_ms: number;
  /**
   * Prefill Time Ms
   *
   * Time taken for prefill in milliseconds
   */
  prefill_time_ms: number;
};

/**
 * Object
 */
export type Object = {
  /**
   * Y Min
   *
   * Top boundary of detection box in normalized format (0 to 1)
   */
  y_min: number;
  /**
   * X Max
   *
   * Right boundary of detection box in normalized format (0 to 1)
   */
  x_max: number;
  /**
   * X Min
   *
   * Left boundary of detection box in normalized format (0 to 1)
   */
  x_min: number;
  /**
   * Y Max
   *
   * Bottom boundary of detection box in normalized format (0 to 1)
   */
  y_max: number;
};

/**
 * SegmentSamplingSettings
 */
export type SegmentSamplingSettings = {
  /**
   * Top P
   *
   * Nucleus sampling probability mass to use, between 0 and 1.
   */
  top_p?: number;
  /**
   * Max Tokens
   *
   * Maximum number of tokens to generate.
   */
  max_tokens?: number;
  /**
   * Temperature
   *
   * Sampling temperature to use. Higher values will make the output more random, while lower values will make it more focused and deterministic.
   */
  temperature?: number;
};

/**
 * MoondreamSegementationOutput
 */
export type Moondream3PreviewSegmentOutput = {
  /**
   * Finish Reason
   *
   * Reason for finishing the output generation
   */
  finish_reason: string;
  /**
   * Image
   *
   * Segmentation mask image. If no object detected or preview not requested, will be null.
   */
  image?: ImageFile;
  /**
   * Bbox
   *
   * Bounding box of the segmented object. If not detected, will be null.
   */
  bbox?: Object;
  /**
   * Path
   *
   * SVG path data representing the segmentation mask. If not detected, will be null.
   */
  path?: string;
  /**
   * Usage Info
   *
   * Usage information for the request
   */
  usage_info: UsageInfo;
};

/**
 * MoondreamSegementationInput
 */
export type Moondream3PreviewSegmentInput = {
  /**
   * Spatial References
   *
   * Spatial references to guide the segmentation. By feeding in references you can help the segmentation process. Must be either list of Point object with x and y members, or list of arrays containing either 2 floats (x,y) or 4 floats (x1,y1,x2,y2).
   * **NOTE**: You can also use the [**point endpoint**](https://fal.ai/models/fal-ai/moondream3-preview/point) to get points for the objects, and pass them in here.
   */
  spatial_references?: Array<Point | Array<number>>;
  /**
   * Settings
   *
   * Sampling settings for the segmentation model
   */
  settings?: SegmentSamplingSettings;
  /**
   * Object
   *
   * Object to be segmented in the image
   */
  object: string;
  /**
   * Preview
   *
   * Whether to preview the output and return a binary mask of the image
   */
  preview?: boolean;
  /**
   * Image URL
   *
   * URL of the image to be processed
   *
   * Max width: 7000px, Max height: 7000px, Timeout: 20.0s
   */
  image_url: string;
};

/**
 * LightingRestorationOutput
 */
export type QwenImageEditPlusLoraGalleryLightingRestorationOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export type QwenImageEditPlusLoraGalleryLightingRestorationInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image to restore lighting for.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * QwenImageOutput
 */
export type QwenImageEdit2509Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseQwenEditImagePlusInput
 */
export type QwenImageEdit2509Input = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * QwenImageOutput
 */
export type QwenImageEdit2509LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * BaseQwenEditImagePlusLoRAInput
 */
export type QwenImageEdit2509LoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate the image with
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Loras
   *
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs
   * and they will be merged together to generate the final image.
   *
   */
  loras?: Array<LoraWeight>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance scale
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * MultipleAnglesOutput
 */
export type QwenImageEdit2509LoraGalleryMultipleAnglesOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments
 */
export type QwenImageEdit2509LoraGalleryMultipleAnglesInput = {
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Wide-Angle Lens
   *
   * Enable wide-angle lens effect
   */
  wide_angle_lens?: boolean;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Vertical Angle (Bird  Worm)
   *
   * Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)
   */
  vertical_angle?: number;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Move Forward  Close-Up
   *
   * Move camera forward (0=no movement, 10=close-up)
   */
  move_forward?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Rotate Right-Left (degrees )
   *
   * Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.
   */
  rotate_right_left?: number;
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * NextSceneOutput
 */
export type QwenImageEdit2509LoraGalleryNextSceneOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * NextSceneInput
 *
 * Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions
 */
export type QwenImageEdit2509LoraGalleryNextSceneInput = {
  /**
   * Prompt
   *
   * Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image to create the next scene from.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * AddBackgroundOutput
 */
export type QwenImageEdit2509LoraGalleryAddBackgroundOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * AddBackgroundInput
 *
 * Input model for Add Background endpoint - Remove white background and add a realistic scene
 */
export type QwenImageEdit2509LoraGalleryAddBackgroundInput = {
  /**
   * Prompt
   *
   * Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to edit. Provide an image with a white or clean background.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FaceToFullPortraitOutput
 */
export type QwenImageEdit2509LoraGalleryFaceToFullPortraitOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * FaceToFullPortraitInput
 *
 * Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image
 */
export type QwenImageEdit2509LoraGalleryFaceToFullPortraitInput = {
  /**
   * Prompt
   *
   * Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the cropped face image. Provide a close-up face photo.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * GroupPhotoOutput
 */
export type QwenImageEdit2509LoraGalleryGroupPhotoOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * GroupPhotoInput
 *
 * Input model for Group Photo endpoint - Create composite group photos with vintage/retro style
 */
export type QwenImageEdit2509LoraGalleryGroupPhotoInput = {
  /**
   * Prompt
   *
   * Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * IntegrateProductOutput
 */
export type QwenImageEdit2509LoraGalleryIntegrateProductOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * IntegrateProductInput
 *
 * Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds
 */
export type QwenImageEdit2509LoraGalleryIntegrateProductInput = {
  /**
   * Prompt
   *
   * Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image with product to integrate into background.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * LightingRestorationOutput
 */
export type QwenImageEdit2509LoraGalleryLightingRestorationOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * LightingRestorationInput
 *
 * Input model for Lighting Restoration endpoint - Restore natural lighting by removing harsh shadows and light spots
 */
export type QwenImageEdit2509LoraGalleryLightingRestorationInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image to restore lighting for.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * RemoveElementOutput
 */
export type QwenImageEdit2509LoraGalleryRemoveElementOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * RemoveElementInput
 *
 * Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image
 */
export type QwenImageEdit2509LoraGalleryRemoveElementInput = {
  /**
   * Prompt
   *
   * Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image containing elements to remove.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * RemoveLightingOutput
 */
export type QwenImageEdit2509LoraGalleryRemoveLightingOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * RemoveLightingInput
 *
 * Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting
 */
export type QwenImageEdit2509LoraGalleryRemoveLightingInput = {
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URL of the image with lighting/shadows to remove.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * ShirtDesignOutput
 */
export type QwenImageEdit2509LoraGalleryShirtDesignOutput = {
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * ShirtDesignInput
 *
 * Input model for Shirt Design endpoint - Put designs/graphics on people's shirts
 */
export type QwenImageEdit2509LoraGalleryShirtDesignInput = {
  /**
   * Prompt
   *
   * Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | unknown;
  /**
   * Acceleration
   *
   * Acceleration level for image generation. 'regular' balances speed and quality.
   */
  acceleration?: "none" | "regular";
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the LoRA effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker for the generated image.
   */
  enable_safety_checker?: boolean;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and won't be saved in history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. Same seed with same prompt will produce same result.
   */
  seed?: number | unknown;
  /**
   * Image URLs
   *
   * The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FluxSingleIDOutput
 */
export type AiBabyAndAgingGeneratorSingleOutput = {
  /**
   * Prompt
   *
   * The final prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * SingleFluxIDInput
 *
 * Input schema for single mode generation
 */
export type AiBabyAndAgingGeneratorSingleInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the image generation
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Id Image Urls
   *
   * List of ID images for single mode (or general reference images)
   */
  id_image_urls: Array<string>;
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: "jpeg" | "png";
  /**
   * Age Group
   *
   * Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).
   */
  age_group:
    | "baby"
    | "toddler"
    | "preschool"
    | "gradeschooler"
    | "teen"
    | "adult"
    | "mid"
    | "senior";
  /**
   * Gender
   *
   * Gender for the generated image. Choose from: 'male' or 'female'.
   */
  gender: "male" | "female";
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed will be used
   */
  seed?: number | unknown;
};

/**
 * FluxMultiIDOutput
 */
export type AiBabyAndAgingGeneratorMultiOutput = {
  /**
   * Prompt
   *
   * The final prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info
   */
  images: Array<ImageType3>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * MultiFluxIDInput
 *
 * Input schema for multi mode generation
 */
export type AiBabyAndAgingGeneratorMultiInput = {
  /**
   * Prompt
   *
   * Text prompt to guide the image generation
   */
  prompt?: string;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Father Weight
   *
   * Weight of the father's influence in multi mode generation
   */
  father_weight?: number;
  /**
   * Mother Image Urls
   *
   * List of mother images for multi mode
   */
  mother_image_urls: Array<string>;
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: "jpeg" | "png";
  /**
   * Age Group
   *
   * Age group for the generated image. Choose from: 'baby' (0-12 months), 'toddler' (1-3 years), 'preschool' (3-5 years), 'gradeschooler' (6-12 years), 'teen' (13-19 years), 'adult' (20-40 years), 'mid' (40-60 years), 'senior' (60+ years).
   */
  age_group:
    | "baby"
    | "toddler"
    | "preschool"
    | "gradeschooler"
    | "teen"
    | "adult"
    | "mid"
    | "senior";
  /**
   * Gender
   *
   * Gender for the generated image. Choose from: 'male' or 'female'.
   */
  gender: "male" | "female";
  /**
   * Father Image Urls
   *
   * List of father images for multi mode
   */
  father_image_urls: Array<string>;
  /**
   * Seed
   *
   * Random seed for reproducibility. If None, a random seed will be used
   */
  seed?: number | unknown;
};

/**
 * Flux2MaxEditOutput
 */
export type Flux2MaxEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2MaxImageEditInput
 */
export type Flux2MaxEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | ImageSize
    | "auto"
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>;
};

/**
 * Flux2TurboEditImageOutput
 */
export type Flux2TurboEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2TurboEditImageInput
 */
export type Flux2TurboEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * EditImageResponse
 */
export type GptImage15EditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
};

/**
 * EditImageRequest
 */
export type GptImage15EditInput = {
  /**
   * Background
   *
   * Background for the generated image
   */
  background?: "auto" | "transparent" | "opaque";
  /**
   * Number of Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Aspect ratio for the generated image
   */
  image_size?: "auto" | "1024x1024" | "1536x1024" | "1024x1536";
  /**
   * Prompt
   *
   * The prompt for image generation
   */
  prompt: string;
  /**
   * Quality
   *
   * Quality for the generated image
   */
  quality?: "low" | "medium" | "high";
  /**
   * Output Format
   *
   * Output format for the images
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Input Fidelity
   *
   * Input fidelity for the generated image
   */
  input_fidelity?: "low" | "high";
  /**
   * Mask Image URL
   *
   * The URL of the mask image to use for the generation. This indicates what part of the image to edit.
   */
  mask_image_url?: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Image URLs
   *
   * The URLs of the images to use as a reference for the generation.
   */
  image_urls: Array<string>;
};

/**
 * Flux2FlashEditImageOutput
 */
export type Flux2FlashEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2FlashEditImageInput
 */
export type Flux2FlashEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * ZImageTurboInpaintOutput
 */
export type ZImageTurboInpaintOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboInpaintInput
 */
export type ZImageTurboInpaintInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Mask Image URL
   *
   * URL of Mask for Inpaint generation.
   */
  mask_image_url: string;
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number;
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for Inpaint generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the inpaint conditioning.
   */
  strength?: number;
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ZImageTurboInpaintOutput
 */
export type ZImageTurboInpaintLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   *
   * The timings of the generation process.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * ZImageTurboInpaintLoRAInput
 */
export type ZImageTurboInpaintLoraInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "auto";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Mask Image URL
   *
   * URL of Mask for Inpaint generation.
   */
  mask_image_url: string;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Control End
   *
   * The end of the controlnet conditioning.
   */
  control_end?: number;
  /**
   * Control Start
   *
   * The start of the controlnet conditioning.
   */
  control_start?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of Image for Inpaint generation.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the inpaint conditioning.
   */
  strength?: number;
  /**
   * Control Scale
   *
   * The scale of the controlnet conditioning.
   */
  control_scale?: number;
  /**
   * Enable Prompt Expansion
   *
   * Whether to enable prompt expansion. Note: this will increase the price by 0.0025 credits per request.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * QwenImageLayeredOutput
 */
export type QwenImageLayeredOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt?: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageInput
 */
export type QwenImageLayeredInput = {
  /**
   * Prompt
   *
   * A caption for the input image.
   */
  prompt?: string;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Num Layers
   *
   * The number of layers to generate.
   */
  num_layers?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "webp";
  /**
   * Image URL
   *
   * The URL of the input image.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
};

/**
 * ImageToImageOutput
 */
export type QwenImageEdit2511Output = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * EditImageInput
 */
export type QwenImageEdit2511Input = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If None, uses the input image dimensions.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * ImageEditOutput
 *
 * Output for Wan 2.6 image editing
 */
export type V26ImageToImageOutput = {
  /**
   * Images
   *
   * Generated images in PNG format
   */
  images: Array<File>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * ImageEditInput
 *
 * Input for Wan 2.6 image editing with reference images (enable_interleave=false)
 */
export type V26ImageToImageInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image. Supports Chinese and English. Max 2000 characters. Example: 'Generate an image using the style of image 1 and background of image 2'.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate (1-4). Directly affects billing cost.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Output image size. Use presets like 'square_hd', 'landscape_16_9', 'portrait_9_16', or specify exact dimensions with ImageSize(width=1280, height=720). Total pixels must be between 768*768 and 1280*1280.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Enable Safety Checker
   *
   * Enable content moderation for input and output.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility (0-2147483647). Same seed produces more consistent results.
   */
  seed?: number;
  /**
   * Image Urls
   *
   * Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), BMP, WEBP.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Content to avoid in the generated image. Max 500 characters.
   */
  negative_prompt?: string;
  /**
   * Enable Prompt Expansion
   *
   * Enable LLM prompt optimization. Significantly improves results for simple prompts but adds 3-4 seconds processing time.
   */
  enable_prompt_expansion?: boolean;
};

/**
 * QwenImageLayeredOutput
 */
export type QwenImageLayeredLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used to generate the image.
   */
  prompt?: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * TextToImageLoRAInput
 */
export type QwenImageLayeredLoraInput = {
  /**
   * Prompt
   *
   * A caption for the input image.
   */
  prompt?: string;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Num Layers
   *
   * The number of layers to generate.
   */
  num_layers?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "png" | "webp";
  /**
   * Image URL
   *
   * The URL of the input image.
   */
  image_url: string;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<LoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * ArchEditOutput
 */
export type AiHomeEditOutput = {
  image: ImageType3;
  /**
   * Status
   *
   * Status message with processing details
   */
  status: string;
};

/**
 * ArchEditInput
 */
export type AiHomeEditInput = {
  /**
   * Input Image Url
   *
   * URL of the image to do architectural editing
   */
  input_image_url: string;
  /**
   * Editing Type
   *
   * Type of editing. Structural editing only edits structural elements such as windows, walls etc. Virtual staging edits your furniture. Both do full editing including structural and furniture
   */
  editing_type: "structural editing" | "virtual staging" | "both";
  /**
   * Style
   *
   * Style for furniture and decor
   */
  style:
    | "minimalistic-interior"
    | "farmhouse-interior"
    | "luxury-interior"
    | "modern-interior"
    | "zen-interior"
    | "mid century-interior"
    | "airbnb-interior"
    | "cozy-interior"
    | "rustic-interior"
    | "christmas-interior"
    | "bohemian-interior"
    | "tropical-interior"
    | "industrial-interior"
    | "japanese-interior"
    | "vintage-interior"
    | "loft-interior"
    | "halloween-interior"
    | "soho-interior"
    | "baroque-interior"
    | "kids room-interior"
    | "girls room-interior"
    | "boys room-interior"
    | "scandinavian-interior"
    | "french country-interior"
    | "mediterranean-interior"
    | "cyberpunk-interior"
    | "hot pink-interior"
    | "biophilic-interior"
    | "ancient egypt-interior"
    | "pixel-interior"
    | "art deco-interior"
    | "modern-exterior"
    | "minimalistic-exterior"
    | "farmhouse-exterior"
    | "cozy-exterior"
    | "luxury-exterior"
    | "colonial-exterior"
    | "zen-exterior"
    | "asian-exterior"
    | "creepy-exterior"
    | "airstone-exterior"
    | "ancient greek-exterior"
    | "art deco-exterior"
    | "brutalist-exterior"
    | "christmas lights-exterior"
    | "contemporary-exterior"
    | "cottage-exterior"
    | "dutch colonial-exterior"
    | "federal colonial-exterior"
    | "fire-exterior"
    | "french provincial-exterior"
    | "full glass-exterior"
    | "georgian colonial-exterior"
    | "gothic-exterior"
    | "greek revival-exterior"
    | "ice-exterior"
    | "italianate-exterior"
    | "mediterranean-exterior"
    | "midcentury-exterior"
    | "middle eastern-exterior"
    | "minecraft-exterior"
    | "morocco-exterior"
    | "neoclassical-exterior"
    | "spanish-exterior"
    | "tudor-exterior"
    | "underwater-exterior"
    | "winter-exterior"
    | "yard lighting-exterior";
  /**
   * Additional Elements
   *
   * Additional elements to include in the options above (e.g., plants, lighting)
   */
  additional_elements?: string | unknown;
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: "jpeg" | "png";
  /**
   * Architecture Type
   *
   * Type of architecture for appropriate furniture selection
   */
  architecture_type:
    | "living room-interior"
    | "bedroom-interior"
    | "kitchen-interior"
    | "dining room-interior"
    | "bathroom-interior"
    | "laundry room-interior"
    | "home office-interior"
    | "study room-interior"
    | "dorm room-interior"
    | "coffee shop-interior"
    | "gaming room-interior"
    | "restaurant-interior"
    | "office-interior"
    | "attic-interior"
    | "toilet-interior"
    | "other-interior"
    | "house-exterior"
    | "villa-exterior"
    | "backyard-exterior"
    | "courtyard-exterior"
    | "ranch-exterior"
    | "office-exterior"
    | "retail-exterior"
    | "tower-exterior"
    | "apartment-exterior"
    | "school-exterior"
    | "museum-exterior"
    | "commercial-exterior"
    | "residential-exterior"
    | "other-exterior";
  /**
   * Color Palette
   *
   * Color palette for furniture and decor
   */
  color_palette:
    | "surprise me"
    | "golden beige"
    | "refined blues"
    | "dusky elegance"
    | "emerald charm"
    | "crimson luxury"
    | "golden sapphire"
    | "soft pastures"
    | "candy sky"
    | "peach meadow"
    | "muted sands"
    | "ocean breeze"
    | "frosted pastels"
    | "spring bloom"
    | "gentle horizon"
    | "seaside breeze"
    | "azure coast"
    | "golden shore"
    | "mediterranean gem"
    | "ocean serenity"
    | "serene blush"
    | "muted horizon"
    | "pastel shores"
    | "dusky calm"
    | "woodland retreat"
    | "meadow glow"
    | "forest canopy"
    | "riverbank calm"
    | "earthy tones"
    | "earthy neutrals"
    | "arctic mist"
    | "aqua drift"
    | "blush bloom"
    | "coral haze"
    | "retro rust"
    | "autumn glow"
    | "rustic charm"
    | "vintage sage"
    | "faded plum"
    | "electric lime"
    | "violet pulse"
    | "neon sorbet"
    | "aqua glow"
    | "fluorescent sunset"
    | "lavender bloom"
    | "petal fresh"
    | "meadow light"
    | "sunny pastures"
    | "frosted mauve"
    | "snowy hearth"
    | "icy blues"
    | "winter twilight"
    | "earthy hues"
    | "stone balance"
    | "neutral sands"
    | "slate shades";
  /**
   * Custom Prompt
   *
   * Custom prompt for architectural editing, it overrides above options when used
   */
  custom_prompt?: string;
};

/**
 * ArchStyleOutput
 */
export type AiHomeStyleOutput = {
  image: ImageType3;
  /**
   * Status
   *
   * Status message with processing details
   */
  status: string;
};

/**
 * ArchStyleInput
 */
export type AiHomeStyleInput = {
  /**
   * Input Image Url
   *
   * URL of the image to do architectural styling
   */
  input_image_url: string;
  /**
   * Input Image Strength
   *
   * Strength of the input image
   */
  input_image_strength?: number;
  /**
   * Additional Elements
   *
   * Additional elements to include in the options above (e.g., plants, lighting)
   */
  additional_elements?: string | unknown;
  /**
   * Output Format
   *
   * The format of the generated image. Choose from: 'jpeg' or 'png'.
   */
  output_format?: "jpeg" | "png";
  /**
   * Style
   *
   * Style for furniture and decor
   */
  style:
    | "minimalistic-interior"
    | "farmhouse-interior"
    | "luxury-interior"
    | "modern-interior"
    | "zen-interior"
    | "mid century-interior"
    | "airbnb-interior"
    | "cozy-interior"
    | "rustic-interior"
    | "christmas-interior"
    | "bohemian-interior"
    | "tropical-interior"
    | "industrial-interior"
    | "japanese-interior"
    | "vintage-interior"
    | "loft-interior"
    | "halloween-interior"
    | "soho-interior"
    | "baroque-interior"
    | "kids room-interior"
    | "girls room-interior"
    | "boys room-interior"
    | "scandinavian-interior"
    | "french country-interior"
    | "mediterranean-interior"
    | "cyberpunk-interior"
    | "hot pink-interior"
    | "biophilic-interior"
    | "ancient egypt-interior"
    | "pixel-interior"
    | "art deco-interior"
    | "modern-exterior"
    | "minimalistic-exterior"
    | "farmhouse-exterior"
    | "cozy-exterior"
    | "luxury-exterior"
    | "colonial-exterior"
    | "zen-exterior"
    | "asian-exterior"
    | "creepy-exterior"
    | "airstone-exterior"
    | "ancient greek-exterior"
    | "art deco-exterior"
    | "brutalist-exterior"
    | "christmas lights-exterior"
    | "contemporary-exterior"
    | "cottage-exterior"
    | "dutch colonial-exterior"
    | "federal colonial-exterior"
    | "fire-exterior"
    | "french provincial-exterior"
    | "full glass-exterior"
    | "georgian colonial-exterior"
    | "gothic-exterior"
    | "greek revival-exterior"
    | "ice-exterior"
    | "italianate-exterior"
    | "mediterranean-exterior"
    | "midcentury-exterior"
    | "middle eastern-exterior"
    | "minecraft-exterior"
    | "morocco-exterior"
    | "neoclassical-exterior"
    | "spanish-exterior"
    | "tudor-exterior"
    | "underwater-exterior"
    | "winter-exterior"
    | "yard lighting-exterior";
  /**
   * Architecture Type
   *
   * Type of architecture for appropriate furniture selection
   */
  architecture_type:
    | "living room-interior"
    | "bedroom-interior"
    | "kitchen-interior"
    | "dining room-interior"
    | "bathroom-interior"
    | "laundry room-interior"
    | "home office-interior"
    | "study room-interior"
    | "dorm room-interior"
    | "coffee shop-interior"
    | "gaming room-interior"
    | "restaurant-interior"
    | "office-interior"
    | "attic-interior"
    | "toilet-interior"
    | "other-interior"
    | "house-exterior"
    | "villa-exterior"
    | "backyard-exterior"
    | "courtyard-exterior"
    | "ranch-exterior"
    | "office-exterior"
    | "retail-exterior"
    | "tower-exterior"
    | "apartment-exterior"
    | "school-exterior"
    | "museum-exterior"
    | "commercial-exterior"
    | "residential-exterior"
    | "other-exterior";
  /**
   * Color Palette
   *
   * Color palette for furniture and decor
   */
  color_palette:
    | "surprise me"
    | "golden beige"
    | "refined blues"
    | "dusky elegance"
    | "emerald charm"
    | "crimson luxury"
    | "golden sapphire"
    | "soft pastures"
    | "candy sky"
    | "peach meadow"
    | "muted sands"
    | "ocean breeze"
    | "frosted pastels"
    | "spring bloom"
    | "gentle horizon"
    | "seaside breeze"
    | "azure coast"
    | "golden shore"
    | "mediterranean gem"
    | "ocean serenity"
    | "serene blush"
    | "muted horizon"
    | "pastel shores"
    | "dusky calm"
    | "woodland retreat"
    | "meadow glow"
    | "forest canopy"
    | "riverbank calm"
    | "earthy tones"
    | "earthy neutrals"
    | "arctic mist"
    | "aqua drift"
    | "blush bloom"
    | "coral haze"
    | "retro rust"
    | "autumn glow"
    | "rustic charm"
    | "vintage sage"
    | "faded plum"
    | "electric lime"
    | "violet pulse"
    | "neon sorbet"
    | "aqua glow"
    | "fluorescent sunset"
    | "lavender bloom"
    | "petal fresh"
    | "meadow light"
    | "sunny pastures"
    | "frosted mauve"
    | "snowy hearth"
    | "icy blues"
    | "winter twilight"
    | "earthy hues"
    | "stone balance"
    | "neutral sands"
    | "slate shades";
  /**
   * Style Image Url
   *
   * URL of the style image, optional. If given, other parameters are ignored
   */
  style_image_url?: string | unknown;
  /**
   * Custom Prompt
   *
   * Custom prompt for architectural editing, it overrides above options when used
   */
  custom_prompt?: string;
  /**
   * Enhanced Rendering
   *
   * It gives better rendering quality with more processing time, additional cost is 0.01 USD per image
   */
  enhanced_rendering?: boolean | unknown;
};

/**
 * ImageToImageOutput
 */
export type QwenImageEdit2511LoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * EditImageLoraInput
 */
export type QwenImageEdit2511LoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image with.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If None, uses the input image dimensions.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * The LoRAs to use for the image generation. You can use up to 3 LoRAs and they will be merged together to generate the final image.
   */
  loras?: Array<LoraWeight>;
  /**
   * Guidance Scale
   *
   * The guidance scale to use for the image generation.
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images to edit.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate an image from.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The same seed and the same prompt given to the same version of the model will output the same image every time.
   */
  seed?: number;
};

/**
 * MultipleAnglesOutput
 *
 * Output model for Multiple Angles endpoint
 */
export type QwenImageEdit2511MultipleAnglesOutput = {
  /**
   * Prompt
   *
   * The constructed prompt used for generation
   */
  prompt: string;
  /**
   * Images
   *
   * The generated/edited images
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * MultipleAnglesInput
 *
 * Input model for Multiple Angles endpoint - Camera control with precise adjustments using <sks> trigger word.
 * Prompt is built automatically from slider values.
 */
export type QwenImageEdit2511MultipleAnglesInput = {
  /**
   * Acceleration
   *
   * Acceleration level for image generation.
   */
  acceleration?: "none" | "regular";
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Horizontal Angle (Azimuth )
   *
   * Horizontal rotation angle around the object in degrees. 0=front view, 90=right side, 180=back view, 270=left side, 360=front view again.
   */
  horizontal_angle?: number;
  /**
   * Guidance Scale
   *
   * The CFG (Classifier Free Guidance) scale.
   */
  guidance_scale?: number;
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Image URLs
   *
   * The URL of the image to adjust camera angle for.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * The negative prompt for the generation
   */
  negative_prompt?: string;
  /**
   * Zoom (Distance)
   *
   * Camera zoom/distance. 0=wide shot (far away), 5=medium shot (normal), 10=close-up (very close).
   */
  zoom?: number;
  /**
   * Vertical Angle (Elevation )
   *
   * Vertical camera angle in degrees. -30=low-angle shot (looking up), 0=eye-level, 30=elevated, 60=high-angle, 90=bird's-eye view (looking down).
   */
  vertical_angle?: number;
  /**
   * Num Images
   *
   * Number of images to generate
   */
  num_images?: number;
  /**
   * Lora Scale
   *
   * The scale factor for the LoRA model. Controls the strength of the camera control effect.
   */
  lora_scale?: number;
  /**
   * Output Format
   *
   * The format of the output image
   */
  output_format?: "png" | "jpeg" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI.
   */
  sync_mode?: boolean;
  /**
   * Additional Prompt
   *
   * Additional text to append to the automatically generated prompt.
   */
  additional_prompt?: string;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * GlmImageToImageOutput
 */
export type GlmImageImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * List of URLs to the generated images.
   */
  images: Array<ImageType2>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * GlmImageToImageInput
 */
export type GlmImageImageToImageInput = {
  /**
   * Prompt
   *
   * Text prompt for image generation.
   */
  prompt: string;
  /**
   * Num Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * Output image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9"
    | "portrait_3_2"
    | "landscape_3_2"
    | "portrait_hd"
    | "landscape_hd";
  /**
   * Enable Safety Checker
   *
   * Enable NSFW safety checking on the generated images.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * Output image format.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If True, the image will be returned as a base64 data URI instead of a URL.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Classifier-free guidance scale. Higher values make the model follow the prompt more closely.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. The same seed with the same prompt will produce the same image.
   */
  seed?: number;
  /**
   * Image Urls
   *
   * URL(s) of the condition image(s) for image-to-image generation. Supports up to 4 URLs for multi-image references.
   */
  image_urls: Array<string>;
  /**
   * Enable Prompt Expansion
   *
   * If True, the prompt will be enhanced using an LLM for more detailed and higher quality results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Num Inference Steps
   *
   * Number of diffusion denoising steps. More steps generally produce higher quality images.
   */
  num_inference_steps?: number;
};

/**
 * Klein9BDistilledEditOutput
 */
export type Flux2Klein9bEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein9BDistilledEditInput
 */
export type Flux2Klein9bEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * Klein4BDistilledEditOutput
 */
export type Flux2Klein4bEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinDistilledEditInput
 */
export type Flux2Klein4bEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * Klein9BBaseEditOutput
 */
export type Flux2Klein9bBaseEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein9BEditImageInput
 */
export type Flux2Klein9bBaseEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * Klein4BBaseEditOutput
 */
export type Flux2Klein4bBaseEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * Klein4BBaseEditInput
 */
export type Flux2Klein4bBaseEditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * KleinT2IOutput
 */
export type Flux2Klein4bBaseEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinBaseEditLoRAInput
 */
export type Flux2Klein4bBaseEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<FalAiFlux2KleinLoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * KleinT2IOutput
 */
export type Flux2Klein9bBaseEditLoraOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated images
   */
  images: Array<ImageFile>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * KleinBaseEditLoRAInput
 */
export type Flux2Klein9bBaseEditLoraInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, uses the input image size.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Guidance Scale
   *
   * Guidance scale for classifier-free guidance.
   */
  guidance_scale?: number;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3).
   */
  loras?: Array<FalAiFlux2KleinLoRaInput>;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI. Output is not stored when this is True.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Negative prompt for classifier-free guidance. Describes what to avoid in the image.
   */
  negative_prompt?: string;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditColorizeOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * ColorizeInput
 */
export type FiboEditColorizeInput = {
  /**
   * Color
   *
   * Select the color palette or aesthetic for the output image
   */
  color:
    | "contemporary color"
    | "vivid color"
    | "black and white colors"
    | "sepia vintage";
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditBlendOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * BlendingInput
 */
export type FiboEditBlendInput = {
  /**
   * Instruction
   *
   * Instruct what elements you would like to blend in your image.
   */
  instruction: string;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditAddObjectByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * AddObjectByTextInput
 */
export type FiboEditAddObjectByTextInput = {
  /**
   * Instruction
   *
   * The full natural language command describing what to add and where.
   */
  instruction: string;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * StructuredInstruction
 */
export type StructuredInstruction = {
  /**
   * Background Setting
   *
   * The background setting of the image to be generated.
   */
  background_setting?: string | unknown;
  /**
   * Artistic Style
   *
   * The artistic style of the image to be generated.
   */
  artistic_style?: string | unknown;
  /**
   * Context
   *
   * The context of the image to be generated.
   */
  context?: string | unknown;
  /**
   * Text Render
   *
   * A list of text to be rendered in the image.
   */
  text_render?: Array<unknown> | unknown;
  /**
   * Objects
   *
   * A list of objects in the image to be generated, along with their attributes and relationships to other objects in the image.
   */
  objects?: Array<PromptObject> | unknown;
  /**
   * Style Medium
   *
   * The style medium of the image to be generated.
   */
  style_medium?: string | unknown;
  /**
   * The photographic characteristics of the image to be generated.
   */
  photographic_characteristics?: PhotographicCharacteristics | unknown;
  /**
   * The aesthetics of the image to be generated.
   */
  aesthetics?: Aesthetics | unknown;
  /**
   * The lighting of the image to be generated.
   */
  lighting?: Lighting | unknown;
  /**
   * Short Description
   *
   * A short description of the image to be generated.
   */
  short_description?: string | unknown;
  /**
   * Edit Instruction
   *
   * The edit instruction for the image.
   */
  edit_instruction?: string | unknown;
};

/**
 * FiboEditOutputModel
 */
export type FiboEditEditOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * FiboEditInputModel
 */
export type FiboEditEditInput = {
  /**
   * Steps Num
   *
   * Number of inference steps.
   */
  steps_num?: number;
  /**
   * Instruction
   *
   * Instruction for image editing.
   */
  instruction?: string | unknown;
  /**
   * Image Url
   *
   * Reference image (file or URL).
   */
  image_url?: string | unknown;
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance scale for text.
   */
  guidance_scale?: number | number;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Mask Url
   *
   * Mask image (file or URL). Optional
   */
  mask_url?: string | unknown;
  /**
   * Negative Prompt
   *
   * Negative prompt for image generation.
   */
  negative_prompt?: string;
  /**
   * The structured prompt to generate an image from.
   */
  structured_instruction?: StructuredInstruction | unknown;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditEraseByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * EraseByTextInput
 */
export type FiboEditEraseByTextInput = {
  /**
   * Object Name
   *
   * The name of the object to remove.
   */
  object_name: string;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRewriteTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * RewriteTextInput
 */
export type FiboEditRewriteTextInput = {
  /**
   * New Text
   *
   * The new text string to appear in the image.
   */
  new_text: string;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRestyleOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * RestyletInput
 */
export type FiboEditRestyleInput = {
  /**
   * Style
   *
   * Select the desired artistic style for the output image.
   */
  style:
    | "3D Render"
    | "Cubism"
    | "Oil Painting"
    | "Anime"
    | "Cartoon"
    | "Coloring Book"
    | "Retro Ad"
    | "Pop Art Halftone"
    | "Vector Art"
    | "Story Board"
    | "Art Nouveau"
    | "Cross Etching"
    | "Wood Cut";
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRelightOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * RelightInput
 */
export type FiboEditRelightInput = {
  /**
   * Light Type
   *
   * The quality/style/time of day.
   */
  light_type:
    | "midday"
    | "blue hour light"
    | "low-angle sunlight"
    | "sunrise light"
    | "spotlight on subject"
    | "overcast light"
    | "soft overcast daylight lighting"
    | "cloud-filtered lighting"
    | "fog-diffused lighting"
    | "moonlight lighting"
    | "starlight nighttime"
    | "soft bokeh lighting"
    | "harsh studio lighting";
  /**
   * Light Direction
   *
   * Where the light comes from.
   */
  light_direction: "front" | "side" | "bottom" | "top-down" | unknown;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditReseasonOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * ReseasonInput
 */
export type FiboEditReseasonInput = {
  /**
   * Season
   *
   * The desired season.
   */
  season: "spring" | "summer" | "autumn" | "winter";
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditRestoreOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * RestoreInput
 */
export type FiboEditRestoreInput = {
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditSketchToColoredImageOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * SketchColoredImageInput
 */
export type FiboEditSketchToColoredImageInput = {
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FiboEditExtraEPOutputModel
 */
export type FiboEditReplaceObjectByTextOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<ImageType3>;
  image: ImageType3;
  /**
   * Structured Instruction
   *
   * Current instruction.
   */
  structured_instruction: {
    [key: string]: unknown;
  };
};

/**
 * ReplaceObjectInput
 */
export type FiboEditReplaceObjectByTextInput = {
  /**
   * Instruction
   *
   * The full natural language command describing what to replace.
   */
  instruction: string;
  /**
   * Image Url
   *
   * The source image.
   */
  image_url: string;
};

/**
 * FaceFusionImageOutput
 *
 * FaceFusion output payload when image content is generated
 */
export type AiFaceSwapFaceswapimageOutput = {
  image: ImageType3;
  /**
   * Processing Time Ms
   *
   * Optional processing duration in milliseconds
   */
  processing_time_ms?: number | unknown;
};

/**
 * FaceSwapInputImage
 *
 * Input schema for image  image face swap
 */
export type AiFaceSwapFaceswapimageInput = {
  /**
   * Enable Occlusion Prevention
   *
   * Enable occlusion prevention for handling faces covered by hands/objects. Warning: Enabling this runs an occlusion-aware model which costs 2x more.
   */
  enable_occlusion_prevention?: boolean;
  /**
   * Source Face Url
   *
   * Source face image. Allowed items: bmp, jpeg, png, tiff, webp
   */
  source_face_url: string;
  /**
   * Target Image Url
   *
   * Target image URL. Allowed items: bmp, jpeg, png, tiff, webp
   */
  target_image_url: string;
};

/**
 * ReplaceBackgroundOutputModel
 */
export type ReplaceBackgroundOutput = {
  /**
   * Images
   *
   * Generated images.
   */
  images?: Array<{
    [key: string]: unknown;
  }>;
  image: ImageType3;
};

/**
 * ReplaceBackgroundInputModel
 */
export type ReplaceBackgroundInput = {
  /**
   * Prompt
   *
   * Prompt for background replacement.
   */
  prompt?: string | unknown;
  /**
   * Steps Num
   *
   * Number of inference steps.
   */
  steps_num?: number;
  /**
   * Sync Mode
   *
   * If true, returns the image directly in the response (increases latency).
   */
  sync_mode?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * Negative prompt for background replacement.
   */
  negative_prompt?: string;
  /**
   * Image Url
   *
   * Reference image (file or URL).
   */
  image_url?: string | unknown;
};

/**
 * QwenImageMaxEditOutput
 */
export type QwenImageMaxEditOutput = {
  /**
   * Images
   *
   * Generated images
   */
  images: Array<File>;
  /**
   * Seed
   *
   * The seed used for generation
   */
  seed: number;
};

/**
 * QwenImageMaxEditInput
 *
 * Input for Qwen Image Max image editing with reference images
 */
export type QwenImageMaxEditInput = {
  /**
   * Prompt
   *
   * Text prompt describing the desired image. Supports Chinese and English. Max 800 characters.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the generated image. If not provided, the size of the final input image will be used.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Prompt Expansion
   *
   * Enable LLM prompt optimization for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducibility (0-2147483647).
   */
  seed?: number;
  /**
   * Image Urls
   *
   * Reference images for editing (1-3 images required). Order matters: reference as 'image 1', 'image 2', 'image 3' in prompt. Resolution: 384-5000px each dimension. Max size: 10MB each. Formats: JPEG, JPG, PNG (no alpha), WEBP.
   */
  image_urls: Array<string>;
  /**
   * Negative Prompt
   *
   * Content to avoid in the generated image. Max 500 characters.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * Enable content moderation for input and output.
   */
  enable_safety_checker?: boolean;
};

/**
 * HunyuanImageEditResponse
 */
export type HunyuanImageV3InstructEditOutput = {
  /**
   * Images
   *
   * A list of the generated images.
   */
  images: Array<Image>;
  /**
   * Seed
   *
   * The base seed used for the generation process.
   */
  seed: number;
};

/**
 * HunyuanImageEditRequest
 */
export type HunyuanImageV3InstructEditInput = {
  /**
   * Prompt
   *
   * The text prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The desired size of the generated image. If auto, image size will be determined by the model.
   */
  image_size?:
    | ImageSize
    | "auto"
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * Random seed for reproducible results. If None, a random seed is used.
   */
  seed?: number;
  /**
   * Image Urls
   *
   * The URLs of the images to use as a reference for the generation. A maximum of 2 images are supported.
   */
  image_urls: Array<string>;
  /**
   * Guidance Scale
   *
   * Controls how much the model adheres to the prompt. Higher values mean stricter adherence.
   */
  guidance_scale?: number;
};

/**
 * XAIImageEditOutput
 */
export type GrokImagineImageEditOutput = {
  /**
   * Images
   *
   * The URL of the edited image.
   */
  images: Array<ImageFile>;
  /**
   * Revised Prompt
   *
   * The enhanced prompt that was used to generate the image.
   */
  revised_prompt: string;
};

/**
 * XAIImageEditInput
 */
export type GrokImagineImageEditInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Number of Images
   *
   * Number of images to generate.
   */
  num_images?: number;
  /**
   * Prompt
   *
   * Text description of the desired image.
   */
  prompt: string;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Image URL
   *
   * URL of the image to edit.
   */
  image_url: string;
};

/**
 * Output
 */
export type ClarityUpscalerOutput = {
  /**
   * The URL of the generated image.
   */
  image: ImageType3;
  /**
   * Seed
   *
   * The seed used to generate the image.
   */
  seed: number;
  /**
   * Timings
   *
   * The timings of the different steps in the workflow.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Input
 */
export type ClarityUpscalerInput = {
  /**
   * Prompt
   *
   * The prompt to use for generating the image. Be as descriptive as possible for best results.
   */
  prompt?: string;
  /**
   * Resemblance
   *
   *
   * The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image.
   * Refers to the strength of the ControlNet.
   *
   */
  resemblance?: number;
  /**
   * Creativity
   *
   *
   * The creativity of the model. The higher the creativity, the more the model will deviate from the prompt.
   * Refers to the denoise strength of the sampling.
   *
   */
  creativity?: number;
  /**
   * Image Url
   *
   * The URL of the image to upscale.
   */
  image_url: string;
  /**
   * Upscale Factor
   *
   * The upscale factor
   */
  upscale_factor?: number;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of Stable Diffusion
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Negative Prompt
   *
   * The negative prompt to use. Use it to address details that you don't want in the image.
   */
  negative_prompt?: string;
  /**
   * Enable Safety Checker
   *
   * If set to false, the safety checker will be disabled.
   */
  enable_safety_checker?: boolean;
};

/**
 * Output
 */
export type AuraSrOutput = {
  /**
   * Image
   *
   * Upscaled image
   */
  image: Image;
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Input
 */
export type AuraSrInput = {
  /**
   * Overlapping Tiles
   *
   * Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.
   */
  overlapping_tiles?: boolean;
  /**
   * Checkpoint
   *
   * Checkpoint to use for upscaling. More coming soon.
   */
  checkpoint?: "v1" | "v2";
  /**
   * Upscaling Factor (Xs)
   *
   * Upscaling factor. More coming soon.
   */
  upscaling_factor?: 4;
  /**
   * Image URL
   *
   * URL of the image to upscale.
   */
  image_url: string;
};

/**
 * Output
 */
export type FluxDevImageToImageOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<ImageType2>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * BaseImageToInput
 */
export type FluxDevImageToImageInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Acceleration
   *
   * The speed of the generation. The higher the speed, the faster the generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * The URL of the image to generate an image from.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Strength
   *
   * The strength of the initial image. Higher strength values are better for this model.
   */
  strength?: number;
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number | unknown;
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Num Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Flux2ProEditOutput
 */
export type Flux2ProEditOutput = {
  /**
   * Images
   *
   * The generated images.
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   * The seed used for the generation.
   */
  seed: number;
};

/**
 * Flux2ProImageEditInput
 */
export type Flux2ProEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Image Size
   *
   * The size of the generated image. If `auto`, the size will be determined by the model.
   */
  image_size?:
    | ImageSize
    | "auto"
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5";
  /**
   * Enable Safety Checker
   *
   * Whether to enable the safety checker.
   */
  enable_safety_checker?: boolean;
  /**
   * Seed
   *
   * The seed to use for the generation.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * List of URLs of input images for editing
   */
  image_urls: Array<string>;
};

/**
 * Flux2EditImageOutput
 */
export type Flux2EditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2EditImageInput
 */
export type Flux2EditInput = {
  /**
   * Prompt
   *
   * The prompt to edit the image.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for the image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URLs of the images for editing. A maximum of 4 images are allowed, if more are provided, only the first 4 will be used.
   */
  image_urls: Array<string>;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * Flux2EditImageLoRAOutput
 */
export type Flux2LoraEditOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The edited images
   */
  images: Array<ImageFile>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
};

/**
 * Flux2EditImageLoRAInput
 */
export type Flux2LoraEditInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Number of Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Image Size
   *
   * The size of the image to generate. The width and height must be between 512 and 2048 pixels.
   */
  image_size?:
    | ImageSize
    | "square_hd"
    | "square"
    | "portrait_4_3"
    | "portrait_16_9"
    | "landscape_4_3"
    | "landscape_16_9";
  /**
   * Acceleration
   *
   * The acceleration level to use for the image generation.
   */
  acceleration?: "none" | "regular" | "high";
  /**
   * Enable Safety Checker
   *
   * If set to true, the safety checker will be enabled.
   */
  enable_safety_checker?: boolean;
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png" | "webp";
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Loras
   *
   * List of LoRA weights to apply (maximum 3). Each LoRA can be a URL, HuggingFace repo ID, or local path.
   */
  loras?: Array<LoRaInput>;
  /**
   * Guidance Scale
   *
   * Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Image URLs
   *
   * The URsL of the images for editing. A maximum of 3 images are allowed, if more are provided, only the first 3 will be used.
   */
  image_urls: Array<string>;
  /**
   * Enable Prompt Expansion
   *
   * If set to true, the prompt will be expanded for better results.
   */
  enable_prompt_expansion?: boolean;
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to perform.
   */
  num_inference_steps?: number;
};

/**
 * FluxKontextOutput
 */
export type FluxProKontextOutput = {
  /**
   * Prompt
   *
   * The prompt used for generating the image.
   */
  prompt: string;
  /**
   * Images
   *
   * The generated image files info.
   */
  images: Array<FalToolkitImageImageImage>;
  /**
   * Timings
   */
  timings: {
    [key: string]: number;
  };
  /**
   * Has Nsfw Concepts
   *
   * Whether the generated images contain NSFW concepts.
   */
  has_nsfw_concepts: Array<boolean>;
  /**
   * Seed
   *
   *
   * Seed of the generated Image. It will be the same value of the one passed in the
   * input or the randomly generated that was used in case none was passed.
   *
   */
  seed: number;
};

/**
 * FluxKontextInput
 */
export type FluxProKontextInput = {
  /**
   * Prompt
   *
   * The prompt to generate an image from.
   */
  prompt: string;
  /**
   * Num Images
   *
   * The number of images to generate.
   */
  num_images?: number;
  /**
   * Aspect Ratio
   *
   * The aspect ratio of the generated image.
   */
  aspect_ratio?:
    | "21:9"
    | "16:9"
    | "4:3"
    | "3:2"
    | "1:1"
    | "2:3"
    | "3:4"
    | "9:16"
    | "9:21";
  /**
   * Output Format
   *
   * The format of the generated image.
   */
  output_format?: "jpeg" | "png";
  /**
   * Image URL
   *
   * Image prompt for the omni model.
   */
  image_url: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Safety Tolerance
   *
   * The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.
   */
  safety_tolerance?: "1" | "2" | "3" | "4" | "5" | "6";
  /**
   * Guidance scale (CFG)
   *
   *
   * The CFG (Classifier Free Guidance) scale is a measure of how close you want
   * the model to stick to your prompt when looking for a related image to show you.
   *
   */
  guidance_scale?: number;
  /**
   * Seed
   *
   *
   * The same seed and the same prompt given to the same version of the model
   * will output the same image every time.
   *
   */
  seed?: number;
  /**
   * Enhance Prompt
   *
   * Whether to enhance the prompt for better results.
   */
  enhance_prompt?: boolean;
};

export type QueueStatus = {
  status: "IN_QUEUE" | "IN_PROGRESS" | "COMPLETED";
  /**
   * The request id.
   */
  request_id: string;
  /**
   * The response url.
   */
  response_url?: string;
  /**
   * The status url.
   */
  status_url?: string;
  /**
   * The cancel url.
   */
  cancel_url?: string;
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown;
  };
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown;
  };
  /**
   * The queue position.
   */
  queue_position?: number;
};

export type GetFalAiFluxProKontextRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/kontext/requests/{request_id}/status";
};

export type GetFalAiFluxProKontextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProKontextRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/requests/{request_id}/cancel";
};

export type PutFalAiFluxProKontextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProKontextRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextData = {
  body: FluxProKontextInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext";
};

export type PostFalAiFluxProKontextResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextResponse =
  PostFalAiFluxProKontextResponses[keyof PostFalAiFluxProKontextResponses];

export type GetFalAiFluxProKontextRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/requests/{request_id}";
};

export type GetFalAiFluxProKontextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextOutput;
};

export type GetFalAiFluxProKontextRequestsByRequestIdResponse =
  GetFalAiFluxProKontextRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/lora/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2LoraEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2LoraEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/lora/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2LoraEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2LoraEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraEditData = {
  body: Flux2LoraEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/lora/edit";
};

export type PostFalAiFlux2LoraEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraEditResponse =
  PostFalAiFlux2LoraEditResponses[keyof PostFalAiFlux2LoraEditResponses];

export type GetFalAiFlux2LoraEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/lora/edit/requests/{request_id}";
};

export type GetFalAiFlux2LoraEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraEditOutput;
};

export type GetFalAiFlux2LoraEditRequestsByRequestIdResponse =
  GetFalAiFlux2LoraEditRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraEditRequestsByRequestIdResponses];

export type GetFalAiFlux2EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2EditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2EditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2EditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2EditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2EditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2EditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2EditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2EditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2EditData = {
  body: Flux2EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/edit";
};

export type PostFalAiFlux2EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2EditResponse =
  PostFalAiFlux2EditResponses[keyof PostFalAiFlux2EditResponses];

export type GetFalAiFlux2EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/edit/requests/{request_id}";
};

export type GetFalAiFlux2EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2EditOutput;
};

export type GetFalAiFlux2EditRequestsByRequestIdResponse =
  GetFalAiFlux2EditRequestsByRequestIdResponses[keyof GetFalAiFlux2EditRequestsByRequestIdResponses];

export type GetFalAiFlux2ProEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-pro/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2ProEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2ProEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2ProEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2ProEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2ProEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-pro/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2ProEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2ProEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2ProEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2ProEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2ProEditData = {
  body: Flux2ProEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-pro/edit";
};

export type PostFalAiFlux2ProEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2ProEditResponse =
  PostFalAiFlux2ProEditResponses[keyof PostFalAiFlux2ProEditResponses];

export type GetFalAiFlux2ProEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-pro/edit/requests/{request_id}";
};

export type GetFalAiFlux2ProEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2ProEditOutput;
};

export type GetFalAiFlux2ProEditRequestsByRequestIdResponse =
  GetFalAiFlux2ProEditRequestsByRequestIdResponses[keyof GetFalAiFlux2ProEditRequestsByRequestIdResponses];

export type GetFalAiFluxDevImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/dev/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxDevImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxDevImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxDevImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxDevImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxDevImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxDevImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxDevImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxDevImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxDevImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxDevImageToImageData = {
  body: FluxDevImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/dev/image-to-image";
};

export type PostFalAiFluxDevImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxDevImageToImageResponse =
  PostFalAiFluxDevImageToImageResponses[keyof PostFalAiFluxDevImageToImageResponses];

export type GetFalAiFluxDevImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxDevImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxDevImageToImageOutput;
};

export type GetFalAiFluxDevImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxDevImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxDevImageToImageRequestsByRequestIdResponses];

export type GetFalAiAuraSrRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/aura-sr/requests/{request_id}/status";
};

export type GetFalAiAuraSrRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAuraSrRequestsByRequestIdStatusResponse =
  GetFalAiAuraSrRequestsByRequestIdStatusResponses[keyof GetFalAiAuraSrRequestsByRequestIdStatusResponses];

export type PutFalAiAuraSrRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/aura-sr/requests/{request_id}/cancel";
};

export type PutFalAiAuraSrRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAuraSrRequestsByRequestIdCancelResponse =
  PutFalAiAuraSrRequestsByRequestIdCancelResponses[keyof PutFalAiAuraSrRequestsByRequestIdCancelResponses];

export type PostFalAiAuraSrData = {
  body: AuraSrInput;
  path?: never;
  query?: never;
  url: "/fal-ai/aura-sr";
};

export type PostFalAiAuraSrResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAuraSrResponse =
  PostFalAiAuraSrResponses[keyof PostFalAiAuraSrResponses];

export type GetFalAiAuraSrRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/aura-sr/requests/{request_id}";
};

export type GetFalAiAuraSrRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AuraSrOutput;
};

export type GetFalAiAuraSrRequestsByRequestIdResponse =
  GetFalAiAuraSrRequestsByRequestIdResponses[keyof GetFalAiAuraSrRequestsByRequestIdResponses];

export type GetFalAiClarityUpscalerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/clarity-upscaler/requests/{request_id}/status";
};

export type GetFalAiClarityUpscalerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiClarityUpscalerRequestsByRequestIdStatusResponse =
  GetFalAiClarityUpscalerRequestsByRequestIdStatusResponses[keyof GetFalAiClarityUpscalerRequestsByRequestIdStatusResponses];

export type PutFalAiClarityUpscalerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/clarity-upscaler/requests/{request_id}/cancel";
};

export type PutFalAiClarityUpscalerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiClarityUpscalerRequestsByRequestIdCancelResponse =
  PutFalAiClarityUpscalerRequestsByRequestIdCancelResponses[keyof PutFalAiClarityUpscalerRequestsByRequestIdCancelResponses];

export type PostFalAiClarityUpscalerData = {
  body: ClarityUpscalerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/clarity-upscaler";
};

export type PostFalAiClarityUpscalerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiClarityUpscalerResponse =
  PostFalAiClarityUpscalerResponses[keyof PostFalAiClarityUpscalerResponses];

export type GetFalAiClarityUpscalerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/clarity-upscaler/requests/{request_id}";
};

export type GetFalAiClarityUpscalerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ClarityUpscalerOutput;
};

export type GetFalAiClarityUpscalerRequestsByRequestIdResponse =
  GetFalAiClarityUpscalerRequestsByRequestIdResponses[keyof GetFalAiClarityUpscalerRequestsByRequestIdResponses];

export type GetXaiGrokImagineImageEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/xai/grok-imagine-image/edit/requests/{request_id}/status";
};

export type GetXaiGrokImagineImageEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetXaiGrokImagineImageEditRequestsByRequestIdStatusResponse =
  GetXaiGrokImagineImageEditRequestsByRequestIdStatusResponses[keyof GetXaiGrokImagineImageEditRequestsByRequestIdStatusResponses];

export type PutXaiGrokImagineImageEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/xai/grok-imagine-image/edit/requests/{request_id}/cancel";
};

export type PutXaiGrokImagineImageEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutXaiGrokImagineImageEditRequestsByRequestIdCancelResponse =
  PutXaiGrokImagineImageEditRequestsByRequestIdCancelResponses[keyof PutXaiGrokImagineImageEditRequestsByRequestIdCancelResponses];

export type PostXaiGrokImagineImageEditData = {
  body: GrokImagineImageEditInput;
  path?: never;
  query?: never;
  url: "/xai/grok-imagine-image/edit";
};

export type PostXaiGrokImagineImageEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostXaiGrokImagineImageEditResponse =
  PostXaiGrokImagineImageEditResponses[keyof PostXaiGrokImagineImageEditResponses];

export type GetXaiGrokImagineImageEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/xai/grok-imagine-image/edit/requests/{request_id}";
};

export type GetXaiGrokImagineImageEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GrokImagineImageEditOutput;
};

export type GetXaiGrokImagineImageEditRequestsByRequestIdResponse =
  GetXaiGrokImagineImageEditRequestsByRequestIdResponses[keyof GetXaiGrokImagineImageEditRequestsByRequestIdResponses];

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hunyuan-image/v3/instruct/edit/requests/{request_id}/status";
};

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdStatusResponses];

export type PutFalAiHunyuanImageV3InstructEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/instruct/edit/requests/{request_id}/cancel";
};

export type PutFalAiHunyuanImageV3InstructEditRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiHunyuanImageV3InstructEditRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanImageV3InstructEditRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanImageV3InstructEditRequestsByRequestIdCancelResponses];

export type PostFalAiHunyuanImageV3InstructEditData = {
  body: HunyuanImageV3InstructEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/instruct/edit";
};

export type PostFalAiHunyuanImageV3InstructEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHunyuanImageV3InstructEditResponse =
  PostFalAiHunyuanImageV3InstructEditResponses[keyof PostFalAiHunyuanImageV3InstructEditResponses];

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/instruct/edit/requests/{request_id}";
};

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HunyuanImageV3InstructEditOutput;
};

export type GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdResponse =
  GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdResponses[keyof GetFalAiHunyuanImageV3InstructEditRequestsByRequestIdResponses];

export type GetFalAiQwenImageMaxEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-max/edit/requests/{request_id}/status";
};

export type GetFalAiQwenImageMaxEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageMaxEditRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageMaxEditRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageMaxEditRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageMaxEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-max/edit/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageMaxEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageMaxEditRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageMaxEditRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageMaxEditRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageMaxEditData = {
  body: QwenImageMaxEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-max/edit";
};

export type PostFalAiQwenImageMaxEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageMaxEditResponse =
  PostFalAiQwenImageMaxEditResponses[keyof PostFalAiQwenImageMaxEditResponses];

export type GetFalAiQwenImageMaxEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-max/edit/requests/{request_id}";
};

export type GetFalAiQwenImageMaxEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageMaxEditOutput;
};

export type GetFalAiQwenImageMaxEditRequestsByRequestIdResponse =
  GetFalAiQwenImageMaxEditRequestsByRequestIdResponses[keyof GetFalAiQwenImageMaxEditRequestsByRequestIdResponses];

export type GetBriaReplaceBackgroundRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/replace-background/requests/{request_id}/status";
};

export type GetBriaReplaceBackgroundRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaReplaceBackgroundRequestsByRequestIdStatusResponse =
  GetBriaReplaceBackgroundRequestsByRequestIdStatusResponses[keyof GetBriaReplaceBackgroundRequestsByRequestIdStatusResponses];

export type PutBriaReplaceBackgroundRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/replace-background/requests/{request_id}/cancel";
};

export type PutBriaReplaceBackgroundRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaReplaceBackgroundRequestsByRequestIdCancelResponse =
  PutBriaReplaceBackgroundRequestsByRequestIdCancelResponses[keyof PutBriaReplaceBackgroundRequestsByRequestIdCancelResponses];

export type PostBriaReplaceBackgroundData = {
  body: ReplaceBackgroundInput;
  path?: never;
  query?: never;
  url: "/bria/replace-background";
};

export type PostBriaReplaceBackgroundResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaReplaceBackgroundResponse =
  PostBriaReplaceBackgroundResponses[keyof PostBriaReplaceBackgroundResponses];

export type GetBriaReplaceBackgroundRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/replace-background/requests/{request_id}";
};

export type GetBriaReplaceBackgroundRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReplaceBackgroundOutput;
};

export type GetBriaReplaceBackgroundRequestsByRequestIdResponse =
  GetBriaReplaceBackgroundRequestsByRequestIdResponses[keyof GetBriaReplaceBackgroundRequestsByRequestIdResponses];

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/half-moon-ai/ai-face-swap/faceswapimage/requests/{request_id}/status";
  };

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdStatusResponse =
  GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdStatusResponses[keyof GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdStatusResponses];

export type PutHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/half-moon-ai/ai-face-swap/faceswapimage/requests/{request_id}/cancel";
  };

export type PutHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdCancelResponse =
  PutHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdCancelResponses[keyof PutHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdCancelResponses];

export type PostHalfMoonAiAiFaceSwapFaceswapimageData = {
  body: AiFaceSwapFaceswapimageInput;
  path?: never;
  query?: never;
  url: "/half-moon-ai/ai-face-swap/faceswapimage";
};

export type PostHalfMoonAiAiFaceSwapFaceswapimageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostHalfMoonAiAiFaceSwapFaceswapimageResponse =
  PostHalfMoonAiAiFaceSwapFaceswapimageResponses[keyof PostHalfMoonAiAiFaceSwapFaceswapimageResponses];

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-face-swap/faceswapimage/requests/{request_id}";
};

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AiFaceSwapFaceswapimageOutput;
};

export type GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdResponse =
  GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdResponses[keyof GetHalfMoonAiAiFaceSwapFaceswapimageRequestsByRequestIdResponses];

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/replace_object_by_text/requests/{request_id}/status";
};

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdStatusResponse =
  GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditReplaceObjectByTextRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/replace_object_by_text/requests/{request_id}/cancel";
};

export type PutBriaFiboEditReplaceObjectByTextRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutBriaFiboEditReplaceObjectByTextRequestsByRequestIdCancelResponse =
  PutBriaFiboEditReplaceObjectByTextRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditReplaceObjectByTextRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditReplaceObjectByTextData = {
  body: FiboEditReplaceObjectByTextInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/replace_object_by_text";
};

export type PostBriaFiboEditReplaceObjectByTextResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditReplaceObjectByTextResponse =
  PostBriaFiboEditReplaceObjectByTextResponses[keyof PostBriaFiboEditReplaceObjectByTextResponses];

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/replace_object_by_text/requests/{request_id}";
};

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditReplaceObjectByTextOutput;
};

export type GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdResponse =
  GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdResponses[keyof GetBriaFiboEditReplaceObjectByTextRequestsByRequestIdResponses];

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/sketch_to_colored_image/requests/{request_id}/status";
};

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdStatusResponse =
  GetBriaFiboEditSketchToColoredImageRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditSketchToColoredImageRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditSketchToColoredImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/sketch_to_colored_image/requests/{request_id}/cancel";
};

export type PutBriaFiboEditSketchToColoredImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutBriaFiboEditSketchToColoredImageRequestsByRequestIdCancelResponse =
  PutBriaFiboEditSketchToColoredImageRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditSketchToColoredImageRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditSketchToColoredImageData = {
  body: FiboEditSketchToColoredImageInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/sketch_to_colored_image";
};

export type PostBriaFiboEditSketchToColoredImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditSketchToColoredImageResponse =
  PostBriaFiboEditSketchToColoredImageResponses[keyof PostBriaFiboEditSketchToColoredImageResponses];

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/sketch_to_colored_image/requests/{request_id}";
};

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditSketchToColoredImageOutput;
};

export type GetBriaFiboEditSketchToColoredImageRequestsByRequestIdResponse =
  GetBriaFiboEditSketchToColoredImageRequestsByRequestIdResponses[keyof GetBriaFiboEditSketchToColoredImageRequestsByRequestIdResponses];

export type GetBriaFiboEditRestoreRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/restore/requests/{request_id}/status";
};

export type GetBriaFiboEditRestoreRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditRestoreRequestsByRequestIdStatusResponse =
  GetBriaFiboEditRestoreRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditRestoreRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditRestoreRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/restore/requests/{request_id}/cancel";
};

export type PutBriaFiboEditRestoreRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditRestoreRequestsByRequestIdCancelResponse =
  PutBriaFiboEditRestoreRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditRestoreRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditRestoreData = {
  body: FiboEditRestoreInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/restore";
};

export type PostBriaFiboEditRestoreResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditRestoreResponse =
  PostBriaFiboEditRestoreResponses[keyof PostBriaFiboEditRestoreResponses];

export type GetBriaFiboEditRestoreRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/restore/requests/{request_id}";
};

export type GetBriaFiboEditRestoreRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditRestoreOutput;
};

export type GetBriaFiboEditRestoreRequestsByRequestIdResponse =
  GetBriaFiboEditRestoreRequestsByRequestIdResponses[keyof GetBriaFiboEditRestoreRequestsByRequestIdResponses];

export type GetBriaFiboEditReseasonRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/reseason/requests/{request_id}/status";
};

export type GetBriaFiboEditReseasonRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditReseasonRequestsByRequestIdStatusResponse =
  GetBriaFiboEditReseasonRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditReseasonRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditReseasonRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/reseason/requests/{request_id}/cancel";
};

export type PutBriaFiboEditReseasonRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditReseasonRequestsByRequestIdCancelResponse =
  PutBriaFiboEditReseasonRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditReseasonRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditReseasonData = {
  body: FiboEditReseasonInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/reseason";
};

export type PostBriaFiboEditReseasonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditReseasonResponse =
  PostBriaFiboEditReseasonResponses[keyof PostBriaFiboEditReseasonResponses];

export type GetBriaFiboEditReseasonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/reseason/requests/{request_id}";
};

export type GetBriaFiboEditReseasonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditReseasonOutput;
};

export type GetBriaFiboEditReseasonRequestsByRequestIdResponse =
  GetBriaFiboEditReseasonRequestsByRequestIdResponses[keyof GetBriaFiboEditReseasonRequestsByRequestIdResponses];

export type GetBriaFiboEditRelightRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/relight/requests/{request_id}/status";
};

export type GetBriaFiboEditRelightRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditRelightRequestsByRequestIdStatusResponse =
  GetBriaFiboEditRelightRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditRelightRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditRelightRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/relight/requests/{request_id}/cancel";
};

export type PutBriaFiboEditRelightRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditRelightRequestsByRequestIdCancelResponse =
  PutBriaFiboEditRelightRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditRelightRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditRelightData = {
  body: FiboEditRelightInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/relight";
};

export type PostBriaFiboEditRelightResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditRelightResponse =
  PostBriaFiboEditRelightResponses[keyof PostBriaFiboEditRelightResponses];

export type GetBriaFiboEditRelightRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/relight/requests/{request_id}";
};

export type GetBriaFiboEditRelightRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditRelightOutput;
};

export type GetBriaFiboEditRelightRequestsByRequestIdResponse =
  GetBriaFiboEditRelightRequestsByRequestIdResponses[keyof GetBriaFiboEditRelightRequestsByRequestIdResponses];

export type GetBriaFiboEditRestyleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/restyle/requests/{request_id}/status";
};

export type GetBriaFiboEditRestyleRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditRestyleRequestsByRequestIdStatusResponse =
  GetBriaFiboEditRestyleRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditRestyleRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditRestyleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/restyle/requests/{request_id}/cancel";
};

export type PutBriaFiboEditRestyleRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditRestyleRequestsByRequestIdCancelResponse =
  PutBriaFiboEditRestyleRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditRestyleRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditRestyleData = {
  body: FiboEditRestyleInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/restyle";
};

export type PostBriaFiboEditRestyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditRestyleResponse =
  PostBriaFiboEditRestyleResponses[keyof PostBriaFiboEditRestyleResponses];

export type GetBriaFiboEditRestyleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/restyle/requests/{request_id}";
};

export type GetBriaFiboEditRestyleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditRestyleOutput;
};

export type GetBriaFiboEditRestyleRequestsByRequestIdResponse =
  GetBriaFiboEditRestyleRequestsByRequestIdResponses[keyof GetBriaFiboEditRestyleRequestsByRequestIdResponses];

export type GetBriaFiboEditRewriteTextRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/rewrite_text/requests/{request_id}/status";
};

export type GetBriaFiboEditRewriteTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditRewriteTextRequestsByRequestIdStatusResponse =
  GetBriaFiboEditRewriteTextRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditRewriteTextRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditRewriteTextRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/rewrite_text/requests/{request_id}/cancel";
};

export type PutBriaFiboEditRewriteTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditRewriteTextRequestsByRequestIdCancelResponse =
  PutBriaFiboEditRewriteTextRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditRewriteTextRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditRewriteTextData = {
  body: FiboEditRewriteTextInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/rewrite_text";
};

export type PostBriaFiboEditRewriteTextResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditRewriteTextResponse =
  PostBriaFiboEditRewriteTextResponses[keyof PostBriaFiboEditRewriteTextResponses];

export type GetBriaFiboEditRewriteTextRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/rewrite_text/requests/{request_id}";
};

export type GetBriaFiboEditRewriteTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditRewriteTextOutput;
};

export type GetBriaFiboEditRewriteTextRequestsByRequestIdResponse =
  GetBriaFiboEditRewriteTextRequestsByRequestIdResponses[keyof GetBriaFiboEditRewriteTextRequestsByRequestIdResponses];

export type GetBriaFiboEditEraseByTextRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/erase_by_text/requests/{request_id}/status";
};

export type GetBriaFiboEditEraseByTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditEraseByTextRequestsByRequestIdStatusResponse =
  GetBriaFiboEditEraseByTextRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditEraseByTextRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditEraseByTextRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/erase_by_text/requests/{request_id}/cancel";
};

export type PutBriaFiboEditEraseByTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditEraseByTextRequestsByRequestIdCancelResponse =
  PutBriaFiboEditEraseByTextRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditEraseByTextRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditEraseByTextData = {
  body: FiboEditEraseByTextInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/erase_by_text";
};

export type PostBriaFiboEditEraseByTextResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditEraseByTextResponse =
  PostBriaFiboEditEraseByTextResponses[keyof PostBriaFiboEditEraseByTextResponses];

export type GetBriaFiboEditEraseByTextRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/erase_by_text/requests/{request_id}";
};

export type GetBriaFiboEditEraseByTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditEraseByTextOutput;
};

export type GetBriaFiboEditEraseByTextRequestsByRequestIdResponse =
  GetBriaFiboEditEraseByTextRequestsByRequestIdResponses[keyof GetBriaFiboEditEraseByTextRequestsByRequestIdResponses];

export type GetBriaFiboEditEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/edit/requests/{request_id}/status";
};

export type GetBriaFiboEditEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditEditRequestsByRequestIdStatusResponse =
  GetBriaFiboEditEditRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditEditRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/edit/requests/{request_id}/cancel";
};

export type PutBriaFiboEditEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditEditRequestsByRequestIdCancelResponse =
  PutBriaFiboEditEditRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditEditRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditEditData = {
  body: FiboEditEditInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/edit";
};

export type PostBriaFiboEditEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditEditResponse =
  PostBriaFiboEditEditResponses[keyof PostBriaFiboEditEditResponses];

export type GetBriaFiboEditEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/edit/requests/{request_id}";
};

export type GetBriaFiboEditEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditEditOutput;
};

export type GetBriaFiboEditEditRequestsByRequestIdResponse =
  GetBriaFiboEditEditRequestsByRequestIdResponses[keyof GetBriaFiboEditEditRequestsByRequestIdResponses];

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/add_object_by_text/requests/{request_id}/status";
};

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdStatusResponse =
  GetBriaFiboEditAddObjectByTextRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditAddObjectByTextRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditAddObjectByTextRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/add_object_by_text/requests/{request_id}/cancel";
};

export type PutBriaFiboEditAddObjectByTextRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditAddObjectByTextRequestsByRequestIdCancelResponse =
  PutBriaFiboEditAddObjectByTextRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditAddObjectByTextRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditAddObjectByTextData = {
  body: FiboEditAddObjectByTextInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/add_object_by_text";
};

export type PostBriaFiboEditAddObjectByTextResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditAddObjectByTextResponse =
  PostBriaFiboEditAddObjectByTextResponses[keyof PostBriaFiboEditAddObjectByTextResponses];

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/add_object_by_text/requests/{request_id}";
};

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditAddObjectByTextOutput;
};

export type GetBriaFiboEditAddObjectByTextRequestsByRequestIdResponse =
  GetBriaFiboEditAddObjectByTextRequestsByRequestIdResponses[keyof GetBriaFiboEditAddObjectByTextRequestsByRequestIdResponses];

export type GetBriaFiboEditBlendRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/blend/requests/{request_id}/status";
};

export type GetBriaFiboEditBlendRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditBlendRequestsByRequestIdStatusResponse =
  GetBriaFiboEditBlendRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditBlendRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditBlendRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/blend/requests/{request_id}/cancel";
};

export type PutBriaFiboEditBlendRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditBlendRequestsByRequestIdCancelResponse =
  PutBriaFiboEditBlendRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditBlendRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditBlendData = {
  body: FiboEditBlendInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/blend";
};

export type PostBriaFiboEditBlendResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditBlendResponse =
  PostBriaFiboEditBlendResponses[keyof PostBriaFiboEditBlendResponses];

export type GetBriaFiboEditBlendRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/blend/requests/{request_id}";
};

export type GetBriaFiboEditBlendRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditBlendOutput;
};

export type GetBriaFiboEditBlendRequestsByRequestIdResponse =
  GetBriaFiboEditBlendRequestsByRequestIdResponses[keyof GetBriaFiboEditBlendRequestsByRequestIdResponses];

export type GetBriaFiboEditColorizeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-edit/colorize/requests/{request_id}/status";
};

export type GetBriaFiboEditColorizeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboEditColorizeRequestsByRequestIdStatusResponse =
  GetBriaFiboEditColorizeRequestsByRequestIdStatusResponses[keyof GetBriaFiboEditColorizeRequestsByRequestIdStatusResponses];

export type PutBriaFiboEditColorizeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/colorize/requests/{request_id}/cancel";
};

export type PutBriaFiboEditColorizeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboEditColorizeRequestsByRequestIdCancelResponse =
  PutBriaFiboEditColorizeRequestsByRequestIdCancelResponses[keyof PutBriaFiboEditColorizeRequestsByRequestIdCancelResponses];

export type PostBriaFiboEditColorizeData = {
  body: FiboEditColorizeInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-edit/colorize";
};

export type PostBriaFiboEditColorizeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboEditColorizeResponse =
  PostBriaFiboEditColorizeResponses[keyof PostBriaFiboEditColorizeResponses];

export type GetBriaFiboEditColorizeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-edit/colorize/requests/{request_id}";
};

export type GetBriaFiboEditColorizeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboEditColorizeOutput;
};

export type GetBriaFiboEditColorizeRequestsByRequestIdResponse =
  GetBriaFiboEditColorizeRequestsByRequestIdResponses[keyof GetBriaFiboEditColorizeRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/base/edit/lora/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit/lora/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bBaseEditLoraData = {
  body: Flux2Klein9bBaseEditLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit/lora";
};

export type PostFalAiFlux2Klein9bBaseEditLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bBaseEditLoraResponse =
  PostFalAiFlux2Klein9bBaseEditLoraResponses[keyof PostFalAiFlux2Klein9bBaseEditLoraResponses];

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit/lora/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bBaseEditLoraOutput;
};

export type GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bBaseEditLoraRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/base/edit/lora/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit/lora/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bBaseEditLoraData = {
  body: Flux2Klein4bBaseEditLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit/lora";
};

export type PostFalAiFlux2Klein4bBaseEditLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bBaseEditLoraResponse =
  PostFalAiFlux2Klein4bBaseEditLoraResponses[keyof PostFalAiFlux2Klein4bBaseEditLoraResponses];

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit/lora/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bBaseEditLoraOutput;
};

export type GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bBaseEditLoraRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/base/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bBaseEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bBaseEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein4bBaseEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bBaseEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bBaseEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bBaseEditData = {
  body: Flux2Klein4bBaseEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit";
};

export type PostFalAiFlux2Klein4bBaseEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bBaseEditResponse =
  PostFalAiFlux2Klein4bBaseEditResponses[keyof PostFalAiFlux2Klein4bBaseEditResponses];

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/edit/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bBaseEditOutput;
};

export type GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bBaseEditRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/base/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bBaseEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bBaseEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein9bBaseEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bBaseEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bBaseEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bBaseEditData = {
  body: Flux2Klein9bBaseEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit";
};

export type PostFalAiFlux2Klein9bBaseEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bBaseEditResponse =
  PostFalAiFlux2Klein9bBaseEditResponses[keyof PostFalAiFlux2Klein9bBaseEditResponses];

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/edit/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bBaseEditOutput;
};

export type GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bBaseEditRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein4bEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bEditData = {
  body: Flux2Klein4bEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/edit";
};

export type PostFalAiFlux2Klein4bEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bEditResponse =
  PostFalAiFlux2Klein4bEditResponses[keyof PostFalAiFlux2Klein4bEditResponses];

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/edit/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bEditOutput;
};

export type GetFalAiFlux2Klein4bEditRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bEditRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bEditRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein9bEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bEditData = {
  body: Flux2Klein9bEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/edit";
};

export type PostFalAiFlux2Klein9bEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bEditResponse =
  PostFalAiFlux2Klein9bEditResponses[keyof PostFalAiFlux2Klein9bEditResponses];

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/edit/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bEditOutput;
};

export type GetFalAiFlux2Klein9bEditRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bEditRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bEditRequestsByRequestIdResponses];

export type GetFalAiGlmImageImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/glm-image/image-to-image/requests/{request_id}/status";
};

export type GetFalAiGlmImageImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGlmImageImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiGlmImageImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiGlmImageImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiGlmImageImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/glm-image/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiGlmImageImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGlmImageImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiGlmImageImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiGlmImageImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiGlmImageImageToImageData = {
  body: GlmImageImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/glm-image/image-to-image";
};

export type PostFalAiGlmImageImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGlmImageImageToImageResponse =
  PostFalAiGlmImageImageToImageResponses[keyof PostFalAiGlmImageImageToImageResponses];

export type GetFalAiGlmImageImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/glm-image/image-to-image/requests/{request_id}";
};

export type GetFalAiGlmImageImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GlmImageImageToImageOutput;
};

export type GetFalAiGlmImageImageToImageRequestsByRequestIdResponse =
  GetFalAiGlmImageImageToImageRequestsByRequestIdResponses[keyof GetFalAiGlmImageImageToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2511-multiple-angles/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2511-multiple-angles/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2511MultipleAnglesData = {
  body: QwenImageEdit2511MultipleAnglesInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511-multiple-angles";
};

export type PostFalAiQwenImageEdit2511MultipleAnglesResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2511MultipleAnglesResponse =
  PostFalAiQwenImageEdit2511MultipleAnglesResponses[keyof PostFalAiQwenImageEdit2511MultipleAnglesResponses];

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511-multiple-angles/requests/{request_id}";
};

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2511MultipleAnglesOutput;
  };

export type GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2511MultipleAnglesRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-2511/lora/requests/{request_id}/status";
};

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2511LoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2511LoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2511LoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511/lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEdit2511LoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEdit2511LoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2511LoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2511LoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2511LoraData = {
  body: QwenImageEdit2511LoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511/lora";
};

export type PostFalAiQwenImageEdit2511LoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2511LoraResponse =
  PostFalAiQwenImageEdit2511LoraResponses[keyof PostFalAiQwenImageEdit2511LoraResponses];

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511/lora/requests/{request_id}";
};

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEdit2511LoraOutput;
};

export type GetFalAiQwenImageEdit2511LoraRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2511LoraRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2511LoraRequestsByRequestIdResponses];

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/half-moon-ai/ai-home/style/requests/{request_id}/status";
};

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdStatusResponse =
  GetHalfMoonAiAiHomeStyleRequestsByRequestIdStatusResponses[keyof GetHalfMoonAiAiHomeStyleRequestsByRequestIdStatusResponses];

export type PutHalfMoonAiAiHomeStyleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-home/style/requests/{request_id}/cancel";
};

export type PutHalfMoonAiAiHomeStyleRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutHalfMoonAiAiHomeStyleRequestsByRequestIdCancelResponse =
  PutHalfMoonAiAiHomeStyleRequestsByRequestIdCancelResponses[keyof PutHalfMoonAiAiHomeStyleRequestsByRequestIdCancelResponses];

export type PostHalfMoonAiAiHomeStyleData = {
  body: AiHomeStyleInput;
  path?: never;
  query?: never;
  url: "/half-moon-ai/ai-home/style";
};

export type PostHalfMoonAiAiHomeStyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostHalfMoonAiAiHomeStyleResponse =
  PostHalfMoonAiAiHomeStyleResponses[keyof PostHalfMoonAiAiHomeStyleResponses];

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-home/style/requests/{request_id}";
};

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AiHomeStyleOutput;
};

export type GetHalfMoonAiAiHomeStyleRequestsByRequestIdResponse =
  GetHalfMoonAiAiHomeStyleRequestsByRequestIdResponses[keyof GetHalfMoonAiAiHomeStyleRequestsByRequestIdResponses];

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/half-moon-ai/ai-home/edit/requests/{request_id}/status";
};

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdStatusResponse =
  GetHalfMoonAiAiHomeEditRequestsByRequestIdStatusResponses[keyof GetHalfMoonAiAiHomeEditRequestsByRequestIdStatusResponses];

export type PutHalfMoonAiAiHomeEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-home/edit/requests/{request_id}/cancel";
};

export type PutHalfMoonAiAiHomeEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutHalfMoonAiAiHomeEditRequestsByRequestIdCancelResponse =
  PutHalfMoonAiAiHomeEditRequestsByRequestIdCancelResponses[keyof PutHalfMoonAiAiHomeEditRequestsByRequestIdCancelResponses];

export type PostHalfMoonAiAiHomeEditData = {
  body: AiHomeEditInput;
  path?: never;
  query?: never;
  url: "/half-moon-ai/ai-home/edit";
};

export type PostHalfMoonAiAiHomeEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostHalfMoonAiAiHomeEditResponse =
  PostHalfMoonAiAiHomeEditResponses[keyof PostHalfMoonAiAiHomeEditResponses];

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-home/edit/requests/{request_id}";
};

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AiHomeEditOutput;
};

export type GetHalfMoonAiAiHomeEditRequestsByRequestIdResponse =
  GetHalfMoonAiAiHomeEditRequestsByRequestIdResponses[keyof GetHalfMoonAiAiHomeEditRequestsByRequestIdResponses];

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-layered/lora/requests/{request_id}/status";
};

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageLayeredLoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageLayeredLoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageLayeredLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-layered/lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageLayeredLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageLayeredLoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageLayeredLoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageLayeredLoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageLayeredLoraData = {
  body: QwenImageLayeredLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-layered/lora";
};

export type PostFalAiQwenImageLayeredLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageLayeredLoraResponse =
  PostFalAiQwenImageLayeredLoraResponses[keyof PostFalAiQwenImageLayeredLoraResponses];

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-layered/lora/requests/{request_id}";
};

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageLayeredLoraOutput;
};

export type GetFalAiQwenImageLayeredLoraRequestsByRequestIdResponse =
  GetFalAiQwenImageLayeredLoraRequestsByRequestIdResponses[keyof GetFalAiQwenImageLayeredLoraRequestsByRequestIdResponses];

export type GetWanV26ImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/wan/v2.6/image-to-image/requests/{request_id}/status";
};

export type GetWanV26ImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetWanV26ImageToImageRequestsByRequestIdStatusResponse =
  GetWanV26ImageToImageRequestsByRequestIdStatusResponses[keyof GetWanV26ImageToImageRequestsByRequestIdStatusResponses];

export type PutWanV26ImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/wan/v2.6/image-to-image/requests/{request_id}/cancel";
};

export type PutWanV26ImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutWanV26ImageToImageRequestsByRequestIdCancelResponse =
  PutWanV26ImageToImageRequestsByRequestIdCancelResponses[keyof PutWanV26ImageToImageRequestsByRequestIdCancelResponses];

export type PostWanV26ImageToImageData = {
  body: V26ImageToImageInput;
  path?: never;
  query?: never;
  url: "/wan/v2.6/image-to-image";
};

export type PostWanV26ImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostWanV26ImageToImageResponse =
  PostWanV26ImageToImageResponses[keyof PostWanV26ImageToImageResponses];

export type GetWanV26ImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/wan/v2.6/image-to-image/requests/{request_id}";
};

export type GetWanV26ImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: V26ImageToImageOutput;
};

export type GetWanV26ImageToImageRequestsByRequestIdResponse =
  GetWanV26ImageToImageRequestsByRequestIdResponses[keyof GetWanV26ImageToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2511RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-2511/requests/{request_id}/status";
};

export type GetFalAiQwenImageEdit2511RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEdit2511RequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2511RequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2511RequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2511RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEdit2511RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEdit2511RequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2511RequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2511RequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2511Data = {
  body: QwenImageEdit2511Input;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511";
};

export type PostFalAiQwenImageEdit2511Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2511Response =
  PostFalAiQwenImageEdit2511Responses[keyof PostFalAiQwenImageEdit2511Responses];

export type GetFalAiQwenImageEdit2511RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2511/requests/{request_id}";
};

export type GetFalAiQwenImageEdit2511RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEdit2511Output;
};

export type GetFalAiQwenImageEdit2511RequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2511RequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2511RequestsByRequestIdResponses];

export type GetFalAiQwenImageLayeredRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-layered/requests/{request_id}/status";
};

export type GetFalAiQwenImageLayeredRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageLayeredRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageLayeredRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageLayeredRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageLayeredRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-layered/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageLayeredRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageLayeredRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageLayeredRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageLayeredRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageLayeredData = {
  body: QwenImageLayeredInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-layered";
};

export type PostFalAiQwenImageLayeredResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageLayeredResponse =
  PostFalAiQwenImageLayeredResponses[keyof PostFalAiQwenImageLayeredResponses];

export type GetFalAiQwenImageLayeredRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-layered/requests/{request_id}";
};

export type GetFalAiQwenImageLayeredRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageLayeredOutput;
};

export type GetFalAiQwenImageLayeredRequestsByRequestIdResponse =
  GetFalAiQwenImageLayeredRequestsByRequestIdResponses[keyof GetFalAiQwenImageLayeredRequestsByRequestIdResponses];

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/inpaint/lora/requests/{request_id}/status";
};

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboInpaintLoraRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboInpaintLoraRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboInpaintLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint/lora/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboInpaintLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageTurboInpaintLoraRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboInpaintLoraRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboInpaintLoraRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboInpaintLoraData = {
  body: ZImageTurboInpaintLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint/lora";
};

export type PostFalAiZImageTurboInpaintLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboInpaintLoraResponse =
  PostFalAiZImageTurboInpaintLoraResponses[keyof PostFalAiZImageTurboInpaintLoraResponses];

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint/lora/requests/{request_id}";
};

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboInpaintLoraOutput;
};

export type GetFalAiZImageTurboInpaintLoraRequestsByRequestIdResponse =
  GetFalAiZImageTurboInpaintLoraRequestsByRequestIdResponses[keyof GetFalAiZImageTurboInpaintLoraRequestsByRequestIdResponses];

export type GetFalAiZImageTurboInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/inpaint/requests/{request_id}/status";
};

export type GetFalAiZImageTurboInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageTurboInpaintRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageTurboInpaintRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboInpaintData = {
  body: ZImageTurboInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint";
};

export type PostFalAiZImageTurboInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboInpaintResponse =
  PostFalAiZImageTurboInpaintResponses[keyof PostFalAiZImageTurboInpaintResponses];

export type GetFalAiZImageTurboInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/inpaint/requests/{request_id}";
};

export type GetFalAiZImageTurboInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboInpaintOutput;
};

export type GetFalAiZImageTurboInpaintRequestsByRequestIdResponse =
  GetFalAiZImageTurboInpaintRequestsByRequestIdResponses[keyof GetFalAiZImageTurboInpaintRequestsByRequestIdResponses];

export type GetFalAiFlux2FlashEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/flash/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2FlashEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2FlashEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2FlashEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2FlashEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2FlashEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/flash/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2FlashEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2FlashEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2FlashEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2FlashEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2FlashEditData = {
  body: Flux2FlashEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/flash/edit";
};

export type PostFalAiFlux2FlashEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2FlashEditResponse =
  PostFalAiFlux2FlashEditResponses[keyof PostFalAiFlux2FlashEditResponses];

export type GetFalAiFlux2FlashEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/flash/edit/requests/{request_id}";
};

export type GetFalAiFlux2FlashEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2FlashEditOutput;
};

export type GetFalAiFlux2FlashEditRequestsByRequestIdResponse =
  GetFalAiFlux2FlashEditRequestsByRequestIdResponses[keyof GetFalAiFlux2FlashEditRequestsByRequestIdResponses];

export type GetFalAiGptImage15EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1.5/edit/requests/{request_id}/status";
};

export type GetFalAiGptImage15EditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage15EditRequestsByRequestIdStatusResponse =
  GetFalAiGptImage15EditRequestsByRequestIdStatusResponses[keyof GetFalAiGptImage15EditRequestsByRequestIdStatusResponses];

export type PutFalAiGptImage15EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1.5/edit/requests/{request_id}/cancel";
};

export type PutFalAiGptImage15EditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage15EditRequestsByRequestIdCancelResponse =
  PutFalAiGptImage15EditRequestsByRequestIdCancelResponses[keyof PutFalAiGptImage15EditRequestsByRequestIdCancelResponses];

export type PostFalAiGptImage15EditData = {
  body: GptImage15EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1.5/edit";
};

export type PostFalAiGptImage15EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage15EditResponse =
  PostFalAiGptImage15EditResponses[keyof PostFalAiGptImage15EditResponses];

export type GetFalAiGptImage15EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1.5/edit/requests/{request_id}";
};

export type GetFalAiGptImage15EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage15EditOutput;
};

export type GetFalAiGptImage15EditRequestsByRequestIdResponse =
  GetFalAiGptImage15EditRequestsByRequestIdResponses[keyof GetFalAiGptImage15EditRequestsByRequestIdResponses];

export type GetFalAiFlux2TurboEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/turbo/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2TurboEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2TurboEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2TurboEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2TurboEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2TurboEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/turbo/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2TurboEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2TurboEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2TurboEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2TurboEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2TurboEditData = {
  body: Flux2TurboEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/turbo/edit";
};

export type PostFalAiFlux2TurboEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2TurboEditResponse =
  PostFalAiFlux2TurboEditResponses[keyof PostFalAiFlux2TurboEditResponses];

export type GetFalAiFlux2TurboEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/turbo/edit/requests/{request_id}";
};

export type GetFalAiFlux2TurboEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2TurboEditOutput;
};

export type GetFalAiFlux2TurboEditRequestsByRequestIdResponse =
  GetFalAiFlux2TurboEditRequestsByRequestIdResponses[keyof GetFalAiFlux2TurboEditRequestsByRequestIdResponses];

export type GetFalAiFlux2MaxEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-max/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2MaxEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2MaxEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2MaxEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2MaxEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2MaxEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-max/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2MaxEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2MaxEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2MaxEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2MaxEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2MaxEditData = {
  body: Flux2MaxEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-max/edit";
};

export type PostFalAiFlux2MaxEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2MaxEditResponse =
  PostFalAiFlux2MaxEditResponses[keyof PostFalAiFlux2MaxEditResponses];

export type GetFalAiFlux2MaxEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-max/edit/requests/{request_id}";
};

export type GetFalAiFlux2MaxEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2MaxEditOutput;
};

export type GetFalAiFlux2MaxEditRequestsByRequestIdResponse =
  GetFalAiFlux2MaxEditRequestsByRequestIdResponses[keyof GetFalAiFlux2MaxEditRequestsByRequestIdResponses];

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/half-moon-ai/ai-baby-and-aging-generator/multi/requests/{request_id}/status";
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdStatusResponse =
  GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdStatusResponses[keyof GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdStatusResponses];

export type PutHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/half-moon-ai/ai-baby-and-aging-generator/multi/requests/{request_id}/cancel";
  };

export type PutHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdCancelResponse =
  PutHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdCancelResponses[keyof PutHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdCancelResponses];

export type PostHalfMoonAiAiBabyAndAgingGeneratorMultiData = {
  body: AiBabyAndAgingGeneratorMultiInput;
  path?: never;
  query?: never;
  url: "/half-moon-ai/ai-baby-and-aging-generator/multi";
};

export type PostHalfMoonAiAiBabyAndAgingGeneratorMultiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostHalfMoonAiAiBabyAndAgingGeneratorMultiResponse =
  PostHalfMoonAiAiBabyAndAgingGeneratorMultiResponses[keyof PostHalfMoonAiAiBabyAndAgingGeneratorMultiResponses];

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/half-moon-ai/ai-baby-and-aging-generator/multi/requests/{request_id}";
};

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: AiBabyAndAgingGeneratorMultiOutput;
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdResponse =
  GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdResponses[keyof GetHalfMoonAiAiBabyAndAgingGeneratorMultiRequestsByRequestIdResponses];

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/half-moon-ai/ai-baby-and-aging-generator/single/requests/{request_id}/status";
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdStatusResponse =
  GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdStatusResponses[keyof GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdStatusResponses];

export type PutHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/half-moon-ai/ai-baby-and-aging-generator/single/requests/{request_id}/cancel";
  };

export type PutHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdCancelResponse =
  PutHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdCancelResponses[keyof PutHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdCancelResponses];

export type PostHalfMoonAiAiBabyAndAgingGeneratorSingleData = {
  body: AiBabyAndAgingGeneratorSingleInput;
  path?: never;
  query?: never;
  url: "/half-moon-ai/ai-baby-and-aging-generator/single";
};

export type PostHalfMoonAiAiBabyAndAgingGeneratorSingleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostHalfMoonAiAiBabyAndAgingGeneratorSingleResponse =
  PostHalfMoonAiAiBabyAndAgingGeneratorSingleResponses[keyof PostHalfMoonAiAiBabyAndAgingGeneratorSingleResponses];

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/half-moon-ai/ai-baby-and-aging-generator/single/requests/{request_id}";
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: AiBabyAndAgingGeneratorSingleOutput;
  };

export type GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdResponse =
  GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdResponses[keyof GetHalfMoonAiAiBabyAndAgingGeneratorSingleRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/shirt-design/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/shirt-design/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryShirtDesignData = {
  body: QwenImageEdit2509LoraGalleryShirtDesignInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/shirt-design";
};

export type PostFalAiQwenImageEdit2509LoraGalleryShirtDesignResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryShirtDesignResponse =
  PostFalAiQwenImageEdit2509LoraGalleryShirtDesignResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryShirtDesignResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/shirt-design/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryShirtDesignOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryShirtDesignRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-lighting/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-lighting/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveLightingData = {
  body: QwenImageEdit2509LoraGalleryRemoveLightingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-lighting";
};

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveLightingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveLightingResponse =
  PostFalAiQwenImageEdit2509LoraGalleryRemoveLightingResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryRemoveLightingResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-lighting/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryRemoveLightingOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryRemoveLightingRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-element/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-element/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveElementData = {
  body: QwenImageEdit2509LoraGalleryRemoveElementInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-element";
};

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveElementResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryRemoveElementResponse =
  PostFalAiQwenImageEdit2509LoraGalleryRemoveElementResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryRemoveElementResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/remove-element/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryRemoveElementOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryRemoveElementRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/lighting-restoration/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/lighting-restoration/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryLightingRestorationData = {
  body: QwenImageEdit2509LoraGalleryLightingRestorationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/lighting-restoration";
};

export type PostFalAiQwenImageEdit2509LoraGalleryLightingRestorationResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type PostFalAiQwenImageEdit2509LoraGalleryLightingRestorationResponse =
  PostFalAiQwenImageEdit2509LoraGalleryLightingRestorationResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryLightingRestorationResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/lighting-restoration/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryLightingRestorationOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryLightingRestorationRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/integrate-product/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/integrate-product/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryIntegrateProductData = {
  body: QwenImageEdit2509LoraGalleryIntegrateProductInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/integrate-product";
};

export type PostFalAiQwenImageEdit2509LoraGalleryIntegrateProductResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryIntegrateProductResponse =
  PostFalAiQwenImageEdit2509LoraGalleryIntegrateProductResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryIntegrateProductResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/integrate-product/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryIntegrateProductOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryIntegrateProductRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/group-photo/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/group-photo/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryGroupPhotoData = {
  body: QwenImageEdit2509LoraGalleryGroupPhotoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/group-photo";
};

export type PostFalAiQwenImageEdit2509LoraGalleryGroupPhotoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryGroupPhotoResponse =
  PostFalAiQwenImageEdit2509LoraGalleryGroupPhotoResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryGroupPhotoResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/group-photo/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryGroupPhotoOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryGroupPhotoRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/face-to-full-portrait/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/face-to-full-portrait/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitData = {
  body: QwenImageEdit2509LoraGalleryFaceToFullPortraitInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/face-to-full-portrait";
};

export type PostFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitResponse =
  PostFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/face-to-full-portrait/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryFaceToFullPortraitOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/add-background/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/add-background/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryAddBackgroundData = {
  body: QwenImageEdit2509LoraGalleryAddBackgroundInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/add-background";
};

export type PostFalAiQwenImageEdit2509LoraGalleryAddBackgroundResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryAddBackgroundResponse =
  PostFalAiQwenImageEdit2509LoraGalleryAddBackgroundResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryAddBackgroundResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/add-background/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryAddBackgroundOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryAddBackgroundRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/next-scene/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/next-scene/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryNextSceneData = {
  body: QwenImageEdit2509LoraGalleryNextSceneInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/next-scene";
};

export type PostFalAiQwenImageEdit2509LoraGalleryNextSceneResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryNextSceneResponse =
  PostFalAiQwenImageEdit2509LoraGalleryNextSceneResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryNextSceneResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/next-scene/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryNextSceneOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryNextSceneRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/multiple-angles/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/multiple-angles/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraGalleryMultipleAnglesData = {
  body: QwenImageEdit2509LoraGalleryMultipleAnglesInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora-gallery/multiple-angles";
};

export type PostFalAiQwenImageEdit2509LoraGalleryMultipleAnglesResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraGalleryMultipleAnglesResponse =
  PostFalAiQwenImageEdit2509LoraGalleryMultipleAnglesResponses[keyof PostFalAiQwenImageEdit2509LoraGalleryMultipleAnglesResponses];

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-2509-lora-gallery/multiple-angles/requests/{request_id}";
  };

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEdit2509LoraGalleryMultipleAnglesOutput;
  };

export type GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraGalleryMultipleAnglesRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-2509-lora/requests/{request_id}/status";
};

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509LoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509LoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509LoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEdit2509LoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEdit2509LoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509LoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509LoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509LoraData = {
  body: QwenImageEdit2509LoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora";
};

export type PostFalAiQwenImageEdit2509LoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509LoraResponse =
  PostFalAiQwenImageEdit2509LoraResponses[keyof PostFalAiQwenImageEdit2509LoraResponses];

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509-lora/requests/{request_id}";
};

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEdit2509LoraOutput;
};

export type GetFalAiQwenImageEdit2509LoraRequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509LoraRequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509LoraRequestsByRequestIdResponses];

export type GetFalAiQwenImageEdit2509RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-2509/requests/{request_id}/status";
};

export type GetFalAiQwenImageEdit2509RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEdit2509RequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEdit2509RequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEdit2509RequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEdit2509RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEdit2509RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEdit2509RequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEdit2509RequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEdit2509RequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEdit2509Data = {
  body: QwenImageEdit2509Input;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509";
};

export type PostFalAiQwenImageEdit2509Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEdit2509Response =
  PostFalAiQwenImageEdit2509Responses[keyof PostFalAiQwenImageEdit2509Responses];

export type GetFalAiQwenImageEdit2509RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-2509/requests/{request_id}";
};

export type GetFalAiQwenImageEdit2509RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEdit2509Output;
};

export type GetFalAiQwenImageEdit2509RequestsByRequestIdResponse =
  GetFalAiQwenImageEdit2509RequestsByRequestIdResponses[keyof GetFalAiQwenImageEdit2509RequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/lighting-restoration/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/lighting-restoration/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryLightingRestorationData = {
  body: QwenImageEditPlusLoraGalleryLightingRestorationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/lighting-restoration";
};

export type PostFalAiQwenImageEditPlusLoraGalleryLightingRestorationResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type PostFalAiQwenImageEditPlusLoraGalleryLightingRestorationResponse =
  PostFalAiQwenImageEditPlusLoraGalleryLightingRestorationResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryLightingRestorationResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/lighting-restoration/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryLightingRestorationOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryLightingRestorationRequestsByRequestIdResponses];

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/moondream3-preview/segment/requests/{request_id}/status";
};

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdStatusResponse =
  GetFalAiMoondream3PreviewSegmentRequestsByRequestIdStatusResponses[keyof GetFalAiMoondream3PreviewSegmentRequestsByRequestIdStatusResponses];

export type PutFalAiMoondream3PreviewSegmentRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/moondream3-preview/segment/requests/{request_id}/cancel";
};

export type PutFalAiMoondream3PreviewSegmentRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiMoondream3PreviewSegmentRequestsByRequestIdCancelResponse =
  PutFalAiMoondream3PreviewSegmentRequestsByRequestIdCancelResponses[keyof PutFalAiMoondream3PreviewSegmentRequestsByRequestIdCancelResponses];

export type PostFalAiMoondream3PreviewSegmentData = {
  body: Moondream3PreviewSegmentInput;
  path?: never;
  query?: never;
  url: "/fal-ai/moondream3-preview/segment";
};

export type PostFalAiMoondream3PreviewSegmentResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMoondream3PreviewSegmentResponse =
  PostFalAiMoondream3PreviewSegmentResponses[keyof PostFalAiMoondream3PreviewSegmentResponses];

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/moondream3-preview/segment/requests/{request_id}";
};

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Moondream3PreviewSegmentOutput;
};

export type GetFalAiMoondream3PreviewSegmentRequestsByRequestIdResponse =
  GetFalAiMoondream3PreviewSegmentRequestsByRequestIdResponses[keyof GetFalAiMoondream3PreviewSegmentRequestsByRequestIdResponses];

export type GetFalAiStepxEdit2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stepx-edit2/requests/{request_id}/status";
};

export type GetFalAiStepxEdit2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStepxEdit2RequestsByRequestIdStatusResponse =
  GetFalAiStepxEdit2RequestsByRequestIdStatusResponses[keyof GetFalAiStepxEdit2RequestsByRequestIdStatusResponses];

export type PutFalAiStepxEdit2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stepx-edit2/requests/{request_id}/cancel";
};

export type PutFalAiStepxEdit2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStepxEdit2RequestsByRequestIdCancelResponse =
  PutFalAiStepxEdit2RequestsByRequestIdCancelResponses[keyof PutFalAiStepxEdit2RequestsByRequestIdCancelResponses];

export type PostFalAiStepxEdit2Data = {
  body: StepxEdit2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/stepx-edit2";
};

export type PostFalAiStepxEdit2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStepxEdit2Response =
  PostFalAiStepxEdit2Responses[keyof PostFalAiStepxEdit2Responses];

export type GetFalAiStepxEdit2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stepx-edit2/requests/{request_id}";
};

export type GetFalAiStepxEdit2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StepxEdit2Output;
};

export type GetFalAiStepxEdit2RequestsByRequestIdResponse =
  GetFalAiStepxEdit2RequestsByRequestIdResponses[keyof GetFalAiStepxEdit2RequestsByRequestIdResponses];

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/controlnet/lora/requests/{request_id}/status";
};

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboControlnetLoraRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboControlnetLoraRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboControlnetLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet/lora/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboControlnetLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiZImageTurboControlnetLoraRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboControlnetLoraRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboControlnetLoraRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboControlnetLoraData = {
  body: ZImageTurboControlnetLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet/lora";
};

export type PostFalAiZImageTurboControlnetLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboControlnetLoraResponse =
  PostFalAiZImageTurboControlnetLoraResponses[keyof PostFalAiZImageTurboControlnetLoraResponses];

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet/lora/requests/{request_id}";
};

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboControlnetLoraOutput;
};

export type GetFalAiZImageTurboControlnetLoraRequestsByRequestIdResponse =
  GetFalAiZImageTurboControlnetLoraRequestsByRequestIdResponses[keyof GetFalAiZImageTurboControlnetLoraRequestsByRequestIdResponses];

export type GetFalAiZImageTurboControlnetRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/controlnet/requests/{request_id}/status";
};

export type GetFalAiZImageTurboControlnetRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageTurboControlnetRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboControlnetRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboControlnetRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboControlnetRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboControlnetRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageTurboControlnetRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboControlnetRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboControlnetRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboControlnetData = {
  body: ZImageTurboControlnetInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet";
};

export type PostFalAiZImageTurboControlnetResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboControlnetResponse =
  PostFalAiZImageTurboControlnetResponses[keyof PostFalAiZImageTurboControlnetResponses];

export type GetFalAiZImageTurboControlnetRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/controlnet/requests/{request_id}";
};

export type GetFalAiZImageTurboControlnetRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboControlnetOutput;
};

export type GetFalAiZImageTurboControlnetRequestsByRequestIdResponse =
  GetFalAiZImageTurboControlnetRequestsByRequestIdResponses[keyof GetFalAiZImageTurboControlnetRequestsByRequestIdResponses];

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/image-to-image/lora/requests/{request_id}/status";
};

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboImageToImageLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image/lora/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboImageToImageLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiZImageTurboImageToImageLoraRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboImageToImageLoraRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboImageToImageLoraRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboImageToImageLoraData = {
  body: ZImageTurboImageToImageLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image/lora";
};

export type PostFalAiZImageTurboImageToImageLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboImageToImageLoraResponse =
  PostFalAiZImageTurboImageToImageLoraResponses[keyof PostFalAiZImageTurboImageToImageLoraResponses];

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image/lora/requests/{request_id}";
};

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboImageToImageLoraOutput;
};

export type GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdResponse =
  GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdResponses[keyof GetFalAiZImageTurboImageToImageLoraRequestsByRequestIdResponses];

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/image-to-image/requests/{request_id}/status";
};

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiZImageTurboImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboImageToImageData = {
  body: ZImageTurboImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image";
};

export type PostFalAiZImageTurboImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboImageToImageResponse =
  PostFalAiZImageTurboImageToImageResponses[keyof PostFalAiZImageTurboImageToImageResponses];

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/image-to-image/requests/{request_id}";
};

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboImageToImageOutput;
};

export type GetFalAiZImageTurboImageToImageRequestsByRequestIdResponse =
  GetFalAiZImageTurboImageToImageRequestsByRequestIdResponses[keyof GetFalAiZImageTurboImageToImageRequestsByRequestIdResponses];

export type GetFalAiLongcatImageEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/longcat-image/edit/requests/{request_id}/status";
};

export type GetFalAiLongcatImageEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLongcatImageEditRequestsByRequestIdStatusResponse =
  GetFalAiLongcatImageEditRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatImageEditRequestsByRequestIdStatusResponses];

export type PutFalAiLongcatImageEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/longcat-image/edit/requests/{request_id}/cancel";
};

export type PutFalAiLongcatImageEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLongcatImageEditRequestsByRequestIdCancelResponse =
  PutFalAiLongcatImageEditRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatImageEditRequestsByRequestIdCancelResponses];

export type PostFalAiLongcatImageEditData = {
  body: LongcatImageEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/longcat-image/edit";
};

export type PostFalAiLongcatImageEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLongcatImageEditResponse =
  PostFalAiLongcatImageEditResponses[keyof PostFalAiLongcatImageEditResponses];

export type GetFalAiLongcatImageEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/longcat-image/edit/requests/{request_id}";
};

export type GetFalAiLongcatImageEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LongcatImageEditOutput;
};

export type GetFalAiLongcatImageEditRequestsByRequestIdResponse =
  GetFalAiLongcatImageEditRequestsByRequestIdResponses[keyof GetFalAiLongcatImageEditRequestsByRequestIdResponses];

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bytedance/seedream/v4.5/edit/requests/{request_id}/status";
};

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceSeedreamV45EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4.5/edit/requests/{request_id}/cancel";
};

export type PutFalAiBytedanceSeedreamV45EditRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceSeedreamV45EditRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedreamV45EditRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedreamV45EditRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceSeedreamV45EditData = {
  body: BytedanceSeedreamV45EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4.5/edit";
};

export type PostFalAiBytedanceSeedreamV45EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceSeedreamV45EditResponse =
  PostFalAiBytedanceSeedreamV45EditResponses[keyof PostFalAiBytedanceSeedreamV45EditResponses];

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4.5/edit/requests/{request_id}";
};

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BytedanceSeedreamV45EditOutput;
};

export type GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedreamV45EditRequestsByRequestIdResponses];

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vidu/q2/reference-to-image/requests/{request_id}/status";
};

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2ReferenceToImageRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2ReferenceToImageRequestsByRequestIdStatusResponses];

export type PutFalAiViduQ2ReferenceToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/q2/reference-to-image/requests/{request_id}/cancel";
};

export type PutFalAiViduQ2ReferenceToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiViduQ2ReferenceToImageRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2ReferenceToImageRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2ReferenceToImageRequestsByRequestIdCancelResponses];

export type PostFalAiViduQ2ReferenceToImageData = {
  body: ViduQ2ReferenceToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vidu/q2/reference-to-image";
};

export type PostFalAiViduQ2ReferenceToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiViduQ2ReferenceToImageResponse =
  PostFalAiViduQ2ReferenceToImageResponses[keyof PostFalAiViduQ2ReferenceToImageResponses];

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/q2/reference-to-image/requests/{request_id}";
};

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ViduQ2ReferenceToImageOutput;
};

export type GetFalAiViduQ2ReferenceToImageRequestsByRequestIdResponse =
  GetFalAiViduQ2ReferenceToImageRequestsByRequestIdResponses[keyof GetFalAiViduQ2ReferenceToImageRequestsByRequestIdResponses];

export type GetFalAiKlingImageO1RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kling-image/o1/requests/{request_id}/status";
};

export type GetFalAiKlingImageO1RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKlingImageO1RequestsByRequestIdStatusResponse =
  GetFalAiKlingImageO1RequestsByRequestIdStatusResponses[keyof GetFalAiKlingImageO1RequestsByRequestIdStatusResponses];

export type PutFalAiKlingImageO1RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-image/o1/requests/{request_id}/cancel";
};

export type PutFalAiKlingImageO1RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKlingImageO1RequestsByRequestIdCancelResponse =
  PutFalAiKlingImageO1RequestsByRequestIdCancelResponses[keyof PutFalAiKlingImageO1RequestsByRequestIdCancelResponses];

export type PostFalAiKlingImageO1Data = {
  body: KlingImageO1Input;
  path?: never;
  query?: never;
  url: "/fal-ai/kling-image/o1";
};

export type PostFalAiKlingImageO1Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKlingImageO1Response =
  PostFalAiKlingImageO1Responses[keyof PostFalAiKlingImageO1Responses];

export type GetFalAiKlingImageO1RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-image/o1/requests/{request_id}";
};

export type GetFalAiKlingImageO1RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KlingImageO1Output;
};

export type GetFalAiKlingImageO1RequestsByRequestIdResponse =
  GetFalAiKlingImageO1RequestsByRequestIdResponses[keyof GetFalAiKlingImageO1RequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/virtual-tryon/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/virtual-tryon/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryVirtualTryonData = {
  body: Flux2LoraGalleryVirtualTryonInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/virtual-tryon";
};

export type PostFalAiFlux2LoraGalleryVirtualTryonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryVirtualTryonResponse =
  PostFalAiFlux2LoraGalleryVirtualTryonResponses[keyof PostFalAiFlux2LoraGalleryVirtualTryonResponses];

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/virtual-tryon/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraGalleryVirtualTryonOutput;
};

export type GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryVirtualTryonRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/multiple-angles/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/multiple-angles/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryMultipleAnglesData = {
  body: Flux2LoraGalleryMultipleAnglesInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/multiple-angles";
};

export type PostFalAiFlux2LoraGalleryMultipleAnglesResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryMultipleAnglesResponse =
  PostFalAiFlux2LoraGalleryMultipleAnglesResponses[keyof PostFalAiFlux2LoraGalleryMultipleAnglesResponses];

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/multiple-angles/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryMultipleAnglesOutput;
  };

export type GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryMultipleAnglesRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/face-to-full-portrait/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/face-to-full-portrait/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryFaceToFullPortraitData = {
  body: Flux2LoraGalleryFaceToFullPortraitInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/face-to-full-portrait";
};

export type PostFalAiFlux2LoraGalleryFaceToFullPortraitResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryFaceToFullPortraitResponse =
  PostFalAiFlux2LoraGalleryFaceToFullPortraitResponses[keyof PostFalAiFlux2LoraGalleryFaceToFullPortraitResponses];

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/face-to-full-portrait/requests/{request_id}";
  };

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryFaceToFullPortraitOutput;
  };

export type GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryFaceToFullPortraitRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/apartment-staging/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/apartment-staging/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryApartmentStagingData = {
  body: Flux2LoraGalleryApartmentStagingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/apartment-staging";
};

export type PostFalAiFlux2LoraGalleryApartmentStagingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryApartmentStagingResponse =
  PostFalAiFlux2LoraGalleryApartmentStagingResponses[keyof PostFalAiFlux2LoraGalleryApartmentStagingResponses];

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/apartment-staging/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryApartmentStagingOutput;
  };

export type GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryApartmentStagingRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/add-background/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/add-background/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryAddBackgroundData = {
  body: Flux2LoraGalleryAddBackgroundInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/add-background";
};

export type PostFalAiFlux2LoraGalleryAddBackgroundResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryAddBackgroundResponse =
  PostFalAiFlux2LoraGalleryAddBackgroundResponses[keyof PostFalAiFlux2LoraGalleryAddBackgroundResponses];

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/add-background/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryAddBackgroundOutput;
  };

export type GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryAddBackgroundRequestsByRequestIdResponses];

export type GetClarityaiCrystalUpscalerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/clarityai/crystal-upscaler/requests/{request_id}/status";
};

export type GetClarityaiCrystalUpscalerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetClarityaiCrystalUpscalerRequestsByRequestIdStatusResponse =
  GetClarityaiCrystalUpscalerRequestsByRequestIdStatusResponses[keyof GetClarityaiCrystalUpscalerRequestsByRequestIdStatusResponses];

export type PutClarityaiCrystalUpscalerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/clarityai/crystal-upscaler/requests/{request_id}/cancel";
};

export type PutClarityaiCrystalUpscalerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutClarityaiCrystalUpscalerRequestsByRequestIdCancelResponse =
  PutClarityaiCrystalUpscalerRequestsByRequestIdCancelResponses[keyof PutClarityaiCrystalUpscalerRequestsByRequestIdCancelResponses];

export type PostClarityaiCrystalUpscalerData = {
  body: CrystalUpscalerInput;
  path?: never;
  query?: never;
  url: "/clarityai/crystal-upscaler";
};

export type PostClarityaiCrystalUpscalerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostClarityaiCrystalUpscalerResponse =
  PostClarityaiCrystalUpscalerResponses[keyof PostClarityaiCrystalUpscalerResponses];

export type GetClarityaiCrystalUpscalerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/clarityai/crystal-upscaler/requests/{request_id}";
};

export type GetClarityaiCrystalUpscalerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CrystalUpscalerOutput;
};

export type GetClarityaiCrystalUpscalerRequestsByRequestIdResponse =
  GetClarityaiCrystalUpscalerRequestsByRequestIdResponses[keyof GetClarityaiCrystalUpscalerRequestsByRequestIdResponses];

export type GetFalAiFlux2FlexEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-flex/edit/requests/{request_id}/status";
};

export type GetFalAiFlux2FlexEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2FlexEditRequestsByRequestIdStatusResponse =
  GetFalAiFlux2FlexEditRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2FlexEditRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2FlexEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-flex/edit/requests/{request_id}/cancel";
};

export type PutFalAiFlux2FlexEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2FlexEditRequestsByRequestIdCancelResponse =
  PutFalAiFlux2FlexEditRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2FlexEditRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2FlexEditData = {
  body: Flux2FlexEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-flex/edit";
};

export type PostFalAiFlux2FlexEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2FlexEditResponse =
  PostFalAiFlux2FlexEditResponses[keyof PostFalAiFlux2FlexEditResponses];

export type GetFalAiFlux2FlexEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-flex/edit/requests/{request_id}";
};

export type GetFalAiFlux2FlexEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2FlexEditOutput;
};

export type GetFalAiFlux2FlexEditRequestsByRequestIdResponse =
  GetFalAiFlux2FlexEditRequestsByRequestIdResponses[keyof GetFalAiFlux2FlexEditRequestsByRequestIdResponses];

export type GetFalAiChronoEditLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/chrono-edit-lora/requests/{request_id}/status";
};

export type GetFalAiChronoEditLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiChronoEditLoraRequestsByRequestIdStatusResponse =
  GetFalAiChronoEditLoraRequestsByRequestIdStatusResponses[keyof GetFalAiChronoEditLoraRequestsByRequestIdStatusResponses];

export type PutFalAiChronoEditLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit-lora/requests/{request_id}/cancel";
};

export type PutFalAiChronoEditLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiChronoEditLoraRequestsByRequestIdCancelResponse =
  PutFalAiChronoEditLoraRequestsByRequestIdCancelResponses[keyof PutFalAiChronoEditLoraRequestsByRequestIdCancelResponses];

export type PostFalAiChronoEditLoraData = {
  body: ChronoEditLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chrono-edit-lora";
};

export type PostFalAiChronoEditLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChronoEditLoraResponse =
  PostFalAiChronoEditLoraResponses[keyof PostFalAiChronoEditLoraResponses];

export type GetFalAiChronoEditLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit-lora/requests/{request_id}";
};

export type GetFalAiChronoEditLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ChronoEditLoraOutput;
};

export type GetFalAiChronoEditLoraRequestsByRequestIdResponse =
  GetFalAiChronoEditLoraRequestsByRequestIdResponses[keyof GetFalAiChronoEditLoraRequestsByRequestIdResponses];

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/chrono-edit-lora-gallery/paintbrush/requests/{request_id}/status";
  };

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdStatusResponse =
  GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdStatusResponses[keyof GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdStatusResponses];

export type PutFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/chrono-edit-lora-gallery/paintbrush/requests/{request_id}/cancel";
  };

export type PutFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdCancelResponse =
  PutFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdCancelResponses[keyof PutFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdCancelResponses];

export type PostFalAiChronoEditLoraGalleryPaintbrushData = {
  body: ChronoEditLoraGalleryPaintbrushInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chrono-edit-lora-gallery/paintbrush";
};

export type PostFalAiChronoEditLoraGalleryPaintbrushResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChronoEditLoraGalleryPaintbrushResponse =
  PostFalAiChronoEditLoraGalleryPaintbrushResponses[keyof PostFalAiChronoEditLoraGalleryPaintbrushResponses];

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit-lora-gallery/paintbrush/requests/{request_id}";
};

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ChronoEditLoraGalleryPaintbrushOutput;
  };

export type GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdResponse =
  GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdResponses[keyof GetFalAiChronoEditLoraGalleryPaintbrushRequestsByRequestIdResponses];

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/chrono-edit-lora-gallery/upscaler/requests/{request_id}/status";
  };

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdStatusResponse =
  GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdStatusResponses[keyof GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdStatusResponses];

export type PutFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/chrono-edit-lora-gallery/upscaler/requests/{request_id}/cancel";
  };

export type PutFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdCancelResponse =
  PutFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdCancelResponses[keyof PutFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdCancelResponses];

export type PostFalAiChronoEditLoraGalleryUpscalerData = {
  body: ChronoEditLoraGalleryUpscalerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chrono-edit-lora-gallery/upscaler";
};

export type PostFalAiChronoEditLoraGalleryUpscalerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChronoEditLoraGalleryUpscalerResponse =
  PostFalAiChronoEditLoraGalleryUpscalerResponses[keyof PostFalAiChronoEditLoraGalleryUpscalerResponses];

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit-lora-gallery/upscaler/requests/{request_id}";
};

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ChronoEditLoraGalleryUpscalerOutput;
  };

export type GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdResponse =
  GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdResponses[keyof GetFalAiChronoEditLoraGalleryUpscalerRequestsByRequestIdResponses];

export type GetFalAiSam3ImageRleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam-3/image-rle/requests/{request_id}/status";
};

export type GetFalAiSam3ImageRleRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSam3ImageRleRequestsByRequestIdStatusResponse =
  GetFalAiSam3ImageRleRequestsByRequestIdStatusResponses[keyof GetFalAiSam3ImageRleRequestsByRequestIdStatusResponses];

export type PutFalAiSam3ImageRleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-3/image-rle/requests/{request_id}/cancel";
};

export type PutFalAiSam3ImageRleRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSam3ImageRleRequestsByRequestIdCancelResponse =
  PutFalAiSam3ImageRleRequestsByRequestIdCancelResponses[keyof PutFalAiSam3ImageRleRequestsByRequestIdCancelResponses];

export type PostFalAiSam3ImageRleData = {
  body: Sam3ImageRleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam-3/image-rle";
};

export type PostFalAiSam3ImageRleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSam3ImageRleResponse =
  PostFalAiSam3ImageRleResponses[keyof PostFalAiSam3ImageRleResponses];

export type GetFalAiSam3ImageRleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-3/image-rle/requests/{request_id}";
};

export type GetFalAiSam3ImageRleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Sam3ImageRleOutput;
};

export type GetFalAiSam3ImageRleRequestsByRequestIdResponse =
  GetFalAiSam3ImageRleRequestsByRequestIdResponses[keyof GetFalAiSam3ImageRleRequestsByRequestIdResponses];

export type GetFalAiSam3ImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam-3/image/requests/{request_id}/status";
};

export type GetFalAiSam3ImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSam3ImageRequestsByRequestIdStatusResponse =
  GetFalAiSam3ImageRequestsByRequestIdStatusResponses[keyof GetFalAiSam3ImageRequestsByRequestIdStatusResponses];

export type PutFalAiSam3ImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-3/image/requests/{request_id}/cancel";
};

export type PutFalAiSam3ImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSam3ImageRequestsByRequestIdCancelResponse =
  PutFalAiSam3ImageRequestsByRequestIdCancelResponses[keyof PutFalAiSam3ImageRequestsByRequestIdCancelResponses];

export type PostFalAiSam3ImageData = {
  body: Sam3ImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam-3/image";
};

export type PostFalAiSam3ImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSam3ImageResponse =
  PostFalAiSam3ImageResponses[keyof PostFalAiSam3ImageResponses];

export type GetFalAiSam3ImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-3/image/requests/{request_id}";
};

export type GetFalAiSam3ImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Sam3ImageOutput;
};

export type GetFalAiSam3ImageRequestsByRequestIdResponse =
  GetFalAiSam3ImageRequestsByRequestIdResponses[keyof GetFalAiSam3ImageRequestsByRequestIdResponses];

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-3-pro-image-preview/edit/requests/{request_id}/status";
};

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdStatusResponse =
  GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdStatusResponses[keyof GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdStatusResponses];

export type PutFalAiGemini3ProImagePreviewEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview/edit/requests/{request_id}/cancel";
};

export type PutFalAiGemini3ProImagePreviewEditRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiGemini3ProImagePreviewEditRequestsByRequestIdCancelResponse =
  PutFalAiGemini3ProImagePreviewEditRequestsByRequestIdCancelResponses[keyof PutFalAiGemini3ProImagePreviewEditRequestsByRequestIdCancelResponses];

export type PostFalAiGemini3ProImagePreviewEditData = {
  body: Gemini3ProImagePreviewEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview/edit";
};

export type PostFalAiGemini3ProImagePreviewEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGemini3ProImagePreviewEditResponse =
  PostFalAiGemini3ProImagePreviewEditResponses[keyof PostFalAiGemini3ProImagePreviewEditResponses];

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview/edit/requests/{request_id}";
};

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Gemini3ProImagePreviewEditOutput;
};

export type GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdResponse =
  GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdResponses[keyof GetFalAiGemini3ProImagePreviewEditRequestsByRequestIdResponses];

export type GetFalAiNanoBananaProEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nano-banana-pro/edit/requests/{request_id}/status";
};

export type GetFalAiNanoBananaProEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNanoBananaProEditRequestsByRequestIdStatusResponse =
  GetFalAiNanoBananaProEditRequestsByRequestIdStatusResponses[keyof GetFalAiNanoBananaProEditRequestsByRequestIdStatusResponses];

export type PutFalAiNanoBananaProEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana-pro/edit/requests/{request_id}/cancel";
};

export type PutFalAiNanoBananaProEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNanoBananaProEditRequestsByRequestIdCancelResponse =
  PutFalAiNanoBananaProEditRequestsByRequestIdCancelResponses[keyof PutFalAiNanoBananaProEditRequestsByRequestIdCancelResponses];

export type PostFalAiNanoBananaProEditData = {
  body: NanoBananaProEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nano-banana-pro/edit";
};

export type PostFalAiNanoBananaProEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNanoBananaProEditResponse =
  PostFalAiNanoBananaProEditResponses[keyof PostFalAiNanoBananaProEditResponses];

export type GetFalAiNanoBananaProEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana-pro/edit/requests/{request_id}";
};

export type GetFalAiNanoBananaProEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NanoBananaProEditOutput;
};

export type GetFalAiNanoBananaProEditRequestsByRequestIdResponse =
  GetFalAiNanoBananaProEditRequestsByRequestIdResponses[keyof GetFalAiNanoBananaProEditRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/multiple-angles/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/multiple-angles/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryMultipleAnglesData = {
  body: QwenImageEditPlusLoraGalleryMultipleAnglesInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/multiple-angles";
};

export type PostFalAiQwenImageEditPlusLoraGalleryMultipleAnglesResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryMultipleAnglesResponse =
  PostFalAiQwenImageEditPlusLoraGalleryMultipleAnglesResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryMultipleAnglesResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/multiple-angles/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryMultipleAnglesOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryMultipleAnglesRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/shirt-design/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/shirt-design/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryShirtDesignData = {
  body: QwenImageEditPlusLoraGalleryShirtDesignInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/shirt-design";
};

export type PostFalAiQwenImageEditPlusLoraGalleryShirtDesignResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryShirtDesignResponse =
  PostFalAiQwenImageEditPlusLoraGalleryShirtDesignResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryShirtDesignResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/shirt-design/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryShirtDesignOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryShirtDesignRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-lighting/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-lighting/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveLightingData = {
  body: QwenImageEditPlusLoraGalleryRemoveLightingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-lighting";
};

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveLightingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveLightingResponse =
  PostFalAiQwenImageEditPlusLoraGalleryRemoveLightingResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryRemoveLightingResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-lighting/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryRemoveLightingOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryRemoveLightingRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-element/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-element/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveElementData = {
  body: QwenImageEditPlusLoraGalleryRemoveElementInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-element";
};

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveElementResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryRemoveElementResponse =
  PostFalAiQwenImageEditPlusLoraGalleryRemoveElementResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryRemoveElementResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/remove-element/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryRemoveElementOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryRemoveElementRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/next-scene/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/next-scene/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryNextSceneData = {
  body: QwenImageEditPlusLoraGalleryNextSceneInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/next-scene";
};

export type PostFalAiQwenImageEditPlusLoraGalleryNextSceneResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryNextSceneResponse =
  PostFalAiQwenImageEditPlusLoraGalleryNextSceneResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryNextSceneResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/next-scene/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryNextSceneOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryNextSceneRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/integrate-product/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/integrate-product/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryIntegrateProductData = {
  body: QwenImageEditPlusLoraGalleryIntegrateProductInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/integrate-product";
};

export type PostFalAiQwenImageEditPlusLoraGalleryIntegrateProductResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryIntegrateProductResponse =
  PostFalAiQwenImageEditPlusLoraGalleryIntegrateProductResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryIntegrateProductResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/integrate-product/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryIntegrateProductOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryIntegrateProductRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/group-photo/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/group-photo/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryGroupPhotoData = {
  body: QwenImageEditPlusLoraGalleryGroupPhotoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/group-photo";
};

export type PostFalAiQwenImageEditPlusLoraGalleryGroupPhotoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryGroupPhotoResponse =
  PostFalAiQwenImageEditPlusLoraGalleryGroupPhotoResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryGroupPhotoResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/group-photo/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryGroupPhotoOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryGroupPhotoRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/face-to-full-portrait/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/face-to-full-portrait/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitData = {
  body: QwenImageEditPlusLoraGalleryFaceToFullPortraitInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/face-to-full-portrait";
};

export type PostFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitResponse =
  PostFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/face-to-full-portrait/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryFaceToFullPortraitOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryFaceToFullPortraitRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/add-background/requests/{request_id}/status";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/add-background/requests/{request_id}/cancel";
  };

export type PutFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraGalleryAddBackgroundData = {
  body: QwenImageEditPlusLoraGalleryAddBackgroundInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora-gallery/add-background";
};

export type PostFalAiQwenImageEditPlusLoraGalleryAddBackgroundResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraGalleryAddBackgroundResponse =
  PostFalAiQwenImageEditPlusLoraGalleryAddBackgroundResponses[keyof PostFalAiQwenImageEditPlusLoraGalleryAddBackgroundResponses];

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/qwen-image-edit-plus-lora-gallery/add-background/requests/{request_id}";
  };

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: QwenImageEditPlusLoraGalleryAddBackgroundOutput;
  };

export type GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraGalleryAddBackgroundRequestsByRequestIdResponses];

export type GetFalAiReveFastRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/reve/fast/remix/requests/{request_id}/status";
};

export type GetFalAiReveFastRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiReveFastRemixRequestsByRequestIdStatusResponse =
  GetFalAiReveFastRemixRequestsByRequestIdStatusResponses[keyof GetFalAiReveFastRemixRequestsByRequestIdStatusResponses];

export type PutFalAiReveFastRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/fast/remix/requests/{request_id}/cancel";
};

export type PutFalAiReveFastRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiReveFastRemixRequestsByRequestIdCancelResponse =
  PutFalAiReveFastRemixRequestsByRequestIdCancelResponses[keyof PutFalAiReveFastRemixRequestsByRequestIdCancelResponses];

export type PostFalAiReveFastRemixData = {
  body: ReveFastRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/reve/fast/remix";
};

export type PostFalAiReveFastRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiReveFastRemixResponse =
  PostFalAiReveFastRemixResponses[keyof PostFalAiReveFastRemixResponses];

export type GetFalAiReveFastRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/fast/remix/requests/{request_id}";
};

export type GetFalAiReveFastRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReveFastRemixOutput;
};

export type GetFalAiReveFastRemixRequestsByRequestIdResponse =
  GetFalAiReveFastRemixRequestsByRequestIdResponses[keyof GetFalAiReveFastRemixRequestsByRequestIdResponses];

export type GetFalAiReveFastEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/reve/fast/edit/requests/{request_id}/status";
};

export type GetFalAiReveFastEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiReveFastEditRequestsByRequestIdStatusResponse =
  GetFalAiReveFastEditRequestsByRequestIdStatusResponses[keyof GetFalAiReveFastEditRequestsByRequestIdStatusResponses];

export type PutFalAiReveFastEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/fast/edit/requests/{request_id}/cancel";
};

export type PutFalAiReveFastEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiReveFastEditRequestsByRequestIdCancelResponse =
  PutFalAiReveFastEditRequestsByRequestIdCancelResponses[keyof PutFalAiReveFastEditRequestsByRequestIdCancelResponses];

export type PostFalAiReveFastEditData = {
  body: ReveFastEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/reve/fast/edit";
};

export type PostFalAiReveFastEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiReveFastEditResponse =
  PostFalAiReveFastEditResponses[keyof PostFalAiReveFastEditResponses];

export type GetFalAiReveFastEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/fast/edit/requests/{request_id}";
};

export type GetFalAiReveFastEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReveFastEditOutput;
};

export type GetFalAiReveFastEditRequestsByRequestIdResponse =
  GetFalAiReveFastEditRequestsByRequestIdResponses[keyof GetFalAiReveFastEditRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/outpaint/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2OutpaintRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2OutpaintRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2OutpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/outpaint/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2OutpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageAppsV2OutpaintRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2OutpaintRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2OutpaintRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2OutpaintData = {
  body: ImageAppsV2OutpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/outpaint";
};

export type PostFalAiImageAppsV2OutpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2OutpaintResponse =
  PostFalAiImageAppsV2OutpaintResponses[keyof PostFalAiImageAppsV2OutpaintResponses];

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/outpaint/requests/{request_id}";
};

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2OutpaintOutput;
};

export type GetFalAiImageAppsV2OutpaintRequestsByRequestIdResponse =
  GetFalAiImageAppsV2OutpaintRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2OutpaintRequestsByRequestIdResponses];

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-vision-upscaler/requests/{request_id}/status";
};

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdStatusResponse =
  GetFalAiFluxVisionUpscalerRequestsByRequestIdStatusResponses[keyof GetFalAiFluxVisionUpscalerRequestsByRequestIdStatusResponses];

export type PutFalAiFluxVisionUpscalerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-vision-upscaler/requests/{request_id}/cancel";
};

export type PutFalAiFluxVisionUpscalerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxVisionUpscalerRequestsByRequestIdCancelResponse =
  PutFalAiFluxVisionUpscalerRequestsByRequestIdCancelResponses[keyof PutFalAiFluxVisionUpscalerRequestsByRequestIdCancelResponses];

export type PostFalAiFluxVisionUpscalerData = {
  body: FluxVisionUpscalerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-vision-upscaler";
};

export type PostFalAiFluxVisionUpscalerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxVisionUpscalerResponse =
  PostFalAiFluxVisionUpscalerResponses[keyof PostFalAiFluxVisionUpscalerResponses];

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-vision-upscaler/requests/{request_id}";
};

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxVisionUpscalerOutput;
};

export type GetFalAiFluxVisionUpscalerRequestsByRequestIdResponse =
  GetFalAiFluxVisionUpscalerRequestsByRequestIdResponses[keyof GetFalAiFluxVisionUpscalerRequestsByRequestIdResponses];

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/emu-3.5-image/edit-image/requests/{request_id}/status";
};

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdStatusResponse =
  GetFalAiEmu35ImageEditImageRequestsByRequestIdStatusResponses[keyof GetFalAiEmu35ImageEditImageRequestsByRequestIdStatusResponses];

export type PutFalAiEmu35ImageEditImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/emu-3.5-image/edit-image/requests/{request_id}/cancel";
};

export type PutFalAiEmu35ImageEditImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiEmu35ImageEditImageRequestsByRequestIdCancelResponse =
  PutFalAiEmu35ImageEditImageRequestsByRequestIdCancelResponses[keyof PutFalAiEmu35ImageEditImageRequestsByRequestIdCancelResponses];

export type PostFalAiEmu35ImageEditImageData = {
  body: Emu35ImageEditImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/emu-3.5-image/edit-image";
};

export type PostFalAiEmu35ImageEditImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiEmu35ImageEditImageResponse =
  PostFalAiEmu35ImageEditImageResponses[keyof PostFalAiEmu35ImageEditImageResponses];

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/emu-3.5-image/edit-image/requests/{request_id}";
};

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Emu35ImageEditImageOutput;
};

export type GetFalAiEmu35ImageEditImageRequestsByRequestIdResponse =
  GetFalAiEmu35ImageEditImageRequestsByRequestIdResponses[keyof GetFalAiEmu35ImageEditImageRequestsByRequestIdResponses];

export type GetFalAiChronoEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/chrono-edit/requests/{request_id}/status";
};

export type GetFalAiChronoEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiChronoEditRequestsByRequestIdStatusResponse =
  GetFalAiChronoEditRequestsByRequestIdStatusResponses[keyof GetFalAiChronoEditRequestsByRequestIdStatusResponses];

export type PutFalAiChronoEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit/requests/{request_id}/cancel";
};

export type PutFalAiChronoEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiChronoEditRequestsByRequestIdCancelResponse =
  PutFalAiChronoEditRequestsByRequestIdCancelResponses[keyof PutFalAiChronoEditRequestsByRequestIdCancelResponses];

export type PostFalAiChronoEditData = {
  body: ChronoEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chrono-edit";
};

export type PostFalAiChronoEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChronoEditResponse =
  PostFalAiChronoEditResponses[keyof PostFalAiChronoEditResponses];

export type GetFalAiChronoEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chrono-edit/requests/{request_id}";
};

export type GetFalAiChronoEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ChronoEditOutput;
};

export type GetFalAiChronoEditRequestsByRequestIdResponse =
  GetFalAiChronoEditRequestsByRequestIdResponses[keyof GetFalAiChronoEditRequestsByRequestIdResponses];

export type GetFalAiGptImage1MiniEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1-mini/edit/requests/{request_id}/status";
};

export type GetFalAiGptImage1MiniEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage1MiniEditRequestsByRequestIdStatusResponse =
  GetFalAiGptImage1MiniEditRequestsByRequestIdStatusResponses[keyof GetFalAiGptImage1MiniEditRequestsByRequestIdStatusResponses];

export type PutFalAiGptImage1MiniEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1-mini/edit/requests/{request_id}/cancel";
};

export type PutFalAiGptImage1MiniEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage1MiniEditRequestsByRequestIdCancelResponse =
  PutFalAiGptImage1MiniEditRequestsByRequestIdCancelResponses[keyof PutFalAiGptImage1MiniEditRequestsByRequestIdCancelResponses];

export type PostFalAiGptImage1MiniEditData = {
  body: GptImage1MiniEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1-mini/edit";
};

export type PostFalAiGptImage1MiniEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage1MiniEditResponse =
  PostFalAiGptImage1MiniEditResponses[keyof PostFalAiGptImage1MiniEditResponses];

export type GetFalAiGptImage1MiniEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1-mini/edit/requests/{request_id}";
};

export type GetFalAiGptImage1MiniEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage1MiniEditOutput;
};

export type GetFalAiGptImage1MiniEditRequestsByRequestIdResponse =
  GetFalAiGptImage1MiniEditRequestsByRequestIdResponses[keyof GetFalAiGptImage1MiniEditRequestsByRequestIdResponses];

export type GetFalAiReveRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/reve/remix/requests/{request_id}/status";
};

export type GetFalAiReveRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiReveRemixRequestsByRequestIdStatusResponse =
  GetFalAiReveRemixRequestsByRequestIdStatusResponses[keyof GetFalAiReveRemixRequestsByRequestIdStatusResponses];

export type PutFalAiReveRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/remix/requests/{request_id}/cancel";
};

export type PutFalAiReveRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiReveRemixRequestsByRequestIdCancelResponse =
  PutFalAiReveRemixRequestsByRequestIdCancelResponses[keyof PutFalAiReveRemixRequestsByRequestIdCancelResponses];

export type PostFalAiReveRemixData = {
  body: ReveRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/reve/remix";
};

export type PostFalAiReveRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiReveRemixResponse =
  PostFalAiReveRemixResponses[keyof PostFalAiReveRemixResponses];

export type GetFalAiReveRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/remix/requests/{request_id}";
};

export type GetFalAiReveRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReveRemixOutput;
};

export type GetFalAiReveRemixRequestsByRequestIdResponse =
  GetFalAiReveRemixRequestsByRequestIdResponses[keyof GetFalAiReveRemixRequestsByRequestIdResponses];

export type GetFalAiReveEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/reve/edit/requests/{request_id}/status";
};

export type GetFalAiReveEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiReveEditRequestsByRequestIdStatusResponse =
  GetFalAiReveEditRequestsByRequestIdStatusResponses[keyof GetFalAiReveEditRequestsByRequestIdStatusResponses];

export type PutFalAiReveEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/edit/requests/{request_id}/cancel";
};

export type PutFalAiReveEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiReveEditRequestsByRequestIdCancelResponse =
  PutFalAiReveEditRequestsByRequestIdCancelResponses[keyof PutFalAiReveEditRequestsByRequestIdCancelResponses];

export type PostFalAiReveEditData = {
  body: ReveEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/reve/edit";
};

export type PostFalAiReveEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiReveEditResponse =
  PostFalAiReveEditResponses[keyof PostFalAiReveEditResponses];

export type GetFalAiReveEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/edit/requests/{request_id}";
};

export type GetFalAiReveEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReveEditOutput;
};

export type GetFalAiReveEditRequestsByRequestIdResponse =
  GetFalAiReveEditRequestsByRequestIdResponses[keyof GetFalAiReveEditRequestsByRequestIdResponses];

export type GetFalAiImage2PixelRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image2pixel/requests/{request_id}/status";
};

export type GetFalAiImage2PixelRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImage2PixelRequestsByRequestIdStatusResponse =
  GetFalAiImage2PixelRequestsByRequestIdStatusResponses[keyof GetFalAiImage2PixelRequestsByRequestIdStatusResponses];

export type PutFalAiImage2PixelRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image2pixel/requests/{request_id}/cancel";
};

export type PutFalAiImage2PixelRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImage2PixelRequestsByRequestIdCancelResponse =
  PutFalAiImage2PixelRequestsByRequestIdCancelResponses[keyof PutFalAiImage2PixelRequestsByRequestIdCancelResponses];

export type PostFalAiImage2PixelData = {
  body: Image2PixelInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image2pixel";
};

export type PostFalAiImage2PixelResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImage2PixelResponse =
  PostFalAiImage2PixelResponses[keyof PostFalAiImage2PixelResponses];

export type GetFalAiImage2PixelRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image2pixel/requests/{request_id}";
};

export type GetFalAiImage2PixelRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Image2PixelOutput;
};

export type GetFalAiImage2PixelRequestsByRequestIdResponse =
  GetFalAiImage2PixelRequestsByRequestIdResponses[keyof GetFalAiImage2PixelRequestsByRequestIdResponses];

export type GetFalAiDreamomni2EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dreamomni2/edit/requests/{request_id}/status";
};

export type GetFalAiDreamomni2EditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDreamomni2EditRequestsByRequestIdStatusResponse =
  GetFalAiDreamomni2EditRequestsByRequestIdStatusResponses[keyof GetFalAiDreamomni2EditRequestsByRequestIdStatusResponses];

export type PutFalAiDreamomni2EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamomni2/edit/requests/{request_id}/cancel";
};

export type PutFalAiDreamomni2EditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDreamomni2EditRequestsByRequestIdCancelResponse =
  PutFalAiDreamomni2EditRequestsByRequestIdCancelResponses[keyof PutFalAiDreamomni2EditRequestsByRequestIdCancelResponses];

export type PostFalAiDreamomni2EditData = {
  body: Dreamomni2EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dreamomni2/edit";
};

export type PostFalAiDreamomni2EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDreamomni2EditResponse =
  PostFalAiDreamomni2EditResponses[keyof PostFalAiDreamomni2EditResponses];

export type GetFalAiDreamomni2EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamomni2/edit/requests/{request_id}";
};

export type GetFalAiDreamomni2EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Dreamomni2EditOutput;
};

export type GetFalAiDreamomni2EditRequestsByRequestIdResponse =
  GetFalAiDreamomni2EditRequestsByRequestIdResponses[keyof GetFalAiDreamomni2EditRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-plus-lora/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusLoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusLoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditPlusLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEditPlusLoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusLoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusLoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusLoraData = {
  body: QwenImageEditPlusLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora";
};

export type PostFalAiQwenImageEditPlusLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusLoraResponse =
  PostFalAiQwenImageEditPlusLoraResponses[keyof PostFalAiQwenImageEditPlusLoraResponses];

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus-lora/requests/{request_id}";
};

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditPlusLoraOutput;
};

export type GetFalAiQwenImageEditPlusLoraRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusLoraRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusLoraRequestsByRequestIdResponses];

export type GetFalAiLucidfluxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lucidflux/requests/{request_id}/status";
};

export type GetFalAiLucidfluxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLucidfluxRequestsByRequestIdStatusResponse =
  GetFalAiLucidfluxRequestsByRequestIdStatusResponses[keyof GetFalAiLucidfluxRequestsByRequestIdStatusResponses];

export type PutFalAiLucidfluxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lucidflux/requests/{request_id}/cancel";
};

export type PutFalAiLucidfluxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLucidfluxRequestsByRequestIdCancelResponse =
  PutFalAiLucidfluxRequestsByRequestIdCancelResponses[keyof PutFalAiLucidfluxRequestsByRequestIdCancelResponses];

export type PostFalAiLucidfluxData = {
  body: LucidfluxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lucidflux";
};

export type PostFalAiLucidfluxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLucidfluxResponse =
  PostFalAiLucidfluxResponses[keyof PostFalAiLucidfluxResponses];

export type GetFalAiLucidfluxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lucidflux/requests/{request_id}";
};

export type GetFalAiLucidfluxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LucidfluxOutput;
};

export type GetFalAiLucidfluxRequestsByRequestIdResponse =
  GetFalAiLucidfluxRequestsByRequestIdResponses[keyof GetFalAiLucidfluxRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit/image-to-image/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageEditImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditImageToImageData = {
  body: QwenImageEditImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit/image-to-image";
};

export type PostFalAiQwenImageEditImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditImageToImageResponse =
  PostFalAiQwenImageEditImageToImageResponses[keyof PostFalAiQwenImageEditImageToImageResponses];

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/image-to-image/requests/{request_id}";
};

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditImageToImageOutput;
};

export type GetFalAiQwenImageEditImageToImageRequestsByRequestIdResponse =
  GetFalAiQwenImageEditImageToImageRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditImageToImageRequestsByRequestIdResponses];

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan-25-preview/image-to-image/requests/{request_id}/status";
};

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiWan25PreviewImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiWan25PreviewImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiWan25PreviewImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan-25-preview/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiWan25PreviewImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiWan25PreviewImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiWan25PreviewImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiWan25PreviewImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiWan25PreviewImageToImageData = {
  body: Wan25PreviewImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan-25-preview/image-to-image";
};

export type PostFalAiWan25PreviewImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWan25PreviewImageToImageResponse =
  PostFalAiWan25PreviewImageToImageResponses[keyof PostFalAiWan25PreviewImageToImageResponses];

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan-25-preview/image-to-image/requests/{request_id}";
};

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Wan25PreviewImageToImageOutput;
};

export type GetFalAiWan25PreviewImageToImageRequestsByRequestIdResponse =
  GetFalAiWan25PreviewImageToImageRequestsByRequestIdResponses[keyof GetFalAiWan25PreviewImageToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditPlusRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-plus/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditPlusRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEditPlusRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditPlusRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditPlusRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditPlusRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditPlusRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEditPlusRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditPlusRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditPlusRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditPlusData = {
  body: QwenImageEditPlusInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus";
};

export type PostFalAiQwenImageEditPlusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditPlusResponse =
  PostFalAiQwenImageEditPlusResponses[keyof PostFalAiQwenImageEditPlusResponses];

export type GetFalAiQwenImageEditPlusRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-plus/requests/{request_id}";
};

export type GetFalAiQwenImageEditPlusRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditPlusOutput;
};

export type GetFalAiQwenImageEditPlusRequestsByRequestIdResponse =
  GetFalAiQwenImageEditPlusRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditPlusRequestsByRequestIdResponses];

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/seedvr/upscale/image/requests/{request_id}/status";
};

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdStatusResponse =
  GetFalAiSeedvrUpscaleImageRequestsByRequestIdStatusResponses[keyof GetFalAiSeedvrUpscaleImageRequestsByRequestIdStatusResponses];

export type PutFalAiSeedvrUpscaleImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/seedvr/upscale/image/requests/{request_id}/cancel";
};

export type PutFalAiSeedvrUpscaleImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSeedvrUpscaleImageRequestsByRequestIdCancelResponse =
  PutFalAiSeedvrUpscaleImageRequestsByRequestIdCancelResponses[keyof PutFalAiSeedvrUpscaleImageRequestsByRequestIdCancelResponses];

export type PostFalAiSeedvrUpscaleImageData = {
  body: SeedvrUpscaleImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/seedvr/upscale/image";
};

export type PostFalAiSeedvrUpscaleImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSeedvrUpscaleImageResponse =
  PostFalAiSeedvrUpscaleImageResponses[keyof PostFalAiSeedvrUpscaleImageResponses];

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/seedvr/upscale/image/requests/{request_id}";
};

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SeedvrUpscaleImageOutput;
};

export type GetFalAiSeedvrUpscaleImageRequestsByRequestIdResponse =
  GetFalAiSeedvrUpscaleImageRequestsByRequestIdResponses[keyof GetFalAiSeedvrUpscaleImageRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/product-holding/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2ProductHoldingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/product-holding/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2ProductHoldingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2ProductHoldingRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2ProductHoldingRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2ProductHoldingRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2ProductHoldingData = {
  body: ImageAppsV2ProductHoldingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/product-holding";
};

export type PostFalAiImageAppsV2ProductHoldingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2ProductHoldingResponse =
  PostFalAiImageAppsV2ProductHoldingResponses[keyof PostFalAiImageAppsV2ProductHoldingResponses];

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/product-holding/requests/{request_id}";
};

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2ProductHoldingOutput;
};

export type GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdResponse =
  GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2ProductHoldingRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-apps-v2/product-photography/requests/{request_id}/status";
  };

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2ProductPhotographyRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-apps-v2/product-photography/requests/{request_id}/cancel";
  };

export type PutFalAiImageAppsV2ProductPhotographyRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2ProductPhotographyRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2ProductPhotographyRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2ProductPhotographyRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2ProductPhotographyData = {
  body: ImageAppsV2ProductPhotographyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/product-photography";
};

export type PostFalAiImageAppsV2ProductPhotographyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2ProductPhotographyResponse =
  PostFalAiImageAppsV2ProductPhotographyResponses[keyof PostFalAiImageAppsV2ProductPhotographyResponses];

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/product-photography/requests/{request_id}";
};

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ImageAppsV2ProductPhotographyOutput;
  };

export type GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdResponse =
  GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2ProductPhotographyRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/virtual-try-on/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2VirtualTryOnRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/virtual-try-on/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2VirtualTryOnRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2VirtualTryOnRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2VirtualTryOnRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2VirtualTryOnRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2VirtualTryOnData = {
  body: ImageAppsV2VirtualTryOnInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/virtual-try-on";
};

export type PostFalAiImageAppsV2VirtualTryOnResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2VirtualTryOnResponse =
  PostFalAiImageAppsV2VirtualTryOnResponses[keyof PostFalAiImageAppsV2VirtualTryOnResponses];

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/virtual-try-on/requests/{request_id}";
};

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2VirtualTryOnOutput;
};

export type GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdResponse =
  GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2VirtualTryOnRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/texture-transform/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2TextureTransformRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2TextureTransformRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2TextureTransformRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/texture-transform/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2TextureTransformRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2TextureTransformRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2TextureTransformRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2TextureTransformRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2TextureTransformData = {
  body: ImageAppsV2TextureTransformInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/texture-transform";
};

export type PostFalAiImageAppsV2TextureTransformResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2TextureTransformResponse =
  PostFalAiImageAppsV2TextureTransformResponses[keyof PostFalAiImageAppsV2TextureTransformResponses];

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/texture-transform/requests/{request_id}";
};

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2TextureTransformOutput;
};

export type GetFalAiImageAppsV2TextureTransformRequestsByRequestIdResponse =
  GetFalAiImageAppsV2TextureTransformRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2TextureTransformRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/relighting/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2RelightingRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2RelightingRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2RelightingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/relighting/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2RelightingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageAppsV2RelightingRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2RelightingRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2RelightingRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2RelightingData = {
  body: ImageAppsV2RelightingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/relighting";
};

export type PostFalAiImageAppsV2RelightingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2RelightingResponse =
  PostFalAiImageAppsV2RelightingResponses[keyof PostFalAiImageAppsV2RelightingResponses];

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/relighting/requests/{request_id}";
};

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2RelightingOutput;
};

export type GetFalAiImageAppsV2RelightingRequestsByRequestIdResponse =
  GetFalAiImageAppsV2RelightingRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2RelightingRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/style-transfer/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2StyleTransferRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2StyleTransferRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2StyleTransferRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/style-transfer/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2StyleTransferRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2StyleTransferRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2StyleTransferRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2StyleTransferRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2StyleTransferData = {
  body: ImageAppsV2StyleTransferInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/style-transfer";
};

export type PostFalAiImageAppsV2StyleTransferResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2StyleTransferResponse =
  PostFalAiImageAppsV2StyleTransferResponses[keyof PostFalAiImageAppsV2StyleTransferResponses];

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/style-transfer/requests/{request_id}";
};

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2StyleTransferOutput;
};

export type GetFalAiImageAppsV2StyleTransferRequestsByRequestIdResponse =
  GetFalAiImageAppsV2StyleTransferRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2StyleTransferRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/photo-restoration/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2PhotoRestorationRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/photo-restoration/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2PhotoRestorationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2PhotoRestorationRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2PhotoRestorationRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2PhotoRestorationRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2PhotoRestorationData = {
  body: ImageAppsV2PhotoRestorationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/photo-restoration";
};

export type PostFalAiImageAppsV2PhotoRestorationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2PhotoRestorationResponse =
  PostFalAiImageAppsV2PhotoRestorationResponses[keyof PostFalAiImageAppsV2PhotoRestorationResponses];

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/photo-restoration/requests/{request_id}";
};

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2PhotoRestorationOutput;
};

export type GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdResponse =
  GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2PhotoRestorationRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/portrait-enhance/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/portrait-enhance/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2PortraitEnhanceData = {
  body: ImageAppsV2PortraitEnhanceInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/portrait-enhance";
};

export type PostFalAiImageAppsV2PortraitEnhanceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2PortraitEnhanceResponse =
  PostFalAiImageAppsV2PortraitEnhanceResponses[keyof PostFalAiImageAppsV2PortraitEnhanceResponses];

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/portrait-enhance/requests/{request_id}";
};

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2PortraitEnhanceOutput;
};

export type GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdResponse =
  GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2PortraitEnhanceRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-apps-v2/photography-effects/requests/{request_id}/status";
  };

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-apps-v2/photography-effects/requests/{request_id}/cancel";
  };

export type PutFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2PhotographyEffectsData = {
  body: ImageAppsV2PhotographyEffectsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/photography-effects";
};

export type PostFalAiImageAppsV2PhotographyEffectsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2PhotographyEffectsResponse =
  PostFalAiImageAppsV2PhotographyEffectsResponses[keyof PostFalAiImageAppsV2PhotographyEffectsResponses];

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/photography-effects/requests/{request_id}";
};

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ImageAppsV2PhotographyEffectsOutput;
  };

export type GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdResponse =
  GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2PhotographyEffectsRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/perspective/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2PerspectiveRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2PerspectiveRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2PerspectiveRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/perspective/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2PerspectiveRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageAppsV2PerspectiveRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2PerspectiveRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2PerspectiveRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2PerspectiveData = {
  body: ImageAppsV2PerspectiveInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/perspective";
};

export type PostFalAiImageAppsV2PerspectiveResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2PerspectiveResponse =
  PostFalAiImageAppsV2PerspectiveResponses[keyof PostFalAiImageAppsV2PerspectiveResponses];

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/perspective/requests/{request_id}";
};

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2PerspectiveOutput;
};

export type GetFalAiImageAppsV2PerspectiveRequestsByRequestIdResponse =
  GetFalAiImageAppsV2PerspectiveRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2PerspectiveRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/object-removal/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2ObjectRemovalRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/object-removal/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2ObjectRemovalRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2ObjectRemovalRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2ObjectRemovalRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2ObjectRemovalRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2ObjectRemovalData = {
  body: ImageAppsV2ObjectRemovalInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/object-removal";
};

export type PostFalAiImageAppsV2ObjectRemovalResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2ObjectRemovalResponse =
  PostFalAiImageAppsV2ObjectRemovalResponses[keyof PostFalAiImageAppsV2ObjectRemovalResponses];

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/object-removal/requests/{request_id}";
};

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2ObjectRemovalOutput;
};

export type GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdResponse =
  GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2ObjectRemovalRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/headshot-photo/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/headshot-photo/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2HeadshotPhotoData = {
  body: ImageAppsV2HeadshotPhotoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/headshot-photo";
};

export type PostFalAiImageAppsV2HeadshotPhotoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2HeadshotPhotoResponse =
  PostFalAiImageAppsV2HeadshotPhotoResponses[keyof PostFalAiImageAppsV2HeadshotPhotoResponses];

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/headshot-photo/requests/{request_id}";
};

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2HeadshotPhotoOutput;
};

export type GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdResponse =
  GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2HeadshotPhotoRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/hair-change/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2HairChangeRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2HairChangeRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2HairChangeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/hair-change/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2HairChangeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageAppsV2HairChangeRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2HairChangeRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2HairChangeRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2HairChangeData = {
  body: ImageAppsV2HairChangeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/hair-change";
};

export type PostFalAiImageAppsV2HairChangeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2HairChangeResponse =
  PostFalAiImageAppsV2HairChangeResponses[keyof PostFalAiImageAppsV2HairChangeResponses];

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/hair-change/requests/{request_id}";
};

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2HairChangeOutput;
};

export type GetFalAiImageAppsV2HairChangeRequestsByRequestIdResponse =
  GetFalAiImageAppsV2HairChangeRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2HairChangeRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/expression-change/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2ExpressionChangeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/expression-change/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2ExpressionChangeRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2ExpressionChangeRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2ExpressionChangeRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2ExpressionChangeRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2ExpressionChangeData = {
  body: ImageAppsV2ExpressionChangeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/expression-change";
};

export type PostFalAiImageAppsV2ExpressionChangeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2ExpressionChangeResponse =
  PostFalAiImageAppsV2ExpressionChangeResponses[keyof PostFalAiImageAppsV2ExpressionChangeResponses];

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/expression-change/requests/{request_id}";
};

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2ExpressionChangeOutput;
};

export type GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdResponse =
  GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2ExpressionChangeRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/city-teleport/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2CityTeleportRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2CityTeleportRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2CityTeleportRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/city-teleport/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2CityTeleportRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2CityTeleportRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2CityTeleportRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2CityTeleportRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2CityTeleportData = {
  body: ImageAppsV2CityTeleportInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/city-teleport";
};

export type PostFalAiImageAppsV2CityTeleportResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2CityTeleportResponse =
  PostFalAiImageAppsV2CityTeleportResponses[keyof PostFalAiImageAppsV2CityTeleportResponses];

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/city-teleport/requests/{request_id}";
};

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2CityTeleportOutput;
};

export type GetFalAiImageAppsV2CityTeleportRequestsByRequestIdResponse =
  GetFalAiImageAppsV2CityTeleportRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2CityTeleportRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-apps-v2/age-modify/requests/{request_id}/status";
};

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2AgeModifyRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2AgeModifyRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2AgeModifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/age-modify/requests/{request_id}/cancel";
};

export type PutFalAiImageAppsV2AgeModifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageAppsV2AgeModifyRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2AgeModifyRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2AgeModifyRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2AgeModifyData = {
  body: ImageAppsV2AgeModifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/age-modify";
};

export type PostFalAiImageAppsV2AgeModifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2AgeModifyResponse =
  PostFalAiImageAppsV2AgeModifyResponses[keyof PostFalAiImageAppsV2AgeModifyResponses];

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/age-modify/requests/{request_id}";
};

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2AgeModifyOutput;
};

export type GetFalAiImageAppsV2AgeModifyRequestsByRequestIdResponse =
  GetFalAiImageAppsV2AgeModifyRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2AgeModifyRequestsByRequestIdResponses];

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-apps-v2/makeup-application/requests/{request_id}/status";
  };

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdStatusResponse =
  GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdStatusResponses[keyof GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdStatusResponses];

export type PutFalAiImageAppsV2MakeupApplicationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-apps-v2/makeup-application/requests/{request_id}/cancel";
  };

export type PutFalAiImageAppsV2MakeupApplicationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageAppsV2MakeupApplicationRequestsByRequestIdCancelResponse =
  PutFalAiImageAppsV2MakeupApplicationRequestsByRequestIdCancelResponses[keyof PutFalAiImageAppsV2MakeupApplicationRequestsByRequestIdCancelResponses];

export type PostFalAiImageAppsV2MakeupApplicationData = {
  body: ImageAppsV2MakeupApplicationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-apps-v2/makeup-application";
};

export type PostFalAiImageAppsV2MakeupApplicationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageAppsV2MakeupApplicationResponse =
  PostFalAiImageAppsV2MakeupApplicationResponses[keyof PostFalAiImageAppsV2MakeupApplicationResponses];

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-apps-v2/makeup-application/requests/{request_id}";
};

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageAppsV2MakeupApplicationOutput;
};

export type GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdResponse =
  GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdResponses[keyof GetFalAiImageAppsV2MakeupApplicationRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit/inpaint/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEditInpaintRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditInpaintData = {
  body: QwenImageEditInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit/inpaint";
};

export type PostFalAiQwenImageEditInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditInpaintResponse =
  PostFalAiQwenImageEditInpaintResponses[keyof PostFalAiQwenImageEditInpaintResponses];

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/inpaint/requests/{request_id}";
};

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditInpaintOutput;
};

export type GetFalAiQwenImageEditInpaintRequestsByRequestIdResponse =
  GetFalAiQwenImageEditInpaintRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditInpaintRequestsByRequestIdResponses];

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/srpo/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxSrpoImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxSrpoImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxSrpoImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/srpo/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxSrpoImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxSrpoImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxSrpoImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxSrpoImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxSrpoImageToImageData = {
  body: FluxSrpoImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/srpo/image-to-image";
};

export type PostFalAiFluxSrpoImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxSrpoImageToImageResponse =
  PostFalAiFluxSrpoImageToImageResponses[keyof PostFalAiFluxSrpoImageToImageResponses];

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/srpo/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxSrpoImageToImageOutput;
};

export type GetFalAiFluxSrpoImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxSrpoImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxSrpoImageToImageRequestsByRequestIdResponses];

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/srpo/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFlux1SrpoImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1SrpoImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1SrpoImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/srpo/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFlux1SrpoImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1SrpoImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFlux1SrpoImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1SrpoImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1SrpoImageToImageData = {
  body: Flux1SrpoImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/srpo/image-to-image";
};

export type PostFalAiFlux1SrpoImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1SrpoImageToImageResponse =
  PostFalAiFlux1SrpoImageToImageResponses[keyof PostFalAiFlux1SrpoImageToImageResponses];

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/srpo/image-to-image/requests/{request_id}";
};

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1SrpoImageToImageOutput;
};

export type GetFalAiFlux1SrpoImageToImageRequestsByRequestIdResponse =
  GetFalAiFlux1SrpoImageToImageRequestsByRequestIdResponses[keyof GetFalAiFlux1SrpoImageToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageEditLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit-lora/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEditLoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditLoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditLoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEditLoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditLoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditLoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditLoraData = {
  body: QwenImageEditLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit-lora";
};

export type PostFalAiQwenImageEditLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditLoraResponse =
  PostFalAiQwenImageEditLoraResponses[keyof PostFalAiQwenImageEditLoraResponses];

export type GetFalAiQwenImageEditLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit-lora/requests/{request_id}";
};

export type GetFalAiQwenImageEditLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditLoraOutput;
};

export type GetFalAiQwenImageEditLoraRequestsByRequestIdResponse =
  GetFalAiQwenImageEditLoraRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditLoraRequestsByRequestIdResponses];

export type GetFalAiViduReferenceToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vidu/reference-to-image/requests/{request_id}/status";
};

export type GetFalAiViduReferenceToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiViduReferenceToImageRequestsByRequestIdStatusResponse =
  GetFalAiViduReferenceToImageRequestsByRequestIdStatusResponses[keyof GetFalAiViduReferenceToImageRequestsByRequestIdStatusResponses];

export type PutFalAiViduReferenceToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/reference-to-image/requests/{request_id}/cancel";
};

export type PutFalAiViduReferenceToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiViduReferenceToImageRequestsByRequestIdCancelResponse =
  PutFalAiViduReferenceToImageRequestsByRequestIdCancelResponses[keyof PutFalAiViduReferenceToImageRequestsByRequestIdCancelResponses];

export type PostFalAiViduReferenceToImageData = {
  body: ViduReferenceToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vidu/reference-to-image";
};

export type PostFalAiViduReferenceToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiViduReferenceToImageResponse =
  PostFalAiViduReferenceToImageResponses[keyof PostFalAiViduReferenceToImageResponses];

export type GetFalAiViduReferenceToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/reference-to-image/requests/{request_id}";
};

export type GetFalAiViduReferenceToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ViduReferenceToImageOutput;
};

export type GetFalAiViduReferenceToImageRequestsByRequestIdResponse =
  GetFalAiViduReferenceToImageRequestsByRequestIdResponses[keyof GetFalAiViduReferenceToImageRequestsByRequestIdResponses];

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bytedance/seedream/v4/edit/requests/{request_id}/status";
};

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceSeedreamV4EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4/edit/requests/{request_id}/cancel";
};

export type PutFalAiBytedanceSeedreamV4EditRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceSeedreamV4EditRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedreamV4EditRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedreamV4EditRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceSeedreamV4EditData = {
  body: BytedanceSeedreamV4EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4/edit";
};

export type PostFalAiBytedanceSeedreamV4EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceSeedreamV4EditResponse =
  PostFalAiBytedanceSeedreamV4EditResponses[keyof PostFalAiBytedanceSeedreamV4EditResponses];

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4/edit/requests/{request_id}";
};

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BytedanceSeedreamV4EditOutput;
};

export type GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedreamV4EditRequestsByRequestIdResponses];

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan/v2.2-a14b/image-to-image/requests/{request_id}/status";
};

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiWanV22A14bImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiWanV22A14bImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiWanV22A14bImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiWanV22A14bImageToImageData = {
  body: WanV22A14bImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/image-to-image";
};

export type PostFalAiWanV22A14bImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWanV22A14bImageToImageResponse =
  PostFalAiWanV22A14bImageToImageResponses[keyof PostFalAiWanV22A14bImageToImageResponses];

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/image-to-image/requests/{request_id}";
};

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: WanV22A14bImageToImageOutput;
};

export type GetFalAiWanV22A14bImageToImageRequestsByRequestIdResponse =
  GetFalAiWanV22A14bImageToImageRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bImageToImageRequestsByRequestIdResponses];

export type GetFalAiUsoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/uso/requests/{request_id}/status";
};

export type GetFalAiUsoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiUsoRequestsByRequestIdStatusResponse =
  GetFalAiUsoRequestsByRequestIdStatusResponses[keyof GetFalAiUsoRequestsByRequestIdStatusResponses];

export type PutFalAiUsoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/uso/requests/{request_id}/cancel";
};

export type PutFalAiUsoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiUsoRequestsByRequestIdCancelResponse =
  PutFalAiUsoRequestsByRequestIdCancelResponses[keyof PutFalAiUsoRequestsByRequestIdCancelResponses];

export type PostFalAiUsoData = {
  body: UsoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/uso";
};

export type PostFalAiUsoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiUsoResponse =
  PostFalAiUsoResponses[keyof PostFalAiUsoResponses];

export type GetFalAiUsoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/uso/requests/{request_id}";
};

export type GetFalAiUsoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: UsoOutput;
};

export type GetFalAiUsoRequestsByRequestIdResponse =
  GetFalAiUsoRequestsByRequestIdResponses[keyof GetFalAiUsoRequestsByRequestIdResponses];

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-25-flash-image/edit/requests/{request_id}/status";
};

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdStatusResponse =
  GetFalAiGemini25FlashImageEditRequestsByRequestIdStatusResponses[keyof GetFalAiGemini25FlashImageEditRequestsByRequestIdStatusResponses];

export type PutFalAiGemini25FlashImageEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-25-flash-image/edit/requests/{request_id}/cancel";
};

export type PutFalAiGemini25FlashImageEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGemini25FlashImageEditRequestsByRequestIdCancelResponse =
  PutFalAiGemini25FlashImageEditRequestsByRequestIdCancelResponses[keyof PutFalAiGemini25FlashImageEditRequestsByRequestIdCancelResponses];

export type PostFalAiGemini25FlashImageEditData = {
  body: Gemini25FlashImageEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-25-flash-image/edit";
};

export type PostFalAiGemini25FlashImageEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGemini25FlashImageEditResponse =
  PostFalAiGemini25FlashImageEditResponses[keyof PostFalAiGemini25FlashImageEditResponses];

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-25-flash-image/edit/requests/{request_id}";
};

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Gemini25FlashImageEditOutput;
};

export type GetFalAiGemini25FlashImageEditRequestsByRequestIdResponse =
  GetFalAiGemini25FlashImageEditRequestsByRequestIdResponses[keyof GetFalAiGemini25FlashImageEditRequestsByRequestIdResponses];

export type GetFalAiQwenImageImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image/image-to-image/requests/{request_id}/status";
};

export type GetFalAiQwenImageImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageImageToImageData = {
  body: QwenImageImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image/image-to-image";
};

export type PostFalAiQwenImageImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageImageToImageResponse =
  PostFalAiQwenImageImageToImageResponses[keyof PostFalAiQwenImageImageToImageResponses];

export type GetFalAiQwenImageImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image/image-to-image/requests/{request_id}";
};

export type GetFalAiQwenImageImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageImageToImageOutput;
};

export type GetFalAiQwenImageImageToImageRequestsByRequestIdResponse =
  GetFalAiQwenImageImageToImageRequestsByRequestIdResponses[keyof GetFalAiQwenImageImageToImageRequestsByRequestIdResponses];

export type GetBriaReimagine32RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/reimagine/3.2/requests/{request_id}/status";
};

export type GetBriaReimagine32RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaReimagine32RequestsByRequestIdStatusResponse =
  GetBriaReimagine32RequestsByRequestIdStatusResponses[keyof GetBriaReimagine32RequestsByRequestIdStatusResponses];

export type PutBriaReimagine32RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/reimagine/3.2/requests/{request_id}/cancel";
};

export type PutBriaReimagine32RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaReimagine32RequestsByRequestIdCancelResponse =
  PutBriaReimagine32RequestsByRequestIdCancelResponses[keyof PutBriaReimagine32RequestsByRequestIdCancelResponses];

export type PostBriaReimagine32Data = {
  body: Reimagine32Input;
  path?: never;
  query?: never;
  url: "/bria/reimagine/3.2";
};

export type PostBriaReimagine32Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaReimagine32Response =
  PostBriaReimagine32Responses[keyof PostBriaReimagine32Responses];

export type GetBriaReimagine32RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/reimagine/3.2/requests/{request_id}";
};

export type GetBriaReimagine32RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Reimagine32Output;
};

export type GetBriaReimagine32RequestsByRequestIdResponse =
  GetBriaReimagine32RequestsByRequestIdResponses[keyof GetBriaReimagine32RequestsByRequestIdResponses];

export type GetFalAiNanoBananaEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nano-banana/edit/requests/{request_id}/status";
};

export type GetFalAiNanoBananaEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNanoBananaEditRequestsByRequestIdStatusResponse =
  GetFalAiNanoBananaEditRequestsByRequestIdStatusResponses[keyof GetFalAiNanoBananaEditRequestsByRequestIdStatusResponses];

export type PutFalAiNanoBananaEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana/edit/requests/{request_id}/cancel";
};

export type PutFalAiNanoBananaEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNanoBananaEditRequestsByRequestIdCancelResponse =
  PutFalAiNanoBananaEditRequestsByRequestIdCancelResponses[keyof PutFalAiNanoBananaEditRequestsByRequestIdCancelResponses];

export type PostFalAiNanoBananaEditData = {
  body: NanoBananaEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nano-banana/edit";
};

export type PostFalAiNanoBananaEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNanoBananaEditResponse =
  PostFalAiNanoBananaEditResponses[keyof PostFalAiNanoBananaEditResponses];

export type GetFalAiNanoBananaEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana/edit/requests/{request_id}";
};

export type GetFalAiNanoBananaEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NanoBananaEditOutput;
};

export type GetFalAiNanoBananaEditRequestsByRequestIdResponse =
  GetFalAiNanoBananaEditRequestsByRequestIdResponses[keyof GetFalAiNanoBananaEditRequestsByRequestIdResponses];

export type GetFalAiNextstep1RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nextstep-1/requests/{request_id}/status";
};

export type GetFalAiNextstep1RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNextstep1RequestsByRequestIdStatusResponse =
  GetFalAiNextstep1RequestsByRequestIdStatusResponses[keyof GetFalAiNextstep1RequestsByRequestIdStatusResponses];

export type PutFalAiNextstep1RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nextstep-1/requests/{request_id}/cancel";
};

export type PutFalAiNextstep1RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNextstep1RequestsByRequestIdCancelResponse =
  PutFalAiNextstep1RequestsByRequestIdCancelResponses[keyof PutFalAiNextstep1RequestsByRequestIdCancelResponses];

export type PostFalAiNextstep1Data = {
  body: Nextstep1Input;
  path?: never;
  query?: never;
  url: "/fal-ai/nextstep-1";
};

export type PostFalAiNextstep1Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNextstep1Response =
  PostFalAiNextstep1Responses[keyof PostFalAiNextstep1Responses];

export type GetFalAiNextstep1RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nextstep-1/requests/{request_id}";
};

export type GetFalAiNextstep1RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Nextstep1Output;
};

export type GetFalAiNextstep1RequestsByRequestIdResponse =
  GetFalAiNextstep1RequestsByRequestIdResponses[keyof GetFalAiNextstep1RequestsByRequestIdResponses];

export type GetFalAiQwenImageEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-edit/requests/{request_id}/status";
};

export type GetFalAiQwenImageEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageEditRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageEditRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageEditRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageEditRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageEditRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageEditRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageEditData = {
  body: QwenImageEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-edit";
};

export type PostFalAiQwenImageEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageEditResponse =
  PostFalAiQwenImageEditResponses[keyof PostFalAiQwenImageEditResponses];

export type GetFalAiQwenImageEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-edit/requests/{request_id}";
};

export type GetFalAiQwenImageEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageEditOutput;
};

export type GetFalAiQwenImageEditRequestsByRequestIdResponse =
  GetFalAiQwenImageEditRequestsByRequestIdResponses[keyof GetFalAiQwenImageEditRequestsByRequestIdResponses];

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/character/edit/requests/{request_id}/status";
};

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramCharacterEditRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramCharacterEditRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramCharacterEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/edit/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramCharacterEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramCharacterEditRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramCharacterEditRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramCharacterEditRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramCharacterEditData = {
  body: IdeogramCharacterEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/character/edit";
};

export type PostFalAiIdeogramCharacterEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramCharacterEditResponse =
  PostFalAiIdeogramCharacterEditResponses[keyof PostFalAiIdeogramCharacterEditResponses];

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/edit/requests/{request_id}";
};

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramCharacterEditOutput;
};

export type GetFalAiIdeogramCharacterEditRequestsByRequestIdResponse =
  GetFalAiIdeogramCharacterEditRequestsByRequestIdResponses[keyof GetFalAiIdeogramCharacterEditRequestsByRequestIdResponses];

export type GetFalAiIdeogramCharacterRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/character/requests/{request_id}/status";
};

export type GetFalAiIdeogramCharacterRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramCharacterRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramCharacterRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramCharacterRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramCharacterRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramCharacterRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramCharacterRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramCharacterRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramCharacterRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramCharacterData = {
  body: IdeogramCharacterInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/character";
};

export type PostFalAiIdeogramCharacterResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramCharacterResponse =
  PostFalAiIdeogramCharacterResponses[keyof PostFalAiIdeogramCharacterResponses];

export type GetFalAiIdeogramCharacterRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/requests/{request_id}";
};

export type GetFalAiIdeogramCharacterRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramCharacterOutput;
};

export type GetFalAiIdeogramCharacterRequestsByRequestIdResponse =
  GetFalAiIdeogramCharacterRequestsByRequestIdResponses[keyof GetFalAiIdeogramCharacterRequestsByRequestIdResponses];

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/character/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramCharacterRemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramCharacterRemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramCharacterRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramCharacterRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramCharacterRemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramCharacterRemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramCharacterRemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramCharacterRemixData = {
  body: IdeogramCharacterRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/character/remix";
};

export type PostFalAiIdeogramCharacterRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramCharacterRemixResponse =
  PostFalAiIdeogramCharacterRemixResponses[keyof PostFalAiIdeogramCharacterRemixResponses];

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/character/remix/requests/{request_id}";
};

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramCharacterRemixOutput;
};

export type GetFalAiIdeogramCharacterRemixRequestsByRequestIdResponse =
  GetFalAiIdeogramCharacterRemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramCharacterRemixRequestsByRequestIdResponses];

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-krea-lora/inpainting/requests/{request_id}/status";
};

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaLoraInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaLoraInpaintingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaLoraInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaLoraInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaLoraInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaLoraInpaintingData = {
  body: FluxKreaLoraInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-krea-lora/inpainting";
};

export type PostFalAiFluxKreaLoraInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaLoraInpaintingResponse =
  PostFalAiFluxKreaLoraInpaintingResponses[keyof PostFalAiFluxKreaLoraInpaintingResponses];

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/inpainting/requests/{request_id}";
};

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaLoraInpaintingOutput;
};

export type GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdResponse =
  GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdResponses[keyof GetFalAiFluxKreaLoraInpaintingRequestsByRequestIdResponses];

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-krea-lora/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaLoraImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaLoraImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxKreaLoraImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaLoraImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaLoraImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaLoraImageToImageData = {
  body: FluxKreaLoraImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-krea-lora/image-to-image";
};

export type PostFalAiFluxKreaLoraImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaLoraImageToImageResponse =
  PostFalAiFluxKreaLoraImageToImageResponses[keyof PostFalAiFluxKreaLoraImageToImageResponses];

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaLoraImageToImageOutput;
};

export type GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxKreaLoraImageToImageRequestsByRequestIdResponses];

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/krea/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaImageToImageData = {
  body: FluxKreaImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/krea/image-to-image";
};

export type PostFalAiFluxKreaImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaImageToImageResponse =
  PostFalAiFluxKreaImageToImageResponses[keyof PostFalAiFluxKreaImageToImageResponses];

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaImageToImageOutput;
};

export type GetFalAiFluxKreaImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxKreaImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxKreaImageToImageRequestsByRequestIdResponses];

export type GetFalAiFluxKreaReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/krea/redux/requests/{request_id}/status";
};

export type GetFalAiFluxKreaReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaReduxRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/redux/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaReduxRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaReduxData = {
  body: FluxKreaReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/krea/redux";
};

export type PostFalAiFluxKreaReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaReduxResponse =
  PostFalAiFluxKreaReduxResponses[keyof PostFalAiFluxKreaReduxResponses];

export type GetFalAiFluxKreaReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/redux/requests/{request_id}";
};

export type GetFalAiFluxKreaReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaReduxOutput;
};

export type GetFalAiFluxKreaReduxRequestsByRequestIdResponse =
  GetFalAiFluxKreaReduxRequestsByRequestIdResponses[keyof GetFalAiFluxKreaReduxRequestsByRequestIdResponses];

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/krea/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFlux1KreaImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1KreaImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1KreaImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFlux1KreaImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1KreaImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFlux1KreaImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1KreaImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1KreaImageToImageData = {
  body: Flux1KreaImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/krea/image-to-image";
};

export type PostFalAiFlux1KreaImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1KreaImageToImageResponse =
  PostFalAiFlux1KreaImageToImageResponses[keyof PostFalAiFlux1KreaImageToImageResponses];

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/image-to-image/requests/{request_id}";
};

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1KreaImageToImageOutput;
};

export type GetFalAiFlux1KreaImageToImageRequestsByRequestIdResponse =
  GetFalAiFlux1KreaImageToImageRequestsByRequestIdResponses[keyof GetFalAiFlux1KreaImageToImageRequestsByRequestIdResponses];

export type GetFalAiFlux1KreaReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/krea/redux/requests/{request_id}/status";
};

export type GetFalAiFlux1KreaReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1KreaReduxRequestsByRequestIdStatusResponse =
  GetFalAiFlux1KreaReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1KreaReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1KreaReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/redux/requests/{request_id}/cancel";
};

export type PutFalAiFlux1KreaReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1KreaReduxRequestsByRequestIdCancelResponse =
  PutFalAiFlux1KreaReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1KreaReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1KreaReduxData = {
  body: Flux1KreaReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/krea/redux";
};

export type PostFalAiFlux1KreaReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1KreaReduxResponse =
  PostFalAiFlux1KreaReduxResponses[keyof PostFalAiFlux1KreaReduxResponses];

export type GetFalAiFlux1KreaReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/redux/requests/{request_id}";
};

export type GetFalAiFlux1KreaReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1KreaReduxOutput;
};

export type GetFalAiFlux1KreaReduxRequestsByRequestIdResponse =
  GetFalAiFlux1KreaReduxRequestsByRequestIdResponses[keyof GetFalAiFlux1KreaReduxRequestsByRequestIdResponses];

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-kontext-lora/inpaint/requests/{request_id}/status";
};

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdStatusResponse =
  GetFalAiFluxKontextLoraInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKontextLoraInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKontextLoraInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiFluxKontextLoraInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKontextLoraInpaintRequestsByRequestIdCancelResponse =
  PutFalAiFluxKontextLoraInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKontextLoraInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKontextLoraInpaintData = {
  body: FluxKontextLoraInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-kontext-lora/inpaint";
};

export type PostFalAiFluxKontextLoraInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKontextLoraInpaintResponse =
  PostFalAiFluxKontextLoraInpaintResponses[keyof PostFalAiFluxKontextLoraInpaintResponses];

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/inpaint/requests/{request_id}";
};

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKontextLoraInpaintOutput;
};

export type GetFalAiFluxKontextLoraInpaintRequestsByRequestIdResponse =
  GetFalAiFluxKontextLoraInpaintRequestsByRequestIdResponses[keyof GetFalAiFluxKontextLoraInpaintRequestsByRequestIdResponses];

export type GetFalAiHunyuanWorldRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hunyuan_world/requests/{request_id}/status";
};

export type GetFalAiHunyuanWorldRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiHunyuanWorldRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanWorldRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanWorldRequestsByRequestIdStatusResponses];

export type PutFalAiHunyuanWorldRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan_world/requests/{request_id}/cancel";
};

export type PutFalAiHunyuanWorldRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiHunyuanWorldRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanWorldRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanWorldRequestsByRequestIdCancelResponses];

export type PostFalAiHunyuanWorldData = {
  body: HunyuanWorldInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hunyuan_world";
};

export type PostFalAiHunyuanWorldResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHunyuanWorldResponse =
  PostFalAiHunyuanWorldResponses[keyof PostFalAiHunyuanWorldResponses];

export type GetFalAiHunyuanWorldRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan_world/requests/{request_id}";
};

export type GetFalAiHunyuanWorldRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HunyuanWorldOutput;
};

export type GetFalAiHunyuanWorldRequestsByRequestIdResponse =
  GetFalAiHunyuanWorldRequestsByRequestIdResponses[keyof GetFalAiHunyuanWorldRequestsByRequestIdResponses];

export type GetFalAiImageEditingRetouchRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/retouch/requests/{request_id}/status";
};

export type GetFalAiImageEditingRetouchRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingRetouchRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingRetouchRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingRetouchRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingRetouchRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/retouch/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingRetouchRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingRetouchRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingRetouchRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingRetouchRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingRetouchData = {
  body: ImageEditingRetouchInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/retouch";
};

export type PostFalAiImageEditingRetouchResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingRetouchResponse =
  PostFalAiImageEditingRetouchResponses[keyof PostFalAiImageEditingRetouchResponses];

export type GetFalAiImageEditingRetouchRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/retouch/requests/{request_id}";
};

export type GetFalAiImageEditingRetouchRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingRetouchOutput;
};

export type GetFalAiImageEditingRetouchRequestsByRequestIdResponse =
  GetFalAiImageEditingRetouchRequestsByRequestIdResponses[keyof GetFalAiImageEditingRetouchRequestsByRequestIdResponses];

export type GetFalAiHidreamE11RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hidream-e1-1/requests/{request_id}/status";
};

export type GetFalAiHidreamE11RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiHidreamE11RequestsByRequestIdStatusResponse =
  GetFalAiHidreamE11RequestsByRequestIdStatusResponses[keyof GetFalAiHidreamE11RequestsByRequestIdStatusResponses];

export type PutFalAiHidreamE11RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-e1-1/requests/{request_id}/cancel";
};

export type PutFalAiHidreamE11RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiHidreamE11RequestsByRequestIdCancelResponse =
  PutFalAiHidreamE11RequestsByRequestIdCancelResponses[keyof PutFalAiHidreamE11RequestsByRequestIdCancelResponses];

export type PostFalAiHidreamE11Data = {
  body: HidreamE11Input;
  path?: never;
  query?: never;
  url: "/fal-ai/hidream-e1-1";
};

export type PostFalAiHidreamE11Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHidreamE11Response =
  PostFalAiHidreamE11Responses[keyof PostFalAiHidreamE11Responses];

export type GetFalAiHidreamE11RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-e1-1/requests/{request_id}";
};

export type GetFalAiHidreamE11RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HidreamE11Output;
};

export type GetFalAiHidreamE11RequestsByRequestIdResponse =
  GetFalAiHidreamE11RequestsByRequestIdResponses[keyof GetFalAiHidreamE11RequestsByRequestIdResponses];

export type GetFalAiRifeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/rife/requests/{request_id}/status";
};

export type GetFalAiRifeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRifeRequestsByRequestIdStatusResponse =
  GetFalAiRifeRequestsByRequestIdStatusResponses[keyof GetFalAiRifeRequestsByRequestIdStatusResponses];

export type PutFalAiRifeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/rife/requests/{request_id}/cancel";
};

export type PutFalAiRifeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRifeRequestsByRequestIdCancelResponse =
  PutFalAiRifeRequestsByRequestIdCancelResponses[keyof PutFalAiRifeRequestsByRequestIdCancelResponses];

export type PostFalAiRifeData = {
  body: RifeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/rife";
};

export type PostFalAiRifeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRifeResponse =
  PostFalAiRifeResponses[keyof PostFalAiRifeResponses];

export type GetFalAiRifeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/rife/requests/{request_id}";
};

export type GetFalAiRifeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RifeOutput;
};

export type GetFalAiRifeRequestsByRequestIdResponse =
  GetFalAiRifeRequestsByRequestIdResponses[keyof GetFalAiRifeRequestsByRequestIdResponses];

export type GetFalAiFilmRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/film/requests/{request_id}/status";
};

export type GetFalAiFilmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFilmRequestsByRequestIdStatusResponse =
  GetFalAiFilmRequestsByRequestIdStatusResponses[keyof GetFalAiFilmRequestsByRequestIdStatusResponses];

export type PutFalAiFilmRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/film/requests/{request_id}/cancel";
};

export type PutFalAiFilmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFilmRequestsByRequestIdCancelResponse =
  PutFalAiFilmRequestsByRequestIdCancelResponses[keyof PutFalAiFilmRequestsByRequestIdCancelResponses];

export type PostFalAiFilmData = {
  body: FilmInput;
  path?: never;
  query?: never;
  url: "/fal-ai/film";
};

export type PostFalAiFilmResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFilmResponse =
  PostFalAiFilmResponses[keyof PostFalAiFilmResponses];

export type GetFalAiFilmRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/film/requests/{request_id}";
};

export type GetFalAiFilmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FilmOutput;
};

export type GetFalAiFilmRequestsByRequestIdResponse =
  GetFalAiFilmRequestsByRequestIdResponses[keyof GetFalAiFilmRequestsByRequestIdResponses];

export type GetFalAiCalligrapherRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/calligrapher/requests/{request_id}/status";
};

export type GetFalAiCalligrapherRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCalligrapherRequestsByRequestIdStatusResponse =
  GetFalAiCalligrapherRequestsByRequestIdStatusResponses[keyof GetFalAiCalligrapherRequestsByRequestIdStatusResponses];

export type PutFalAiCalligrapherRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/calligrapher/requests/{request_id}/cancel";
};

export type PutFalAiCalligrapherRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCalligrapherRequestsByRequestIdCancelResponse =
  PutFalAiCalligrapherRequestsByRequestIdCancelResponses[keyof PutFalAiCalligrapherRequestsByRequestIdCancelResponses];

export type PostFalAiCalligrapherData = {
  body: CalligrapherInput;
  path?: never;
  query?: never;
  url: "/fal-ai/calligrapher";
};

export type PostFalAiCalligrapherResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCalligrapherResponse =
  PostFalAiCalligrapherResponses[keyof PostFalAiCalligrapherResponses];

export type GetFalAiCalligrapherRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/calligrapher/requests/{request_id}";
};

export type GetFalAiCalligrapherRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CalligrapherOutput;
};

export type GetFalAiCalligrapherRequestsByRequestIdResponse =
  GetFalAiCalligrapherRequestsByRequestIdResponses[keyof GetFalAiCalligrapherRequestsByRequestIdResponses];

export type GetFalAiBriaReimagineRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/reimagine/requests/{request_id}/status";
};

export type GetFalAiBriaReimagineRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaReimagineRequestsByRequestIdStatusResponse =
  GetFalAiBriaReimagineRequestsByRequestIdStatusResponses[keyof GetFalAiBriaReimagineRequestsByRequestIdStatusResponses];

export type PutFalAiBriaReimagineRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/reimagine/requests/{request_id}/cancel";
};

export type PutFalAiBriaReimagineRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaReimagineRequestsByRequestIdCancelResponse =
  PutFalAiBriaReimagineRequestsByRequestIdCancelResponses[keyof PutFalAiBriaReimagineRequestsByRequestIdCancelResponses];

export type PostFalAiBriaReimagineData = {
  body: BriaReimagineInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/reimagine";
};

export type PostFalAiBriaReimagineResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaReimagineResponse =
  PostFalAiBriaReimagineResponses[keyof PostFalAiBriaReimagineResponses];

export type GetFalAiBriaReimagineRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/reimagine/requests/{request_id}";
};

export type GetFalAiBriaReimagineRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaReimagineOutput;
};

export type GetFalAiBriaReimagineRequestsByRequestIdResponse =
  GetFalAiBriaReimagineRequestsByRequestIdResponses[keyof GetFalAiBriaReimagineRequestsByRequestIdResponses];

export type GetFalAiImageEditingRealismRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/realism/requests/{request_id}/status";
};

export type GetFalAiImageEditingRealismRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingRealismRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingRealismRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingRealismRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingRealismRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/realism/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingRealismRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingRealismRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingRealismRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingRealismRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingRealismData = {
  body: ImageEditingRealismInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/realism";
};

export type PostFalAiImageEditingRealismResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingRealismResponse =
  PostFalAiImageEditingRealismResponses[keyof PostFalAiImageEditingRealismResponses];

export type GetFalAiImageEditingRealismRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/realism/requests/{request_id}";
};

export type GetFalAiImageEditingRealismRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingRealismOutput;
};

export type GetFalAiImageEditingRealismRequestsByRequestIdResponse =
  GetFalAiImageEditingRealismRequestsByRequestIdResponses[keyof GetFalAiImageEditingRealismRequestsByRequestIdResponses];

export type GetFalAiPostProcessingVignetteRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/vignette/requests/{request_id}/status";
};

export type GetFalAiPostProcessingVignetteRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingVignetteRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingVignetteRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingVignetteRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingVignetteRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/vignette/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingVignetteRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingVignetteRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingVignetteRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingVignetteRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingVignetteData = {
  body: PostProcessingVignetteInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/vignette";
};

export type PostFalAiPostProcessingVignetteResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingVignetteResponse =
  PostFalAiPostProcessingVignetteResponses[keyof PostFalAiPostProcessingVignetteResponses];

export type GetFalAiPostProcessingVignetteRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/vignette/requests/{request_id}";
};

export type GetFalAiPostProcessingVignetteRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingVignetteOutput;
};

export type GetFalAiPostProcessingVignetteRequestsByRequestIdResponse =
  GetFalAiPostProcessingVignetteRequestsByRequestIdResponses[keyof GetFalAiPostProcessingVignetteRequestsByRequestIdResponses];

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/solarize/requests/{request_id}/status";
};

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingSolarizeRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingSolarizeRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingSolarizeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/solarize/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingSolarizeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingSolarizeRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingSolarizeRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingSolarizeRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingSolarizeData = {
  body: PostProcessingSolarizeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/solarize";
};

export type PostFalAiPostProcessingSolarizeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingSolarizeResponse =
  PostFalAiPostProcessingSolarizeResponses[keyof PostFalAiPostProcessingSolarizeResponses];

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/solarize/requests/{request_id}";
};

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingSolarizeOutput;
};

export type GetFalAiPostProcessingSolarizeRequestsByRequestIdResponse =
  GetFalAiPostProcessingSolarizeRequestsByRequestIdResponses[keyof GetFalAiPostProcessingSolarizeRequestsByRequestIdResponses];

export type GetFalAiPostProcessingSharpenRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/sharpen/requests/{request_id}/status";
};

export type GetFalAiPostProcessingSharpenRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingSharpenRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingSharpenRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingSharpenRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingSharpenRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/sharpen/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingSharpenRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingSharpenRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingSharpenRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingSharpenRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingSharpenData = {
  body: PostProcessingSharpenInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/sharpen";
};

export type PostFalAiPostProcessingSharpenResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingSharpenResponse =
  PostFalAiPostProcessingSharpenResponses[keyof PostFalAiPostProcessingSharpenResponses];

export type GetFalAiPostProcessingSharpenRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/sharpen/requests/{request_id}";
};

export type GetFalAiPostProcessingSharpenRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingSharpenOutput;
};

export type GetFalAiPostProcessingSharpenRequestsByRequestIdResponse =
  GetFalAiPostProcessingSharpenRequestsByRequestIdResponses[keyof GetFalAiPostProcessingSharpenRequestsByRequestIdResponses];

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/parabolize/requests/{request_id}/status";
};

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingParabolizeRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingParabolizeRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingParabolizeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/parabolize/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingParabolizeRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingParabolizeRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingParabolizeRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingParabolizeRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingParabolizeData = {
  body: PostProcessingParabolizeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/parabolize";
};

export type PostFalAiPostProcessingParabolizeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingParabolizeResponse =
  PostFalAiPostProcessingParabolizeResponses[keyof PostFalAiPostProcessingParabolizeResponses];

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/parabolize/requests/{request_id}";
};

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingParabolizeOutput;
};

export type GetFalAiPostProcessingParabolizeRequestsByRequestIdResponse =
  GetFalAiPostProcessingParabolizeRequestsByRequestIdResponses[keyof GetFalAiPostProcessingParabolizeRequestsByRequestIdResponses];

export type GetFalAiPostProcessingGrainRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/grain/requests/{request_id}/status";
};

export type GetFalAiPostProcessingGrainRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingGrainRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingGrainRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingGrainRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingGrainRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/grain/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingGrainRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingGrainRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingGrainRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingGrainRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingGrainData = {
  body: PostProcessingGrainInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/grain";
};

export type PostFalAiPostProcessingGrainResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingGrainResponse =
  PostFalAiPostProcessingGrainResponses[keyof PostFalAiPostProcessingGrainResponses];

export type GetFalAiPostProcessingGrainRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/grain/requests/{request_id}";
};

export type GetFalAiPostProcessingGrainRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingGrainOutput;
};

export type GetFalAiPostProcessingGrainRequestsByRequestIdResponse =
  GetFalAiPostProcessingGrainRequestsByRequestIdResponses[keyof GetFalAiPostProcessingGrainRequestsByRequestIdResponses];

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/dodge-burn/requests/{request_id}/status";
};

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingDodgeBurnRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingDodgeBurnRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingDodgeBurnRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/dodge-burn/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingDodgeBurnRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingDodgeBurnRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingDodgeBurnRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingDodgeBurnRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingDodgeBurnData = {
  body: PostProcessingDodgeBurnInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/dodge-burn";
};

export type PostFalAiPostProcessingDodgeBurnResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingDodgeBurnResponse =
  PostFalAiPostProcessingDodgeBurnResponses[keyof PostFalAiPostProcessingDodgeBurnResponses];

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/dodge-burn/requests/{request_id}";
};

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingDodgeBurnOutput;
};

export type GetFalAiPostProcessingDodgeBurnRequestsByRequestIdResponse =
  GetFalAiPostProcessingDodgeBurnRequestsByRequestIdResponses[keyof GetFalAiPostProcessingDodgeBurnRequestsByRequestIdResponses];

export type GetFalAiPostProcessingDissolveRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/dissolve/requests/{request_id}/status";
};

export type GetFalAiPostProcessingDissolveRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingDissolveRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingDissolveRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingDissolveRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingDissolveRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/dissolve/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingDissolveRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingDissolveRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingDissolveRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingDissolveRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingDissolveData = {
  body: PostProcessingDissolveInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/dissolve";
};

export type PostFalAiPostProcessingDissolveResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingDissolveResponse =
  PostFalAiPostProcessingDissolveResponses[keyof PostFalAiPostProcessingDissolveResponses];

export type GetFalAiPostProcessingDissolveRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/dissolve/requests/{request_id}";
};

export type GetFalAiPostProcessingDissolveRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingDissolveOutput;
};

export type GetFalAiPostProcessingDissolveRequestsByRequestIdResponse =
  GetFalAiPostProcessingDissolveRequestsByRequestIdResponses[keyof GetFalAiPostProcessingDissolveRequestsByRequestIdResponses];

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/desaturate/requests/{request_id}/status";
};

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingDesaturateRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingDesaturateRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingDesaturateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/desaturate/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingDesaturateRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingDesaturateRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingDesaturateRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingDesaturateRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingDesaturateData = {
  body: PostProcessingDesaturateInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/desaturate";
};

export type PostFalAiPostProcessingDesaturateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingDesaturateResponse =
  PostFalAiPostProcessingDesaturateResponses[keyof PostFalAiPostProcessingDesaturateResponses];

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/desaturate/requests/{request_id}";
};

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingDesaturateOutput;
};

export type GetFalAiPostProcessingDesaturateRequestsByRequestIdResponse =
  GetFalAiPostProcessingDesaturateRequestsByRequestIdResponses[keyof GetFalAiPostProcessingDesaturateRequestsByRequestIdResponses];

export type GetFalAiPostProcessingColorTintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/color-tint/requests/{request_id}/status";
};

export type GetFalAiPostProcessingColorTintRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingColorTintRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingColorTintRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingColorTintRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingColorTintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/color-tint/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingColorTintRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingColorTintRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingColorTintRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingColorTintRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingColorTintData = {
  body: PostProcessingColorTintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/color-tint";
};

export type PostFalAiPostProcessingColorTintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingColorTintResponse =
  PostFalAiPostProcessingColorTintResponses[keyof PostFalAiPostProcessingColorTintResponses];

export type GetFalAiPostProcessingColorTintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/color-tint/requests/{request_id}";
};

export type GetFalAiPostProcessingColorTintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingColorTintOutput;
};

export type GetFalAiPostProcessingColorTintRequestsByRequestIdResponse =
  GetFalAiPostProcessingColorTintRequestsByRequestIdResponses[keyof GetFalAiPostProcessingColorTintRequestsByRequestIdResponses];

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/post-processing/color-correction/requests/{request_id}/status";
  };

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingColorCorrectionRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingColorCorrectionRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingColorCorrectionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/post-processing/color-correction/requests/{request_id}/cancel";
  };

export type PutFalAiPostProcessingColorCorrectionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingColorCorrectionRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingColorCorrectionRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingColorCorrectionRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingColorCorrectionData = {
  body: PostProcessingColorCorrectionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/color-correction";
};

export type PostFalAiPostProcessingColorCorrectionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingColorCorrectionResponse =
  PostFalAiPostProcessingColorCorrectionResponses[keyof PostFalAiPostProcessingColorCorrectionResponses];

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/color-correction/requests/{request_id}";
};

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: PostProcessingColorCorrectionOutput;
  };

export type GetFalAiPostProcessingColorCorrectionRequestsByRequestIdResponse =
  GetFalAiPostProcessingColorCorrectionRequestsByRequestIdResponses[keyof GetFalAiPostProcessingColorCorrectionRequestsByRequestIdResponses];

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/post-processing/chromatic-aberration/requests/{request_id}/status";
  };

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingChromaticAberrationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/post-processing/chromatic-aberration/requests/{request_id}/cancel";
  };

export type PutFalAiPostProcessingChromaticAberrationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPostProcessingChromaticAberrationRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingChromaticAberrationRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingChromaticAberrationRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingChromaticAberrationData = {
  body: PostProcessingChromaticAberrationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/chromatic-aberration";
};

export type PostFalAiPostProcessingChromaticAberrationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingChromaticAberrationResponse =
  PostFalAiPostProcessingChromaticAberrationResponses[keyof PostFalAiPostProcessingChromaticAberrationResponses];

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/chromatic-aberration/requests/{request_id}";
};

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: PostProcessingChromaticAberrationOutput;
  };

export type GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdResponse =
  GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdResponses[keyof GetFalAiPostProcessingChromaticAberrationRequestsByRequestIdResponses];

export type GetFalAiPostProcessingBlurRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/blur/requests/{request_id}/status";
};

export type GetFalAiPostProcessingBlurRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingBlurRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingBlurRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingBlurRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingBlurRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/blur/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingBlurRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingBlurRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingBlurRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingBlurRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingBlurData = {
  body: PostProcessingBlurInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing/blur";
};

export type PostFalAiPostProcessingBlurResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingBlurResponse =
  PostFalAiPostProcessingBlurResponses[keyof PostFalAiPostProcessingBlurResponses];

export type GetFalAiPostProcessingBlurRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/blur/requests/{request_id}";
};

export type GetFalAiPostProcessingBlurRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingBlurOutput;
};

export type GetFalAiPostProcessingBlurRequestsByRequestIdResponse =
  GetFalAiPostProcessingBlurRequestsByRequestIdResponses[keyof GetFalAiPostProcessingBlurRequestsByRequestIdResponses];

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/youtube-thumbnails/requests/{request_id}/status";
  };

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/youtube-thumbnails/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingYoutubeThumbnailsData = {
  body: ImageEditingYoutubeThumbnailsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/youtube-thumbnails";
};

export type PostFalAiImageEditingYoutubeThumbnailsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingYoutubeThumbnailsResponse =
  PostFalAiImageEditingYoutubeThumbnailsResponses[keyof PostFalAiImageEditingYoutubeThumbnailsResponses];

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/youtube-thumbnails/requests/{request_id}";
};

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ImageEditingYoutubeThumbnailsOutput;
  };

export type GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdResponse =
  GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdResponses[keyof GetFalAiImageEditingYoutubeThumbnailsRequestsByRequestIdResponses];

export type GetFalAiTopazUpscaleImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/topaz/upscale/image/requests/{request_id}/status";
};

export type GetFalAiTopazUpscaleImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiTopazUpscaleImageRequestsByRequestIdStatusResponse =
  GetFalAiTopazUpscaleImageRequestsByRequestIdStatusResponses[keyof GetFalAiTopazUpscaleImageRequestsByRequestIdStatusResponses];

export type PutFalAiTopazUpscaleImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/topaz/upscale/image/requests/{request_id}/cancel";
};

export type PutFalAiTopazUpscaleImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiTopazUpscaleImageRequestsByRequestIdCancelResponse =
  PutFalAiTopazUpscaleImageRequestsByRequestIdCancelResponses[keyof PutFalAiTopazUpscaleImageRequestsByRequestIdCancelResponses];

export type PostFalAiTopazUpscaleImageData = {
  body: TopazUpscaleImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/topaz/upscale/image";
};

export type PostFalAiTopazUpscaleImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiTopazUpscaleImageResponse =
  PostFalAiTopazUpscaleImageResponses[keyof PostFalAiTopazUpscaleImageResponses];

export type GetFalAiTopazUpscaleImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/topaz/upscale/image/requests/{request_id}";
};

export type GetFalAiTopazUpscaleImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: TopazUpscaleImageOutput;
};

export type GetFalAiTopazUpscaleImageRequestsByRequestIdResponse =
  GetFalAiTopazUpscaleImageRequestsByRequestIdResponses[keyof GetFalAiTopazUpscaleImageRequestsByRequestIdResponses];

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/broccoli-haircut/requests/{request_id}/status";
};

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingBroccoliHaircutRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/broccoli-haircut/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingBroccoliHaircutRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingBroccoliHaircutRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingBroccoliHaircutRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingBroccoliHaircutRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingBroccoliHaircutData = {
  body: ImageEditingBroccoliHaircutInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/broccoli-haircut";
};

export type PostFalAiImageEditingBroccoliHaircutResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingBroccoliHaircutResponse =
  PostFalAiImageEditingBroccoliHaircutResponses[keyof PostFalAiImageEditingBroccoliHaircutResponses];

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/broccoli-haircut/requests/{request_id}";
};

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingBroccoliHaircutOutput;
};

export type GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdResponse =
  GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdResponses[keyof GetFalAiImageEditingBroccoliHaircutRequestsByRequestIdResponses];

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/wojak-style/requests/{request_id}/status";
};

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingWojakStyleRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingWojakStyleRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingWojakStyleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/wojak-style/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingWojakStyleRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingWojakStyleRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingWojakStyleRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingWojakStyleRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingWojakStyleData = {
  body: ImageEditingWojakStyleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/wojak-style";
};

export type PostFalAiImageEditingWojakStyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingWojakStyleResponse =
  PostFalAiImageEditingWojakStyleResponses[keyof PostFalAiImageEditingWojakStyleResponses];

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/wojak-style/requests/{request_id}";
};

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingWojakStyleOutput;
};

export type GetFalAiImageEditingWojakStyleRequestsByRequestIdResponse =
  GetFalAiImageEditingWojakStyleRequestsByRequestIdResponses[keyof GetFalAiImageEditingWojakStyleRequestsByRequestIdResponses];

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/plushie-style/requests/{request_id}/status";
};

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingPlushieStyleRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingPlushieStyleRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingPlushieStyleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/plushie-style/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingPlushieStyleRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingPlushieStyleRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingPlushieStyleRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingPlushieStyleRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingPlushieStyleData = {
  body: ImageEditingPlushieStyleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/plushie-style";
};

export type PostFalAiImageEditingPlushieStyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingPlushieStyleResponse =
  PostFalAiImageEditingPlushieStyleResponses[keyof PostFalAiImageEditingPlushieStyleResponses];

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/plushie-style/requests/{request_id}";
};

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingPlushieStyleOutput;
};

export type GetFalAiImageEditingPlushieStyleRequestsByRequestIdResponse =
  GetFalAiImageEditingPlushieStyleRequestsByRequestIdResponses[keyof GetFalAiImageEditingPlushieStyleRequestsByRequestIdResponses];

export type GetFalAiFluxKontextLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-kontext-lora/requests/{request_id}/status";
};

export type GetFalAiFluxKontextLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKontextLoraRequestsByRequestIdStatusResponse =
  GetFalAiFluxKontextLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKontextLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKontextLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/requests/{request_id}/cancel";
};

export type PutFalAiFluxKontextLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKontextLoraRequestsByRequestIdCancelResponse =
  PutFalAiFluxKontextLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKontextLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKontextLoraData = {
  body: FluxKontextLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-kontext-lora";
};

export type PostFalAiFluxKontextLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKontextLoraResponse =
  PostFalAiFluxKontextLoraResponses[keyof PostFalAiFluxKontextLoraResponses];

export type GetFalAiFluxKontextLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/requests/{request_id}";
};

export type GetFalAiFluxKontextLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKontextLoraOutput;
};

export type GetFalAiFluxKontextLoraRequestsByRequestIdResponse =
  GetFalAiFluxKontextLoraRequestsByRequestIdResponses[keyof GetFalAiFluxKontextLoraRequestsByRequestIdResponses];

export type GetFalAiFashnTryonV16RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fashn/tryon/v1.6/requests/{request_id}/status";
};

export type GetFalAiFashnTryonV16RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFashnTryonV16RequestsByRequestIdStatusResponse =
  GetFalAiFashnTryonV16RequestsByRequestIdStatusResponses[keyof GetFalAiFashnTryonV16RequestsByRequestIdStatusResponses];

export type PutFalAiFashnTryonV16RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.6/requests/{request_id}/cancel";
};

export type PutFalAiFashnTryonV16RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFashnTryonV16RequestsByRequestIdCancelResponse =
  PutFalAiFashnTryonV16RequestsByRequestIdCancelResponses[keyof PutFalAiFashnTryonV16RequestsByRequestIdCancelResponses];

export type PostFalAiFashnTryonV16Data = {
  body: FashnTryonV16Input;
  path?: never;
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.6";
};

export type PostFalAiFashnTryonV16Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFashnTryonV16Response =
  PostFalAiFashnTryonV16Responses[keyof PostFalAiFashnTryonV16Responses];

export type GetFalAiFashnTryonV16RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.6/requests/{request_id}";
};

export type GetFalAiFashnTryonV16RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FashnTryonV16Output;
};

export type GetFalAiFashnTryonV16RequestsByRequestIdResponse =
  GetFalAiFashnTryonV16RequestsByRequestIdResponses[keyof GetFalAiFashnTryonV16RequestsByRequestIdResponses];

export type GetFalAiChainOfZoomRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/chain-of-zoom/requests/{request_id}/status";
};

export type GetFalAiChainOfZoomRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiChainOfZoomRequestsByRequestIdStatusResponse =
  GetFalAiChainOfZoomRequestsByRequestIdStatusResponses[keyof GetFalAiChainOfZoomRequestsByRequestIdStatusResponses];

export type PutFalAiChainOfZoomRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chain-of-zoom/requests/{request_id}/cancel";
};

export type PutFalAiChainOfZoomRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiChainOfZoomRequestsByRequestIdCancelResponse =
  PutFalAiChainOfZoomRequestsByRequestIdCancelResponses[keyof PutFalAiChainOfZoomRequestsByRequestIdCancelResponses];

export type PostFalAiChainOfZoomData = {
  body: ChainOfZoomInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chain-of-zoom";
};

export type PostFalAiChainOfZoomResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChainOfZoomResponse =
  PostFalAiChainOfZoomResponses[keyof PostFalAiChainOfZoomResponses];

export type GetFalAiChainOfZoomRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chain-of-zoom/requests/{request_id}";
};

export type GetFalAiChainOfZoomRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ChainOfZoomOutput;
};

export type GetFalAiChainOfZoomRequestsByRequestIdResponse =
  GetFalAiChainOfZoomRequestsByRequestIdResponses[keyof GetFalAiChainOfZoomRequestsByRequestIdResponses];

export type GetFalAiPasdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/pasd/requests/{request_id}/status";
};

export type GetFalAiPasdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPasdRequestsByRequestIdStatusResponse =
  GetFalAiPasdRequestsByRequestIdStatusResponses[keyof GetFalAiPasdRequestsByRequestIdStatusResponses];

export type PutFalAiPasdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pasd/requests/{request_id}/cancel";
};

export type PutFalAiPasdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPasdRequestsByRequestIdCancelResponse =
  PutFalAiPasdRequestsByRequestIdCancelResponses[keyof PutFalAiPasdRequestsByRequestIdCancelResponses];

export type PostFalAiPasdData = {
  body: PasdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/pasd";
};

export type PostFalAiPasdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPasdResponse =
  PostFalAiPasdResponses[keyof PostFalAiPasdResponses];

export type GetFalAiPasdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pasd/requests/{request_id}";
};

export type GetFalAiPasdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PasdOutput;
};

export type GetFalAiPasdRequestsByRequestIdResponse =
  GetFalAiPasdRequestsByRequestIdResponses[keyof GetFalAiPasdRequestsByRequestIdResponses];

export type GetFalAiObjectRemovalBboxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/object-removal/bbox/requests/{request_id}/status";
};

export type GetFalAiObjectRemovalBboxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiObjectRemovalBboxRequestsByRequestIdStatusResponse =
  GetFalAiObjectRemovalBboxRequestsByRequestIdStatusResponses[keyof GetFalAiObjectRemovalBboxRequestsByRequestIdStatusResponses];

export type PutFalAiObjectRemovalBboxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/bbox/requests/{request_id}/cancel";
};

export type PutFalAiObjectRemovalBboxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiObjectRemovalBboxRequestsByRequestIdCancelResponse =
  PutFalAiObjectRemovalBboxRequestsByRequestIdCancelResponses[keyof PutFalAiObjectRemovalBboxRequestsByRequestIdCancelResponses];

export type PostFalAiObjectRemovalBboxData = {
  body: ObjectRemovalBboxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/object-removal/bbox";
};

export type PostFalAiObjectRemovalBboxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiObjectRemovalBboxResponse =
  PostFalAiObjectRemovalBboxResponses[keyof PostFalAiObjectRemovalBboxResponses];

export type GetFalAiObjectRemovalBboxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/bbox/requests/{request_id}";
};

export type GetFalAiObjectRemovalBboxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ObjectRemovalBboxOutput;
};

export type GetFalAiObjectRemovalBboxRequestsByRequestIdResponse =
  GetFalAiObjectRemovalBboxRequestsByRequestIdResponses[keyof GetFalAiObjectRemovalBboxRequestsByRequestIdResponses];

export type GetFalAiObjectRemovalMaskRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/object-removal/mask/requests/{request_id}/status";
};

export type GetFalAiObjectRemovalMaskRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiObjectRemovalMaskRequestsByRequestIdStatusResponse =
  GetFalAiObjectRemovalMaskRequestsByRequestIdStatusResponses[keyof GetFalAiObjectRemovalMaskRequestsByRequestIdStatusResponses];

export type PutFalAiObjectRemovalMaskRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/mask/requests/{request_id}/cancel";
};

export type PutFalAiObjectRemovalMaskRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiObjectRemovalMaskRequestsByRequestIdCancelResponse =
  PutFalAiObjectRemovalMaskRequestsByRequestIdCancelResponses[keyof PutFalAiObjectRemovalMaskRequestsByRequestIdCancelResponses];

export type PostFalAiObjectRemovalMaskData = {
  body: ObjectRemovalMaskInput;
  path?: never;
  query?: never;
  url: "/fal-ai/object-removal/mask";
};

export type PostFalAiObjectRemovalMaskResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiObjectRemovalMaskResponse =
  PostFalAiObjectRemovalMaskResponses[keyof PostFalAiObjectRemovalMaskResponses];

export type GetFalAiObjectRemovalMaskRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/mask/requests/{request_id}";
};

export type GetFalAiObjectRemovalMaskRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ObjectRemovalMaskOutput;
};

export type GetFalAiObjectRemovalMaskRequestsByRequestIdResponse =
  GetFalAiObjectRemovalMaskRequestsByRequestIdResponses[keyof GetFalAiObjectRemovalMaskRequestsByRequestIdResponses];

export type GetFalAiObjectRemovalRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/object-removal/requests/{request_id}/status";
};

export type GetFalAiObjectRemovalRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiObjectRemovalRequestsByRequestIdStatusResponse =
  GetFalAiObjectRemovalRequestsByRequestIdStatusResponses[keyof GetFalAiObjectRemovalRequestsByRequestIdStatusResponses];

export type PutFalAiObjectRemovalRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/requests/{request_id}/cancel";
};

export type PutFalAiObjectRemovalRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiObjectRemovalRequestsByRequestIdCancelResponse =
  PutFalAiObjectRemovalRequestsByRequestIdCancelResponses[keyof PutFalAiObjectRemovalRequestsByRequestIdCancelResponses];

export type PostFalAiObjectRemovalData = {
  body: ObjectRemovalInput;
  path?: never;
  query?: never;
  url: "/fal-ai/object-removal";
};

export type PostFalAiObjectRemovalResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiObjectRemovalResponse =
  PostFalAiObjectRemovalResponses[keyof PostFalAiObjectRemovalResponses];

export type GetFalAiObjectRemovalRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/object-removal/requests/{request_id}";
};

export type GetFalAiObjectRemovalRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ObjectRemovalOutput;
};

export type GetFalAiObjectRemovalRequestsByRequestIdResponse =
  GetFalAiObjectRemovalRequestsByRequestIdResponses[keyof GetFalAiObjectRemovalRequestsByRequestIdResponses];

export type GetFalAiRecraftVectorizeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft/vectorize/requests/{request_id}/status";
};

export type GetFalAiRecraftVectorizeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraftVectorizeRequestsByRequestIdStatusResponse =
  GetFalAiRecraftVectorizeRequestsByRequestIdStatusResponses[keyof GetFalAiRecraftVectorizeRequestsByRequestIdStatusResponses];

export type PutFalAiRecraftVectorizeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/vectorize/requests/{request_id}/cancel";
};

export type PutFalAiRecraftVectorizeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraftVectorizeRequestsByRequestIdCancelResponse =
  PutFalAiRecraftVectorizeRequestsByRequestIdCancelResponses[keyof PutFalAiRecraftVectorizeRequestsByRequestIdCancelResponses];

export type PostFalAiRecraftVectorizeData = {
  body: RecraftVectorizeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft/vectorize";
};

export type PostFalAiRecraftVectorizeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraftVectorizeResponse =
  PostFalAiRecraftVectorizeResponses[keyof PostFalAiRecraftVectorizeResponses];

export type GetFalAiRecraftVectorizeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/vectorize/requests/{request_id}";
};

export type GetFalAiRecraftVectorizeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RecraftVectorizeOutput;
};

export type GetFalAiRecraftVectorizeRequestsByRequestIdResponse =
  GetFalAiRecraftVectorizeRequestsByRequestIdResponses[keyof GetFalAiRecraftVectorizeRequestsByRequestIdResponses];

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ffmpeg-api/extract-frame/requests/{request_id}/status";
};

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdStatusResponse =
  GetFalAiFfmpegApiExtractFrameRequestsByRequestIdStatusResponses[keyof GetFalAiFfmpegApiExtractFrameRequestsByRequestIdStatusResponses];

export type PutFalAiFfmpegApiExtractFrameRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ffmpeg-api/extract-frame/requests/{request_id}/cancel";
};

export type PutFalAiFfmpegApiExtractFrameRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFfmpegApiExtractFrameRequestsByRequestIdCancelResponse =
  PutFalAiFfmpegApiExtractFrameRequestsByRequestIdCancelResponses[keyof PutFalAiFfmpegApiExtractFrameRequestsByRequestIdCancelResponses];

export type PostFalAiFfmpegApiExtractFrameData = {
  body: FfmpegApiExtractFrameInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ffmpeg-api/extract-frame";
};

export type PostFalAiFfmpegApiExtractFrameResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFfmpegApiExtractFrameResponse =
  PostFalAiFfmpegApiExtractFrameResponses[keyof PostFalAiFfmpegApiExtractFrameResponses];

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ffmpeg-api/extract-frame/requests/{request_id}";
};

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FfmpegApiExtractFrameOutput;
};

export type GetFalAiFfmpegApiExtractFrameRequestsByRequestIdResponse =
  GetFalAiFfmpegApiExtractFrameRequestsByRequestIdResponses[keyof GetFalAiFfmpegApiExtractFrameRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/flash/modify/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonFlashModifyRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonFlashModifyRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonFlashModifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/modify/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonFlashModifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonFlashModifyRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonFlashModifyRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonFlashModifyRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonFlashModifyData = {
  body: LumaPhotonFlashModifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon/flash/modify";
};

export type PostFalAiLumaPhotonFlashModifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonFlashModifyResponse =
  PostFalAiLumaPhotonFlashModifyResponses[keyof PostFalAiLumaPhotonFlashModifyResponses];

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/modify/requests/{request_id}";
};

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonFlashModifyOutput;
};

export type GetFalAiLumaPhotonFlashModifyRequestsByRequestIdResponse =
  GetFalAiLumaPhotonFlashModifyRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonFlashModifyRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonModifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/modify/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonModifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonModifyRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonModifyRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonModifyRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonModifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/modify/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonModifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonModifyRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonModifyRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonModifyRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonModifyData = {
  body: LumaPhotonModifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon/modify";
};

export type PostFalAiLumaPhotonModifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonModifyResponse =
  PostFalAiLumaPhotonModifyResponses[keyof PostFalAiLumaPhotonModifyResponses];

export type GetFalAiLumaPhotonModifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/modify/requests/{request_id}";
};

export type GetFalAiLumaPhotonModifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonModifyOutput;
};

export type GetFalAiLumaPhotonModifyRequestsByRequestIdResponse =
  GetFalAiLumaPhotonModifyRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonModifyRequestsByRequestIdResponses];

export type GetFalAiImageEditingReframeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/reframe/requests/{request_id}/status";
};

export type GetFalAiImageEditingReframeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingReframeRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingReframeRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingReframeRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingReframeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/reframe/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingReframeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingReframeRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingReframeRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingReframeRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingReframeData = {
  body: ImageEditingReframeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/reframe";
};

export type PostFalAiImageEditingReframeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingReframeResponse =
  PostFalAiImageEditingReframeResponses[keyof PostFalAiImageEditingReframeResponses];

export type GetFalAiImageEditingReframeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/reframe/requests/{request_id}";
};

export type GetFalAiImageEditingReframeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingReframeOutput;
};

export type GetFalAiImageEditingReframeRequestsByRequestIdResponse =
  GetFalAiImageEditingReframeRequestsByRequestIdResponses[keyof GetFalAiImageEditingReframeRequestsByRequestIdResponses];

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/baby-version/requests/{request_id}/status";
};

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingBabyVersionRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingBabyVersionRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingBabyVersionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/baby-version/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingBabyVersionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingBabyVersionRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingBabyVersionRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingBabyVersionRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingBabyVersionData = {
  body: ImageEditingBabyVersionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/baby-version";
};

export type PostFalAiImageEditingBabyVersionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingBabyVersionResponse =
  PostFalAiImageEditingBabyVersionResponses[keyof PostFalAiImageEditingBabyVersionResponses];

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/baby-version/requests/{request_id}";
};

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingBabyVersionOutput;
};

export type GetFalAiImageEditingBabyVersionRequestsByRequestIdResponse =
  GetFalAiImageEditingBabyVersionRequestsByRequestIdResponses[keyof GetFalAiImageEditingBabyVersionRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/flash/reframe/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonFlashReframeRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonFlashReframeRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonFlashReframeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/reframe/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonFlashReframeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonFlashReframeRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonFlashReframeRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonFlashReframeRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonFlashReframeData = {
  body: LumaPhotonFlashReframeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon/flash/reframe";
};

export type PostFalAiLumaPhotonFlashReframeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonFlashReframeResponse =
  PostFalAiLumaPhotonFlashReframeResponses[keyof PostFalAiLumaPhotonFlashReframeResponses];

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/reframe/requests/{request_id}";
};

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonFlashReframeOutput;
};

export type GetFalAiLumaPhotonFlashReframeRequestsByRequestIdResponse =
  GetFalAiLumaPhotonFlashReframeRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonFlashReframeRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonReframeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/reframe/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonReframeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonReframeRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonReframeRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonReframeRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonReframeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/reframe/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonReframeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonReframeRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonReframeRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonReframeRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonReframeData = {
  body: LumaPhotonReframeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon/reframe";
};

export type PostFalAiLumaPhotonReframeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonReframeResponse =
  PostFalAiLumaPhotonReframeResponses[keyof PostFalAiLumaPhotonReframeResponses];

export type GetFalAiLumaPhotonReframeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/reframe/requests/{request_id}";
};

export type GetFalAiLumaPhotonReframeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonReframeOutput;
};

export type GetFalAiLumaPhotonReframeRequestsByRequestIdResponse =
  GetFalAiLumaPhotonReframeRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonReframeRequestsByRequestIdResponses];

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/schnell/redux/requests/{request_id}/status";
};

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdStatusResponse =
  GetFalAiFlux1SchnellReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1SchnellReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1SchnellReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/schnell/redux/requests/{request_id}/cancel";
};

export type PutFalAiFlux1SchnellReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1SchnellReduxRequestsByRequestIdCancelResponse =
  PutFalAiFlux1SchnellReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1SchnellReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1SchnellReduxData = {
  body: Flux1SchnellReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/schnell/redux";
};

export type PostFalAiFlux1SchnellReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1SchnellReduxResponse =
  PostFalAiFlux1SchnellReduxResponses[keyof PostFalAiFlux1SchnellReduxResponses];

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/schnell/redux/requests/{request_id}";
};

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1SchnellReduxOutput;
};

export type GetFalAiFlux1SchnellReduxRequestsByRequestIdResponse =
  GetFalAiFlux1SchnellReduxRequestsByRequestIdResponses[keyof GetFalAiFlux1SchnellReduxRequestsByRequestIdResponses];

export type GetFalAiFlux1DevReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/dev/redux/requests/{request_id}/status";
};

export type GetFalAiFlux1DevReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1DevReduxRequestsByRequestIdStatusResponse =
  GetFalAiFlux1DevReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1DevReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1DevReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/redux/requests/{request_id}/cancel";
};

export type PutFalAiFlux1DevReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1DevReduxRequestsByRequestIdCancelResponse =
  PutFalAiFlux1DevReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1DevReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1DevReduxData = {
  body: Flux1DevReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/dev/redux";
};

export type PostFalAiFlux1DevReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1DevReduxResponse =
  PostFalAiFlux1DevReduxResponses[keyof PostFalAiFlux1DevReduxResponses];

export type GetFalAiFlux1DevReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/redux/requests/{request_id}";
};

export type GetFalAiFlux1DevReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1DevReduxOutput;
};

export type GetFalAiFlux1DevReduxRequestsByRequestIdResponse =
  GetFalAiFlux1DevReduxRequestsByRequestIdResponses[keyof GetFalAiFlux1DevReduxRequestsByRequestIdResponses];

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/dev/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFlux1DevImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1DevImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1DevImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFlux1DevImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1DevImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFlux1DevImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1DevImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1DevImageToImageData = {
  body: Flux1DevImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/dev/image-to-image";
};

export type PostFalAiFlux1DevImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1DevImageToImageResponse =
  PostFalAiFlux1DevImageToImageResponses[keyof PostFalAiFlux1DevImageToImageResponses];

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/image-to-image/requests/{request_id}";
};

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1DevImageToImageOutput;
};

export type GetFalAiFlux1DevImageToImageRequestsByRequestIdResponse =
  GetFalAiFlux1DevImageToImageRequestsByRequestIdResponses[keyof GetFalAiFlux1DevImageToImageRequestsByRequestIdResponses];

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/text-removal/requests/{request_id}/status";
};

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingTextRemovalRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingTextRemovalRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingTextRemovalRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/text-removal/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingTextRemovalRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingTextRemovalRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingTextRemovalRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingTextRemovalRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingTextRemovalData = {
  body: ImageEditingTextRemovalInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/text-removal";
};

export type PostFalAiImageEditingTextRemovalResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingTextRemovalResponse =
  PostFalAiImageEditingTextRemovalResponses[keyof PostFalAiImageEditingTextRemovalResponses];

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/text-removal/requests/{request_id}";
};

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingTextRemovalOutput;
};

export type GetFalAiImageEditingTextRemovalRequestsByRequestIdResponse =
  GetFalAiImageEditingTextRemovalRequestsByRequestIdResponses[keyof GetFalAiImageEditingTextRemovalRequestsByRequestIdResponses];

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/photo-restoration/requests/{request_id}/status";
  };

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingPhotoRestorationRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingPhotoRestorationRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingPhotoRestorationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/photo-restoration/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingPhotoRestorationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingPhotoRestorationRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingPhotoRestorationRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingPhotoRestorationRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingPhotoRestorationData = {
  body: ImageEditingPhotoRestorationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/photo-restoration";
};

export type PostFalAiImageEditingPhotoRestorationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingPhotoRestorationResponse =
  PostFalAiImageEditingPhotoRestorationResponses[keyof PostFalAiImageEditingPhotoRestorationResponses];

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/photo-restoration/requests/{request_id}";
};

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingPhotoRestorationOutput;
};

export type GetFalAiImageEditingPhotoRestorationRequestsByRequestIdResponse =
  GetFalAiImageEditingPhotoRestorationRequestsByRequestIdResponses[keyof GetFalAiImageEditingPhotoRestorationRequestsByRequestIdResponses];

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/weather-effect/requests/{request_id}/status";
};

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingWeatherEffectRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingWeatherEffectRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingWeatherEffectRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/weather-effect/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingWeatherEffectRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingWeatherEffectRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingWeatherEffectRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingWeatherEffectRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingWeatherEffectData = {
  body: ImageEditingWeatherEffectInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/weather-effect";
};

export type PostFalAiImageEditingWeatherEffectResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingWeatherEffectResponse =
  PostFalAiImageEditingWeatherEffectResponses[keyof PostFalAiImageEditingWeatherEffectResponses];

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/weather-effect/requests/{request_id}";
};

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingWeatherEffectOutput;
};

export type GetFalAiImageEditingWeatherEffectRequestsByRequestIdResponse =
  GetFalAiImageEditingWeatherEffectRequestsByRequestIdResponses[keyof GetFalAiImageEditingWeatherEffectRequestsByRequestIdResponses];

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/time-of-day/requests/{request_id}/status";
};

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingTimeOfDayRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingTimeOfDayRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingTimeOfDayRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/time-of-day/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingTimeOfDayRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingTimeOfDayRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingTimeOfDayRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingTimeOfDayRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingTimeOfDayData = {
  body: ImageEditingTimeOfDayInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/time-of-day";
};

export type PostFalAiImageEditingTimeOfDayResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingTimeOfDayResponse =
  PostFalAiImageEditingTimeOfDayResponses[keyof PostFalAiImageEditingTimeOfDayResponses];

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/time-of-day/requests/{request_id}";
};

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingTimeOfDayOutput;
};

export type GetFalAiImageEditingTimeOfDayRequestsByRequestIdResponse =
  GetFalAiImageEditingTimeOfDayRequestsByRequestIdResponses[keyof GetFalAiImageEditingTimeOfDayRequestsByRequestIdResponses];

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/style-transfer/requests/{request_id}/status";
};

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingStyleTransferRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingStyleTransferRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingStyleTransferRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/style-transfer/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingStyleTransferRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingStyleTransferRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingStyleTransferRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingStyleTransferRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingStyleTransferData = {
  body: ImageEditingStyleTransferInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/style-transfer";
};

export type PostFalAiImageEditingStyleTransferResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingStyleTransferResponse =
  PostFalAiImageEditingStyleTransferResponses[keyof PostFalAiImageEditingStyleTransferResponses];

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/style-transfer/requests/{request_id}";
};

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingStyleTransferOutput;
};

export type GetFalAiImageEditingStyleTransferRequestsByRequestIdResponse =
  GetFalAiImageEditingStyleTransferRequestsByRequestIdResponses[keyof GetFalAiImageEditingStyleTransferRequestsByRequestIdResponses];

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/scene-composition/requests/{request_id}/status";
  };

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingSceneCompositionRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingSceneCompositionRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingSceneCompositionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/scene-composition/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingSceneCompositionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingSceneCompositionRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingSceneCompositionRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingSceneCompositionRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingSceneCompositionData = {
  body: ImageEditingSceneCompositionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/scene-composition";
};

export type PostFalAiImageEditingSceneCompositionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingSceneCompositionResponse =
  PostFalAiImageEditingSceneCompositionResponses[keyof PostFalAiImageEditingSceneCompositionResponses];

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/scene-composition/requests/{request_id}";
};

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingSceneCompositionOutput;
};

export type GetFalAiImageEditingSceneCompositionRequestsByRequestIdResponse =
  GetFalAiImageEditingSceneCompositionRequestsByRequestIdResponses[keyof GetFalAiImageEditingSceneCompositionRequestsByRequestIdResponses];

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/professional-photo/requests/{request_id}/status";
  };

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingProfessionalPhotoRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/professional-photo/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingProfessionalPhotoRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingProfessionalPhotoRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingProfessionalPhotoRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingProfessionalPhotoRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingProfessionalPhotoData = {
  body: ImageEditingProfessionalPhotoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/professional-photo";
};

export type PostFalAiImageEditingProfessionalPhotoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingProfessionalPhotoResponse =
  PostFalAiImageEditingProfessionalPhotoResponses[keyof PostFalAiImageEditingProfessionalPhotoResponses];

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/professional-photo/requests/{request_id}";
};

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ImageEditingProfessionalPhotoOutput;
  };

export type GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdResponse =
  GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdResponses[keyof GetFalAiImageEditingProfessionalPhotoRequestsByRequestIdResponses];

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/object-removal/requests/{request_id}/status";
};

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingObjectRemovalRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingObjectRemovalRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingObjectRemovalRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/object-removal/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingObjectRemovalRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingObjectRemovalRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingObjectRemovalRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingObjectRemovalRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingObjectRemovalData = {
  body: ImageEditingObjectRemovalInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/object-removal";
};

export type PostFalAiImageEditingObjectRemovalResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingObjectRemovalResponse =
  PostFalAiImageEditingObjectRemovalResponses[keyof PostFalAiImageEditingObjectRemovalResponses];

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/object-removal/requests/{request_id}";
};

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingObjectRemovalOutput;
};

export type GetFalAiImageEditingObjectRemovalRequestsByRequestIdResponse =
  GetFalAiImageEditingObjectRemovalRequestsByRequestIdResponses[keyof GetFalAiImageEditingObjectRemovalRequestsByRequestIdResponses];

export type GetFalAiImageEditingHairChangeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/hair-change/requests/{request_id}/status";
};

export type GetFalAiImageEditingHairChangeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingHairChangeRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingHairChangeRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingHairChangeRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingHairChangeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/hair-change/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingHairChangeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingHairChangeRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingHairChangeRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingHairChangeRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingHairChangeData = {
  body: ImageEditingHairChangeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/hair-change";
};

export type PostFalAiImageEditingHairChangeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingHairChangeResponse =
  PostFalAiImageEditingHairChangeResponses[keyof PostFalAiImageEditingHairChangeResponses];

export type GetFalAiImageEditingHairChangeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/hair-change/requests/{request_id}";
};

export type GetFalAiImageEditingHairChangeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingHairChangeOutput;
};

export type GetFalAiImageEditingHairChangeRequestsByRequestIdResponse =
  GetFalAiImageEditingHairChangeRequestsByRequestIdResponses[keyof GetFalAiImageEditingHairChangeRequestsByRequestIdResponses];

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/face-enhancement/requests/{request_id}/status";
};

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingFaceEnhancementRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingFaceEnhancementRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingFaceEnhancementRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/face-enhancement/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingFaceEnhancementRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingFaceEnhancementRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingFaceEnhancementRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingFaceEnhancementRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingFaceEnhancementData = {
  body: ImageEditingFaceEnhancementInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/face-enhancement";
};

export type PostFalAiImageEditingFaceEnhancementResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingFaceEnhancementResponse =
  PostFalAiImageEditingFaceEnhancementResponses[keyof PostFalAiImageEditingFaceEnhancementResponses];

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/face-enhancement/requests/{request_id}";
};

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingFaceEnhancementOutput;
};

export type GetFalAiImageEditingFaceEnhancementRequestsByRequestIdResponse =
  GetFalAiImageEditingFaceEnhancementRequestsByRequestIdResponses[keyof GetFalAiImageEditingFaceEnhancementRequestsByRequestIdResponses];

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/expression-change/requests/{request_id}/status";
  };

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingExpressionChangeRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingExpressionChangeRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingExpressionChangeRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/expression-change/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingExpressionChangeRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingExpressionChangeRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingExpressionChangeRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingExpressionChangeRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingExpressionChangeData = {
  body: ImageEditingExpressionChangeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/expression-change";
};

export type PostFalAiImageEditingExpressionChangeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingExpressionChangeResponse =
  PostFalAiImageEditingExpressionChangeResponses[keyof PostFalAiImageEditingExpressionChangeResponses];

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/expression-change/requests/{request_id}";
};

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingExpressionChangeOutput;
};

export type GetFalAiImageEditingExpressionChangeRequestsByRequestIdResponse =
  GetFalAiImageEditingExpressionChangeRequestsByRequestIdResponses[keyof GetFalAiImageEditingExpressionChangeRequestsByRequestIdResponses];

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/color-correction/requests/{request_id}/status";
};

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingColorCorrectionRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingColorCorrectionRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingColorCorrectionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/color-correction/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingColorCorrectionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingColorCorrectionRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingColorCorrectionRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingColorCorrectionRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingColorCorrectionData = {
  body: ImageEditingColorCorrectionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/color-correction";
};

export type PostFalAiImageEditingColorCorrectionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingColorCorrectionResponse =
  PostFalAiImageEditingColorCorrectionResponses[keyof PostFalAiImageEditingColorCorrectionResponses];

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/color-correction/requests/{request_id}";
};

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingColorCorrectionOutput;
};

export type GetFalAiImageEditingColorCorrectionRequestsByRequestIdResponse =
  GetFalAiImageEditingColorCorrectionRequestsByRequestIdResponses[keyof GetFalAiImageEditingColorCorrectionRequestsByRequestIdResponses];

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/cartoonify/requests/{request_id}/status";
};

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingCartoonifyRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingCartoonifyRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingCartoonifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/cartoonify/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingCartoonifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageEditingCartoonifyRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingCartoonifyRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingCartoonifyRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingCartoonifyData = {
  body: ImageEditingCartoonifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/cartoonify";
};

export type PostFalAiImageEditingCartoonifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingCartoonifyResponse =
  PostFalAiImageEditingCartoonifyResponses[keyof PostFalAiImageEditingCartoonifyResponses];

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/cartoonify/requests/{request_id}";
};

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingCartoonifyOutput;
};

export type GetFalAiImageEditingCartoonifyRequestsByRequestIdResponse =
  GetFalAiImageEditingCartoonifyRequestsByRequestIdResponses[keyof GetFalAiImageEditingCartoonifyRequestsByRequestIdResponses];

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-editing/background-change/requests/{request_id}/status";
  };

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingBackgroundChangeRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingBackgroundChangeRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingBackgroundChangeRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-editing/background-change/requests/{request_id}/cancel";
  };

export type PutFalAiImageEditingBackgroundChangeRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingBackgroundChangeRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingBackgroundChangeRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingBackgroundChangeRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingBackgroundChangeData = {
  body: ImageEditingBackgroundChangeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/background-change";
};

export type PostFalAiImageEditingBackgroundChangeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingBackgroundChangeResponse =
  PostFalAiImageEditingBackgroundChangeResponses[keyof PostFalAiImageEditingBackgroundChangeResponses];

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/background-change/requests/{request_id}";
};

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingBackgroundChangeOutput;
};

export type GetFalAiImageEditingBackgroundChangeRequestsByRequestIdResponse =
  GetFalAiImageEditingBackgroundChangeRequestsByRequestIdResponses[keyof GetFalAiImageEditingBackgroundChangeRequestsByRequestIdResponses];

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-editing/age-progression/requests/{request_id}/status";
};

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdStatusResponse =
  GetFalAiImageEditingAgeProgressionRequestsByRequestIdStatusResponses[keyof GetFalAiImageEditingAgeProgressionRequestsByRequestIdStatusResponses];

export type PutFalAiImageEditingAgeProgressionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/age-progression/requests/{request_id}/cancel";
};

export type PutFalAiImageEditingAgeProgressionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageEditingAgeProgressionRequestsByRequestIdCancelResponse =
  PutFalAiImageEditingAgeProgressionRequestsByRequestIdCancelResponses[keyof PutFalAiImageEditingAgeProgressionRequestsByRequestIdCancelResponses];

export type PostFalAiImageEditingAgeProgressionData = {
  body: ImageEditingAgeProgressionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-editing/age-progression";
};

export type PostFalAiImageEditingAgeProgressionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageEditingAgeProgressionResponse =
  PostFalAiImageEditingAgeProgressionResponses[keyof PostFalAiImageEditingAgeProgressionResponses];

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-editing/age-progression/requests/{request_id}";
};

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageEditingAgeProgressionOutput;
};

export type GetFalAiImageEditingAgeProgressionRequestsByRequestIdResponse =
  GetFalAiImageEditingAgeProgressionRequestsByRequestIdResponses[keyof GetFalAiImageEditingAgeProgressionRequestsByRequestIdResponses];

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/kontext/max/multi/requests/{request_id}/status";
};

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextMaxMultiRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextMaxMultiRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextMaxMultiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/multi/requests/{request_id}/cancel";
};

export type PutFalAiFluxProKontextMaxMultiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProKontextMaxMultiRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextMaxMultiRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextMaxMultiRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextMaxMultiData = {
  body: FluxProKontextMaxMultiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/multi";
};

export type PostFalAiFluxProKontextMaxMultiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextMaxMultiResponse =
  PostFalAiFluxProKontextMaxMultiResponses[keyof PostFalAiFluxProKontextMaxMultiResponses];

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/multi/requests/{request_id}";
};

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextMaxMultiOutput;
};

export type GetFalAiFluxProKontextMaxMultiRequestsByRequestIdResponse =
  GetFalAiFluxProKontextMaxMultiRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextMaxMultiRequestsByRequestIdResponses];

export type GetFalAiFluxProKontextMultiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/kontext/multi/requests/{request_id}/status";
};

export type GetFalAiFluxProKontextMultiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProKontextMultiRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextMultiRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextMultiRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextMultiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/multi/requests/{request_id}/cancel";
};

export type PutFalAiFluxProKontextMultiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProKontextMultiRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextMultiRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextMultiRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextMultiData = {
  body: FluxProKontextMultiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext/multi";
};

export type PostFalAiFluxProKontextMultiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextMultiResponse =
  PostFalAiFluxProKontextMultiResponses[keyof PostFalAiFluxProKontextMultiResponses];

export type GetFalAiFluxProKontextMultiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/multi/requests/{request_id}";
};

export type GetFalAiFluxProKontextMultiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextMultiOutput;
};

export type GetFalAiFluxProKontextMultiRequestsByRequestIdResponse =
  GetFalAiFluxProKontextMultiRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextMultiRequestsByRequestIdResponses];

export type GetFalAiFluxProKontextMaxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/kontext/max/requests/{request_id}/status";
};

export type GetFalAiFluxProKontextMaxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProKontextMaxRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextMaxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextMaxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextMaxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/requests/{request_id}/cancel";
};

export type PutFalAiFluxProKontextMaxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProKontextMaxRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextMaxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextMaxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextMaxData = {
  body: FluxProKontextMaxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max";
};

export type PostFalAiFluxProKontextMaxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextMaxResponse =
  PostFalAiFluxProKontextMaxResponses[keyof PostFalAiFluxProKontextMaxResponses];

export type GetFalAiFluxProKontextMaxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/requests/{request_id}";
};

export type GetFalAiFluxProKontextMaxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextMaxOutput;
};

export type GetFalAiFluxProKontextMaxRequestsByRequestIdResponse =
  GetFalAiFluxProKontextMaxRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextMaxRequestsByRequestIdResponses];

export type GetFalAiFluxKontextDevRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-kontext/dev/requests/{request_id}/status";
};

export type GetFalAiFluxKontextDevRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKontextDevRequestsByRequestIdStatusResponse =
  GetFalAiFluxKontextDevRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKontextDevRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKontextDevRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext/dev/requests/{request_id}/cancel";
};

export type PutFalAiFluxKontextDevRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKontextDevRequestsByRequestIdCancelResponse =
  PutFalAiFluxKontextDevRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKontextDevRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKontextDevData = {
  body: FluxKontextDevInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-kontext/dev";
};

export type PostFalAiFluxKontextDevResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKontextDevResponse =
  PostFalAiFluxKontextDevResponses[keyof PostFalAiFluxKontextDevResponses];

export type GetFalAiFluxKontextDevRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext/dev/requests/{request_id}";
};

export type GetFalAiFluxKontextDevRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKontextDevOutput;
};

export type GetFalAiFluxKontextDevRequestsByRequestIdResponse =
  GetFalAiFluxKontextDevRequestsByRequestIdResponses[keyof GetFalAiFluxKontextDevRequestsByRequestIdResponses];

export type GetFalAiBagelEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bagel/edit/requests/{request_id}/status";
};

export type GetFalAiBagelEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBagelEditRequestsByRequestIdStatusResponse =
  GetFalAiBagelEditRequestsByRequestIdStatusResponses[keyof GetFalAiBagelEditRequestsByRequestIdStatusResponses];

export type PutFalAiBagelEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bagel/edit/requests/{request_id}/cancel";
};

export type PutFalAiBagelEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBagelEditRequestsByRequestIdCancelResponse =
  PutFalAiBagelEditRequestsByRequestIdCancelResponses[keyof PutFalAiBagelEditRequestsByRequestIdCancelResponses];

export type PostFalAiBagelEditData = {
  body: BagelEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bagel/edit";
};

export type PostFalAiBagelEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBagelEditResponse =
  PostFalAiBagelEditResponses[keyof PostFalAiBagelEditResponses];

export type GetFalAiBagelEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bagel/edit/requests/{request_id}";
};

export type GetFalAiBagelEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BagelEditOutput;
};

export type GetFalAiBagelEditRequestsByRequestIdResponse =
  GetFalAiBagelEditRequestsByRequestIdResponses[keyof GetFalAiBagelEditRequestsByRequestIdResponses];

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/smoretalk-ai/rembg-enhance/requests/{request_id}/status";
};

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdStatusResponse =
  GetSmoretalkAiRembgEnhanceRequestsByRequestIdStatusResponses[keyof GetSmoretalkAiRembgEnhanceRequestsByRequestIdStatusResponses];

export type PutSmoretalkAiRembgEnhanceRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/smoretalk-ai/rembg-enhance/requests/{request_id}/cancel";
};

export type PutSmoretalkAiRembgEnhanceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutSmoretalkAiRembgEnhanceRequestsByRequestIdCancelResponse =
  PutSmoretalkAiRembgEnhanceRequestsByRequestIdCancelResponses[keyof PutSmoretalkAiRembgEnhanceRequestsByRequestIdCancelResponses];

export type PostSmoretalkAiRembgEnhanceData = {
  body: RembgEnhanceInput;
  path?: never;
  query?: never;
  url: "/smoretalk-ai/rembg-enhance";
};

export type PostSmoretalkAiRembgEnhanceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostSmoretalkAiRembgEnhanceResponse =
  PostSmoretalkAiRembgEnhanceResponses[keyof PostSmoretalkAiRembgEnhanceResponses];

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/smoretalk-ai/rembg-enhance/requests/{request_id}";
};

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RembgEnhanceOutput;
};

export type GetSmoretalkAiRembgEnhanceRequestsByRequestIdResponse =
  GetSmoretalkAiRembgEnhanceRequestsByRequestIdResponses[keyof GetSmoretalkAiRembgEnhanceRequestsByRequestIdResponses];

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft/upscale/creative/requests/{request_id}/status";
};

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdStatusResponse =
  GetFalAiRecraftUpscaleCreativeRequestsByRequestIdStatusResponses[keyof GetFalAiRecraftUpscaleCreativeRequestsByRequestIdStatusResponses];

export type PutFalAiRecraftUpscaleCreativeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/upscale/creative/requests/{request_id}/cancel";
};

export type PutFalAiRecraftUpscaleCreativeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraftUpscaleCreativeRequestsByRequestIdCancelResponse =
  PutFalAiRecraftUpscaleCreativeRequestsByRequestIdCancelResponses[keyof PutFalAiRecraftUpscaleCreativeRequestsByRequestIdCancelResponses];

export type PostFalAiRecraftUpscaleCreativeData = {
  body: RecraftUpscaleCreativeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft/upscale/creative";
};

export type PostFalAiRecraftUpscaleCreativeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraftUpscaleCreativeResponse =
  PostFalAiRecraftUpscaleCreativeResponses[keyof PostFalAiRecraftUpscaleCreativeResponses];

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/upscale/creative/requests/{request_id}";
};

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RecraftUpscaleCreativeOutput;
};

export type GetFalAiRecraftUpscaleCreativeRequestsByRequestIdResponse =
  GetFalAiRecraftUpscaleCreativeRequestsByRequestIdResponses[keyof GetFalAiRecraftUpscaleCreativeRequestsByRequestIdResponses];

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft/upscale/crisp/requests/{request_id}/status";
};

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdStatusResponse =
  GetFalAiRecraftUpscaleCrispRequestsByRequestIdStatusResponses[keyof GetFalAiRecraftUpscaleCrispRequestsByRequestIdStatusResponses];

export type PutFalAiRecraftUpscaleCrispRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/upscale/crisp/requests/{request_id}/cancel";
};

export type PutFalAiRecraftUpscaleCrispRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraftUpscaleCrispRequestsByRequestIdCancelResponse =
  PutFalAiRecraftUpscaleCrispRequestsByRequestIdCancelResponses[keyof PutFalAiRecraftUpscaleCrispRequestsByRequestIdCancelResponses];

export type PostFalAiRecraftUpscaleCrispData = {
  body: RecraftUpscaleCrispInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft/upscale/crisp";
};

export type PostFalAiRecraftUpscaleCrispResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraftUpscaleCrispResponse =
  PostFalAiRecraftUpscaleCrispResponses[keyof PostFalAiRecraftUpscaleCrispResponses];

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/upscale/crisp/requests/{request_id}";
};

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RecraftUpscaleCrispOutput;
};

export type GetFalAiRecraftUpscaleCrispRequestsByRequestIdResponse =
  GetFalAiRecraftUpscaleCrispRequestsByRequestIdResponses[keyof GetFalAiRecraftUpscaleCrispRequestsByRequestIdResponses];

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft/v3/image-to-image/requests/{request_id}/status";
};

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiRecraftV3ImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiRecraftV3ImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiRecraftV3ImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/v3/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiRecraftV3ImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraftV3ImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiRecraftV3ImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiRecraftV3ImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiRecraftV3ImageToImageData = {
  body: RecraftV3ImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft/v3/image-to-image";
};

export type PostFalAiRecraftV3ImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraftV3ImageToImageResponse =
  PostFalAiRecraftV3ImageToImageResponses[keyof PostFalAiRecraftV3ImageToImageResponses];

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/v3/image-to-image/requests/{request_id}";
};

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RecraftV3ImageToImageOutput;
};

export type GetFalAiRecraftV3ImageToImageRequestsByRequestIdResponse =
  GetFalAiRecraftV3ImageToImageRequestsByRequestIdResponses[keyof GetFalAiRecraftV3ImageToImageRequestsByRequestIdResponses];

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/minimax/image-01/subject-reference/requests/{request_id}/status";
  };

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/minimax/image-01/subject-reference/requests/{request_id}/cancel";
  };

export type PutFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxImage01SubjectReferenceData = {
  body: MinimaxImage01SubjectReferenceInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/image-01/subject-reference";
};

export type PostFalAiMinimaxImage01SubjectReferenceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxImage01SubjectReferenceResponse =
  PostFalAiMinimaxImage01SubjectReferenceResponses[keyof PostFalAiMinimaxImage01SubjectReferenceResponses];

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/image-01/subject-reference/requests/{request_id}";
};

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: MinimaxImage01SubjectReferenceOutput;
  };

export type GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdResponse =
  GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdResponses[keyof GetFalAiMinimaxImage01SubjectReferenceRequestsByRequestIdResponses];

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hidream-i1-full/image-to-image/requests/{request_id}/status";
};

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiHidreamI1FullImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiHidreamI1FullImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiHidreamI1FullImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-full/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiHidreamI1FullImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiHidreamI1FullImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiHidreamI1FullImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiHidreamI1FullImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiHidreamI1FullImageToImageData = {
  body: HidreamI1FullImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hidream-i1-full/image-to-image";
};

export type PostFalAiHidreamI1FullImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHidreamI1FullImageToImageResponse =
  PostFalAiHidreamI1FullImageToImageResponses[keyof PostFalAiHidreamI1FullImageToImageResponses];

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-full/image-to-image/requests/{request_id}";
};

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HidreamI1FullImageToImageOutput;
};

export type GetFalAiHidreamI1FullImageToImageRequestsByRequestIdResponse =
  GetFalAiHidreamI1FullImageToImageRequestsByRequestIdResponses[keyof GetFalAiHidreamI1FullImageToImageRequestsByRequestIdResponses];

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v3/reframe/requests/{request_id}/status";
};

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV3ReframeRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV3ReframeRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV3ReframeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/reframe/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV3ReframeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV3ReframeRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV3ReframeRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV3ReframeRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV3ReframeData = {
  body: IdeogramV3ReframeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v3/reframe";
};

export type PostFalAiIdeogramV3ReframeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV3ReframeResponse =
  PostFalAiIdeogramV3ReframeResponses[keyof PostFalAiIdeogramV3ReframeResponses];

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/reframe/requests/{request_id}";
};

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV3ReframeOutput;
};

export type GetFalAiIdeogramV3ReframeRequestsByRequestIdResponse =
  GetFalAiIdeogramV3ReframeRequestsByRequestIdResponses[keyof GetFalAiIdeogramV3ReframeRequestsByRequestIdResponses];

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v3/replace-background/requests/{request_id}/status";
};

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/replace-background/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV3ReplaceBackgroundData = {
  body: IdeogramV3ReplaceBackgroundInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v3/replace-background";
};

export type PostFalAiIdeogramV3ReplaceBackgroundResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV3ReplaceBackgroundResponse =
  PostFalAiIdeogramV3ReplaceBackgroundResponses[keyof PostFalAiIdeogramV3ReplaceBackgroundResponses];

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/replace-background/requests/{request_id}";
};

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV3ReplaceBackgroundOutput;
};

export type GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdResponse =
  GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdResponses[keyof GetFalAiIdeogramV3ReplaceBackgroundRequestsByRequestIdResponses];

export type GetFalAiIdeogramV3RemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v3/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramV3RemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV3RemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV3RemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV3RemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV3RemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV3RemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV3RemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV3RemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV3RemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV3RemixData = {
  body: IdeogramV3RemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v3/remix";
};

export type PostFalAiIdeogramV3RemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV3RemixResponse =
  PostFalAiIdeogramV3RemixResponses[keyof PostFalAiIdeogramV3RemixResponses];

export type GetFalAiIdeogramV3RemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/remix/requests/{request_id}";
};

export type GetFalAiIdeogramV3RemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV3RemixOutput;
};

export type GetFalAiIdeogramV3RemixRequestsByRequestIdResponse =
  GetFalAiIdeogramV3RemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramV3RemixRequestsByRequestIdResponses];

export type GetFalAiIdeogramV3EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v3/edit/requests/{request_id}/status";
};

export type GetFalAiIdeogramV3EditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV3EditRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV3EditRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV3EditRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV3EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/edit/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV3EditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV3EditRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV3EditRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV3EditRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV3EditData = {
  body: IdeogramV3EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v3/edit";
};

export type PostFalAiIdeogramV3EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV3EditResponse =
  PostFalAiIdeogramV3EditResponses[keyof PostFalAiIdeogramV3EditResponses];

export type GetFalAiIdeogramV3EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/edit/requests/{request_id}";
};

export type GetFalAiIdeogramV3EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV3EditOutput;
};

export type GetFalAiIdeogramV3EditRequestsByRequestIdResponse =
  GetFalAiIdeogramV3EditRequestsByRequestIdResponses[keyof GetFalAiIdeogramV3EditRequestsByRequestIdResponses];

export type GetFalAiStep1xEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/step1x-edit/requests/{request_id}/status";
};

export type GetFalAiStep1xEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStep1xEditRequestsByRequestIdStatusResponse =
  GetFalAiStep1xEditRequestsByRequestIdStatusResponses[keyof GetFalAiStep1xEditRequestsByRequestIdStatusResponses];

export type PutFalAiStep1xEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/step1x-edit/requests/{request_id}/cancel";
};

export type PutFalAiStep1xEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStep1xEditRequestsByRequestIdCancelResponse =
  PutFalAiStep1xEditRequestsByRequestIdCancelResponses[keyof PutFalAiStep1xEditRequestsByRequestIdCancelResponses];

export type PostFalAiStep1xEditData = {
  body: Step1xEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/step1x-edit";
};

export type PostFalAiStep1xEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStep1xEditResponse =
  PostFalAiStep1xEditResponses[keyof PostFalAiStep1xEditResponses];

export type GetFalAiStep1xEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/step1x-edit/requests/{request_id}";
};

export type GetFalAiStep1xEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Step1xEditOutput;
};

export type GetFalAiStep1xEditRequestsByRequestIdResponse =
  GetFalAiStep1xEditRequestsByRequestIdResponses[keyof GetFalAiStep1xEditRequestsByRequestIdResponses];

export type GetFalAiImage2SvgRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image2svg/requests/{request_id}/status";
};

export type GetFalAiImage2SvgRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImage2SvgRequestsByRequestIdStatusResponse =
  GetFalAiImage2SvgRequestsByRequestIdStatusResponses[keyof GetFalAiImage2SvgRequestsByRequestIdStatusResponses];

export type PutFalAiImage2SvgRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image2svg/requests/{request_id}/cancel";
};

export type PutFalAiImage2SvgRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImage2SvgRequestsByRequestIdCancelResponse =
  PutFalAiImage2SvgRequestsByRequestIdCancelResponses[keyof PutFalAiImage2SvgRequestsByRequestIdCancelResponses];

export type PostFalAiImage2SvgData = {
  body: Image2SvgInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image2svg";
};

export type PostFalAiImage2SvgResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImage2SvgResponse =
  PostFalAiImage2SvgResponses[keyof PostFalAiImage2SvgResponses];

export type GetFalAiImage2SvgRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image2svg/requests/{request_id}";
};

export type GetFalAiImage2SvgRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Image2SvgOutput;
};

export type GetFalAiImage2SvgRequestsByRequestIdResponse =
  GetFalAiImage2SvgRequestsByRequestIdResponses[keyof GetFalAiImage2SvgRequestsByRequestIdResponses];

export type GetFalAiUnoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/uno/requests/{request_id}/status";
};

export type GetFalAiUnoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiUnoRequestsByRequestIdStatusResponse =
  GetFalAiUnoRequestsByRequestIdStatusResponses[keyof GetFalAiUnoRequestsByRequestIdStatusResponses];

export type PutFalAiUnoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/uno/requests/{request_id}/cancel";
};

export type PutFalAiUnoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiUnoRequestsByRequestIdCancelResponse =
  PutFalAiUnoRequestsByRequestIdCancelResponses[keyof PutFalAiUnoRequestsByRequestIdCancelResponses];

export type PostFalAiUnoData = {
  body: UnoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/uno";
};

export type PostFalAiUnoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiUnoResponse =
  PostFalAiUnoResponses[keyof PostFalAiUnoResponses];

export type GetFalAiUnoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/uno/requests/{request_id}";
};

export type GetFalAiUnoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: UnoOutput;
};

export type GetFalAiUnoRequestsByRequestIdResponse =
  GetFalAiUnoRequestsByRequestIdResponses[keyof GetFalAiUnoRequestsByRequestIdResponses];

export type GetFalAiGptImage1EditImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1/edit-image/requests/{request_id}/status";
};

export type GetFalAiGptImage1EditImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage1EditImageRequestsByRequestIdStatusResponse =
  GetFalAiGptImage1EditImageRequestsByRequestIdStatusResponses[keyof GetFalAiGptImage1EditImageRequestsByRequestIdStatusResponses];

export type PutFalAiGptImage1EditImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1/edit-image/requests/{request_id}/cancel";
};

export type PutFalAiGptImage1EditImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage1EditImageRequestsByRequestIdCancelResponse =
  PutFalAiGptImage1EditImageRequestsByRequestIdCancelResponses[keyof PutFalAiGptImage1EditImageRequestsByRequestIdCancelResponses];

export type PostFalAiGptImage1EditImageData = {
  body: GptImage1EditImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1/edit-image";
};

export type PostFalAiGptImage1EditImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage1EditImageResponse =
  PostFalAiGptImage1EditImageResponses[keyof PostFalAiGptImage1EditImageResponses];

export type GetFalAiGptImage1EditImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1/edit-image/requests/{request_id}";
};

export type GetFalAiGptImage1EditImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage1EditImageOutput;
};

export type GetFalAiGptImage1EditImageRequestsByRequestIdResponse =
  GetFalAiGptImage1EditImageRequestsByRequestIdResponses[keyof GetFalAiGptImage1EditImageRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux-lora/inpainting/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux-lora/inpainting/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxLoraInpaintingData = {
  body: JuggernautFluxLoraInpaintingInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux-lora/inpainting";
};

export type PostRundiffusionFalJuggernautFluxLoraInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxLoraInpaintingResponse =
  PostRundiffusionFalJuggernautFluxLoraInpaintingResponses[keyof PostRundiffusionFalJuggernautFluxLoraInpaintingResponses];

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux-lora/inpainting/requests/{request_id}";
  };

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: JuggernautFluxLoraInpaintingOutput;
  };

export type GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxLoraInpaintingRequestsByRequestIdResponses];

export type GetFalAiFashnTryonV15RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fashn/tryon/v1.5/requests/{request_id}/status";
};

export type GetFalAiFashnTryonV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFashnTryonV15RequestsByRequestIdStatusResponse =
  GetFalAiFashnTryonV15RequestsByRequestIdStatusResponses[keyof GetFalAiFashnTryonV15RequestsByRequestIdStatusResponses];

export type PutFalAiFashnTryonV15RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.5/requests/{request_id}/cancel";
};

export type PutFalAiFashnTryonV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFashnTryonV15RequestsByRequestIdCancelResponse =
  PutFalAiFashnTryonV15RequestsByRequestIdCancelResponses[keyof PutFalAiFashnTryonV15RequestsByRequestIdCancelResponses];

export type PostFalAiFashnTryonV15Data = {
  body: FashnTryonV15Input;
  path?: never;
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.5";
};

export type PostFalAiFashnTryonV15Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFashnTryonV15Response =
  PostFalAiFashnTryonV15Responses[keyof PostFalAiFashnTryonV15Responses];

export type GetFalAiFashnTryonV15RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fashn/tryon/v1.5/requests/{request_id}";
};

export type GetFalAiFashnTryonV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FashnTryonV15Output;
};

export type GetFalAiFashnTryonV15RequestsByRequestIdResponse =
  GetFalAiFashnTryonV15RequestsByRequestIdResponses[keyof GetFalAiFashnTryonV15RequestsByRequestIdResponses];

export type GetFalAiPlushifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/plushify/requests/{request_id}/status";
};

export type GetFalAiPlushifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPlushifyRequestsByRequestIdStatusResponse =
  GetFalAiPlushifyRequestsByRequestIdStatusResponses[keyof GetFalAiPlushifyRequestsByRequestIdStatusResponses];

export type PutFalAiPlushifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/plushify/requests/{request_id}/cancel";
};

export type PutFalAiPlushifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPlushifyRequestsByRequestIdCancelResponse =
  PutFalAiPlushifyRequestsByRequestIdCancelResponses[keyof PutFalAiPlushifyRequestsByRequestIdCancelResponses];

export type PostFalAiPlushifyData = {
  body: PlushifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/plushify";
};

export type PostFalAiPlushifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPlushifyResponse =
  PostFalAiPlushifyResponses[keyof PostFalAiPlushifyResponses];

export type GetFalAiPlushifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/plushify/requests/{request_id}";
};

export type GetFalAiPlushifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PlushifyOutput;
};

export type GetFalAiPlushifyRequestsByRequestIdResponse =
  GetFalAiPlushifyRequestsByRequestIdResponses[keyof GetFalAiPlushifyRequestsByRequestIdResponses];

export type GetFalAiInstantCharacterRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/instant-character/requests/{request_id}/status";
};

export type GetFalAiInstantCharacterRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiInstantCharacterRequestsByRequestIdStatusResponse =
  GetFalAiInstantCharacterRequestsByRequestIdStatusResponses[keyof GetFalAiInstantCharacterRequestsByRequestIdStatusResponses];

export type PutFalAiInstantCharacterRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/instant-character/requests/{request_id}/cancel";
};

export type PutFalAiInstantCharacterRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiInstantCharacterRequestsByRequestIdCancelResponse =
  PutFalAiInstantCharacterRequestsByRequestIdCancelResponses[keyof PutFalAiInstantCharacterRequestsByRequestIdCancelResponses];

export type PostFalAiInstantCharacterData = {
  body: InstantCharacterInput;
  path?: never;
  query?: never;
  url: "/fal-ai/instant-character";
};

export type PostFalAiInstantCharacterResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiInstantCharacterResponse =
  PostFalAiInstantCharacterResponses[keyof PostFalAiInstantCharacterResponses];

export type GetFalAiInstantCharacterRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/instant-character/requests/{request_id}";
};

export type GetFalAiInstantCharacterRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: InstantCharacterOutput;
};

export type GetFalAiInstantCharacterRequestsByRequestIdResponse =
  GetFalAiInstantCharacterRequestsByRequestIdResponses[keyof GetFalAiInstantCharacterRequestsByRequestIdResponses];

export type GetFalAiCartoonifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/cartoonify/requests/{request_id}/status";
};

export type GetFalAiCartoonifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCartoonifyRequestsByRequestIdStatusResponse =
  GetFalAiCartoonifyRequestsByRequestIdStatusResponses[keyof GetFalAiCartoonifyRequestsByRequestIdStatusResponses];

export type PutFalAiCartoonifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cartoonify/requests/{request_id}/cancel";
};

export type PutFalAiCartoonifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCartoonifyRequestsByRequestIdCancelResponse =
  PutFalAiCartoonifyRequestsByRequestIdCancelResponses[keyof PutFalAiCartoonifyRequestsByRequestIdCancelResponses];

export type PostFalAiCartoonifyData = {
  body: CartoonifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/cartoonify";
};

export type PostFalAiCartoonifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCartoonifyResponse =
  PostFalAiCartoonifyResponses[keyof PostFalAiCartoonifyResponses];

export type GetFalAiCartoonifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cartoonify/requests/{request_id}";
};

export type GetFalAiCartoonifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CartoonifyOutput;
};

export type GetFalAiCartoonifyRequestsByRequestIdResponse =
  GetFalAiCartoonifyRequestsByRequestIdResponses[keyof GetFalAiCartoonifyRequestsByRequestIdResponses];

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/finegrain-eraser/mask/requests/{request_id}/status";
};

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdStatusResponse =
  GetFalAiFinegrainEraserMaskRequestsByRequestIdStatusResponses[keyof GetFalAiFinegrainEraserMaskRequestsByRequestIdStatusResponses];

export type PutFalAiFinegrainEraserMaskRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/mask/requests/{request_id}/cancel";
};

export type PutFalAiFinegrainEraserMaskRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFinegrainEraserMaskRequestsByRequestIdCancelResponse =
  PutFalAiFinegrainEraserMaskRequestsByRequestIdCancelResponses[keyof PutFalAiFinegrainEraserMaskRequestsByRequestIdCancelResponses];

export type PostFalAiFinegrainEraserMaskData = {
  body: FinegrainEraserMaskInput;
  path?: never;
  query?: never;
  url: "/fal-ai/finegrain-eraser/mask";
};

export type PostFalAiFinegrainEraserMaskResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFinegrainEraserMaskResponse =
  PostFalAiFinegrainEraserMaskResponses[keyof PostFalAiFinegrainEraserMaskResponses];

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/mask/requests/{request_id}";
};

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FinegrainEraserMaskOutput;
};

export type GetFalAiFinegrainEraserMaskRequestsByRequestIdResponse =
  GetFalAiFinegrainEraserMaskRequestsByRequestIdResponses[keyof GetFalAiFinegrainEraserMaskRequestsByRequestIdResponses];

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/finegrain-eraser/bbox/requests/{request_id}/status";
};

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdStatusResponse =
  GetFalAiFinegrainEraserBboxRequestsByRequestIdStatusResponses[keyof GetFalAiFinegrainEraserBboxRequestsByRequestIdStatusResponses];

export type PutFalAiFinegrainEraserBboxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/bbox/requests/{request_id}/cancel";
};

export type PutFalAiFinegrainEraserBboxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFinegrainEraserBboxRequestsByRequestIdCancelResponse =
  PutFalAiFinegrainEraserBboxRequestsByRequestIdCancelResponses[keyof PutFalAiFinegrainEraserBboxRequestsByRequestIdCancelResponses];

export type PostFalAiFinegrainEraserBboxData = {
  body: FinegrainEraserBboxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/finegrain-eraser/bbox";
};

export type PostFalAiFinegrainEraserBboxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFinegrainEraserBboxResponse =
  PostFalAiFinegrainEraserBboxResponses[keyof PostFalAiFinegrainEraserBboxResponses];

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/bbox/requests/{request_id}";
};

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FinegrainEraserBboxOutput;
};

export type GetFalAiFinegrainEraserBboxRequestsByRequestIdResponse =
  GetFalAiFinegrainEraserBboxRequestsByRequestIdResponses[keyof GetFalAiFinegrainEraserBboxRequestsByRequestIdResponses];

export type GetFalAiFinegrainEraserRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/finegrain-eraser/requests/{request_id}/status";
};

export type GetFalAiFinegrainEraserRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFinegrainEraserRequestsByRequestIdStatusResponse =
  GetFalAiFinegrainEraserRequestsByRequestIdStatusResponses[keyof GetFalAiFinegrainEraserRequestsByRequestIdStatusResponses];

export type PutFalAiFinegrainEraserRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/requests/{request_id}/cancel";
};

export type PutFalAiFinegrainEraserRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFinegrainEraserRequestsByRequestIdCancelResponse =
  PutFalAiFinegrainEraserRequestsByRequestIdCancelResponses[keyof PutFalAiFinegrainEraserRequestsByRequestIdCancelResponses];

export type PostFalAiFinegrainEraserData = {
  body: FinegrainEraserInput;
  path?: never;
  query?: never;
  url: "/fal-ai/finegrain-eraser";
};

export type PostFalAiFinegrainEraserResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFinegrainEraserResponse =
  PostFalAiFinegrainEraserResponses[keyof PostFalAiFinegrainEraserResponses];

export type GetFalAiFinegrainEraserRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/finegrain-eraser/requests/{request_id}";
};

export type GetFalAiFinegrainEraserRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FinegrainEraserOutput;
};

export type GetFalAiFinegrainEraserRequestsByRequestIdResponse =
  GetFalAiFinegrainEraserRequestsByRequestIdResponses[keyof GetFalAiFinegrainEraserRequestsByRequestIdResponses];

export type GetFalAiStarVectorRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/star-vector/requests/{request_id}/status";
};

export type GetFalAiStarVectorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStarVectorRequestsByRequestIdStatusResponse =
  GetFalAiStarVectorRequestsByRequestIdStatusResponses[keyof GetFalAiStarVectorRequestsByRequestIdStatusResponses];

export type PutFalAiStarVectorRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/star-vector/requests/{request_id}/cancel";
};

export type PutFalAiStarVectorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStarVectorRequestsByRequestIdCancelResponse =
  PutFalAiStarVectorRequestsByRequestIdCancelResponses[keyof PutFalAiStarVectorRequestsByRequestIdCancelResponses];

export type PostFalAiStarVectorData = {
  body: StarVectorInput;
  path?: never;
  query?: never;
  url: "/fal-ai/star-vector";
};

export type PostFalAiStarVectorResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStarVectorResponse =
  PostFalAiStarVectorResponses[keyof PostFalAiStarVectorResponses];

export type GetFalAiStarVectorRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/star-vector/requests/{request_id}";
};

export type GetFalAiStarVectorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StarVectorOutput;
};

export type GetFalAiStarVectorRequestsByRequestIdResponse =
  GetFalAiStarVectorRequestsByRequestIdResponses[keyof GetFalAiStarVectorRequestsByRequestIdResponses];

export type GetFalAiGhiblifyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ghiblify/requests/{request_id}/status";
};

export type GetFalAiGhiblifyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGhiblifyRequestsByRequestIdStatusResponse =
  GetFalAiGhiblifyRequestsByRequestIdStatusResponses[keyof GetFalAiGhiblifyRequestsByRequestIdStatusResponses];

export type PutFalAiGhiblifyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ghiblify/requests/{request_id}/cancel";
};

export type PutFalAiGhiblifyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGhiblifyRequestsByRequestIdCancelResponse =
  PutFalAiGhiblifyRequestsByRequestIdCancelResponses[keyof PutFalAiGhiblifyRequestsByRequestIdCancelResponses];

export type PostFalAiGhiblifyData = {
  body: GhiblifyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ghiblify";
};

export type PostFalAiGhiblifyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGhiblifyResponse =
  PostFalAiGhiblifyResponses[keyof PostFalAiGhiblifyResponses];

export type GetFalAiGhiblifyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ghiblify/requests/{request_id}";
};

export type GetFalAiGhiblifyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GhiblifyOutput;
};

export type GetFalAiGhiblifyRequestsByRequestIdResponse =
  GetFalAiGhiblifyRequestsByRequestIdResponses[keyof GetFalAiGhiblifyRequestsByRequestIdResponses];

export type GetFalAiTheraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/thera/requests/{request_id}/status";
};

export type GetFalAiTheraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiTheraRequestsByRequestIdStatusResponse =
  GetFalAiTheraRequestsByRequestIdStatusResponses[keyof GetFalAiTheraRequestsByRequestIdStatusResponses];

export type PutFalAiTheraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/thera/requests/{request_id}/cancel";
};

export type PutFalAiTheraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiTheraRequestsByRequestIdCancelResponse =
  PutFalAiTheraRequestsByRequestIdCancelResponses[keyof PutFalAiTheraRequestsByRequestIdCancelResponses];

export type PostFalAiTheraData = {
  body: TheraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/thera";
};

export type PostFalAiTheraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiTheraResponse =
  PostFalAiTheraResponses[keyof PostFalAiTheraResponses];

export type GetFalAiTheraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/thera/requests/{request_id}";
};

export type GetFalAiTheraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: TheraOutput;
};

export type GetFalAiTheraRequestsByRequestIdResponse =
  GetFalAiTheraRequestsByRequestIdResponses[keyof GetFalAiTheraRequestsByRequestIdResponses];

export type GetFalAiMixDehazeNetRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/mix-dehaze-net/requests/{request_id}/status";
};

export type GetFalAiMixDehazeNetRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMixDehazeNetRequestsByRequestIdStatusResponse =
  GetFalAiMixDehazeNetRequestsByRequestIdStatusResponses[keyof GetFalAiMixDehazeNetRequestsByRequestIdStatusResponses];

export type PutFalAiMixDehazeNetRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/mix-dehaze-net/requests/{request_id}/cancel";
};

export type PutFalAiMixDehazeNetRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMixDehazeNetRequestsByRequestIdCancelResponse =
  PutFalAiMixDehazeNetRequestsByRequestIdCancelResponses[keyof PutFalAiMixDehazeNetRequestsByRequestIdCancelResponses];

export type PostFalAiMixDehazeNetData = {
  body: MixDehazeNetInput;
  path?: never;
  query?: never;
  url: "/fal-ai/mix-dehaze-net";
};

export type PostFalAiMixDehazeNetResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMixDehazeNetResponse =
  PostFalAiMixDehazeNetResponses[keyof PostFalAiMixDehazeNetResponses];

export type GetFalAiMixDehazeNetRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/mix-dehaze-net/requests/{request_id}";
};

export type GetFalAiMixDehazeNetRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MixDehazeNetOutput;
};

export type GetFalAiMixDehazeNetRequestsByRequestIdResponse =
  GetFalAiMixDehazeNetRequestsByRequestIdResponses[keyof GetFalAiMixDehazeNetRequestsByRequestIdResponses];

export type GetFalAiGeminiFlashEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-flash-edit/requests/{request_id}/status";
};

export type GetFalAiGeminiFlashEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGeminiFlashEditRequestsByRequestIdStatusResponse =
  GetFalAiGeminiFlashEditRequestsByRequestIdStatusResponses[keyof GetFalAiGeminiFlashEditRequestsByRequestIdStatusResponses];

export type PutFalAiGeminiFlashEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-flash-edit/requests/{request_id}/cancel";
};

export type PutFalAiGeminiFlashEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGeminiFlashEditRequestsByRequestIdCancelResponse =
  PutFalAiGeminiFlashEditRequestsByRequestIdCancelResponses[keyof PutFalAiGeminiFlashEditRequestsByRequestIdCancelResponses];

export type PostFalAiGeminiFlashEditData = {
  body: GeminiFlashEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-flash-edit";
};

export type PostFalAiGeminiFlashEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGeminiFlashEditResponse =
  PostFalAiGeminiFlashEditResponses[keyof PostFalAiGeminiFlashEditResponses];

export type GetFalAiGeminiFlashEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-flash-edit/requests/{request_id}";
};

export type GetFalAiGeminiFlashEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GeminiFlashEditOutput;
};

export type GetFalAiGeminiFlashEditRequestsByRequestIdResponse =
  GetFalAiGeminiFlashEditRequestsByRequestIdResponses[keyof GetFalAiGeminiFlashEditRequestsByRequestIdResponses];

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-flash-edit/multi/requests/{request_id}/status";
};

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdStatusResponse =
  GetFalAiGeminiFlashEditMultiRequestsByRequestIdStatusResponses[keyof GetFalAiGeminiFlashEditMultiRequestsByRequestIdStatusResponses];

export type PutFalAiGeminiFlashEditMultiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-flash-edit/multi/requests/{request_id}/cancel";
};

export type PutFalAiGeminiFlashEditMultiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGeminiFlashEditMultiRequestsByRequestIdCancelResponse =
  PutFalAiGeminiFlashEditMultiRequestsByRequestIdCancelResponses[keyof PutFalAiGeminiFlashEditMultiRequestsByRequestIdCancelResponses];

export type PostFalAiGeminiFlashEditMultiData = {
  body: GeminiFlashEditMultiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-flash-edit/multi";
};

export type PostFalAiGeminiFlashEditMultiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGeminiFlashEditMultiResponse =
  PostFalAiGeminiFlashEditMultiResponses[keyof PostFalAiGeminiFlashEditMultiResponses];

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-flash-edit/multi/requests/{request_id}";
};

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GeminiFlashEditMultiOutput;
};

export type GetFalAiGeminiFlashEditMultiRequestsByRequestIdResponse =
  GetFalAiGeminiFlashEditMultiRequestsByRequestIdResponses[keyof GetFalAiGeminiFlashEditMultiRequestsByRequestIdResponses];

export type GetFalAiInvisibleWatermarkRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/invisible-watermark/requests/{request_id}/status";
};

export type GetFalAiInvisibleWatermarkRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiInvisibleWatermarkRequestsByRequestIdStatusResponse =
  GetFalAiInvisibleWatermarkRequestsByRequestIdStatusResponses[keyof GetFalAiInvisibleWatermarkRequestsByRequestIdStatusResponses];

export type PutFalAiInvisibleWatermarkRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/invisible-watermark/requests/{request_id}/cancel";
};

export type PutFalAiInvisibleWatermarkRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiInvisibleWatermarkRequestsByRequestIdCancelResponse =
  PutFalAiInvisibleWatermarkRequestsByRequestIdCancelResponses[keyof PutFalAiInvisibleWatermarkRequestsByRequestIdCancelResponses];

export type PostFalAiInvisibleWatermarkData = {
  body: InvisibleWatermarkInput;
  path?: never;
  query?: never;
  url: "/fal-ai/invisible-watermark";
};

export type PostFalAiInvisibleWatermarkResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiInvisibleWatermarkResponse =
  PostFalAiInvisibleWatermarkResponses[keyof PostFalAiInvisibleWatermarkResponses];

export type GetFalAiInvisibleWatermarkRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/invisible-watermark/requests/{request_id}";
};

export type GetFalAiInvisibleWatermarkRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: InvisibleWatermarkOutput;
};

export type GetFalAiInvisibleWatermarkRequestsByRequestIdResponse =
  GetFalAiInvisibleWatermarkRequestsByRequestIdResponses[keyof GetFalAiInvisibleWatermarkRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux/base/image-to-image/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/base/image-to-image/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxBaseImageToImageData = {
  body: JuggernautFluxBaseImageToImageInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/base/image-to-image";
};

export type PostRundiffusionFalJuggernautFluxBaseImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxBaseImageToImageResponse =
  PostRundiffusionFalJuggernautFluxBaseImageToImageResponses[keyof PostRundiffusionFalJuggernautFluxBaseImageToImageResponses];

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/base/image-to-image/requests/{request_id}";
  };

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: JuggernautFluxBaseImageToImageOutput;
  };

export type GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxBaseImageToImageRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux/pro/image-to-image/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/pro/image-to-image/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxProImageToImageData = {
  body: JuggernautFluxProImageToImageInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/pro/image-to-image";
};

export type PostRundiffusionFalJuggernautFluxProImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxProImageToImageResponse =
  PostRundiffusionFalJuggernautFluxProImageToImageResponses[keyof PostRundiffusionFalJuggernautFluxProImageToImageResponses];

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/pro/image-to-image/requests/{request_id}";
  };

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: JuggernautFluxProImageToImageOutput;
  };

export type GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxProImageToImageRequestsByRequestIdResponses];

export type GetFalAiDocresDewarpRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/docres/dewarp/requests/{request_id}/status";
};

export type GetFalAiDocresDewarpRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDocresDewarpRequestsByRequestIdStatusResponse =
  GetFalAiDocresDewarpRequestsByRequestIdStatusResponses[keyof GetFalAiDocresDewarpRequestsByRequestIdStatusResponses];

export type PutFalAiDocresDewarpRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/docres/dewarp/requests/{request_id}/cancel";
};

export type PutFalAiDocresDewarpRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDocresDewarpRequestsByRequestIdCancelResponse =
  PutFalAiDocresDewarpRequestsByRequestIdCancelResponses[keyof PutFalAiDocresDewarpRequestsByRequestIdCancelResponses];

export type PostFalAiDocresDewarpData = {
  body: DocresDewarpInput;
  path?: never;
  query?: never;
  url: "/fal-ai/docres/dewarp";
};

export type PostFalAiDocresDewarpResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDocresDewarpResponse =
  PostFalAiDocresDewarpResponses[keyof PostFalAiDocresDewarpResponses];

export type GetFalAiDocresDewarpRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/docres/dewarp/requests/{request_id}";
};

export type GetFalAiDocresDewarpRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DocresDewarpOutput;
};

export type GetFalAiDocresDewarpRequestsByRequestIdResponse =
  GetFalAiDocresDewarpRequestsByRequestIdResponses[keyof GetFalAiDocresDewarpRequestsByRequestIdResponses];

export type GetFalAiDocresRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/docres/requests/{request_id}/status";
};

export type GetFalAiDocresRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDocresRequestsByRequestIdStatusResponse =
  GetFalAiDocresRequestsByRequestIdStatusResponses[keyof GetFalAiDocresRequestsByRequestIdStatusResponses];

export type PutFalAiDocresRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/docres/requests/{request_id}/cancel";
};

export type PutFalAiDocresRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDocresRequestsByRequestIdCancelResponse =
  PutFalAiDocresRequestsByRequestIdCancelResponses[keyof PutFalAiDocresRequestsByRequestIdCancelResponses];

export type PostFalAiDocresData = {
  body: DocresInput;
  path?: never;
  query?: never;
  url: "/fal-ai/docres";
};

export type PostFalAiDocresResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDocresResponse =
  PostFalAiDocresResponses[keyof PostFalAiDocresResponses];

export type GetFalAiDocresRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/docres/requests/{request_id}";
};

export type GetFalAiDocresRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DocresOutput;
};

export type GetFalAiDocresRequestsByRequestIdResponse =
  GetFalAiDocresRequestsByRequestIdResponses[keyof GetFalAiDocresRequestsByRequestIdResponses];

export type GetFalAiSwin2SrRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/swin2sr/requests/{request_id}/status";
};

export type GetFalAiSwin2SrRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSwin2SrRequestsByRequestIdStatusResponse =
  GetFalAiSwin2SrRequestsByRequestIdStatusResponses[keyof GetFalAiSwin2SrRequestsByRequestIdStatusResponses];

export type PutFalAiSwin2SrRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/swin2sr/requests/{request_id}/cancel";
};

export type PutFalAiSwin2SrRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSwin2SrRequestsByRequestIdCancelResponse =
  PutFalAiSwin2SrRequestsByRequestIdCancelResponses[keyof PutFalAiSwin2SrRequestsByRequestIdCancelResponses];

export type PostFalAiSwin2SrData = {
  body: Swin2SrInput;
  path?: never;
  query?: never;
  url: "/fal-ai/swin2sr";
};

export type PostFalAiSwin2SrResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSwin2SrResponse =
  PostFalAiSwin2SrResponses[keyof PostFalAiSwin2SrResponses];

export type GetFalAiSwin2SrRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/swin2sr/requests/{request_id}";
};

export type GetFalAiSwin2SrRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Swin2SrOutput;
};

export type GetFalAiSwin2SrRequestsByRequestIdResponse =
  GetFalAiSwin2SrRequestsByRequestIdResponses[keyof GetFalAiSwin2SrRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2a/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2aRemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2aRemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2aRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2aRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2aRemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2aRemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2aRemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2aRemixData = {
  body: IdeogramV2aRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2a/remix";
};

export type PostFalAiIdeogramV2aRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2aRemixResponse =
  PostFalAiIdeogramV2aRemixResponses[keyof PostFalAiIdeogramV2aRemixResponses];

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/remix/requests/{request_id}";
};

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2aRemixOutput;
};

export type GetFalAiIdeogramV2aRemixRequestsByRequestIdResponse =
  GetFalAiIdeogramV2aRemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2aRemixRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2a/turbo/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2aTurboRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2aTurboRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2aTurboRemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2aTurboRemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2aTurboRemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2aTurboRemixData = {
  body: IdeogramV2aTurboRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo/remix";
};

export type PostFalAiIdeogramV2aTurboRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2aTurboRemixResponse =
  PostFalAiIdeogramV2aTurboRemixResponses[keyof PostFalAiIdeogramV2aTurboRemixResponses];

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo/remix/requests/{request_id}";
};

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2aTurboRemixOutput;
};

export type GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdResponse =
  GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2aTurboRemixRequestsByRequestIdResponses];

export type GetFalAiEvfSamRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/evf-sam/requests/{request_id}/status";
};

export type GetFalAiEvfSamRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiEvfSamRequestsByRequestIdStatusResponse =
  GetFalAiEvfSamRequestsByRequestIdStatusResponses[keyof GetFalAiEvfSamRequestsByRequestIdStatusResponses];

export type PutFalAiEvfSamRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/evf-sam/requests/{request_id}/cancel";
};

export type PutFalAiEvfSamRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiEvfSamRequestsByRequestIdCancelResponse =
  PutFalAiEvfSamRequestsByRequestIdCancelResponses[keyof PutFalAiEvfSamRequestsByRequestIdCancelResponses];

export type PostFalAiEvfSamData = {
  body: EvfSamInput;
  path?: never;
  query?: never;
  url: "/fal-ai/evf-sam";
};

export type PostFalAiEvfSamResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiEvfSamResponse =
  PostFalAiEvfSamResponses[keyof PostFalAiEvfSamResponses];

export type GetFalAiEvfSamRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/evf-sam/requests/{request_id}";
};

export type GetFalAiEvfSamRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: EvfSamOutput;
};

export type GetFalAiEvfSamRequestsByRequestIdResponse =
  GetFalAiEvfSamRequestsByRequestIdResponses[keyof GetFalAiEvfSamRequestsByRequestIdResponses];

export type GetFalAiDdcolorRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ddcolor/requests/{request_id}/status";
};

export type GetFalAiDdcolorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDdcolorRequestsByRequestIdStatusResponse =
  GetFalAiDdcolorRequestsByRequestIdStatusResponses[keyof GetFalAiDdcolorRequestsByRequestIdStatusResponses];

export type PutFalAiDdcolorRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ddcolor/requests/{request_id}/cancel";
};

export type PutFalAiDdcolorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDdcolorRequestsByRequestIdCancelResponse =
  PutFalAiDdcolorRequestsByRequestIdCancelResponses[keyof PutFalAiDdcolorRequestsByRequestIdCancelResponses];

export type PostFalAiDdcolorData = {
  body: DdcolorInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ddcolor";
};

export type PostFalAiDdcolorResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDdcolorResponse =
  PostFalAiDdcolorResponses[keyof PostFalAiDdcolorResponses];

export type GetFalAiDdcolorRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ddcolor/requests/{request_id}";
};

export type GetFalAiDdcolorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DdcolorOutput;
};

export type GetFalAiDdcolorRequestsByRequestIdResponse =
  GetFalAiDdcolorRequestsByRequestIdResponses[keyof GetFalAiDdcolorRequestsByRequestIdResponses];

export type GetFalAiSam2AutoSegmentRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam2/auto-segment/requests/{request_id}/status";
};

export type GetFalAiSam2AutoSegmentRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSam2AutoSegmentRequestsByRequestIdStatusResponse =
  GetFalAiSam2AutoSegmentRequestsByRequestIdStatusResponses[keyof GetFalAiSam2AutoSegmentRequestsByRequestIdStatusResponses];

export type PutFalAiSam2AutoSegmentRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam2/auto-segment/requests/{request_id}/cancel";
};

export type PutFalAiSam2AutoSegmentRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSam2AutoSegmentRequestsByRequestIdCancelResponse =
  PutFalAiSam2AutoSegmentRequestsByRequestIdCancelResponses[keyof PutFalAiSam2AutoSegmentRequestsByRequestIdCancelResponses];

export type PostFalAiSam2AutoSegmentData = {
  body: Sam2AutoSegmentInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam2/auto-segment";
};

export type PostFalAiSam2AutoSegmentResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSam2AutoSegmentResponse =
  PostFalAiSam2AutoSegmentResponses[keyof PostFalAiSam2AutoSegmentResponses];

export type GetFalAiSam2AutoSegmentRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam2/auto-segment/requests/{request_id}";
};

export type GetFalAiSam2AutoSegmentRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Sam2AutoSegmentOutput;
};

export type GetFalAiSam2AutoSegmentRequestsByRequestIdResponse =
  GetFalAiSam2AutoSegmentRequestsByRequestIdResponses[keyof GetFalAiSam2AutoSegmentRequestsByRequestIdResponses];

export type GetFalAiDrctSuperResolutionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/drct-super-resolution/requests/{request_id}/status";
};

export type GetFalAiDrctSuperResolutionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDrctSuperResolutionRequestsByRequestIdStatusResponse =
  GetFalAiDrctSuperResolutionRequestsByRequestIdStatusResponses[keyof GetFalAiDrctSuperResolutionRequestsByRequestIdStatusResponses];

export type PutFalAiDrctSuperResolutionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/drct-super-resolution/requests/{request_id}/cancel";
};

export type PutFalAiDrctSuperResolutionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDrctSuperResolutionRequestsByRequestIdCancelResponse =
  PutFalAiDrctSuperResolutionRequestsByRequestIdCancelResponses[keyof PutFalAiDrctSuperResolutionRequestsByRequestIdCancelResponses];

export type PostFalAiDrctSuperResolutionData = {
  body: DrctSuperResolutionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/drct-super-resolution";
};

export type PostFalAiDrctSuperResolutionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDrctSuperResolutionResponse =
  PostFalAiDrctSuperResolutionResponses[keyof PostFalAiDrctSuperResolutionResponses];

export type GetFalAiDrctSuperResolutionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/drct-super-resolution/requests/{request_id}";
};

export type GetFalAiDrctSuperResolutionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DrctSuperResolutionOutput;
};

export type GetFalAiDrctSuperResolutionRequestsByRequestIdResponse =
  GetFalAiDrctSuperResolutionRequestsByRequestIdResponses[keyof GetFalAiDrctSuperResolutionRequestsByRequestIdResponses];

export type GetFalAiNafnetDeblurRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nafnet/deblur/requests/{request_id}/status";
};

export type GetFalAiNafnetDeblurRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNafnetDeblurRequestsByRequestIdStatusResponse =
  GetFalAiNafnetDeblurRequestsByRequestIdStatusResponses[keyof GetFalAiNafnetDeblurRequestsByRequestIdStatusResponses];

export type PutFalAiNafnetDeblurRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nafnet/deblur/requests/{request_id}/cancel";
};

export type PutFalAiNafnetDeblurRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNafnetDeblurRequestsByRequestIdCancelResponse =
  PutFalAiNafnetDeblurRequestsByRequestIdCancelResponses[keyof PutFalAiNafnetDeblurRequestsByRequestIdCancelResponses];

export type PostFalAiNafnetDeblurData = {
  body: NafnetDeblurInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nafnet/deblur";
};

export type PostFalAiNafnetDeblurResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNafnetDeblurResponse =
  PostFalAiNafnetDeblurResponses[keyof PostFalAiNafnetDeblurResponses];

export type GetFalAiNafnetDeblurRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nafnet/deblur/requests/{request_id}";
};

export type GetFalAiNafnetDeblurRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NafnetDeblurOutput;
};

export type GetFalAiNafnetDeblurRequestsByRequestIdResponse =
  GetFalAiNafnetDeblurRequestsByRequestIdResponses[keyof GetFalAiNafnetDeblurRequestsByRequestIdResponses];

export type GetFalAiNafnetDenoiseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nafnet/denoise/requests/{request_id}/status";
};

export type GetFalAiNafnetDenoiseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNafnetDenoiseRequestsByRequestIdStatusResponse =
  GetFalAiNafnetDenoiseRequestsByRequestIdStatusResponses[keyof GetFalAiNafnetDenoiseRequestsByRequestIdStatusResponses];

export type PutFalAiNafnetDenoiseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nafnet/denoise/requests/{request_id}/cancel";
};

export type PutFalAiNafnetDenoiseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNafnetDenoiseRequestsByRequestIdCancelResponse =
  PutFalAiNafnetDenoiseRequestsByRequestIdCancelResponses[keyof PutFalAiNafnetDenoiseRequestsByRequestIdCancelResponses];

export type PostFalAiNafnetDenoiseData = {
  body: NafnetDenoiseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nafnet/denoise";
};

export type PostFalAiNafnetDenoiseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNafnetDenoiseResponse =
  PostFalAiNafnetDenoiseResponses[keyof PostFalAiNafnetDenoiseResponses];

export type GetFalAiNafnetDenoiseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nafnet/denoise/requests/{request_id}";
};

export type GetFalAiNafnetDenoiseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NafnetDenoiseOutput;
};

export type GetFalAiNafnetDenoiseRequestsByRequestIdResponse =
  GetFalAiNafnetDenoiseRequestsByRequestIdResponses[keyof GetFalAiNafnetDenoiseRequestsByRequestIdResponses];

export type GetFalAiPostProcessingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/post-processing/requests/{request_id}/status";
};

export type GetFalAiPostProcessingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPostProcessingRequestsByRequestIdStatusResponse =
  GetFalAiPostProcessingRequestsByRequestIdStatusResponses[keyof GetFalAiPostProcessingRequestsByRequestIdStatusResponses];

export type PutFalAiPostProcessingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/requests/{request_id}/cancel";
};

export type PutFalAiPostProcessingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPostProcessingRequestsByRequestIdCancelResponse =
  PutFalAiPostProcessingRequestsByRequestIdCancelResponses[keyof PutFalAiPostProcessingRequestsByRequestIdCancelResponses];

export type PostFalAiPostProcessingData = {
  body: PostProcessingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/post-processing";
};

export type PostFalAiPostProcessingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPostProcessingResponse =
  PostFalAiPostProcessingResponses[keyof PostFalAiPostProcessingResponses];

export type GetFalAiPostProcessingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/post-processing/requests/{request_id}";
};

export type GetFalAiPostProcessingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PostProcessingOutput;
};

export type GetFalAiPostProcessingRequestsByRequestIdResponse =
  GetFalAiPostProcessingRequestsByRequestIdResponses[keyof GetFalAiPostProcessingRequestsByRequestIdResponses];

export type GetFalAiFloweditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flowedit/requests/{request_id}/status";
};

export type GetFalAiFloweditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFloweditRequestsByRequestIdStatusResponse =
  GetFalAiFloweditRequestsByRequestIdStatusResponses[keyof GetFalAiFloweditRequestsByRequestIdStatusResponses];

export type PutFalAiFloweditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flowedit/requests/{request_id}/cancel";
};

export type PutFalAiFloweditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFloweditRequestsByRequestIdCancelResponse =
  PutFalAiFloweditRequestsByRequestIdCancelResponses[keyof PutFalAiFloweditRequestsByRequestIdCancelResponses];

export type PostFalAiFloweditData = {
  body: FloweditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flowedit";
};

export type PostFalAiFloweditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFloweditResponse =
  PostFalAiFloweditResponses[keyof PostFalAiFloweditResponses];

export type GetFalAiFloweditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flowedit/requests/{request_id}";
};

export type GetFalAiFloweditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FloweditOutput;
};

export type GetFalAiFloweditRequestsByRequestIdResponse =
  GetFalAiFloweditRequestsByRequestIdResponses[keyof GetFalAiFloweditRequestsByRequestIdResponses];

export type GetFalAiBenV2ImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ben/v2/image/requests/{request_id}/status";
};

export type GetFalAiBenV2ImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBenV2ImageRequestsByRequestIdStatusResponse =
  GetFalAiBenV2ImageRequestsByRequestIdStatusResponses[keyof GetFalAiBenV2ImageRequestsByRequestIdStatusResponses];

export type PutFalAiBenV2ImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ben/v2/image/requests/{request_id}/cancel";
};

export type PutFalAiBenV2ImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBenV2ImageRequestsByRequestIdCancelResponse =
  PutFalAiBenV2ImageRequestsByRequestIdCancelResponses[keyof PutFalAiBenV2ImageRequestsByRequestIdCancelResponses];

export type PostFalAiBenV2ImageData = {
  body: BenV2ImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ben/v2/image";
};

export type PostFalAiBenV2ImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBenV2ImageResponse =
  PostFalAiBenV2ImageResponses[keyof PostFalAiBenV2ImageResponses];

export type GetFalAiBenV2ImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ben/v2/image/requests/{request_id}";
};

export type GetFalAiBenV2ImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BenV2ImageOutput;
};

export type GetFalAiBenV2ImageRequestsByRequestIdResponse =
  GetFalAiBenV2ImageRequestsByRequestIdResponses[keyof GetFalAiBenV2ImageRequestsByRequestIdResponses];

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-control-lora-canny/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-control-lora-canny/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxControlLoraCannyImageToImageData = {
  body: FluxControlLoraCannyImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-control-lora-canny/image-to-image";
};

export type PostFalAiFluxControlLoraCannyImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxControlLoraCannyImageToImageResponse =
  PostFalAiFluxControlLoraCannyImageToImageResponses[keyof PostFalAiFluxControlLoraCannyImageToImageResponses];

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-canny/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FluxControlLoraCannyImageToImageOutput;
  };

export type GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxControlLoraCannyImageToImageRequestsByRequestIdResponses];

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-control-lora-depth/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-control-lora-depth/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxControlLoraDepthImageToImageData = {
  body: FluxControlLoraDepthImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-control-lora-depth/image-to-image";
};

export type PostFalAiFluxControlLoraDepthImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxControlLoraDepthImageToImageResponse =
  PostFalAiFluxControlLoraDepthImageToImageResponses[keyof PostFalAiFluxControlLoraDepthImageToImageResponses];

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-depth/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FluxControlLoraDepthImageToImageOutput;
  };

export type GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxControlLoraDepthImageToImageRequestsByRequestIdResponses];

export type GetFalAiIdeogramUpscaleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/upscale/requests/{request_id}/status";
};

export type GetFalAiIdeogramUpscaleRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramUpscaleRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramUpscaleRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramUpscaleRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramUpscaleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/upscale/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramUpscaleRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramUpscaleRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramUpscaleRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramUpscaleRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramUpscaleData = {
  body: IdeogramUpscaleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/upscale";
};

export type PostFalAiIdeogramUpscaleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramUpscaleResponse =
  PostFalAiIdeogramUpscaleResponses[keyof PostFalAiIdeogramUpscaleResponses];

export type GetFalAiIdeogramUpscaleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/upscale/requests/{request_id}";
};

export type GetFalAiIdeogramUpscaleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramUpscaleOutput;
};

export type GetFalAiIdeogramUpscaleRequestsByRequestIdResponse =
  GetFalAiIdeogramUpscaleRequestsByRequestIdResponses[keyof GetFalAiIdeogramUpscaleRequestsByRequestIdResponses];

export type GetFalAiCodeformerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/codeformer/requests/{request_id}/status";
};

export type GetFalAiCodeformerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCodeformerRequestsByRequestIdStatusResponse =
  GetFalAiCodeformerRequestsByRequestIdStatusResponses[keyof GetFalAiCodeformerRequestsByRequestIdStatusResponses];

export type PutFalAiCodeformerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/codeformer/requests/{request_id}/cancel";
};

export type PutFalAiCodeformerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCodeformerRequestsByRequestIdCancelResponse =
  PutFalAiCodeformerRequestsByRequestIdCancelResponses[keyof PutFalAiCodeformerRequestsByRequestIdCancelResponses];

export type PostFalAiCodeformerData = {
  body: CodeformerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/codeformer";
};

export type PostFalAiCodeformerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCodeformerResponse =
  PostFalAiCodeformerResponses[keyof PostFalAiCodeformerResponses];

export type GetFalAiCodeformerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/codeformer/requests/{request_id}";
};

export type GetFalAiCodeformerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CodeformerOutput;
};

export type GetFalAiCodeformerRequestsByRequestIdResponse =
  GetFalAiCodeformerRequestsByRequestIdResponses[keyof GetFalAiCodeformerRequestsByRequestIdResponses];

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kling/v1-5/kolors-virtual-try-on/requests/{request_id}/status";
};

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdStatusResponse =
  GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdStatusResponses[keyof GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdStatusResponses];

export type PutFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling/v1-5/kolors-virtual-try-on/requests/{request_id}/cancel";
};

export type PutFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdCancelResponse =
  PutFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdCancelResponses[keyof PutFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdCancelResponses];

export type PostFalAiKlingV15KolorsVirtualTryOnData = {
  body: KlingV15KolorsVirtualTryOnInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kling/v1-5/kolors-virtual-try-on";
};

export type PostFalAiKlingV15KolorsVirtualTryOnResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKlingV15KolorsVirtualTryOnResponse =
  PostFalAiKlingV15KolorsVirtualTryOnResponses[keyof PostFalAiKlingV15KolorsVirtualTryOnResponses];

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling/v1-5/kolors-virtual-try-on/requests/{request_id}";
};

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KlingV15KolorsVirtualTryOnOutput;
};

export type GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdResponse =
  GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdResponses[keyof GetFalAiKlingV15KolorsVirtualTryOnRequestsByRequestIdResponses];

export type GetFalAiFluxLoraCannyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora-canny/requests/{request_id}/status";
};

export type GetFalAiFluxLoraCannyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraCannyRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraCannyRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraCannyRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraCannyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-canny/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraCannyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraCannyRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraCannyRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraCannyRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraCannyData = {
  body: FluxLoraCannyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora-canny";
};

export type PostFalAiFluxLoraCannyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraCannyResponse =
  PostFalAiFluxLoraCannyResponses[keyof PostFalAiFluxLoraCannyResponses];

export type GetFalAiFluxLoraCannyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-canny/requests/{request_id}";
};

export type GetFalAiFluxLoraCannyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraCannyOutput;
};

export type GetFalAiFluxLoraCannyRequestsByRequestIdResponse =
  GetFalAiFluxLoraCannyRequestsByRequestIdResponses[keyof GetFalAiFluxLoraCannyRequestsByRequestIdResponses];

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1/fill-finetuned/requests/{request_id}/status";
};

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV1FillFinetunedRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV1FillFinetunedRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV1FillFinetunedRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill-finetuned/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV1FillFinetunedRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV1FillFinetunedRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV1FillFinetunedRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV1FillFinetunedRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV1FillFinetunedData = {
  body: FluxProV1FillFinetunedInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill-finetuned";
};

export type PostFalAiFluxProV1FillFinetunedResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV1FillFinetunedResponse =
  PostFalAiFluxProV1FillFinetunedResponses[keyof PostFalAiFluxProV1FillFinetunedResponses];

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill-finetuned/requests/{request_id}";
};

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV1FillFinetunedOutput;
};

export type GetFalAiFluxProV1FillFinetunedRequestsByRequestIdResponse =
  GetFalAiFluxProV1FillFinetunedRequestsByRequestIdResponses[keyof GetFalAiFluxProV1FillFinetunedRequestsByRequestIdResponses];

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/moondream-next/detection/requests/{request_id}/status";
};

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdStatusResponse =
  GetFalAiMoondreamNextDetectionRequestsByRequestIdStatusResponses[keyof GetFalAiMoondreamNextDetectionRequestsByRequestIdStatusResponses];

export type PutFalAiMoondreamNextDetectionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/moondream-next/detection/requests/{request_id}/cancel";
};

export type PutFalAiMoondreamNextDetectionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMoondreamNextDetectionRequestsByRequestIdCancelResponse =
  PutFalAiMoondreamNextDetectionRequestsByRequestIdCancelResponses[keyof PutFalAiMoondreamNextDetectionRequestsByRequestIdCancelResponses];

export type PostFalAiMoondreamNextDetectionData = {
  body: MoondreamNextDetectionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/moondream-next/detection";
};

export type PostFalAiMoondreamNextDetectionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMoondreamNextDetectionResponse =
  PostFalAiMoondreamNextDetectionResponses[keyof PostFalAiMoondreamNextDetectionResponses];

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/moondream-next/detection/requests/{request_id}";
};

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MoondreamNextDetectionOutput;
};

export type GetFalAiMoondreamNextDetectionRequestsByRequestIdResponse =
  GetFalAiMoondreamNextDetectionRequestsByRequestIdResponses[keyof GetFalAiMoondreamNextDetectionRequestsByRequestIdResponses];

export type GetFalAiBriaEraserRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/eraser/requests/{request_id}/status";
};

export type GetFalAiBriaEraserRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaEraserRequestsByRequestIdStatusResponse =
  GetFalAiBriaEraserRequestsByRequestIdStatusResponses[keyof GetFalAiBriaEraserRequestsByRequestIdStatusResponses];

export type PutFalAiBriaEraserRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/eraser/requests/{request_id}/cancel";
};

export type PutFalAiBriaEraserRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaEraserRequestsByRequestIdCancelResponse =
  PutFalAiBriaEraserRequestsByRequestIdCancelResponses[keyof PutFalAiBriaEraserRequestsByRequestIdCancelResponses];

export type PostFalAiBriaEraserData = {
  body: BriaEraserInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/eraser";
};

export type PostFalAiBriaEraserResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaEraserResponse =
  PostFalAiBriaEraserResponses[keyof PostFalAiBriaEraserResponses];

export type GetFalAiBriaEraserRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/eraser/requests/{request_id}";
};

export type GetFalAiBriaEraserRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaEraserOutput;
};

export type GetFalAiBriaEraserRequestsByRequestIdResponse =
  GetFalAiBriaEraserRequestsByRequestIdResponses[keyof GetFalAiBriaEraserRequestsByRequestIdResponses];

export type GetFalAiBriaExpandRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/expand/requests/{request_id}/status";
};

export type GetFalAiBriaExpandRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaExpandRequestsByRequestIdStatusResponse =
  GetFalAiBriaExpandRequestsByRequestIdStatusResponses[keyof GetFalAiBriaExpandRequestsByRequestIdStatusResponses];

export type PutFalAiBriaExpandRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/expand/requests/{request_id}/cancel";
};

export type PutFalAiBriaExpandRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaExpandRequestsByRequestIdCancelResponse =
  PutFalAiBriaExpandRequestsByRequestIdCancelResponses[keyof PutFalAiBriaExpandRequestsByRequestIdCancelResponses];

export type PostFalAiBriaExpandData = {
  body: BriaExpandInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/expand";
};

export type PostFalAiBriaExpandResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaExpandResponse =
  PostFalAiBriaExpandResponses[keyof PostFalAiBriaExpandResponses];

export type GetFalAiBriaExpandRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/expand/requests/{request_id}";
};

export type GetFalAiBriaExpandRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaExpandOutput;
};

export type GetFalAiBriaExpandRequestsByRequestIdResponse =
  GetFalAiBriaExpandRequestsByRequestIdResponses[keyof GetFalAiBriaExpandRequestsByRequestIdResponses];

export type GetFalAiBriaGenfillRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/genfill/requests/{request_id}/status";
};

export type GetFalAiBriaGenfillRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaGenfillRequestsByRequestIdStatusResponse =
  GetFalAiBriaGenfillRequestsByRequestIdStatusResponses[keyof GetFalAiBriaGenfillRequestsByRequestIdStatusResponses];

export type PutFalAiBriaGenfillRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/genfill/requests/{request_id}/cancel";
};

export type PutFalAiBriaGenfillRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaGenfillRequestsByRequestIdCancelResponse =
  PutFalAiBriaGenfillRequestsByRequestIdCancelResponses[keyof PutFalAiBriaGenfillRequestsByRequestIdCancelResponses];

export type PostFalAiBriaGenfillData = {
  body: BriaGenfillInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/genfill";
};

export type PostFalAiBriaGenfillResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaGenfillResponse =
  PostFalAiBriaGenfillResponses[keyof PostFalAiBriaGenfillResponses];

export type GetFalAiBriaGenfillRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/genfill/requests/{request_id}";
};

export type GetFalAiBriaGenfillRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaGenfillOutput;
};

export type GetFalAiBriaGenfillRequestsByRequestIdResponse =
  GetFalAiBriaGenfillRequestsByRequestIdResponses[keyof GetFalAiBriaGenfillRequestsByRequestIdResponses];

export type GetFalAiBriaProductShotRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/product-shot/requests/{request_id}/status";
};

export type GetFalAiBriaProductShotRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaProductShotRequestsByRequestIdStatusResponse =
  GetFalAiBriaProductShotRequestsByRequestIdStatusResponses[keyof GetFalAiBriaProductShotRequestsByRequestIdStatusResponses];

export type PutFalAiBriaProductShotRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/product-shot/requests/{request_id}/cancel";
};

export type PutFalAiBriaProductShotRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaProductShotRequestsByRequestIdCancelResponse =
  PutFalAiBriaProductShotRequestsByRequestIdCancelResponses[keyof PutFalAiBriaProductShotRequestsByRequestIdCancelResponses];

export type PostFalAiBriaProductShotData = {
  body: BriaProductShotInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/product-shot";
};

export type PostFalAiBriaProductShotResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaProductShotResponse =
  PostFalAiBriaProductShotResponses[keyof PostFalAiBriaProductShotResponses];

export type GetFalAiBriaProductShotRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/product-shot/requests/{request_id}";
};

export type GetFalAiBriaProductShotRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaProductShotOutput;
};

export type GetFalAiBriaProductShotRequestsByRequestIdResponse =
  GetFalAiBriaProductShotRequestsByRequestIdResponses[keyof GetFalAiBriaProductShotRequestsByRequestIdResponses];

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/background/remove/requests/{request_id}/status";
};

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdStatusResponse =
  GetFalAiBriaBackgroundRemoveRequestsByRequestIdStatusResponses[keyof GetFalAiBriaBackgroundRemoveRequestsByRequestIdStatusResponses];

export type PutFalAiBriaBackgroundRemoveRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/background/remove/requests/{request_id}/cancel";
};

export type PutFalAiBriaBackgroundRemoveRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaBackgroundRemoveRequestsByRequestIdCancelResponse =
  PutFalAiBriaBackgroundRemoveRequestsByRequestIdCancelResponses[keyof PutFalAiBriaBackgroundRemoveRequestsByRequestIdCancelResponses];

export type PostFalAiBriaBackgroundRemoveData = {
  body: BriaBackgroundRemoveInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/background/remove";
};

export type PostFalAiBriaBackgroundRemoveResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaBackgroundRemoveResponse =
  PostFalAiBriaBackgroundRemoveResponses[keyof PostFalAiBriaBackgroundRemoveResponses];

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/background/remove/requests/{request_id}";
};

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaBackgroundRemoveOutput;
};

export type GetFalAiBriaBackgroundRemoveRequestsByRequestIdResponse =
  GetFalAiBriaBackgroundRemoveRequestsByRequestIdResponses[keyof GetFalAiBriaBackgroundRemoveRequestsByRequestIdResponses];

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/background/replace/requests/{request_id}/status";
};

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdStatusResponse =
  GetFalAiBriaBackgroundReplaceRequestsByRequestIdStatusResponses[keyof GetFalAiBriaBackgroundReplaceRequestsByRequestIdStatusResponses];

export type PutFalAiBriaBackgroundReplaceRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/background/replace/requests/{request_id}/cancel";
};

export type PutFalAiBriaBackgroundReplaceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaBackgroundReplaceRequestsByRequestIdCancelResponse =
  PutFalAiBriaBackgroundReplaceRequestsByRequestIdCancelResponses[keyof PutFalAiBriaBackgroundReplaceRequestsByRequestIdCancelResponses];

export type PostFalAiBriaBackgroundReplaceData = {
  body: BriaBackgroundReplaceInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/background/replace";
};

export type PostFalAiBriaBackgroundReplaceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaBackgroundReplaceResponse =
  PostFalAiBriaBackgroundReplaceResponses[keyof PostFalAiBriaBackgroundReplaceResponses];

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/background/replace/requests/{request_id}";
};

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaBackgroundReplaceOutput;
};

export type GetFalAiBriaBackgroundReplaceRequestsByRequestIdResponse =
  GetFalAiBriaBackgroundReplaceRequestsByRequestIdResponses[keyof GetFalAiBriaBackgroundReplaceRequestsByRequestIdResponses];

export type GetFalAiFluxLoraFillRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora-fill/requests/{request_id}/status";
};

export type GetFalAiFluxLoraFillRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraFillRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraFillRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraFillRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraFillRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-fill/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraFillRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraFillRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraFillRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraFillRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraFillData = {
  body: FluxLoraFillInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora-fill";
};

export type PostFalAiFluxLoraFillResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraFillResponse =
  PostFalAiFluxLoraFillResponses[keyof PostFalAiFluxLoraFillResponses];

export type GetFalAiFluxLoraFillRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-fill/requests/{request_id}";
};

export type GetFalAiFluxLoraFillRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraFillOutput;
};

export type GetFalAiFluxLoraFillRequestsByRequestIdResponse =
  GetFalAiFluxLoraFillRequestsByRequestIdResponses[keyof GetFalAiFluxLoraFillRequestsByRequestIdResponses];

export type GetFalAiCatVtonRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/cat-vton/requests/{request_id}/status";
};

export type GetFalAiCatVtonRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCatVtonRequestsByRequestIdStatusResponse =
  GetFalAiCatVtonRequestsByRequestIdStatusResponses[keyof GetFalAiCatVtonRequestsByRequestIdStatusResponses];

export type PutFalAiCatVtonRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cat-vton/requests/{request_id}/cancel";
};

export type PutFalAiCatVtonRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCatVtonRequestsByRequestIdCancelResponse =
  PutFalAiCatVtonRequestsByRequestIdCancelResponses[keyof PutFalAiCatVtonRequestsByRequestIdCancelResponses];

export type PostFalAiCatVtonData = {
  body: CatVtonInput;
  path?: never;
  query?: never;
  url: "/fal-ai/cat-vton";
};

export type PostFalAiCatVtonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCatVtonResponse =
  PostFalAiCatVtonResponses[keyof PostFalAiCatVtonResponses];

export type GetFalAiCatVtonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cat-vton/requests/{request_id}";
};

export type GetFalAiCatVtonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CatVtonOutput;
};

export type GetFalAiCatVtonRequestsByRequestIdResponse =
  GetFalAiCatVtonRequestsByRequestIdResponses[keyof GetFalAiCatVtonRequestsByRequestIdResponses];

export type GetFalAiLeffaPoseTransferRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/leffa/pose-transfer/requests/{request_id}/status";
};

export type GetFalAiLeffaPoseTransferRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLeffaPoseTransferRequestsByRequestIdStatusResponse =
  GetFalAiLeffaPoseTransferRequestsByRequestIdStatusResponses[keyof GetFalAiLeffaPoseTransferRequestsByRequestIdStatusResponses];

export type PutFalAiLeffaPoseTransferRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/leffa/pose-transfer/requests/{request_id}/cancel";
};

export type PutFalAiLeffaPoseTransferRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLeffaPoseTransferRequestsByRequestIdCancelResponse =
  PutFalAiLeffaPoseTransferRequestsByRequestIdCancelResponses[keyof PutFalAiLeffaPoseTransferRequestsByRequestIdCancelResponses];

export type PostFalAiLeffaPoseTransferData = {
  body: LeffaPoseTransferInput;
  path?: never;
  query?: never;
  url: "/fal-ai/leffa/pose-transfer";
};

export type PostFalAiLeffaPoseTransferResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLeffaPoseTransferResponse =
  PostFalAiLeffaPoseTransferResponses[keyof PostFalAiLeffaPoseTransferResponses];

export type GetFalAiLeffaPoseTransferRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/leffa/pose-transfer/requests/{request_id}";
};

export type GetFalAiLeffaPoseTransferRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LeffaPoseTransferOutput;
};

export type GetFalAiLeffaPoseTransferRequestsByRequestIdResponse =
  GetFalAiLeffaPoseTransferRequestsByRequestIdResponses[keyof GetFalAiLeffaPoseTransferRequestsByRequestIdResponses];

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/leffa/virtual-tryon/requests/{request_id}/status";
};

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdStatusResponse =
  GetFalAiLeffaVirtualTryonRequestsByRequestIdStatusResponses[keyof GetFalAiLeffaVirtualTryonRequestsByRequestIdStatusResponses];

export type PutFalAiLeffaVirtualTryonRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/leffa/virtual-tryon/requests/{request_id}/cancel";
};

export type PutFalAiLeffaVirtualTryonRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLeffaVirtualTryonRequestsByRequestIdCancelResponse =
  PutFalAiLeffaVirtualTryonRequestsByRequestIdCancelResponses[keyof PutFalAiLeffaVirtualTryonRequestsByRequestIdCancelResponses];

export type PostFalAiLeffaVirtualTryonData = {
  body: LeffaVirtualTryonInput;
  path?: never;
  query?: never;
  url: "/fal-ai/leffa/virtual-tryon";
};

export type PostFalAiLeffaVirtualTryonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLeffaVirtualTryonResponse =
  PostFalAiLeffaVirtualTryonResponses[keyof PostFalAiLeffaVirtualTryonResponses];

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/leffa/virtual-tryon/requests/{request_id}";
};

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LeffaVirtualTryonOutput;
};

export type GetFalAiLeffaVirtualTryonRequestsByRequestIdResponse =
  GetFalAiLeffaVirtualTryonRequestsByRequestIdResponses[keyof GetFalAiLeffaVirtualTryonRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2EditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/edit/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2EditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2EditRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2EditRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2EditRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2EditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/edit/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2EditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2EditRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2EditRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2EditRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2EditData = {
  body: IdeogramV2EditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2/edit";
};

export type PostFalAiIdeogramV2EditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2EditResponse =
  PostFalAiIdeogramV2EditResponses[keyof PostFalAiIdeogramV2EditResponses];

export type GetFalAiIdeogramV2EditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/edit/requests/{request_id}";
};

export type GetFalAiIdeogramV2EditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2EditOutput;
};

export type GetFalAiIdeogramV2EditRequestsByRequestIdResponse =
  GetFalAiIdeogramV2EditRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2EditRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2RemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2RemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2RemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2RemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2RemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2RemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2RemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2RemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2RemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2RemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2RemixData = {
  body: IdeogramV2RemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2/remix";
};

export type PostFalAiIdeogramV2RemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2RemixResponse =
  PostFalAiIdeogramV2RemixResponses[keyof PostFalAiIdeogramV2RemixResponses];

export type GetFalAiIdeogramV2RemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/remix/requests/{request_id}";
};

export type GetFalAiIdeogramV2RemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2RemixOutput;
};

export type GetFalAiIdeogramV2RemixRequestsByRequestIdResponse =
  GetFalAiIdeogramV2RemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2RemixRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/turbo/edit/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2TurboEditRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2TurboEditRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2TurboEditRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/edit/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2TurboEditRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2TurboEditRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2TurboEditRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2TurboEditRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2TurboEditData = {
  body: IdeogramV2TurboEditInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/edit";
};

export type PostFalAiIdeogramV2TurboEditResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2TurboEditResponse =
  PostFalAiIdeogramV2TurboEditResponses[keyof PostFalAiIdeogramV2TurboEditResponses];

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/edit/requests/{request_id}";
};

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2TurboEditOutput;
};

export type GetFalAiIdeogramV2TurboEditRequestsByRequestIdResponse =
  GetFalAiIdeogramV2TurboEditRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2TurboEditRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/turbo/remix/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2TurboRemixRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2TurboRemixRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2TurboRemixRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/remix/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2TurboRemixRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2TurboRemixRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2TurboRemixRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2TurboRemixRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2TurboRemixData = {
  body: IdeogramV2TurboRemixInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/remix";
};

export type PostFalAiIdeogramV2TurboRemixResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2TurboRemixResponse =
  PostFalAiIdeogramV2TurboRemixResponses[keyof PostFalAiIdeogramV2TurboRemixResponses];

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/remix/requests/{request_id}";
};

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2TurboRemixOutput;
};

export type GetFalAiIdeogramV2TurboRemixRequestsByRequestIdResponse =
  GetFalAiIdeogramV2TurboRemixRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2TurboRemixRequestsByRequestIdResponses];

export type GetFalAiFluxSchnellReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/schnell/redux/requests/{request_id}/status";
};

export type GetFalAiFluxSchnellReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxSchnellReduxRequestsByRequestIdStatusResponse =
  GetFalAiFluxSchnellReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxSchnellReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxSchnellReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/schnell/redux/requests/{request_id}/cancel";
};

export type PutFalAiFluxSchnellReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxSchnellReduxRequestsByRequestIdCancelResponse =
  PutFalAiFluxSchnellReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxSchnellReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxSchnellReduxData = {
  body: FluxSchnellReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/schnell/redux";
};

export type PostFalAiFluxSchnellReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxSchnellReduxResponse =
  PostFalAiFluxSchnellReduxResponses[keyof PostFalAiFluxSchnellReduxResponses];

export type GetFalAiFluxSchnellReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/schnell/redux/requests/{request_id}";
};

export type GetFalAiFluxSchnellReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxSchnellReduxOutput;
};

export type GetFalAiFluxSchnellReduxRequestsByRequestIdResponse =
  GetFalAiFluxSchnellReduxRequestsByRequestIdResponses[keyof GetFalAiFluxSchnellReduxRequestsByRequestIdResponses];

export type GetFalAiFluxProV11ReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1.1/redux/requests/{request_id}/status";
};

export type GetFalAiFluxProV11ReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV11ReduxRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV11ReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV11ReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV11ReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1/redux/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV11ReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV11ReduxRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV11ReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV11ReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV11ReduxData = {
  body: FluxProV11ReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1.1/redux";
};

export type PostFalAiFluxProV11ReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV11ReduxResponse =
  PostFalAiFluxProV11ReduxResponses[keyof PostFalAiFluxProV11ReduxResponses];

export type GetFalAiFluxProV11ReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1/redux/requests/{request_id}";
};

export type GetFalAiFluxProV11ReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV11ReduxOutput;
};

export type GetFalAiFluxProV11ReduxRequestsByRequestIdResponse =
  GetFalAiFluxProV11ReduxRequestsByRequestIdResponses[keyof GetFalAiFluxProV11ReduxRequestsByRequestIdResponses];

export type GetFalAiFluxLoraDepthRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora-depth/requests/{request_id}/status";
};

export type GetFalAiFluxLoraDepthRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraDepthRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraDepthRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraDepthRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraDepthRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-depth/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraDepthRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraDepthRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraDepthRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraDepthRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraDepthData = {
  body: FluxLoraDepthInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora-depth";
};

export type PostFalAiFluxLoraDepthResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraDepthResponse =
  PostFalAiFluxLoraDepthResponses[keyof PostFalAiFluxLoraDepthResponses];

export type GetFalAiFluxLoraDepthRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora-depth/requests/{request_id}";
};

export type GetFalAiFluxLoraDepthRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraDepthOutput;
};

export type GetFalAiFluxLoraDepthRequestsByRequestIdResponse =
  GetFalAiFluxLoraDepthRequestsByRequestIdResponses[keyof GetFalAiFluxLoraDepthRequestsByRequestIdResponses];

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1.1-ultra/redux/requests/{request_id}/status";
};

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV11UltraReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV11UltraReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV11UltraReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra/redux/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV11UltraReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV11UltraReduxRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV11UltraReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV11UltraReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV11UltraReduxData = {
  body: FluxProV11UltraReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra/redux";
};

export type PostFalAiFluxProV11UltraReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV11UltraReduxResponse =
  PostFalAiFluxProV11UltraReduxResponses[keyof PostFalAiFluxProV11UltraReduxResponses];

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra/redux/requests/{request_id}";
};

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV11UltraReduxOutput;
};

export type GetFalAiFluxProV11UltraReduxRequestsByRequestIdResponse =
  GetFalAiFluxProV11UltraReduxRequestsByRequestIdResponses[keyof GetFalAiFluxProV11UltraReduxRequestsByRequestIdResponses];

export type GetFalAiFluxProV1FillRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1/fill/requests/{request_id}/status";
};

export type GetFalAiFluxProV1FillRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV1FillRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV1FillRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV1FillRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV1FillRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV1FillRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV1FillRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV1FillRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV1FillRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV1FillData = {
  body: FluxProV1FillInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill";
};

export type PostFalAiFluxProV1FillResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV1FillResponse =
  PostFalAiFluxProV1FillResponses[keyof PostFalAiFluxProV1FillResponses];

export type GetFalAiFluxProV1FillRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1/fill/requests/{request_id}";
};

export type GetFalAiFluxProV1FillRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV1FillOutput;
};

export type GetFalAiFluxProV1FillRequestsByRequestIdResponse =
  GetFalAiFluxProV1FillRequestsByRequestIdResponses[keyof GetFalAiFluxProV1FillRequestsByRequestIdResponses];

export type GetFalAiFluxDevReduxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/dev/redux/requests/{request_id}/status";
};

export type GetFalAiFluxDevReduxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxDevReduxRequestsByRequestIdStatusResponse =
  GetFalAiFluxDevReduxRequestsByRequestIdStatusResponses[keyof GetFalAiFluxDevReduxRequestsByRequestIdStatusResponses];

export type PutFalAiFluxDevReduxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/redux/requests/{request_id}/cancel";
};

export type PutFalAiFluxDevReduxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxDevReduxRequestsByRequestIdCancelResponse =
  PutFalAiFluxDevReduxRequestsByRequestIdCancelResponses[keyof PutFalAiFluxDevReduxRequestsByRequestIdCancelResponses];

export type PostFalAiFluxDevReduxData = {
  body: FluxDevReduxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/dev/redux";
};

export type PostFalAiFluxDevReduxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxDevReduxResponse =
  PostFalAiFluxDevReduxResponses[keyof PostFalAiFluxDevReduxResponses];

export type GetFalAiFluxDevReduxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/redux/requests/{request_id}";
};

export type GetFalAiFluxDevReduxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxDevReduxOutput;
};

export type GetFalAiFluxDevReduxRequestsByRequestIdResponse =
  GetFalAiFluxDevReduxRequestsByRequestIdResponses[keyof GetFalAiFluxDevReduxRequestsByRequestIdResponses];

export type GetFalAiKolorsImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kolors/image-to-image/requests/{request_id}/status";
};

export type GetFalAiKolorsImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKolorsImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiKolorsImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiKolorsImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiKolorsImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kolors/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiKolorsImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKolorsImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiKolorsImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiKolorsImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiKolorsImageToImageData = {
  body: KolorsImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kolors/image-to-image";
};

export type PostFalAiKolorsImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKolorsImageToImageResponse =
  PostFalAiKolorsImageToImageResponses[keyof PostFalAiKolorsImageToImageResponses];

export type GetFalAiKolorsImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kolors/image-to-image/requests/{request_id}";
};

export type GetFalAiKolorsImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KolorsImageToImageOutput;
};

export type GetFalAiKolorsImageToImageRequestsByRequestIdResponse =
  GetFalAiKolorsImageToImageRequestsByRequestIdResponses[keyof GetFalAiKolorsImageToImageRequestsByRequestIdResponses];

export type GetFalAiIclightV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/iclight-v2/requests/{request_id}/status";
};

export type GetFalAiIclightV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIclightV2RequestsByRequestIdStatusResponse =
  GetFalAiIclightV2RequestsByRequestIdStatusResponses[keyof GetFalAiIclightV2RequestsByRequestIdStatusResponses];

export type PutFalAiIclightV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/iclight-v2/requests/{request_id}/cancel";
};

export type PutFalAiIclightV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIclightV2RequestsByRequestIdCancelResponse =
  PutFalAiIclightV2RequestsByRequestIdCancelResponses[keyof PutFalAiIclightV2RequestsByRequestIdCancelResponses];

export type PostFalAiIclightV2Data = {
  body: IclightV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/iclight-v2";
};

export type PostFalAiIclightV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIclightV2Response =
  PostFalAiIclightV2Responses[keyof PostFalAiIclightV2Responses];

export type GetFalAiIclightV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/iclight-v2/requests/{request_id}";
};

export type GetFalAiIclightV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IclightV2Output;
};

export type GetFalAiIclightV2RequestsByRequestIdResponse =
  GetFalAiIclightV2RequestsByRequestIdResponses[keyof GetFalAiIclightV2RequestsByRequestIdResponses];

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-differential-diffusion/requests/{request_id}/status";
};

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiFluxDifferentialDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiFluxDifferentialDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiFluxDifferentialDiffusionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-differential-diffusion/requests/{request_id}/cancel";
};

export type PutFalAiFluxDifferentialDiffusionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxDifferentialDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiFluxDifferentialDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiFluxDifferentialDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiFluxDifferentialDiffusionData = {
  body: FluxDifferentialDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-differential-diffusion";
};

export type PostFalAiFluxDifferentialDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxDifferentialDiffusionResponse =
  PostFalAiFluxDifferentialDiffusionResponses[keyof PostFalAiFluxDifferentialDiffusionResponses];

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-differential-diffusion/requests/{request_id}";
};

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxDifferentialDiffusionOutput;
};

export type GetFalAiFluxDifferentialDiffusionRequestsByRequestIdResponse =
  GetFalAiFluxDifferentialDiffusionRequestsByRequestIdResponses[keyof GetFalAiFluxDifferentialDiffusionRequestsByRequestIdResponses];

export type GetFalAiFluxPulidRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pulid/requests/{request_id}/status";
};

export type GetFalAiFluxPulidRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxPulidRequestsByRequestIdStatusResponse =
  GetFalAiFluxPulidRequestsByRequestIdStatusResponses[keyof GetFalAiFluxPulidRequestsByRequestIdStatusResponses];

export type PutFalAiFluxPulidRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pulid/requests/{request_id}/cancel";
};

export type PutFalAiFluxPulidRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxPulidRequestsByRequestIdCancelResponse =
  PutFalAiFluxPulidRequestsByRequestIdCancelResponses[keyof PutFalAiFluxPulidRequestsByRequestIdCancelResponses];

export type PostFalAiFluxPulidData = {
  body: FluxPulidInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pulid";
};

export type PostFalAiFluxPulidResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxPulidResponse =
  PostFalAiFluxPulidResponses[keyof PostFalAiFluxPulidResponses];

export type GetFalAiFluxPulidRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pulid/requests/{request_id}";
};

export type GetFalAiFluxPulidRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxPulidOutput;
};

export type GetFalAiFluxPulidRequestsByRequestIdResponse =
  GetFalAiFluxPulidRequestsByRequestIdResponses[keyof GetFalAiFluxPulidRequestsByRequestIdResponses];

export type GetFalAiBirefnetV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/birefnet/v2/requests/{request_id}/status";
};

export type GetFalAiBirefnetV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBirefnetV2RequestsByRequestIdStatusResponse =
  GetFalAiBirefnetV2RequestsByRequestIdStatusResponses[keyof GetFalAiBirefnetV2RequestsByRequestIdStatusResponses];

export type PutFalAiBirefnetV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/birefnet/v2/requests/{request_id}/cancel";
};

export type PutFalAiBirefnetV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBirefnetV2RequestsByRequestIdCancelResponse =
  PutFalAiBirefnetV2RequestsByRequestIdCancelResponses[keyof PutFalAiBirefnetV2RequestsByRequestIdCancelResponses];

export type PostFalAiBirefnetV2Data = {
  body: BirefnetV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/birefnet/v2";
};

export type PostFalAiBirefnetV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBirefnetV2Response =
  PostFalAiBirefnetV2Responses[keyof PostFalAiBirefnetV2Responses];

export type GetFalAiBirefnetV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/birefnet/v2/requests/{request_id}";
};

export type GetFalAiBirefnetV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BirefnetV2Output;
};

export type GetFalAiBirefnetV2RequestsByRequestIdResponse =
  GetFalAiBirefnetV2RequestsByRequestIdResponses[keyof GetFalAiBirefnetV2RequestsByRequestIdResponses];

export type GetFalAiLivePortraitImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/live-portrait/image/requests/{request_id}/status";
};

export type GetFalAiLivePortraitImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLivePortraitImageRequestsByRequestIdStatusResponse =
  GetFalAiLivePortraitImageRequestsByRequestIdStatusResponses[keyof GetFalAiLivePortraitImageRequestsByRequestIdStatusResponses];

export type PutFalAiLivePortraitImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/live-portrait/image/requests/{request_id}/cancel";
};

export type PutFalAiLivePortraitImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLivePortraitImageRequestsByRequestIdCancelResponse =
  PutFalAiLivePortraitImageRequestsByRequestIdCancelResponses[keyof PutFalAiLivePortraitImageRequestsByRequestIdCancelResponses];

export type PostFalAiLivePortraitImageData = {
  body: LivePortraitImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/live-portrait/image";
};

export type PostFalAiLivePortraitImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLivePortraitImageResponse =
  PostFalAiLivePortraitImageResponses[keyof PostFalAiLivePortraitImageResponses];

export type GetFalAiLivePortraitImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/live-portrait/image/requests/{request_id}";
};

export type GetFalAiLivePortraitImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LivePortraitImageOutput;
};

export type GetFalAiLivePortraitImageRequestsByRequestIdResponse =
  GetFalAiLivePortraitImageRequestsByRequestIdResponses[keyof GetFalAiLivePortraitImageRequestsByRequestIdResponses];

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-general/rf-inversion/requests/{request_id}/status";
};

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdStatusResponse =
  GetFalAiFluxGeneralRfInversionRequestsByRequestIdStatusResponses[keyof GetFalAiFluxGeneralRfInversionRequestsByRequestIdStatusResponses];

export type PutFalAiFluxGeneralRfInversionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/rf-inversion/requests/{request_id}/cancel";
};

export type PutFalAiFluxGeneralRfInversionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxGeneralRfInversionRequestsByRequestIdCancelResponse =
  PutFalAiFluxGeneralRfInversionRequestsByRequestIdCancelResponses[keyof PutFalAiFluxGeneralRfInversionRequestsByRequestIdCancelResponses];

export type PostFalAiFluxGeneralRfInversionData = {
  body: FluxGeneralRfInversionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-general/rf-inversion";
};

export type PostFalAiFluxGeneralRfInversionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxGeneralRfInversionResponse =
  PostFalAiFluxGeneralRfInversionResponses[keyof PostFalAiFluxGeneralRfInversionResponses];

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/rf-inversion/requests/{request_id}";
};

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxGeneralRfInversionOutput;
};

export type GetFalAiFluxGeneralRfInversionRequestsByRequestIdResponse =
  GetFalAiFluxGeneralRfInversionRequestsByRequestIdResponses[keyof GetFalAiFluxGeneralRfInversionRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/hed/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsHedRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsHedRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsHedRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/hed/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsHedRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsHedRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsHedRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsHedRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsHedData = {
  body: ImagePreprocessorsHedInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/hed";
};

export type PostFalAiImagePreprocessorsHedResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsHedResponse =
  PostFalAiImagePreprocessorsHedResponses[keyof PostFalAiImagePreprocessorsHedResponses];

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/hed/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsHedOutput;
};

export type GetFalAiImagePreprocessorsHedRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsHedRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsHedRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/image-preprocessors/depth-anything/v2/requests/{request_id}/status";
  };

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/image-preprocessors/depth-anything/v2/requests/{request_id}/cancel";
  };

export type PutFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsDepthAnythingV2Data = {
  body: ImagePreprocessorsDepthAnythingV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/depth-anything/v2";
};

export type PostFalAiImagePreprocessorsDepthAnythingV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsDepthAnythingV2Response =
  PostFalAiImagePreprocessorsDepthAnythingV2Responses[keyof PostFalAiImagePreprocessorsDepthAnythingV2Responses];

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/depth-anything/v2/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ImagePreprocessorsDepthAnythingV2Output;
  };

export type GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsDepthAnythingV2RequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/scribble/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsScribbleRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsScribbleRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsScribbleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/scribble/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsScribbleRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImagePreprocessorsScribbleRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsScribbleRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsScribbleRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsScribbleData = {
  body: ImagePreprocessorsScribbleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/scribble";
};

export type PostFalAiImagePreprocessorsScribbleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsScribbleResponse =
  PostFalAiImagePreprocessorsScribbleResponses[keyof PostFalAiImagePreprocessorsScribbleResponses];

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/scribble/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsScribbleOutput;
};

export type GetFalAiImagePreprocessorsScribbleRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsScribbleRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsScribbleRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/mlsd/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsMlsdRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsMlsdRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsMlsdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/mlsd/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsMlsdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsMlsdRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsMlsdRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsMlsdRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsMlsdData = {
  body: ImagePreprocessorsMlsdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/mlsd";
};

export type PostFalAiImagePreprocessorsMlsdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsMlsdResponse =
  PostFalAiImagePreprocessorsMlsdResponses[keyof PostFalAiImagePreprocessorsMlsdResponses];

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/mlsd/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsMlsdOutput;
};

export type GetFalAiImagePreprocessorsMlsdRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsMlsdRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsMlsdRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/sam/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsSamRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsSamRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsSamRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/sam/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsSamRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsSamRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsSamRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsSamRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsSamData = {
  body: ImagePreprocessorsSamInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/sam";
};

export type PostFalAiImagePreprocessorsSamResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsSamResponse =
  PostFalAiImagePreprocessorsSamResponses[keyof PostFalAiImagePreprocessorsSamResponses];

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/sam/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsSamOutput;
};

export type GetFalAiImagePreprocessorsSamRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsSamRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsSamRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/midas/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsMidasRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsMidasRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsMidasRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/midas/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsMidasRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImagePreprocessorsMidasRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsMidasRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsMidasRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsMidasData = {
  body: ImagePreprocessorsMidasInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/midas";
};

export type PostFalAiImagePreprocessorsMidasResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsMidasResponse =
  PostFalAiImagePreprocessorsMidasResponses[keyof PostFalAiImagePreprocessorsMidasResponses];

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/midas/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsMidasOutput;
};

export type GetFalAiImagePreprocessorsMidasRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsMidasRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsMidasRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/teed/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsTeedRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsTeedRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsTeedRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/teed/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsTeedRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsTeedRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsTeedRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsTeedRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsTeedData = {
  body: ImagePreprocessorsTeedInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/teed";
};

export type PostFalAiImagePreprocessorsTeedResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsTeedResponse =
  PostFalAiImagePreprocessorsTeedResponses[keyof PostFalAiImagePreprocessorsTeedResponses];

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/teed/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsTeedOutput;
};

export type GetFalAiImagePreprocessorsTeedRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsTeedRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsTeedRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/lineart/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsLineartRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsLineartRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsLineartRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/lineart/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsLineartRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImagePreprocessorsLineartRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsLineartRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsLineartRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsLineartData = {
  body: ImagePreprocessorsLineartInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/lineart";
};

export type PostFalAiImagePreprocessorsLineartResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsLineartResponse =
  PostFalAiImagePreprocessorsLineartResponses[keyof PostFalAiImagePreprocessorsLineartResponses];

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/lineart/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsLineartOutput;
};

export type GetFalAiImagePreprocessorsLineartRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsLineartRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsLineartRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/zoe/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsZoeRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsZoeRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsZoeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/zoe/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsZoeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsZoeRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsZoeRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsZoeRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsZoeData = {
  body: ImagePreprocessorsZoeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/zoe";
};

export type PostFalAiImagePreprocessorsZoeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsZoeResponse =
  PostFalAiImagePreprocessorsZoeResponses[keyof PostFalAiImagePreprocessorsZoeResponses];

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/zoe/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsZoeOutput;
};

export type GetFalAiImagePreprocessorsZoeRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsZoeRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsZoeRequestsByRequestIdResponses];

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/image-preprocessors/pidi/requests/{request_id}/status";
};

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdStatusResponse =
  GetFalAiImagePreprocessorsPidiRequestsByRequestIdStatusResponses[keyof GetFalAiImagePreprocessorsPidiRequestsByRequestIdStatusResponses];

export type PutFalAiImagePreprocessorsPidiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/pidi/requests/{request_id}/cancel";
};

export type PutFalAiImagePreprocessorsPidiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagePreprocessorsPidiRequestsByRequestIdCancelResponse =
  PutFalAiImagePreprocessorsPidiRequestsByRequestIdCancelResponses[keyof PutFalAiImagePreprocessorsPidiRequestsByRequestIdCancelResponses];

export type PostFalAiImagePreprocessorsPidiData = {
  body: ImagePreprocessorsPidiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/image-preprocessors/pidi";
};

export type PostFalAiImagePreprocessorsPidiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagePreprocessorsPidiResponse =
  PostFalAiImagePreprocessorsPidiResponses[keyof PostFalAiImagePreprocessorsPidiResponses];

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/image-preprocessors/pidi/requests/{request_id}";
};

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImagePreprocessorsPidiOutput;
};

export type GetFalAiImagePreprocessorsPidiRequestsByRequestIdResponse =
  GetFalAiImagePreprocessorsPidiRequestsByRequestIdResponses[keyof GetFalAiImagePreprocessorsPidiRequestsByRequestIdResponses];

export type GetFalAiSam2ImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam2/image/requests/{request_id}/status";
};

export type GetFalAiSam2ImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSam2ImageRequestsByRequestIdStatusResponse =
  GetFalAiSam2ImageRequestsByRequestIdStatusResponses[keyof GetFalAiSam2ImageRequestsByRequestIdStatusResponses];

export type PutFalAiSam2ImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam2/image/requests/{request_id}/cancel";
};

export type PutFalAiSam2ImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSam2ImageRequestsByRequestIdCancelResponse =
  PutFalAiSam2ImageRequestsByRequestIdCancelResponses[keyof PutFalAiSam2ImageRequestsByRequestIdCancelResponses];

export type PostFalAiSam2ImageData = {
  body: Sam2ImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam2/image";
};

export type PostFalAiSam2ImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSam2ImageResponse =
  PostFalAiSam2ImageResponses[keyof PostFalAiSam2ImageResponses];

export type GetFalAiSam2ImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam2/image/requests/{request_id}";
};

export type GetFalAiSam2ImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Sam2ImageOutput;
};

export type GetFalAiSam2ImageRequestsByRequestIdResponse =
  GetFalAiSam2ImageRequestsByRequestIdResponses[keyof GetFalAiSam2ImageRequestsByRequestIdResponses];

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-general/inpainting/requests/{request_id}/status";
};

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFluxGeneralInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFluxGeneralInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFluxGeneralInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFluxGeneralInpaintingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxGeneralInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFluxGeneralInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFluxGeneralInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFluxGeneralInpaintingData = {
  body: FluxGeneralInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-general/inpainting";
};

export type PostFalAiFluxGeneralInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxGeneralInpaintingResponse =
  PostFalAiFluxGeneralInpaintingResponses[keyof PostFalAiFluxGeneralInpaintingResponses];

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/inpainting/requests/{request_id}";
};

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxGeneralInpaintingOutput;
};

export type GetFalAiFluxGeneralInpaintingRequestsByRequestIdResponse =
  GetFalAiFluxGeneralInpaintingRequestsByRequestIdResponses[keyof GetFalAiFluxGeneralInpaintingRequestsByRequestIdResponses];

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-general/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxGeneralImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxGeneralImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxGeneralImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxGeneralImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxGeneralImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxGeneralImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxGeneralImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxGeneralImageToImageData = {
  body: FluxGeneralImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-general/image-to-image";
};

export type PostFalAiFluxGeneralImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxGeneralImageToImageResponse =
  PostFalAiFluxGeneralImageToImageResponses[keyof PostFalAiFluxGeneralImageToImageResponses];

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxGeneralImageToImageOutput;
};

export type GetFalAiFluxGeneralImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxGeneralImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxGeneralImageToImageRequestsByRequestIdResponses];

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-general/differential-diffusion/requests/{request_id}/status";
  };

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-general/differential-diffusion/requests/{request_id}/cancel";
  };

export type PutFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiFluxGeneralDifferentialDiffusionData = {
  body: FluxGeneralDifferentialDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-general/differential-diffusion";
};

export type PostFalAiFluxGeneralDifferentialDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxGeneralDifferentialDiffusionResponse =
  PostFalAiFluxGeneralDifferentialDiffusionResponses[keyof PostFalAiFluxGeneralDifferentialDiffusionResponses];

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/differential-diffusion/requests/{request_id}";
};

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FluxGeneralDifferentialDiffusionOutput;
  };

export type GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdResponse =
  GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdResponses[keyof GetFalAiFluxGeneralDifferentialDiffusionRequestsByRequestIdResponses];

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraImageToImageData = {
  body: FluxLoraImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora/image-to-image";
};

export type PostFalAiFluxLoraImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraImageToImageResponse =
  PostFalAiFluxLoraImageToImageResponses[keyof PostFalAiFluxLoraImageToImageResponses];

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/image-to-image/requests/{request_id}";
};

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraImageToImageOutput;
};

export type GetFalAiFluxLoraImageToImageRequestsByRequestIdResponse =
  GetFalAiFluxLoraImageToImageRequestsByRequestIdResponses[keyof GetFalAiFluxLoraImageToImageRequestsByRequestIdResponses];

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/sdxl-controlnet-union/inpainting/requests/{request_id}/status";
  };

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/sdxl-controlnet-union/inpainting/requests/{request_id}/cancel";
  };

export type PutFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiSdxlControlnetUnionInpaintingData = {
  body: SdxlControlnetUnionInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/inpainting";
};

export type PostFalAiSdxlControlnetUnionInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSdxlControlnetUnionInpaintingResponse =
  PostFalAiSdxlControlnetUnionInpaintingResponses[keyof PostFalAiSdxlControlnetUnionInpaintingResponses];

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/inpainting/requests/{request_id}";
};

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SdxlControlnetUnionInpaintingOutput;
  };

export type GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdResponse =
  GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdResponses[keyof GetFalAiSdxlControlnetUnionInpaintingRequestsByRequestIdResponses];

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/sdxl-controlnet-union/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/sdxl-controlnet-union/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiSdxlControlnetUnionImageToImageData = {
  body: SdxlControlnetUnionImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/image-to-image";
};

export type PostFalAiSdxlControlnetUnionImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSdxlControlnetUnionImageToImageResponse =
  PostFalAiSdxlControlnetUnionImageToImageResponses[keyof PostFalAiSdxlControlnetUnionImageToImageResponses];

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/image-to-image/requests/{request_id}";
};

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: SdxlControlnetUnionImageToImageOutput;
  };

export type GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdResponse =
  GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdResponses[keyof GetFalAiSdxlControlnetUnionImageToImageRequestsByRequestIdResponses];

export type GetFalAiEra3dRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/era-3d/requests/{request_id}/status";
};

export type GetFalAiEra3dRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiEra3dRequestsByRequestIdStatusResponse =
  GetFalAiEra3dRequestsByRequestIdStatusResponses[keyof GetFalAiEra3dRequestsByRequestIdStatusResponses];

export type PutFalAiEra3dRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/era-3d/requests/{request_id}/cancel";
};

export type PutFalAiEra3dRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiEra3dRequestsByRequestIdCancelResponse =
  PutFalAiEra3dRequestsByRequestIdCancelResponses[keyof PutFalAiEra3dRequestsByRequestIdCancelResponses];

export type PostFalAiEra3dData = {
  body: Era3dInput;
  path?: never;
  query?: never;
  url: "/fal-ai/era-3d";
};

export type PostFalAiEra3dResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiEra3dResponse =
  PostFalAiEra3dResponses[keyof PostFalAiEra3dResponses];

export type GetFalAiEra3dRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/era-3d/requests/{request_id}";
};

export type GetFalAiEra3dRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Era3dOutput;
};

export type GetFalAiEra3dRequestsByRequestIdResponse =
  GetFalAiEra3dRequestsByRequestIdResponses[keyof GetFalAiEra3dRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/dense-region-caption/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/dense-region-caption/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeDenseRegionCaptionData = {
  body: Florence2LargeDenseRegionCaptionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/dense-region-caption";
};

export type PostFalAiFlorence2LargeDenseRegionCaptionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeDenseRegionCaptionResponse =
  PostFalAiFlorence2LargeDenseRegionCaptionResponses[keyof PostFalAiFlorence2LargeDenseRegionCaptionResponses];

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/florence-2-large/dense-region-caption/requests/{request_id}";
};

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeDenseRegionCaptionOutput;
  };

export type GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeDenseRegionCaptionRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/referring-expression-segmentation/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/referring-expression-segmentation/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeReferringExpressionSegmentationData = {
  body: Florence2LargeReferringExpressionSegmentationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/referring-expression-segmentation";
};

export type PostFalAiFlorence2LargeReferringExpressionSegmentationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeReferringExpressionSegmentationResponse =
  PostFalAiFlorence2LargeReferringExpressionSegmentationResponses[keyof PostFalAiFlorence2LargeReferringExpressionSegmentationResponses];

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/referring-expression-segmentation/requests/{request_id}";
  };

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeReferringExpressionSegmentationOutput;
  };

export type GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeReferringExpressionSegmentationRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/object-detection/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeObjectDetectionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/object-detection/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeObjectDetectionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeObjectDetectionRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeObjectDetectionRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeObjectDetectionRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeObjectDetectionData = {
  body: Florence2LargeObjectDetectionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/object-detection";
};

export type PostFalAiFlorence2LargeObjectDetectionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeObjectDetectionResponse =
  PostFalAiFlorence2LargeObjectDetectionResponses[keyof PostFalAiFlorence2LargeObjectDetectionResponses];

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/florence-2-large/object-detection/requests/{request_id}";
};

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeObjectDetectionOutput;
  };

export type GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeObjectDetectionRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/open-vocabulary-detection/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/open-vocabulary-detection/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeOpenVocabularyDetectionData = {
  body: Florence2LargeOpenVocabularyDetectionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/open-vocabulary-detection";
};

export type PostFalAiFlorence2LargeOpenVocabularyDetectionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeOpenVocabularyDetectionResponse =
  PostFalAiFlorence2LargeOpenVocabularyDetectionResponses[keyof PostFalAiFlorence2LargeOpenVocabularyDetectionResponses];

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/open-vocabulary-detection/requests/{request_id}";
  };

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeOpenVocabularyDetectionOutput;
  };

export type GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeOpenVocabularyDetectionRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/caption-to-phrase-grounding/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/caption-to-phrase-grounding/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeCaptionToPhraseGroundingData = {
  body: Florence2LargeCaptionToPhraseGroundingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/caption-to-phrase-grounding";
};

export type PostFalAiFlorence2LargeCaptionToPhraseGroundingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeCaptionToPhraseGroundingResponse =
  PostFalAiFlorence2LargeCaptionToPhraseGroundingResponses[keyof PostFalAiFlorence2LargeCaptionToPhraseGroundingResponses];

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/caption-to-phrase-grounding/requests/{request_id}";
  };

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeCaptionToPhraseGroundingOutput;
  };

export type GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeCaptionToPhraseGroundingRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/region-proposal/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeRegionProposalRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/region-proposal/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeRegionProposalRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeRegionProposalRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeRegionProposalRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeRegionProposalRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeRegionProposalData = {
  body: Florence2LargeRegionProposalInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/region-proposal";
};

export type PostFalAiFlorence2LargeRegionProposalResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeRegionProposalResponse =
  PostFalAiFlorence2LargeRegionProposalResponses[keyof PostFalAiFlorence2LargeRegionProposalResponses];

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/florence-2-large/region-proposal/requests/{request_id}";
};

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Florence2LargeRegionProposalOutput;
};

export type GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeRegionProposalRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/florence-2-large/ocr-with-region/requests/{request_id}/status";
};

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/florence-2-large/ocr-with-region/requests/{request_id}/cancel";
};

export type PutFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeOcrWithRegionData = {
  body: Florence2LargeOcrWithRegionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/ocr-with-region";
};

export type PostFalAiFlorence2LargeOcrWithRegionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeOcrWithRegionResponse =
  PostFalAiFlorence2LargeOcrWithRegionResponses[keyof PostFalAiFlorence2LargeOcrWithRegionResponses];

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/florence-2-large/ocr-with-region/requests/{request_id}";
};

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Florence2LargeOcrWithRegionOutput;
};

export type GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeOcrWithRegionRequestsByRequestIdResponses];

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/florence-2-large/region-to-segmentation/requests/{request_id}/status";
  };

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdStatusResponse =
  GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdStatusResponses[keyof GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdStatusResponses];

export type PutFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/region-to-segmentation/requests/{request_id}/cancel";
  };

export type PutFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdCancelResponse =
  PutFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdCancelResponses[keyof PutFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdCancelResponses];

export type PostFalAiFlorence2LargeRegionToSegmentationData = {
  body: Florence2LargeRegionToSegmentationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/florence-2-large/region-to-segmentation";
};

export type PostFalAiFlorence2LargeRegionToSegmentationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlorence2LargeRegionToSegmentationResponse =
  PostFalAiFlorence2LargeRegionToSegmentationResponses[keyof PostFalAiFlorence2LargeRegionToSegmentationResponses];

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/florence-2-large/region-to-segmentation/requests/{request_id}";
  };

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Florence2LargeRegionToSegmentationOutput;
  };

export type GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdResponse =
  GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdResponses[keyof GetFalAiFlorence2LargeRegionToSegmentationRequestsByRequestIdResponses];

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/stable-diffusion-v3-medium/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/stable-diffusion-v3-medium/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiStableDiffusionV3MediumImageToImageData = {
  body: StableDiffusionV3MediumImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-diffusion-v3-medium/image-to-image";
};

export type PostFalAiStableDiffusionV3MediumImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableDiffusionV3MediumImageToImageResponse =
  PostFalAiStableDiffusionV3MediumImageToImageResponses[keyof PostFalAiStableDiffusionV3MediumImageToImageResponses];

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/stable-diffusion-v3-medium/image-to-image/requests/{request_id}";
  };

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: StableDiffusionV3MediumImageToImageOutput;
  };

export type GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdResponse =
  GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdResponses[keyof GetFalAiStableDiffusionV3MediumImageToImageRequestsByRequestIdResponses];

export type GetFalAiDwposeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dwpose/requests/{request_id}/status";
};

export type GetFalAiDwposeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDwposeRequestsByRequestIdStatusResponse =
  GetFalAiDwposeRequestsByRequestIdStatusResponses[keyof GetFalAiDwposeRequestsByRequestIdStatusResponses];

export type PutFalAiDwposeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dwpose/requests/{request_id}/cancel";
};

export type PutFalAiDwposeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDwposeRequestsByRequestIdCancelResponse =
  PutFalAiDwposeRequestsByRequestIdCancelResponses[keyof PutFalAiDwposeRequestsByRequestIdCancelResponses];

export type PostFalAiDwposeData = {
  body: DwposeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dwpose";
};

export type PostFalAiDwposeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDwposeResponse =
  PostFalAiDwposeResponses[keyof PostFalAiDwposeResponses];

export type GetFalAiDwposeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dwpose/requests/{request_id}";
};

export type GetFalAiDwposeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DwposeOutput;
};

export type GetFalAiDwposeRequestsByRequestIdResponse =
  GetFalAiDwposeRequestsByRequestIdResponses[keyof GetFalAiDwposeRequestsByRequestIdResponses];

export type GetFalAiSd15DepthControlnetRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sd15-depth-controlnet/requests/{request_id}/status";
};

export type GetFalAiSd15DepthControlnetRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSd15DepthControlnetRequestsByRequestIdStatusResponse =
  GetFalAiSd15DepthControlnetRequestsByRequestIdStatusResponses[keyof GetFalAiSd15DepthControlnetRequestsByRequestIdStatusResponses];

export type PutFalAiSd15DepthControlnetRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sd15-depth-controlnet/requests/{request_id}/cancel";
};

export type PutFalAiSd15DepthControlnetRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSd15DepthControlnetRequestsByRequestIdCancelResponse =
  PutFalAiSd15DepthControlnetRequestsByRequestIdCancelResponses[keyof PutFalAiSd15DepthControlnetRequestsByRequestIdCancelResponses];

export type PostFalAiSd15DepthControlnetData = {
  body: Sd15DepthControlnetInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sd15-depth-controlnet";
};

export type PostFalAiSd15DepthControlnetResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSd15DepthControlnetResponse =
  PostFalAiSd15DepthControlnetResponses[keyof PostFalAiSd15DepthControlnetResponses];

export type GetFalAiSd15DepthControlnetRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sd15-depth-controlnet/requests/{request_id}";
};

export type GetFalAiSd15DepthControlnetRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Sd15DepthControlnetOutput;
};

export type GetFalAiSd15DepthControlnetRequestsByRequestIdResponse =
  GetFalAiSd15DepthControlnetRequestsByRequestIdResponses[keyof GetFalAiSd15DepthControlnetRequestsByRequestIdResponses];

export type GetFalAiCcsrRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ccsr/requests/{request_id}/status";
};

export type GetFalAiCcsrRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCcsrRequestsByRequestIdStatusResponse =
  GetFalAiCcsrRequestsByRequestIdStatusResponses[keyof GetFalAiCcsrRequestsByRequestIdStatusResponses];

export type PutFalAiCcsrRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ccsr/requests/{request_id}/cancel";
};

export type PutFalAiCcsrRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCcsrRequestsByRequestIdCancelResponse =
  PutFalAiCcsrRequestsByRequestIdCancelResponses[keyof PutFalAiCcsrRequestsByRequestIdCancelResponses];

export type PostFalAiCcsrData = {
  body: CcsrInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ccsr";
};

export type PostFalAiCcsrResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCcsrResponse =
  PostFalAiCcsrResponses[keyof PostFalAiCcsrResponses];

export type GetFalAiCcsrRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ccsr/requests/{request_id}";
};

export type GetFalAiCcsrRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CcsrOutput;
};

export type GetFalAiCcsrRequestsByRequestIdResponse =
  GetFalAiCcsrRequestsByRequestIdResponses[keyof GetFalAiCcsrRequestsByRequestIdResponses];

export type GetFalAiOmniZeroRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/omni-zero/requests/{request_id}/status";
};

export type GetFalAiOmniZeroRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiOmniZeroRequestsByRequestIdStatusResponse =
  GetFalAiOmniZeroRequestsByRequestIdStatusResponses[keyof GetFalAiOmniZeroRequestsByRequestIdStatusResponses];

export type PutFalAiOmniZeroRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omni-zero/requests/{request_id}/cancel";
};

export type PutFalAiOmniZeroRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiOmniZeroRequestsByRequestIdCancelResponse =
  PutFalAiOmniZeroRequestsByRequestIdCancelResponses[keyof PutFalAiOmniZeroRequestsByRequestIdCancelResponses];

export type PostFalAiOmniZeroData = {
  body: OmniZeroInput;
  path?: never;
  query?: never;
  url: "/fal-ai/omni-zero";
};

export type PostFalAiOmniZeroResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiOmniZeroResponse =
  PostFalAiOmniZeroResponses[keyof PostFalAiOmniZeroResponses];

export type GetFalAiOmniZeroRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omni-zero/requests/{request_id}";
};

export type GetFalAiOmniZeroRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: OmniZeroOutput;
};

export type GetFalAiOmniZeroRequestsByRequestIdResponse =
  GetFalAiOmniZeroRequestsByRequestIdResponses[keyof GetFalAiOmniZeroRequestsByRequestIdResponses];

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ip-adapter-face-id/requests/{request_id}/status";
};

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdStatusResponse =
  GetFalAiIpAdapterFaceIdRequestsByRequestIdStatusResponses[keyof GetFalAiIpAdapterFaceIdRequestsByRequestIdStatusResponses];

export type PutFalAiIpAdapterFaceIdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ip-adapter-face-id/requests/{request_id}/cancel";
};

export type PutFalAiIpAdapterFaceIdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIpAdapterFaceIdRequestsByRequestIdCancelResponse =
  PutFalAiIpAdapterFaceIdRequestsByRequestIdCancelResponses[keyof PutFalAiIpAdapterFaceIdRequestsByRequestIdCancelResponses];

export type PostFalAiIpAdapterFaceIdData = {
  body: IpAdapterFaceIdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ip-adapter-face-id";
};

export type PostFalAiIpAdapterFaceIdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIpAdapterFaceIdResponse =
  PostFalAiIpAdapterFaceIdResponses[keyof PostFalAiIpAdapterFaceIdResponses];

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ip-adapter-face-id/requests/{request_id}";
};

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IpAdapterFaceIdOutput;
};

export type GetFalAiIpAdapterFaceIdRequestsByRequestIdResponse =
  GetFalAiIpAdapterFaceIdRequestsByRequestIdResponses[keyof GetFalAiIpAdapterFaceIdRequestsByRequestIdResponses];

export type GetFalAiLoraInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lora/inpaint/requests/{request_id}/status";
};

export type GetFalAiLoraInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLoraInpaintRequestsByRequestIdStatusResponse =
  GetFalAiLoraInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiLoraInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiLoraInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiLoraInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLoraInpaintRequestsByRequestIdCancelResponse =
  PutFalAiLoraInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiLoraInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiLoraInpaintData = {
  body: LoraInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lora/inpaint";
};

export type PostFalAiLoraInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLoraInpaintResponse =
  PostFalAiLoraInpaintResponses[keyof PostFalAiLoraInpaintResponses];

export type GetFalAiLoraInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/inpaint/requests/{request_id}";
};

export type GetFalAiLoraInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LoraInpaintOutput;
};

export type GetFalAiLoraInpaintRequestsByRequestIdResponse =
  GetFalAiLoraInpaintRequestsByRequestIdResponses[keyof GetFalAiLoraInpaintRequestsByRequestIdResponses];

export type GetFalAiLoraImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lora/image-to-image/requests/{request_id}/status";
};

export type GetFalAiLoraImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLoraImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiLoraImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiLoraImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiLoraImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiLoraImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLoraImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiLoraImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiLoraImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiLoraImageToImageData = {
  body: LoraImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lora/image-to-image";
};

export type PostFalAiLoraImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLoraImageToImageResponse =
  PostFalAiLoraImageToImageResponses[keyof PostFalAiLoraImageToImageResponses];

export type GetFalAiLoraImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/image-to-image/requests/{request_id}";
};

export type GetFalAiLoraImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LoraImageToImageOutput;
};

export type GetFalAiLoraImageToImageRequestsByRequestIdResponse =
  GetFalAiLoraImageToImageRequestsByRequestIdResponses[keyof GetFalAiLoraImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-sdxl/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFastSdxlImageToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastSdxlImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlImageToImageData = {
  body: FastSdxlImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl/image-to-image";
};

export type PostFalAiFastSdxlImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlImageToImageResponse =
  PostFalAiFastSdxlImageToImageResponses[keyof PostFalAiFastSdxlImageToImageResponses];

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/image-to-image/requests/{request_id}";
};

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastSdxlImageToImageOutput;
};

export type GetFalAiFastSdxlImageToImageRequestsByRequestIdResponse =
  GetFalAiFastSdxlImageToImageRequestsByRequestIdResponses[keyof GetFalAiFastSdxlImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-sdxl/inpainting/requests/{request_id}/status";
};

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFastSdxlInpaintingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastSdxlInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlInpaintingData = {
  body: FastSdxlInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl/inpainting";
};

export type PostFalAiFastSdxlInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlInpaintingResponse =
  PostFalAiFastSdxlInpaintingResponses[keyof PostFalAiFastSdxlInpaintingResponses];

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/inpainting/requests/{request_id}";
};

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastSdxlInpaintingOutput;
};

export type GetFalAiFastSdxlInpaintingRequestsByRequestIdResponse =
  GetFalAiFastSdxlInpaintingRequestsByRequestIdResponses[keyof GetFalAiFastSdxlInpaintingRequestsByRequestIdResponses];

export type GetFalAiFaceToStickerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/face-to-sticker/requests/{request_id}/status";
};

export type GetFalAiFaceToStickerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFaceToStickerRequestsByRequestIdStatusResponse =
  GetFalAiFaceToStickerRequestsByRequestIdStatusResponses[keyof GetFalAiFaceToStickerRequestsByRequestIdStatusResponses];

export type PutFalAiFaceToStickerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/face-to-sticker/requests/{request_id}/cancel";
};

export type PutFalAiFaceToStickerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFaceToStickerRequestsByRequestIdCancelResponse =
  PutFalAiFaceToStickerRequestsByRequestIdCancelResponses[keyof PutFalAiFaceToStickerRequestsByRequestIdCancelResponses];

export type PostFalAiFaceToStickerData = {
  body: FaceToStickerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/face-to-sticker";
};

export type PostFalAiFaceToStickerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFaceToStickerResponse =
  PostFalAiFaceToStickerResponses[keyof PostFalAiFaceToStickerResponses];

export type GetFalAiFaceToStickerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/face-to-sticker/requests/{request_id}";
};

export type GetFalAiFaceToStickerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FaceToStickerOutput;
};

export type GetFalAiFaceToStickerRequestsByRequestIdResponse =
  GetFalAiFaceToStickerRequestsByRequestIdResponses[keyof GetFalAiFaceToStickerRequestsByRequestIdResponses];

export type GetFalAiPhotomakerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/photomaker/requests/{request_id}/status";
};

export type GetFalAiPhotomakerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPhotomakerRequestsByRequestIdStatusResponse =
  GetFalAiPhotomakerRequestsByRequestIdStatusResponses[keyof GetFalAiPhotomakerRequestsByRequestIdStatusResponses];

export type PutFalAiPhotomakerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/photomaker/requests/{request_id}/cancel";
};

export type PutFalAiPhotomakerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPhotomakerRequestsByRequestIdCancelResponse =
  PutFalAiPhotomakerRequestsByRequestIdCancelResponses[keyof PutFalAiPhotomakerRequestsByRequestIdCancelResponses];

export type PostFalAiPhotomakerData = {
  body: PhotomakerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/photomaker";
};

export type PostFalAiPhotomakerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPhotomakerResponse =
  PostFalAiPhotomakerResponses[keyof PostFalAiPhotomakerResponses];

export type GetFalAiPhotomakerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/photomaker/requests/{request_id}";
};

export type GetFalAiPhotomakerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PhotomakerOutput;
};

export type GetFalAiPhotomakerRequestsByRequestIdResponse =
  GetFalAiPhotomakerRequestsByRequestIdResponses[keyof GetFalAiPhotomakerRequestsByRequestIdResponses];

export type GetFalAiCreativeUpscalerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/creative-upscaler/requests/{request_id}/status";
};

export type GetFalAiCreativeUpscalerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCreativeUpscalerRequestsByRequestIdStatusResponse =
  GetFalAiCreativeUpscalerRequestsByRequestIdStatusResponses[keyof GetFalAiCreativeUpscalerRequestsByRequestIdStatusResponses];

export type PutFalAiCreativeUpscalerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/creative-upscaler/requests/{request_id}/cancel";
};

export type PutFalAiCreativeUpscalerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCreativeUpscalerRequestsByRequestIdCancelResponse =
  PutFalAiCreativeUpscalerRequestsByRequestIdCancelResponses[keyof PutFalAiCreativeUpscalerRequestsByRequestIdCancelResponses];

export type PostFalAiCreativeUpscalerData = {
  body: CreativeUpscalerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/creative-upscaler";
};

export type PostFalAiCreativeUpscalerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCreativeUpscalerResponse =
  PostFalAiCreativeUpscalerResponses[keyof PostFalAiCreativeUpscalerResponses];

export type GetFalAiCreativeUpscalerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/creative-upscaler/requests/{request_id}";
};

export type GetFalAiCreativeUpscalerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: CreativeUpscalerOutput;
};

export type GetFalAiCreativeUpscalerRequestsByRequestIdResponse =
  GetFalAiCreativeUpscalerRequestsByRequestIdResponses[keyof GetFalAiCreativeUpscalerRequestsByRequestIdResponses];

export type GetFalAiBirefnetRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/birefnet/requests/{request_id}/status";
};

export type GetFalAiBirefnetRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBirefnetRequestsByRequestIdStatusResponse =
  GetFalAiBirefnetRequestsByRequestIdStatusResponses[keyof GetFalAiBirefnetRequestsByRequestIdStatusResponses];

export type PutFalAiBirefnetRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/birefnet/requests/{request_id}/cancel";
};

export type PutFalAiBirefnetRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBirefnetRequestsByRequestIdCancelResponse =
  PutFalAiBirefnetRequestsByRequestIdCancelResponses[keyof PutFalAiBirefnetRequestsByRequestIdCancelResponses];

export type PostFalAiBirefnetData = {
  body: BirefnetInput;
  path?: never;
  query?: never;
  url: "/fal-ai/birefnet";
};

export type PostFalAiBirefnetResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBirefnetResponse =
  PostFalAiBirefnetResponses[keyof PostFalAiBirefnetResponses];

export type GetFalAiBirefnetRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/birefnet/requests/{request_id}";
};

export type GetFalAiBirefnetRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BirefnetOutput;
};

export type GetFalAiBirefnetRequestsByRequestIdResponse =
  GetFalAiBirefnetRequestsByRequestIdResponses[keyof GetFalAiBirefnetRequestsByRequestIdResponses];

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/playground-v25/image-to-image/requests/{request_id}/status";
};

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiPlaygroundV25ImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiPlaygroundV25ImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPlaygroundV25ImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiPlaygroundV25ImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiPlaygroundV25ImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiPlaygroundV25ImageToImageData = {
  body: PlaygroundV25ImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/playground-v25/image-to-image";
};

export type PostFalAiPlaygroundV25ImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPlaygroundV25ImageToImageResponse =
  PostFalAiPlaygroundV25ImageToImageResponses[keyof PostFalAiPlaygroundV25ImageToImageResponses];

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/image-to-image/requests/{request_id}";
};

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PlaygroundV25ImageToImageOutput;
};

export type GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdResponse =
  GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdResponses[keyof GetFalAiPlaygroundV25ImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/fast-lightning-sdxl/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFastLightningSdxlImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/fast-lightning-sdxl/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFastLightningSdxlImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastLightningSdxlImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFastLightningSdxlImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFastLightningSdxlImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFastLightningSdxlImageToImageData = {
  body: FastLightningSdxlImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/image-to-image";
};

export type PostFalAiFastLightningSdxlImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLightningSdxlImageToImageResponse =
  PostFalAiFastLightningSdxlImageToImageResponses[keyof PostFalAiFastLightningSdxlImageToImageResponses];

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/image-to-image/requests/{request_id}";
};

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FastLightningSdxlImageToImageOutput;
  };

export type GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdResponse =
  GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdResponses[keyof GetFalAiFastLightningSdxlImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-lightning-sdxl/inpainting/requests/{request_id}/status";
};

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFastLightningSdxlInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFastLightningSdxlInpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastLightningSdxlInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFastLightningSdxlInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFastLightningSdxlInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFastLightningSdxlInpaintingData = {
  body: FastLightningSdxlInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/inpainting";
};

export type PostFalAiFastLightningSdxlInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLightningSdxlInpaintingResponse =
  PostFalAiFastLightningSdxlInpaintingResponses[keyof PostFalAiFastLightningSdxlInpaintingResponses];

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/inpainting/requests/{request_id}";
};

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastLightningSdxlInpaintingOutput;
};

export type GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdResponse =
  GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdResponses[keyof GetFalAiFastLightningSdxlInpaintingRequestsByRequestIdResponses];

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/playground-v25/inpainting/requests/{request_id}/status";
};

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdStatusResponse =
  GetFalAiPlaygroundV25InpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiPlaygroundV25InpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiPlaygroundV25InpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiPlaygroundV25InpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiPlaygroundV25InpaintingRequestsByRequestIdCancelResponse =
  PutFalAiPlaygroundV25InpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiPlaygroundV25InpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiPlaygroundV25InpaintingData = {
  body: PlaygroundV25InpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/playground-v25/inpainting";
};

export type PostFalAiPlaygroundV25InpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPlaygroundV25InpaintingResponse =
  PostFalAiPlaygroundV25InpaintingResponses[keyof PostFalAiPlaygroundV25InpaintingResponses];

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/inpainting/requests/{request_id}";
};

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PlaygroundV25InpaintingOutput;
};

export type GetFalAiPlaygroundV25InpaintingRequestsByRequestIdResponse =
  GetFalAiPlaygroundV25InpaintingRequestsByRequestIdResponses[keyof GetFalAiPlaygroundV25InpaintingRequestsByRequestIdResponses];

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-lcm-diffusion/inpainting/requests/{request_id}/status";
};

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFastLcmDiffusionInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFastLcmDiffusionInpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastLcmDiffusionInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFastLcmDiffusionInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFastLcmDiffusionInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFastLcmDiffusionInpaintingData = {
  body: FastLcmDiffusionInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/inpainting";
};

export type PostFalAiFastLcmDiffusionInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLcmDiffusionInpaintingResponse =
  PostFalAiFastLcmDiffusionInpaintingResponses[keyof PostFalAiFastLcmDiffusionInpaintingResponses];

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/inpainting/requests/{request_id}";
};

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastLcmDiffusionInpaintingOutput;
};

export type GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdResponse =
  GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdResponses[keyof GetFalAiFastLcmDiffusionInpaintingRequestsByRequestIdResponses];

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/fast-lcm-diffusion/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFastLcmDiffusionImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/fast-lcm-diffusion/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFastLcmDiffusionImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastLcmDiffusionImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFastLcmDiffusionImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFastLcmDiffusionImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFastLcmDiffusionImageToImageData = {
  body: FastLcmDiffusionImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/image-to-image";
};

export type PostFalAiFastLcmDiffusionImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLcmDiffusionImageToImageResponse =
  PostFalAiFastLcmDiffusionImageToImageResponses[keyof PostFalAiFastLcmDiffusionImageToImageResponses];

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/image-to-image/requests/{request_id}";
};

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastLcmDiffusionImageToImageOutput;
};

export type GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdResponse =
  GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdResponses[keyof GetFalAiFastLcmDiffusionImageToImageRequestsByRequestIdResponses];

export type GetFalAiRetoucherRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/retoucher/requests/{request_id}/status";
};

export type GetFalAiRetoucherRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRetoucherRequestsByRequestIdStatusResponse =
  GetFalAiRetoucherRequestsByRequestIdStatusResponses[keyof GetFalAiRetoucherRequestsByRequestIdStatusResponses];

export type PutFalAiRetoucherRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/retoucher/requests/{request_id}/cancel";
};

export type PutFalAiRetoucherRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRetoucherRequestsByRequestIdCancelResponse =
  PutFalAiRetoucherRequestsByRequestIdCancelResponses[keyof PutFalAiRetoucherRequestsByRequestIdCancelResponses];

export type PostFalAiRetoucherData = {
  body: RetoucherInput;
  path?: never;
  query?: never;
  url: "/fal-ai/retoucher";
};

export type PostFalAiRetoucherResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRetoucherResponse =
  PostFalAiRetoucherResponses[keyof PostFalAiRetoucherResponses];

export type GetFalAiRetoucherRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/retoucher/requests/{request_id}";
};

export type GetFalAiRetoucherRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RetoucherOutput;
};

export type GetFalAiRetoucherRequestsByRequestIdResponse =
  GetFalAiRetoucherRequestsByRequestIdResponses[keyof GetFalAiRetoucherRequestsByRequestIdResponses];

export type GetFalAiImageutilsDepthRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imageutils/depth/requests/{request_id}/status";
};

export type GetFalAiImageutilsDepthRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageutilsDepthRequestsByRequestIdStatusResponse =
  GetFalAiImageutilsDepthRequestsByRequestIdStatusResponses[keyof GetFalAiImageutilsDepthRequestsByRequestIdStatusResponses];

export type PutFalAiImageutilsDepthRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/depth/requests/{request_id}/cancel";
};

export type PutFalAiImageutilsDepthRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageutilsDepthRequestsByRequestIdCancelResponse =
  PutFalAiImageutilsDepthRequestsByRequestIdCancelResponses[keyof PutFalAiImageutilsDepthRequestsByRequestIdCancelResponses];

export type PostFalAiImageutilsDepthData = {
  body: ImageutilsDepthInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imageutils/depth";
};

export type PostFalAiImageutilsDepthResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageutilsDepthResponse =
  PostFalAiImageutilsDepthResponses[keyof PostFalAiImageutilsDepthResponses];

export type GetFalAiImageutilsDepthRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/depth/requests/{request_id}";
};

export type GetFalAiImageutilsDepthRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageutilsDepthOutput;
};

export type GetFalAiImageutilsDepthRequestsByRequestIdResponse =
  GetFalAiImageutilsDepthRequestsByRequestIdResponses[keyof GetFalAiImageutilsDepthRequestsByRequestIdResponses];

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imageutils/marigold-depth/requests/{request_id}/status";
};

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdStatusResponse =
  GetFalAiImageutilsMarigoldDepthRequestsByRequestIdStatusResponses[keyof GetFalAiImageutilsMarigoldDepthRequestsByRequestIdStatusResponses];

export type PutFalAiImageutilsMarigoldDepthRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/marigold-depth/requests/{request_id}/cancel";
};

export type PutFalAiImageutilsMarigoldDepthRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiImageutilsMarigoldDepthRequestsByRequestIdCancelResponse =
  PutFalAiImageutilsMarigoldDepthRequestsByRequestIdCancelResponses[keyof PutFalAiImageutilsMarigoldDepthRequestsByRequestIdCancelResponses];

export type PostFalAiImageutilsMarigoldDepthData = {
  body: ImageutilsMarigoldDepthInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imageutils/marigold-depth";
};

export type PostFalAiImageutilsMarigoldDepthResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageutilsMarigoldDepthResponse =
  PostFalAiImageutilsMarigoldDepthResponses[keyof PostFalAiImageutilsMarigoldDepthResponses];

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/marigold-depth/requests/{request_id}";
};

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageutilsMarigoldDepthOutput;
};

export type GetFalAiImageutilsMarigoldDepthRequestsByRequestIdResponse =
  GetFalAiImageutilsMarigoldDepthRequestsByRequestIdResponses[keyof GetFalAiImageutilsMarigoldDepthRequestsByRequestIdResponses];

export type GetFalAiPulidRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/pulid/requests/{request_id}/status";
};

export type GetFalAiPulidRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPulidRequestsByRequestIdStatusResponse =
  GetFalAiPulidRequestsByRequestIdStatusResponses[keyof GetFalAiPulidRequestsByRequestIdStatusResponses];

export type PutFalAiPulidRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pulid/requests/{request_id}/cancel";
};

export type PutFalAiPulidRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPulidRequestsByRequestIdCancelResponse =
  PutFalAiPulidRequestsByRequestIdCancelResponses[keyof PutFalAiPulidRequestsByRequestIdCancelResponses];

export type PostFalAiPulidData = {
  body: PulidInput;
  path?: never;
  query?: never;
  url: "/fal-ai/pulid";
};

export type PostFalAiPulidResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPulidResponse =
  PostFalAiPulidResponses[keyof PostFalAiPulidResponses];

export type GetFalAiPulidRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pulid/requests/{request_id}";
};

export type GetFalAiPulidRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PulidOutput;
};

export type GetFalAiPulidRequestsByRequestIdResponse =
  GetFalAiPulidRequestsByRequestIdResponses[keyof GetFalAiPulidRequestsByRequestIdResponses];

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/fast-sdxl-controlnet-canny/image-to-image/requests/{request_id}/status";
  };

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/fast-sdxl-controlnet-canny/image-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlControlnetCannyImageToImageData = {
  body: FastSdxlControlnetCannyImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny/image-to-image";
};

export type PostFalAiFastSdxlControlnetCannyImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlControlnetCannyImageToImageResponse =
  PostFalAiFastSdxlControlnetCannyImageToImageResponses[keyof PostFalAiFastSdxlControlnetCannyImageToImageResponses];

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/fast-sdxl-controlnet-canny/image-to-image/requests/{request_id}";
  };

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FastSdxlControlnetCannyImageToImageOutput;
  };

export type GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdResponse =
  GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdResponses[keyof GetFalAiFastSdxlControlnetCannyImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/fast-sdxl-controlnet-canny/inpainting/requests/{request_id}/status";
  };

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/fast-sdxl-controlnet-canny/inpainting/requests/{request_id}/cancel";
  };

export type PutFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlControlnetCannyInpaintingData = {
  body: FastSdxlControlnetCannyInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny/inpainting";
};

export type PostFalAiFastSdxlControlnetCannyInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlControlnetCannyInpaintingResponse =
  PostFalAiFastSdxlControlnetCannyInpaintingResponses[keyof PostFalAiFastSdxlControlnetCannyInpaintingResponses];

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny/inpainting/requests/{request_id}";
};

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: FastSdxlControlnetCannyInpaintingOutput;
  };

export type GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdResponse =
  GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdResponses[keyof GetFalAiFastSdxlControlnetCannyInpaintingRequestsByRequestIdResponses];

export type GetFalAiLcmSd15I2iRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lcm-sd15-i2i/requests/{request_id}/status";
};

export type GetFalAiLcmSd15I2iRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLcmSd15I2iRequestsByRequestIdStatusResponse =
  GetFalAiLcmSd15I2iRequestsByRequestIdStatusResponses[keyof GetFalAiLcmSd15I2iRequestsByRequestIdStatusResponses];

export type PutFalAiLcmSd15I2iRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lcm-sd15-i2i/requests/{request_id}/cancel";
};

export type PutFalAiLcmSd15I2iRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLcmSd15I2iRequestsByRequestIdCancelResponse =
  PutFalAiLcmSd15I2iRequestsByRequestIdCancelResponses[keyof PutFalAiLcmSd15I2iRequestsByRequestIdCancelResponses];

export type PostFalAiLcmSd15I2iData = {
  body: LcmSd15I2iInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lcm-sd15-i2i";
};

export type PostFalAiLcmSd15I2iResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLcmSd15I2iResponse =
  PostFalAiLcmSd15I2iResponses[keyof PostFalAiLcmSd15I2iResponses];

export type GetFalAiLcmSd15I2iRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lcm-sd15-i2i/requests/{request_id}";
};

export type GetFalAiLcmSd15I2iRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LcmSd15I2iOutput;
};

export type GetFalAiLcmSd15I2iRequestsByRequestIdResponse =
  GetFalAiLcmSd15I2iRequestsByRequestIdResponses[keyof GetFalAiLcmSd15I2iRequestsByRequestIdResponses];

export type GetFalAiInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/inpaint/requests/{request_id}/status";
};

export type GetFalAiInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiInpaintRequestsByRequestIdStatusResponse =
  GetFalAiInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiInpaintRequestsByRequestIdCancelResponse =
  PutFalAiInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiInpaintData = {
  body: InpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/inpaint";
};

export type PostFalAiInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiInpaintResponse =
  PostFalAiInpaintResponses[keyof PostFalAiInpaintResponses];

export type GetFalAiInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/inpaint/requests/{request_id}";
};

export type GetFalAiInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: InpaintOutput;
};

export type GetFalAiInpaintRequestsByRequestIdResponse =
  GetFalAiInpaintRequestsByRequestIdResponses[keyof GetFalAiInpaintRequestsByRequestIdResponses];

export type GetFalAiEsrganRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/esrgan/requests/{request_id}/status";
};

export type GetFalAiEsrganRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiEsrganRequestsByRequestIdStatusResponse =
  GetFalAiEsrganRequestsByRequestIdStatusResponses[keyof GetFalAiEsrganRequestsByRequestIdStatusResponses];

export type PutFalAiEsrganRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/esrgan/requests/{request_id}/cancel";
};

export type PutFalAiEsrganRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiEsrganRequestsByRequestIdCancelResponse =
  PutFalAiEsrganRequestsByRequestIdCancelResponses[keyof PutFalAiEsrganRequestsByRequestIdCancelResponses];

export type PostFalAiEsrganData = {
  body: EsrganInput;
  path?: never;
  query?: never;
  url: "/fal-ai/esrgan";
};

export type PostFalAiEsrganResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiEsrganResponse =
  PostFalAiEsrganResponses[keyof PostFalAiEsrganResponses];

export type GetFalAiEsrganRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/esrgan/requests/{request_id}";
};

export type GetFalAiEsrganRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: EsrganOutput;
};

export type GetFalAiEsrganRequestsByRequestIdResponse =
  GetFalAiEsrganRequestsByRequestIdResponses[keyof GetFalAiEsrganRequestsByRequestIdResponses];

export type GetFalAiImageutilsRembgRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imageutils/rembg/requests/{request_id}/status";
};

export type GetFalAiImageutilsRembgRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImageutilsRembgRequestsByRequestIdStatusResponse =
  GetFalAiImageutilsRembgRequestsByRequestIdStatusResponses[keyof GetFalAiImageutilsRembgRequestsByRequestIdStatusResponses];

export type PutFalAiImageutilsRembgRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/rembg/requests/{request_id}/cancel";
};

export type PutFalAiImageutilsRembgRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImageutilsRembgRequestsByRequestIdCancelResponse =
  PutFalAiImageutilsRembgRequestsByRequestIdCancelResponses[keyof PutFalAiImageutilsRembgRequestsByRequestIdCancelResponses];

export type PostFalAiImageutilsRembgData = {
  body: ImageutilsRembgInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imageutils/rembg";
};

export type PostFalAiImageutilsRembgResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImageutilsRembgResponse =
  PostFalAiImageutilsRembgResponses[keyof PostFalAiImageutilsRembgResponses];

export type GetFalAiImageutilsRembgRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imageutils/rembg/requests/{request_id}";
};

export type GetFalAiImageutilsRembgRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ImageutilsRembgOutput;
};

export type GetFalAiImageutilsRembgRequestsByRequestIdResponse =
  GetFalAiImageutilsRembgRequestsByRequestIdResponses[keyof GetFalAiImageutilsRembgRequestsByRequestIdResponses];

export type GetFalAiImagen4PreviewRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imagen4/preview/requests/{request_id}/status";
};

export type GetFalAiImagen4PreviewRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagen4PreviewRequestsByRequestIdStatusResponse =
  GetFalAiImagen4PreviewRequestsByRequestIdStatusResponses[keyof GetFalAiImagen4PreviewRequestsByRequestIdStatusResponses];

export type PutFalAiImagen4PreviewRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/requests/{request_id}/cancel";
};

export type PutFalAiImagen4PreviewRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagen4PreviewRequestsByRequestIdCancelResponse =
  PutFalAiImagen4PreviewRequestsByRequestIdCancelResponses[keyof PutFalAiImagen4PreviewRequestsByRequestIdCancelResponses];

export type PostFalAiImagen4PreviewData = {
  body: Imagen4PreviewInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imagen4/preview";
};

export type PostFalAiImagen4PreviewResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagen4PreviewResponse =
  PostFalAiImagen4PreviewResponses[keyof PostFalAiImagen4PreviewResponses];

export type GetFalAiImagen4PreviewRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/requests/{request_id}";
};

export type GetFalAiImagen4PreviewRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Imagen4PreviewOutput;
};

export type GetFalAiImagen4PreviewRequestsByRequestIdResponse =
  GetFalAiImagen4PreviewRequestsByRequestIdResponses[keyof GetFalAiImagen4PreviewRequestsByRequestIdResponses];

export type GetFalAiFluxProV11UltraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1.1-ultra/requests/{request_id}/status";
};

export type GetFalAiFluxProV11UltraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV11UltraRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV11UltraRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV11UltraRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV11UltraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV11UltraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV11UltraRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV11UltraRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV11UltraRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV11UltraData = {
  body: FluxProV11UltraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra";
};

export type PostFalAiFluxProV11UltraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV11UltraResponse =
  PostFalAiFluxProV11UltraResponses[keyof PostFalAiFluxProV11UltraResponses];

export type GetFalAiFluxProV11UltraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra/requests/{request_id}";
};

export type GetFalAiFluxProV11UltraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV11UltraOutput;
};

export type GetFalAiFluxProV11UltraRequestsByRequestIdResponse =
  GetFalAiFluxProV11UltraRequestsByRequestIdResponses[keyof GetFalAiFluxProV11UltraRequestsByRequestIdResponses];

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft/v3/text-to-image/requests/{request_id}/status";
};

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiRecraftV3TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiRecraftV3TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiRecraftV3TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/v3/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiRecraftV3TextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraftV3TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiRecraftV3TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiRecraftV3TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiRecraftV3TextToImageData = {
  body: RecraftV3TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft/v3/text-to-image";
};

export type PostFalAiRecraftV3TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraftV3TextToImageResponse =
  PostFalAiRecraftV3TextToImageResponses[keyof PostFalAiRecraftV3TextToImageResponses];

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft/v3/text-to-image/requests/{request_id}";
};

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RecraftV3TextToImageOutput;
};

export type GetFalAiRecraftV3TextToImageRequestsByRequestIdResponse =
  GetFalAiRecraftV3TextToImageRequestsByRequestIdResponses[keyof GetFalAiRecraftV3TextToImageRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/lora/requests/{request_id}/status";
};

export type GetFalAiFlux2LoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2LoraRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/lora/requests/{request_id}/cancel";
};

export type PutFalAiFlux2LoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2LoraRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraData = {
  body: Flux2LoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/lora";
};

export type PostFalAiFlux2LoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraResponse =
  PostFalAiFlux2LoraResponses[keyof PostFalAiFlux2LoraResponses];

export type GetFalAiFlux2LoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/lora/requests/{request_id}";
};

export type GetFalAiFlux2LoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraOutput;
};

export type GetFalAiFlux2LoraRequestsByRequestIdResponse =
  GetFalAiFlux2LoraRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraRequestsByRequestIdResponses];

export type GetFalAiFlux2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/requests/{request_id}/status";
};

export type GetFalAiFlux2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2RequestsByRequestIdStatusResponse =
  GetFalAiFlux2RequestsByRequestIdStatusResponses[keyof GetFalAiFlux2RequestsByRequestIdStatusResponses];

export type PutFalAiFlux2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/requests/{request_id}/cancel";
};

export type PutFalAiFlux2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2RequestsByRequestIdCancelResponse =
  PutFalAiFlux2RequestsByRequestIdCancelResponses[keyof PutFalAiFlux2RequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Data = {
  body: Flux2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2";
};

export type PostFalAiFlux2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Response =
  PostFalAiFlux2Responses[keyof PostFalAiFlux2Responses];

export type GetFalAiFlux2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/requests/{request_id}";
};

export type GetFalAiFlux2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Output;
};

export type GetFalAiFlux2RequestsByRequestIdResponse =
  GetFalAiFlux2RequestsByRequestIdResponses[keyof GetFalAiFlux2RequestsByRequestIdResponses];

export type GetFalAiFlux2ProRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-pro/requests/{request_id}/status";
};

export type GetFalAiFlux2ProRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2ProRequestsByRequestIdStatusResponse =
  GetFalAiFlux2ProRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2ProRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2ProRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-pro/requests/{request_id}/cancel";
};

export type PutFalAiFlux2ProRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2ProRequestsByRequestIdCancelResponse =
  PutFalAiFlux2ProRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2ProRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2ProData = {
  body: Flux2ProInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-pro";
};

export type PostFalAiFlux2ProResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2ProResponse =
  PostFalAiFlux2ProResponses[keyof PostFalAiFlux2ProResponses];

export type GetFalAiFlux2ProRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-pro/requests/{request_id}";
};

export type GetFalAiFlux2ProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2ProOutput;
};

export type GetFalAiFlux2ProRequestsByRequestIdResponse =
  GetFalAiFlux2ProRequestsByRequestIdResponses[keyof GetFalAiFlux2ProRequestsByRequestIdResponses];

export type GetBriaTextToImage32RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/text-to-image/3.2/requests/{request_id}/status";
};

export type GetBriaTextToImage32RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaTextToImage32RequestsByRequestIdStatusResponse =
  GetBriaTextToImage32RequestsByRequestIdStatusResponses[keyof GetBriaTextToImage32RequestsByRequestIdStatusResponses];

export type PutBriaTextToImage32RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/text-to-image/3.2/requests/{request_id}/cancel";
};

export type PutBriaTextToImage32RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaTextToImage32RequestsByRequestIdCancelResponse =
  PutBriaTextToImage32RequestsByRequestIdCancelResponses[keyof PutBriaTextToImage32RequestsByRequestIdCancelResponses];

export type PostBriaTextToImage32Data = {
  body: TextToImage32Input;
  path?: never;
  query?: never;
  url: "/bria/text-to-image/3.2";
};

export type PostBriaTextToImage32Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaTextToImage32Response =
  PostBriaTextToImage32Responses[keyof PostBriaTextToImage32Responses];

export type GetBriaTextToImage32RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/text-to-image/3.2/requests/{request_id}";
};

export type GetBriaTextToImage32RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: TextToImage32Output;
};

export type GetBriaTextToImage32RequestsByRequestIdResponse =
  GetBriaTextToImage32RequestsByRequestIdResponses[keyof GetBriaTextToImage32RequestsByRequestIdResponses];

export type GetFalAiImagen4PreviewFastRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imagen4/preview/fast/requests/{request_id}/status";
};

export type GetFalAiImagen4PreviewFastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagen4PreviewFastRequestsByRequestIdStatusResponse =
  GetFalAiImagen4PreviewFastRequestsByRequestIdStatusResponses[keyof GetFalAiImagen4PreviewFastRequestsByRequestIdStatusResponses];

export type PutFalAiImagen4PreviewFastRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/fast/requests/{request_id}/cancel";
};

export type PutFalAiImagen4PreviewFastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagen4PreviewFastRequestsByRequestIdCancelResponse =
  PutFalAiImagen4PreviewFastRequestsByRequestIdCancelResponses[keyof PutFalAiImagen4PreviewFastRequestsByRequestIdCancelResponses];

export type PostFalAiImagen4PreviewFastData = {
  body: Imagen4PreviewFastInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imagen4/preview/fast";
};

export type PostFalAiImagen4PreviewFastResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagen4PreviewFastResponse =
  PostFalAiImagen4PreviewFastResponses[keyof PostFalAiImagen4PreviewFastResponses];

export type GetFalAiImagen4PreviewFastRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/fast/requests/{request_id}";
};

export type GetFalAiImagen4PreviewFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Imagen4PreviewFastOutput;
};

export type GetFalAiImagen4PreviewFastRequestsByRequestIdResponse =
  GetFalAiImagen4PreviewFastRequestsByRequestIdResponses[keyof GetFalAiImagen4PreviewFastRequestsByRequestIdResponses];

export type GetFalAiHidreamI1FullRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hidream-i1-full/requests/{request_id}/status";
};

export type GetFalAiHidreamI1FullRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiHidreamI1FullRequestsByRequestIdStatusResponse =
  GetFalAiHidreamI1FullRequestsByRequestIdStatusResponses[keyof GetFalAiHidreamI1FullRequestsByRequestIdStatusResponses];

export type PutFalAiHidreamI1FullRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-full/requests/{request_id}/cancel";
};

export type PutFalAiHidreamI1FullRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiHidreamI1FullRequestsByRequestIdCancelResponse =
  PutFalAiHidreamI1FullRequestsByRequestIdCancelResponses[keyof PutFalAiHidreamI1FullRequestsByRequestIdCancelResponses];

export type PostFalAiHidreamI1FullData = {
  body: HidreamI1FullInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hidream-i1-full";
};

export type PostFalAiHidreamI1FullResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHidreamI1FullResponse =
  PostFalAiHidreamI1FullResponses[keyof PostFalAiHidreamI1FullResponses];

export type GetFalAiHidreamI1FullRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-full/requests/{request_id}";
};

export type GetFalAiHidreamI1FullRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HidreamI1FullOutput;
};

export type GetFalAiHidreamI1FullRequestsByRequestIdResponse =
  GetFalAiHidreamI1FullRequestsByRequestIdResponses[keyof GetFalAiHidreamI1FullRequestsByRequestIdResponses];

export type GetFalAiHidreamI1DevRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hidream-i1-dev/requests/{request_id}/status";
};

export type GetFalAiHidreamI1DevRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiHidreamI1DevRequestsByRequestIdStatusResponse =
  GetFalAiHidreamI1DevRequestsByRequestIdStatusResponses[keyof GetFalAiHidreamI1DevRequestsByRequestIdStatusResponses];

export type PutFalAiHidreamI1DevRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-dev/requests/{request_id}/cancel";
};

export type PutFalAiHidreamI1DevRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiHidreamI1DevRequestsByRequestIdCancelResponse =
  PutFalAiHidreamI1DevRequestsByRequestIdCancelResponses[keyof PutFalAiHidreamI1DevRequestsByRequestIdCancelResponses];

export type PostFalAiHidreamI1DevData = {
  body: HidreamI1DevInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hidream-i1-dev";
};

export type PostFalAiHidreamI1DevResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHidreamI1DevResponse =
  PostFalAiHidreamI1DevResponses[keyof PostFalAiHidreamI1DevResponses];

export type GetFalAiHidreamI1DevRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-dev/requests/{request_id}";
};

export type GetFalAiHidreamI1DevRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HidreamI1DevOutput;
};

export type GetFalAiHidreamI1DevRequestsByRequestIdResponse =
  GetFalAiHidreamI1DevRequestsByRequestIdResponses[keyof GetFalAiHidreamI1DevRequestsByRequestIdResponses];

export type GetFalAiHidreamI1FastRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hidream-i1-fast/requests/{request_id}/status";
};

export type GetFalAiHidreamI1FastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiHidreamI1FastRequestsByRequestIdStatusResponse =
  GetFalAiHidreamI1FastRequestsByRequestIdStatusResponses[keyof GetFalAiHidreamI1FastRequestsByRequestIdStatusResponses];

export type PutFalAiHidreamI1FastRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-fast/requests/{request_id}/cancel";
};

export type PutFalAiHidreamI1FastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiHidreamI1FastRequestsByRequestIdCancelResponse =
  PutFalAiHidreamI1FastRequestsByRequestIdCancelResponses[keyof PutFalAiHidreamI1FastRequestsByRequestIdCancelResponses];

export type PostFalAiHidreamI1FastData = {
  body: HidreamI1FastInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hidream-i1-fast";
};

export type PostFalAiHidreamI1FastResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHidreamI1FastResponse =
  PostFalAiHidreamI1FastResponses[keyof PostFalAiHidreamI1FastResponses];

export type GetFalAiHidreamI1FastRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hidream-i1-fast/requests/{request_id}";
};

export type GetFalAiHidreamI1FastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HidreamI1FastOutput;
};

export type GetFalAiHidreamI1FastRequestsByRequestIdResponse =
  GetFalAiHidreamI1FastRequestsByRequestIdResponses[keyof GetFalAiHidreamI1FastRequestsByRequestIdResponses];

export type GetFalAiFluxDevRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/dev/requests/{request_id}/status";
};

export type GetFalAiFluxDevRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxDevRequestsByRequestIdStatusResponse =
  GetFalAiFluxDevRequestsByRequestIdStatusResponses[keyof GetFalAiFluxDevRequestsByRequestIdStatusResponses];

export type PutFalAiFluxDevRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/requests/{request_id}/cancel";
};

export type PutFalAiFluxDevRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxDevRequestsByRequestIdCancelResponse =
  PutFalAiFluxDevRequestsByRequestIdCancelResponses[keyof PutFalAiFluxDevRequestsByRequestIdCancelResponses];

export type PostFalAiFluxDevData = {
  body: FluxDevInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/dev";
};

export type PostFalAiFluxDevResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxDevResponse =
  PostFalAiFluxDevResponses[keyof PostFalAiFluxDevResponses];

export type GetFalAiFluxDevRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/dev/requests/{request_id}";
};

export type GetFalAiFluxDevRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxDevOutput;
};

export type GetFalAiFluxDevRequestsByRequestIdResponse =
  GetFalAiFluxDevRequestsByRequestIdResponses[keyof GetFalAiFluxDevRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2RequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2RequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2RequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2RequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2RequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2RequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2Data = {
  body: IdeogramV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2";
};

export type PostFalAiIdeogramV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2Response =
  PostFalAiIdeogramV2Responses[keyof PostFalAiIdeogramV2Responses];

export type GetFalAiIdeogramV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/requests/{request_id}";
};

export type GetFalAiIdeogramV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2Output;
};

export type GetFalAiIdeogramV2RequestsByRequestIdResponse =
  GetFalAiIdeogramV2RequestsByRequestIdResponses[keyof GetFalAiIdeogramV2RequestsByRequestIdResponses];

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-diffusion-v35-large/requests/{request_id}/status";
};

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdStatusResponse =
  GetFalAiStableDiffusionV35LargeRequestsByRequestIdStatusResponses[keyof GetFalAiStableDiffusionV35LargeRequestsByRequestIdStatusResponses];

export type PutFalAiStableDiffusionV35LargeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-large/requests/{request_id}/cancel";
};

export type PutFalAiStableDiffusionV35LargeRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableDiffusionV35LargeRequestsByRequestIdCancelResponse =
  PutFalAiStableDiffusionV35LargeRequestsByRequestIdCancelResponses[keyof PutFalAiStableDiffusionV35LargeRequestsByRequestIdCancelResponses];

export type PostFalAiStableDiffusionV35LargeData = {
  body: StableDiffusionV35LargeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-large";
};

export type PostFalAiStableDiffusionV35LargeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableDiffusionV35LargeResponse =
  PostFalAiStableDiffusionV35LargeResponses[keyof PostFalAiStableDiffusionV35LargeResponses];

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-large/requests/{request_id}";
};

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableDiffusionV35LargeOutput;
};

export type GetFalAiStableDiffusionV35LargeRequestsByRequestIdResponse =
  GetFalAiStableDiffusionV35LargeRequestsByRequestIdResponses[keyof GetFalAiStableDiffusionV35LargeRequestsByRequestIdResponses];

export type GetFalAiFluxGeneralRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-general/requests/{request_id}/status";
};

export type GetFalAiFluxGeneralRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxGeneralRequestsByRequestIdStatusResponse =
  GetFalAiFluxGeneralRequestsByRequestIdStatusResponses[keyof GetFalAiFluxGeneralRequestsByRequestIdStatusResponses];

export type PutFalAiFluxGeneralRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/requests/{request_id}/cancel";
};

export type PutFalAiFluxGeneralRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxGeneralRequestsByRequestIdCancelResponse =
  PutFalAiFluxGeneralRequestsByRequestIdCancelResponses[keyof PutFalAiFluxGeneralRequestsByRequestIdCancelResponses];

export type PostFalAiFluxGeneralData = {
  body: FluxGeneralInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-general";
};

export type PostFalAiFluxGeneralResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxGeneralResponse =
  PostFalAiFluxGeneralResponses[keyof PostFalAiFluxGeneralResponses];

export type GetFalAiFluxGeneralRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-general/requests/{request_id}";
};

export type GetFalAiFluxGeneralRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxGeneralOutput;
};

export type GetFalAiFluxGeneralRequestsByRequestIdResponse =
  GetFalAiFluxGeneralRequestsByRequestIdResponses[keyof GetFalAiFluxGeneralRequestsByRequestIdResponses];

export type GetFalAiFluxLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora/requests/{request_id}/status";
};

export type GetFalAiFluxLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraData = {
  body: FluxLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora";
};

export type PostFalAiFluxLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraResponse =
  PostFalAiFluxLoraResponses[keyof PostFalAiFluxLoraResponses];

export type GetFalAiFluxLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/requests/{request_id}";
};

export type GetFalAiFluxLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraOutput;
};

export type GetFalAiFluxLoraRequestsByRequestIdResponse =
  GetFalAiFluxLoraRequestsByRequestIdResponses[keyof GetFalAiFluxLoraRequestsByRequestIdResponses];

export type GetXaiGrokImagineImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/xai/grok-imagine-image/requests/{request_id}/status";
};

export type GetXaiGrokImagineImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetXaiGrokImagineImageRequestsByRequestIdStatusResponse =
  GetXaiGrokImagineImageRequestsByRequestIdStatusResponses[keyof GetXaiGrokImagineImageRequestsByRequestIdStatusResponses];

export type PutXaiGrokImagineImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/xai/grok-imagine-image/requests/{request_id}/cancel";
};

export type PutXaiGrokImagineImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutXaiGrokImagineImageRequestsByRequestIdCancelResponse =
  PutXaiGrokImagineImageRequestsByRequestIdCancelResponses[keyof PutXaiGrokImagineImageRequestsByRequestIdCancelResponses];

export type PostXaiGrokImagineImageData = {
  body: GrokImagineImageInput;
  path?: never;
  query?: never;
  url: "/xai/grok-imagine-image";
};

export type PostXaiGrokImagineImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostXaiGrokImagineImageResponse =
  PostXaiGrokImagineImageResponses[keyof PostXaiGrokImagineImageResponses];

export type GetXaiGrokImagineImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/xai/grok-imagine-image/requests/{request_id}";
};

export type GetXaiGrokImagineImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GrokImagineImageOutput;
};

export type GetXaiGrokImagineImageRequestsByRequestIdResponse =
  GetXaiGrokImagineImageRequestsByRequestIdResponses[keyof GetXaiGrokImagineImageRequestsByRequestIdResponses];

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/hunyuan-image/v3/instruct/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/hunyuan-image/v3/instruct/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiHunyuanImageV3InstructTextToImageData = {
  body: HunyuanImageV3InstructTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/instruct/text-to-image";
};

export type PostFalAiHunyuanImageV3InstructTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHunyuanImageV3InstructTextToImageResponse =
  PostFalAiHunyuanImageV3InstructTextToImageResponses[keyof PostFalAiHunyuanImageV3InstructTextToImageResponses];

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/instruct/text-to-image/requests/{request_id}";
};

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: HunyuanImageV3InstructTextToImageOutput;
  };

export type GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdResponse =
  GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdResponses[keyof GetFalAiHunyuanImageV3InstructTextToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-max/text-to-image/requests/{request_id}/status";
};

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageMaxTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageMaxTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageMaxTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-max/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageMaxTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwenImageMaxTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageMaxTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageMaxTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageMaxTextToImageData = {
  body: QwenImageMaxTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-max/text-to-image";
};

export type PostFalAiQwenImageMaxTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageMaxTextToImageResponse =
  PostFalAiQwenImageMaxTextToImageResponses[keyof PostFalAiQwenImageMaxTextToImageResponses];

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-max/text-to-image/requests/{request_id}";
};

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageMaxTextToImageOutput;
};

export type GetFalAiQwenImageMaxTextToImageRequestsByRequestIdResponse =
  GetFalAiQwenImageMaxTextToImageRequestsByRequestIdResponses[keyof GetFalAiQwenImageMaxTextToImageRequestsByRequestIdResponses];

export type GetFalAiZImageBaseLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/base/lora/requests/{request_id}/status";
};

export type GetFalAiZImageBaseLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageBaseLoraRequestsByRequestIdStatusResponse =
  GetFalAiZImageBaseLoraRequestsByRequestIdStatusResponses[keyof GetFalAiZImageBaseLoraRequestsByRequestIdStatusResponses];

export type PutFalAiZImageBaseLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/base/lora/requests/{request_id}/cancel";
};

export type PutFalAiZImageBaseLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageBaseLoraRequestsByRequestIdCancelResponse =
  PutFalAiZImageBaseLoraRequestsByRequestIdCancelResponses[keyof PutFalAiZImageBaseLoraRequestsByRequestIdCancelResponses];

export type PostFalAiZImageBaseLoraData = {
  body: ZImageBaseLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/base/lora";
};

export type PostFalAiZImageBaseLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageBaseLoraResponse =
  PostFalAiZImageBaseLoraResponses[keyof PostFalAiZImageBaseLoraResponses];

export type GetFalAiZImageBaseLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/base/lora/requests/{request_id}";
};

export type GetFalAiZImageBaseLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageBaseLoraOutput;
};

export type GetFalAiZImageBaseLoraRequestsByRequestIdResponse =
  GetFalAiZImageBaseLoraRequestsByRequestIdResponses[keyof GetFalAiZImageBaseLoraRequestsByRequestIdResponses];

export type GetFalAiZImageBaseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/base/requests/{request_id}/status";
};

export type GetFalAiZImageBaseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageBaseRequestsByRequestIdStatusResponse =
  GetFalAiZImageBaseRequestsByRequestIdStatusResponses[keyof GetFalAiZImageBaseRequestsByRequestIdStatusResponses];

export type PutFalAiZImageBaseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/base/requests/{request_id}/cancel";
};

export type PutFalAiZImageBaseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageBaseRequestsByRequestIdCancelResponse =
  PutFalAiZImageBaseRequestsByRequestIdCancelResponses[keyof PutFalAiZImageBaseRequestsByRequestIdCancelResponses];

export type PostFalAiZImageBaseData = {
  body: ZImageBaseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/base";
};

export type PostFalAiZImageBaseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageBaseResponse =
  PostFalAiZImageBaseResponses[keyof PostFalAiZImageBaseResponses];

export type GetFalAiZImageBaseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/base/requests/{request_id}";
};

export type GetFalAiZImageBaseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageBaseOutput;
};

export type GetFalAiZImageBaseRequestsByRequestIdResponse =
  GetFalAiZImageBaseRequestsByRequestIdResponses[keyof GetFalAiZImageBaseRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/base/lora/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bBaseLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/lora/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bBaseLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein9bBaseLoraRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bBaseLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bBaseLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bBaseLoraData = {
  body: Flux2Klein9bBaseLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/lora";
};

export type PostFalAiFlux2Klein9bBaseLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bBaseLoraResponse =
  PostFalAiFlux2Klein9bBaseLoraResponses[keyof PostFalAiFlux2Klein9bBaseLoraResponses];

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/lora/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bBaseLoraOutput;
};

export type GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bBaseLoraRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/base/lora/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bBaseLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/lora/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bBaseLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein4bBaseLoraRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bBaseLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bBaseLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bBaseLoraData = {
  body: Flux2Klein4bBaseLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/lora";
};

export type PostFalAiFlux2Klein4bBaseLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bBaseLoraResponse =
  PostFalAiFlux2Klein4bBaseLoraResponses[keyof PostFalAiFlux2Klein4bBaseLoraResponses];

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/lora/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bBaseLoraOutput;
};

export type GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bBaseLoraRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/base/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bBaseRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bBaseRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bBaseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bBaseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein9bBaseRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bBaseRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bBaseRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bBaseData = {
  body: Flux2Klein9bBaseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base";
};

export type PostFalAiFlux2Klein9bBaseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bBaseResponse =
  PostFalAiFlux2Klein9bBaseResponses[keyof PostFalAiFlux2Klein9bBaseResponses];

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/base/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bBaseOutput;
};

export type GetFalAiFlux2Klein9bBaseRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bBaseRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bBaseRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/base/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bBaseRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bBaseRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bBaseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bBaseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein4bBaseRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bBaseRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bBaseRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bBaseData = {
  body: Flux2Klein4bBaseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base";
};

export type PostFalAiFlux2Klein4bBaseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bBaseResponse =
  PostFalAiFlux2Klein4bBaseResponses[keyof PostFalAiFlux2Klein4bBaseResponses];

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/base/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bBaseOutput;
};

export type GetFalAiFlux2Klein4bBaseRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bBaseRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bBaseRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein9bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/9b/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein9bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein9bRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein9bRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein9bRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein9bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein9bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein9bRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein9bRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein9bRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein9bData = {
  body: Flux2Klein9bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/9b";
};

export type PostFalAiFlux2Klein9bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein9bResponse =
  PostFalAiFlux2Klein9bResponses[keyof PostFalAiFlux2Klein9bResponses];

export type GetFalAiFlux2Klein9bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/9b/requests/{request_id}";
};

export type GetFalAiFlux2Klein9bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein9bOutput;
};

export type GetFalAiFlux2Klein9bRequestsByRequestIdResponse =
  GetFalAiFlux2Klein9bRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein9bRequestsByRequestIdResponses];

export type GetFalAiFlux2Klein4bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/klein/4b/requests/{request_id}/status";
};

export type GetFalAiFlux2Klein4bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2Klein4bRequestsByRequestIdStatusResponse =
  GetFalAiFlux2Klein4bRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2Klein4bRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2Klein4bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/requests/{request_id}/cancel";
};

export type PutFalAiFlux2Klein4bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2Klein4bRequestsByRequestIdCancelResponse =
  PutFalAiFlux2Klein4bRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2Klein4bRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2Klein4bData = {
  body: Flux2Klein4bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/klein/4b";
};

export type PostFalAiFlux2Klein4bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2Klein4bResponse =
  PostFalAiFlux2Klein4bResponses[keyof PostFalAiFlux2Klein4bResponses];

export type GetFalAiFlux2Klein4bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/klein/4b/requests/{request_id}";
};

export type GetFalAiFlux2Klein4bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2Klein4bOutput;
};

export type GetFalAiFlux2Klein4bRequestsByRequestIdResponse =
  GetFalAiFlux2Klein4bRequestsByRequestIdResponses[keyof GetFalAiFlux2Klein4bRequestsByRequestIdResponses];

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/imagineart/imagineart-1.5-pro-preview/text-to-image/requests/{request_id}/status";
  };

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdStatusResponse =
  GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdStatusResponses[keyof GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdStatusResponses];

export type PutImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/imagineart/imagineart-1.5-pro-preview/text-to-image/requests/{request_id}/cancel";
  };

export type PutImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdCancelResponse =
  PutImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdCancelResponses[keyof PutImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdCancelResponses];

export type PostImagineartImagineart15ProPreviewTextToImageData = {
  body: Imagineart15ProPreviewTextToImageInput;
  path?: never;
  query?: never;
  url: "/imagineart/imagineart-1.5-pro-preview/text-to-image";
};

export type PostImagineartImagineart15ProPreviewTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostImagineartImagineart15ProPreviewTextToImageResponse =
  PostImagineartImagineart15ProPreviewTextToImageResponses[keyof PostImagineartImagineart15ProPreviewTextToImageResponses];

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/imagineart/imagineart-1.5-pro-preview/text-to-image/requests/{request_id}";
  };

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Imagineart15ProPreviewTextToImageOutput;
  };

export type GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdResponse =
  GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdResponses[keyof GetImagineartImagineart15ProPreviewTextToImageRequestsByRequestIdResponses];

export type GetFalAiGlmImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/glm-image/requests/{request_id}/status";
};

export type GetFalAiGlmImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGlmImageRequestsByRequestIdStatusResponse =
  GetFalAiGlmImageRequestsByRequestIdStatusResponses[keyof GetFalAiGlmImageRequestsByRequestIdStatusResponses];

export type PutFalAiGlmImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/glm-image/requests/{request_id}/cancel";
};

export type PutFalAiGlmImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGlmImageRequestsByRequestIdCancelResponse =
  PutFalAiGlmImageRequestsByRequestIdCancelResponses[keyof PutFalAiGlmImageRequestsByRequestIdCancelResponses];

export type PostFalAiGlmImageData = {
  body: GlmImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/glm-image";
};

export type PostFalAiGlmImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGlmImageResponse =
  PostFalAiGlmImageResponses[keyof PostFalAiGlmImageResponses];

export type GetFalAiGlmImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/glm-image/requests/{request_id}";
};

export type GetFalAiGlmImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GlmImageOutput;
};

export type GetFalAiGlmImageRequestsByRequestIdResponse =
  GetFalAiGlmImageRequestsByRequestIdResponses[keyof GetFalAiGlmImageRequestsByRequestIdResponses];

export type GetFalAiQwenImage2512LoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-2512/lora/requests/{request_id}/status";
};

export type GetFalAiQwenImage2512LoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImage2512LoraRequestsByRequestIdStatusResponse =
  GetFalAiQwenImage2512LoraRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImage2512LoraRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImage2512LoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-2512/lora/requests/{request_id}/cancel";
};

export type PutFalAiQwenImage2512LoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImage2512LoraRequestsByRequestIdCancelResponse =
  PutFalAiQwenImage2512LoraRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImage2512LoraRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImage2512LoraData = {
  body: QwenImage2512LoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-2512/lora";
};

export type PostFalAiQwenImage2512LoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImage2512LoraResponse =
  PostFalAiQwenImage2512LoraResponses[keyof PostFalAiQwenImage2512LoraResponses];

export type GetFalAiQwenImage2512LoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-2512/lora/requests/{request_id}";
};

export type GetFalAiQwenImage2512LoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImage2512LoraOutput;
};

export type GetFalAiQwenImage2512LoraRequestsByRequestIdResponse =
  GetFalAiQwenImage2512LoraRequestsByRequestIdResponses[keyof GetFalAiQwenImage2512LoraRequestsByRequestIdResponses];

export type GetFalAiQwenImage2512RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image-2512/requests/{request_id}/status";
};

export type GetFalAiQwenImage2512RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImage2512RequestsByRequestIdStatusResponse =
  GetFalAiQwenImage2512RequestsByRequestIdStatusResponses[keyof GetFalAiQwenImage2512RequestsByRequestIdStatusResponses];

export type PutFalAiQwenImage2512RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-2512/requests/{request_id}/cancel";
};

export type PutFalAiQwenImage2512RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImage2512RequestsByRequestIdCancelResponse =
  PutFalAiQwenImage2512RequestsByRequestIdCancelResponses[keyof PutFalAiQwenImage2512RequestsByRequestIdCancelResponses];

export type PostFalAiQwenImage2512Data = {
  body: QwenImage2512Input;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image-2512";
};

export type PostFalAiQwenImage2512Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImage2512Response =
  PostFalAiQwenImage2512Responses[keyof PostFalAiQwenImage2512Responses];

export type GetFalAiQwenImage2512RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image-2512/requests/{request_id}";
};

export type GetFalAiQwenImage2512RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImage2512Output;
};

export type GetFalAiQwenImage2512RequestsByRequestIdResponse =
  GetFalAiQwenImage2512RequestsByRequestIdResponses[keyof GetFalAiQwenImage2512RequestsByRequestIdResponses];

export type GetWanV26TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/wan/v2.6/text-to-image/requests/{request_id}/status";
};

export type GetWanV26TextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetWanV26TextToImageRequestsByRequestIdStatusResponse =
  GetWanV26TextToImageRequestsByRequestIdStatusResponses[keyof GetWanV26TextToImageRequestsByRequestIdStatusResponses];

export type PutWanV26TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/wan/v2.6/text-to-image/requests/{request_id}/cancel";
};

export type PutWanV26TextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutWanV26TextToImageRequestsByRequestIdCancelResponse =
  PutWanV26TextToImageRequestsByRequestIdCancelResponses[keyof PutWanV26TextToImageRequestsByRequestIdCancelResponses];

export type PostWanV26TextToImageData = {
  body: V26TextToImageInput;
  path?: never;
  query?: never;
  url: "/wan/v2.6/text-to-image";
};

export type PostWanV26TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostWanV26TextToImageResponse =
  PostWanV26TextToImageResponses[keyof PostWanV26TextToImageResponses];

export type GetWanV26TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/wan/v2.6/text-to-image/requests/{request_id}";
};

export type GetWanV26TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: V26TextToImageOutput;
};

export type GetWanV26TextToImageRequestsByRequestIdResponse =
  GetWanV26TextToImageRequestsByRequestIdResponses[keyof GetWanV26TextToImageRequestsByRequestIdResponses];

export type GetFalAiFlux2FlashRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/flash/requests/{request_id}/status";
};

export type GetFalAiFlux2FlashRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2FlashRequestsByRequestIdStatusResponse =
  GetFalAiFlux2FlashRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2FlashRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2FlashRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/flash/requests/{request_id}/cancel";
};

export type PutFalAiFlux2FlashRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2FlashRequestsByRequestIdCancelResponse =
  PutFalAiFlux2FlashRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2FlashRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2FlashData = {
  body: Flux2FlashInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/flash";
};

export type PostFalAiFlux2FlashResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2FlashResponse =
  PostFalAiFlux2FlashResponses[keyof PostFalAiFlux2FlashResponses];

export type GetFalAiFlux2FlashRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/flash/requests/{request_id}";
};

export type GetFalAiFlux2FlashRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2FlashOutput;
};

export type GetFalAiFlux2FlashRequestsByRequestIdResponse =
  GetFalAiFlux2FlashRequestsByRequestIdResponses[keyof GetFalAiFlux2FlashRequestsByRequestIdResponses];

export type GetFalAiGptImage15RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1.5/requests/{request_id}/status";
};

export type GetFalAiGptImage15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage15RequestsByRequestIdStatusResponse =
  GetFalAiGptImage15RequestsByRequestIdStatusResponses[keyof GetFalAiGptImage15RequestsByRequestIdStatusResponses];

export type PutFalAiGptImage15RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1.5/requests/{request_id}/cancel";
};

export type PutFalAiGptImage15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage15RequestsByRequestIdCancelResponse =
  PutFalAiGptImage15RequestsByRequestIdCancelResponses[keyof PutFalAiGptImage15RequestsByRequestIdCancelResponses];

export type PostFalAiGptImage15Data = {
  body: GptImage15Input;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1.5";
};

export type PostFalAiGptImage15Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage15Response =
  PostFalAiGptImage15Responses[keyof PostFalAiGptImage15Responses];

export type GetFalAiGptImage15RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1.5/requests/{request_id}";
};

export type GetFalAiGptImage15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage15Output;
};

export type GetFalAiGptImage15RequestsByRequestIdResponse =
  GetFalAiGptImage15RequestsByRequestIdResponses[keyof GetFalAiGptImage15RequestsByRequestIdResponses];

export type GetBriaFiboLiteGenerateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo-lite/generate/requests/{request_id}/status";
};

export type GetBriaFiboLiteGenerateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboLiteGenerateRequestsByRequestIdStatusResponse =
  GetBriaFiboLiteGenerateRequestsByRequestIdStatusResponses[keyof GetBriaFiboLiteGenerateRequestsByRequestIdStatusResponses];

export type PutBriaFiboLiteGenerateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-lite/generate/requests/{request_id}/cancel";
};

export type PutBriaFiboLiteGenerateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboLiteGenerateRequestsByRequestIdCancelResponse =
  PutBriaFiboLiteGenerateRequestsByRequestIdCancelResponses[keyof PutBriaFiboLiteGenerateRequestsByRequestIdCancelResponses];

export type PostBriaFiboLiteGenerateData = {
  body: FiboLiteGenerateInput;
  path?: never;
  query?: never;
  url: "/bria/fibo-lite/generate";
};

export type PostBriaFiboLiteGenerateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboLiteGenerateResponse =
  PostBriaFiboLiteGenerateResponses[keyof PostBriaFiboLiteGenerateResponses];

export type GetBriaFiboLiteGenerateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo-lite/generate/requests/{request_id}";
};

export type GetBriaFiboLiteGenerateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboLiteGenerateOutput;
};

export type GetBriaFiboLiteGenerateRequestsByRequestIdResponse =
  GetBriaFiboLiteGenerateRequestsByRequestIdResponses[keyof GetBriaFiboLiteGenerateRequestsByRequestIdResponses];

export type GetFalAiFlux2TurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2/turbo/requests/{request_id}/status";
};

export type GetFalAiFlux2TurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2TurboRequestsByRequestIdStatusResponse =
  GetFalAiFlux2TurboRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2TurboRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2TurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/turbo/requests/{request_id}/cancel";
};

export type PutFalAiFlux2TurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2TurboRequestsByRequestIdCancelResponse =
  PutFalAiFlux2TurboRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2TurboRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2TurboData = {
  body: Flux2TurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2/turbo";
};

export type PostFalAiFlux2TurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2TurboResponse =
  PostFalAiFlux2TurboResponses[keyof PostFalAiFlux2TurboResponses];

export type GetFalAiFlux2TurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2/turbo/requests/{request_id}";
};

export type GetFalAiFlux2TurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2TurboOutput;
};

export type GetFalAiFlux2TurboRequestsByRequestIdResponse =
  GetFalAiFlux2TurboRequestsByRequestIdResponses[keyof GetFalAiFlux2TurboRequestsByRequestIdResponses];

export type GetFalAiFlux2MaxRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-max/requests/{request_id}/status";
};

export type GetFalAiFlux2MaxRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2MaxRequestsByRequestIdStatusResponse =
  GetFalAiFlux2MaxRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2MaxRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2MaxRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-max/requests/{request_id}/cancel";
};

export type PutFalAiFlux2MaxRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2MaxRequestsByRequestIdCancelResponse =
  PutFalAiFlux2MaxRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2MaxRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2MaxData = {
  body: Flux2MaxInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-max";
};

export type PostFalAiFlux2MaxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2MaxResponse =
  PostFalAiFlux2MaxResponses[keyof PostFalAiFlux2MaxResponses];

export type GetFalAiFlux2MaxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-max/requests/{request_id}";
};

export type GetFalAiFlux2MaxRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2MaxOutput;
};

export type GetFalAiFlux2MaxRequestsByRequestIdResponse =
  GetFalAiFlux2MaxRequestsByRequestIdResponses[keyof GetFalAiFlux2MaxRequestsByRequestIdResponses];

export type GetFalAiLongcatImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/longcat-image/requests/{request_id}/status";
};

export type GetFalAiLongcatImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLongcatImageRequestsByRequestIdStatusResponse =
  GetFalAiLongcatImageRequestsByRequestIdStatusResponses[keyof GetFalAiLongcatImageRequestsByRequestIdStatusResponses];

export type PutFalAiLongcatImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/longcat-image/requests/{request_id}/cancel";
};

export type PutFalAiLongcatImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLongcatImageRequestsByRequestIdCancelResponse =
  PutFalAiLongcatImageRequestsByRequestIdCancelResponses[keyof PutFalAiLongcatImageRequestsByRequestIdCancelResponses];

export type PostFalAiLongcatImageData = {
  body: LongcatImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/longcat-image";
};

export type PostFalAiLongcatImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLongcatImageResponse =
  PostFalAiLongcatImageResponses[keyof PostFalAiLongcatImageResponses];

export type GetFalAiLongcatImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/longcat-image/requests/{request_id}";
};

export type GetFalAiLongcatImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LongcatImageOutput;
};

export type GetFalAiLongcatImageRequestsByRequestIdResponse =
  GetFalAiLongcatImageRequestsByRequestIdResponses[keyof GetFalAiLongcatImageRequestsByRequestIdResponses];

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/bytedance/seedream/v4.5/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/bytedance/seedream/v4.5/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceSeedreamV45TextToImageData = {
  body: BytedanceSeedreamV45TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4.5/text-to-image";
};

export type PostFalAiBytedanceSeedreamV45TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceSeedreamV45TextToImageResponse =
  PostFalAiBytedanceSeedreamV45TextToImageResponses[keyof PostFalAiBytedanceSeedreamV45TextToImageResponses];

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4.5/text-to-image/requests/{request_id}";
};

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: BytedanceSeedreamV45TextToImageOutput;
  };

export type GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedreamV45TextToImageRequestsByRequestIdResponses];

export type GetFalAiViduQ2TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vidu/q2/text-to-image/requests/{request_id}/status";
};

export type GetFalAiViduQ2TextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiViduQ2TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiViduQ2TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiViduQ2TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiViduQ2TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/q2/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiViduQ2TextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiViduQ2TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiViduQ2TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiViduQ2TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiViduQ2TextToImageData = {
  body: ViduQ2TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vidu/q2/text-to-image";
};

export type PostFalAiViduQ2TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiViduQ2TextToImageResponse =
  PostFalAiViduQ2TextToImageResponses[keyof PostFalAiViduQ2TextToImageResponses];

export type GetFalAiViduQ2TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vidu/q2/text-to-image/requests/{request_id}";
};

export type GetFalAiViduQ2TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ViduQ2TextToImageOutput;
};

export type GetFalAiViduQ2TextToImageRequestsByRequestIdResponse =
  GetFalAiViduQ2TextToImageRequestsByRequestIdResponses[keyof GetFalAiViduQ2TextToImageRequestsByRequestIdResponses];

export type GetFalAiZImageTurboLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/lora/requests/{request_id}/status";
};

export type GetFalAiZImageTurboLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageTurboLoraRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboLoraRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboLoraRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/lora/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageTurboLoraRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboLoraRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboLoraRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboLoraData = {
  body: ZImageTurboLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo/lora";
};

export type PostFalAiZImageTurboLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboLoraResponse =
  PostFalAiZImageTurboLoraResponses[keyof PostFalAiZImageTurboLoraResponses];

export type GetFalAiZImageTurboLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/lora/requests/{request_id}";
};

export type GetFalAiZImageTurboLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboLoraOutput;
};

export type GetFalAiZImageTurboLoraRequestsByRequestIdResponse =
  GetFalAiZImageTurboLoraRequestsByRequestIdResponses[keyof GetFalAiZImageTurboLoraRequestsByRequestIdResponses];

export type GetFalAiOvisImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ovis-image/requests/{request_id}/status";
};

export type GetFalAiOvisImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiOvisImageRequestsByRequestIdStatusResponse =
  GetFalAiOvisImageRequestsByRequestIdStatusResponses[keyof GetFalAiOvisImageRequestsByRequestIdStatusResponses];

export type PutFalAiOvisImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ovis-image/requests/{request_id}/cancel";
};

export type PutFalAiOvisImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiOvisImageRequestsByRequestIdCancelResponse =
  PutFalAiOvisImageRequestsByRequestIdCancelResponses[keyof PutFalAiOvisImageRequestsByRequestIdCancelResponses];

export type PostFalAiOvisImageData = {
  body: OvisImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ovis-image";
};

export type PostFalAiOvisImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiOvisImageResponse =
  PostFalAiOvisImageResponses[keyof PostFalAiOvisImageResponses];

export type GetFalAiOvisImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ovis-image/requests/{request_id}";
};

export type GetFalAiOvisImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: OvisImageOutput;
};

export type GetFalAiOvisImageRequestsByRequestIdResponse =
  GetFalAiOvisImageRequestsByRequestIdResponses[keyof GetFalAiOvisImageRequestsByRequestIdResponses];

export type GetFalAiZImageTurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/z-image/turbo/requests/{request_id}/status";
};

export type GetFalAiZImageTurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZImageTurboRequestsByRequestIdStatusResponse =
  GetFalAiZImageTurboRequestsByRequestIdStatusResponses[keyof GetFalAiZImageTurboRequestsByRequestIdStatusResponses];

export type PutFalAiZImageTurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/requests/{request_id}/cancel";
};

export type PutFalAiZImageTurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZImageTurboRequestsByRequestIdCancelResponse =
  PutFalAiZImageTurboRequestsByRequestIdCancelResponses[keyof PutFalAiZImageTurboRequestsByRequestIdCancelResponses];

export type PostFalAiZImageTurboData = {
  body: ZImageTurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/z-image/turbo";
};

export type PostFalAiZImageTurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZImageTurboResponse =
  PostFalAiZImageTurboResponses[keyof PostFalAiZImageTurboResponses];

export type GetFalAiZImageTurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/z-image/turbo/requests/{request_id}";
};

export type GetFalAiZImageTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZImageTurboOutput;
};

export type GetFalAiZImageTurboRequestsByRequestIdResponse =
  GetFalAiZImageTurboRequestsByRequestIdResponses[keyof GetFalAiZImageTurboRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/sepia-vintage/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/sepia-vintage/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGallerySepiaVintageData = {
  body: Flux2LoraGallerySepiaVintageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/sepia-vintage";
};

export type PostFalAiFlux2LoraGallerySepiaVintageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGallerySepiaVintageResponse =
  PostFalAiFlux2LoraGallerySepiaVintageResponses[keyof PostFalAiFlux2LoraGallerySepiaVintageResponses];

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/sepia-vintage/requests/{request_id}";
};

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraGallerySepiaVintageOutput;
};

export type GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGallerySepiaVintageRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/satellite-view-style/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/satellite-view-style/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGallerySatelliteViewStyleData = {
  body: Flux2LoraGallerySatelliteViewStyleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/satellite-view-style";
};

export type PostFalAiFlux2LoraGallerySatelliteViewStyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGallerySatelliteViewStyleResponse =
  PostFalAiFlux2LoraGallerySatelliteViewStyleResponses[keyof PostFalAiFlux2LoraGallerySatelliteViewStyleResponses];

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/satellite-view-style/requests/{request_id}";
  };

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGallerySatelliteViewStyleOutput;
  };

export type GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGallerySatelliteViewStyleRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-lora-gallery/realism/requests/{request_id}/status";
};

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryRealismRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/realism/requests/{request_id}/cancel";
};

export type PutFalAiFlux2LoraGalleryRealismRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryRealismRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryRealismRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryRealismRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryRealismData = {
  body: Flux2LoraGalleryRealismInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/realism";
};

export type PostFalAiFlux2LoraGalleryRealismResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryRealismResponse =
  PostFalAiFlux2LoraGalleryRealismResponses[keyof PostFalAiFlux2LoraGalleryRealismResponses];

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/realism/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraGalleryRealismOutput;
};

export type GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryRealismRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-lora-gallery/hdr-style/requests/{request_id}/status";
};

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/hdr-style/requests/{request_id}/cancel";
};

export type PutFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryHdrStyleData = {
  body: Flux2LoraGalleryHdrStyleInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/hdr-style";
};

export type PostFalAiFlux2LoraGalleryHdrStyleResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryHdrStyleResponse =
  PostFalAiFlux2LoraGalleryHdrStyleResponses[keyof PostFalAiFlux2LoraGalleryHdrStyleResponses];

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/hdr-style/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2LoraGalleryHdrStyleOutput;
};

export type GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryHdrStyleRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/digital-comic-art/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/digital-comic-art/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryDigitalComicArtData = {
  body: Flux2LoraGalleryDigitalComicArtInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/digital-comic-art";
};

export type PostFalAiFlux2LoraGalleryDigitalComicArtResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryDigitalComicArtResponse =
  PostFalAiFlux2LoraGalleryDigitalComicArtResponses[keyof PostFalAiFlux2LoraGalleryDigitalComicArtResponses];

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/digital-comic-art/requests/{request_id}";
};

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryDigitalComicArtOutput;
  };

export type GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryDigitalComicArtRequestsByRequestIdResponses];

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-2-lora-gallery/ballpoint-pen-sketch/requests/{request_id}/status";
  };

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdStatusResponse =
  GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/ballpoint-pen-sketch/requests/{request_id}/cancel";
  };

export type PutFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdCancelResponse =
  PutFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2LoraGalleryBallpointPenSketchData = {
  body: Flux2LoraGalleryBallpointPenSketchInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-lora-gallery/ballpoint-pen-sketch";
};

export type PostFalAiFlux2LoraGalleryBallpointPenSketchResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2LoraGalleryBallpointPenSketchResponse =
  PostFalAiFlux2LoraGalleryBallpointPenSketchResponses[keyof PostFalAiFlux2LoraGalleryBallpointPenSketchResponses];

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-2-lora-gallery/ballpoint-pen-sketch/requests/{request_id}";
  };

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Flux2LoraGalleryBallpointPenSketchOutput;
  };

export type GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdResponse =
  GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdResponses[keyof GetFalAiFlux2LoraGalleryBallpointPenSketchRequestsByRequestIdResponses];

export type GetFalAiFlux2FlexRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-2-flex/requests/{request_id}/status";
};

export type GetFalAiFlux2FlexRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux2FlexRequestsByRequestIdStatusResponse =
  GetFalAiFlux2FlexRequestsByRequestIdStatusResponses[keyof GetFalAiFlux2FlexRequestsByRequestIdStatusResponses];

export type PutFalAiFlux2FlexRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-flex/requests/{request_id}/cancel";
};

export type PutFalAiFlux2FlexRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux2FlexRequestsByRequestIdCancelResponse =
  PutFalAiFlux2FlexRequestsByRequestIdCancelResponses[keyof PutFalAiFlux2FlexRequestsByRequestIdCancelResponses];

export type PostFalAiFlux2FlexData = {
  body: Flux2FlexInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-2-flex";
};

export type PostFalAiFlux2FlexResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux2FlexResponse =
  PostFalAiFlux2FlexResponses[keyof PostFalAiFlux2FlexResponses];

export type GetFalAiFlux2FlexRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-2-flex/requests/{request_id}";
};

export type GetFalAiFlux2FlexRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux2FlexOutput;
};

export type GetFalAiFlux2FlexRequestsByRequestIdResponse =
  GetFalAiFlux2FlexRequestsByRequestIdResponses[keyof GetFalAiFlux2FlexRequestsByRequestIdResponses];

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-3-pro-image-preview/requests/{request_id}/status";
};

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdStatusResponse =
  GetFalAiGemini3ProImagePreviewRequestsByRequestIdStatusResponses[keyof GetFalAiGemini3ProImagePreviewRequestsByRequestIdStatusResponses];

export type PutFalAiGemini3ProImagePreviewRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview/requests/{request_id}/cancel";
};

export type PutFalAiGemini3ProImagePreviewRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGemini3ProImagePreviewRequestsByRequestIdCancelResponse =
  PutFalAiGemini3ProImagePreviewRequestsByRequestIdCancelResponses[keyof PutFalAiGemini3ProImagePreviewRequestsByRequestIdCancelResponses];

export type PostFalAiGemini3ProImagePreviewData = {
  body: Gemini3ProImagePreviewInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview";
};

export type PostFalAiGemini3ProImagePreviewResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGemini3ProImagePreviewResponse =
  PostFalAiGemini3ProImagePreviewResponses[keyof PostFalAiGemini3ProImagePreviewResponses];

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-3-pro-image-preview/requests/{request_id}";
};

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Gemini3ProImagePreviewOutput;
};

export type GetFalAiGemini3ProImagePreviewRequestsByRequestIdResponse =
  GetFalAiGemini3ProImagePreviewRequestsByRequestIdResponses[keyof GetFalAiGemini3ProImagePreviewRequestsByRequestIdResponses];

export type GetFalAiNanoBananaProRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nano-banana-pro/requests/{request_id}/status";
};

export type GetFalAiNanoBananaProRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNanoBananaProRequestsByRequestIdStatusResponse =
  GetFalAiNanoBananaProRequestsByRequestIdStatusResponses[keyof GetFalAiNanoBananaProRequestsByRequestIdStatusResponses];

export type PutFalAiNanoBananaProRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana-pro/requests/{request_id}/cancel";
};

export type PutFalAiNanoBananaProRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNanoBananaProRequestsByRequestIdCancelResponse =
  PutFalAiNanoBananaProRequestsByRequestIdCancelResponses[keyof PutFalAiNanoBananaProRequestsByRequestIdCancelResponses];

export type PostFalAiNanoBananaProData = {
  body: NanoBananaProInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nano-banana-pro";
};

export type PostFalAiNanoBananaProResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNanoBananaProResponse =
  PostFalAiNanoBananaProResponses[keyof PostFalAiNanoBananaProResponses];

export type GetFalAiNanoBananaProRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana-pro/requests/{request_id}";
};

export type GetFalAiNanoBananaProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NanoBananaProOutput;
};

export type GetFalAiNanoBananaProRequestsByRequestIdResponse =
  GetFalAiNanoBananaProRequestsByRequestIdResponses[keyof GetFalAiNanoBananaProRequestsByRequestIdResponses];

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/imagineart/imagineart-1.5-preview/text-to-image/requests/{request_id}/status";
  };

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdStatusResponse =
  GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdStatusResponses[keyof GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdStatusResponses];

export type PutImagineartImagineart15PreviewTextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/imagineart/imagineart-1.5-preview/text-to-image/requests/{request_id}/cancel";
  };

export type PutImagineartImagineart15PreviewTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutImagineartImagineart15PreviewTextToImageRequestsByRequestIdCancelResponse =
  PutImagineartImagineart15PreviewTextToImageRequestsByRequestIdCancelResponses[keyof PutImagineartImagineart15PreviewTextToImageRequestsByRequestIdCancelResponses];

export type PostImagineartImagineart15PreviewTextToImageData = {
  body: Imagineart15PreviewTextToImageInput;
  path?: never;
  query?: never;
  url: "/imagineart/imagineart-1.5-preview/text-to-image";
};

export type PostImagineartImagineart15PreviewTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostImagineartImagineart15PreviewTextToImageResponse =
  PostImagineartImagineart15PreviewTextToImageResponses[keyof PostImagineartImagineart15PreviewTextToImageResponses];

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/imagineart/imagineart-1.5-preview/text-to-image/requests/{request_id}";
  };

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: Imagineart15PreviewTextToImageOutput;
  };

export type GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdResponse =
  GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdResponses[keyof GetImagineartImagineart15PreviewTextToImageRequestsByRequestIdResponses];

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/emu-3.5-image/text-to-image/requests/{request_id}/status";
};

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiEmu35ImageTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiEmu35ImageTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiEmu35ImageTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/emu-3.5-image/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiEmu35ImageTextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiEmu35ImageTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiEmu35ImageTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiEmu35ImageTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiEmu35ImageTextToImageData = {
  body: Emu35ImageTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/emu-3.5-image/text-to-image";
};

export type PostFalAiEmu35ImageTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiEmu35ImageTextToImageResponse =
  PostFalAiEmu35ImageTextToImageResponses[keyof PostFalAiEmu35ImageTextToImageResponses];

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/emu-3.5-image/text-to-image/requests/{request_id}";
};

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Emu35ImageTextToImageOutput;
};

export type GetFalAiEmu35ImageTextToImageRequestsByRequestIdResponse =
  GetFalAiEmu35ImageTextToImageRequestsByRequestIdResponses[keyof GetFalAiEmu35ImageTextToImageRequestsByRequestIdResponses];

export type GetBriaFiboGenerateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/bria/fibo/generate/requests/{request_id}/status";
};

export type GetBriaFiboGenerateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBriaFiboGenerateRequestsByRequestIdStatusResponse =
  GetBriaFiboGenerateRequestsByRequestIdStatusResponses[keyof GetBriaFiboGenerateRequestsByRequestIdStatusResponses];

export type PutBriaFiboGenerateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo/generate/requests/{request_id}/cancel";
};

export type PutBriaFiboGenerateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBriaFiboGenerateRequestsByRequestIdCancelResponse =
  PutBriaFiboGenerateRequestsByRequestIdCancelResponses[keyof PutBriaFiboGenerateRequestsByRequestIdCancelResponses];

export type PostBriaFiboGenerateData = {
  body: FiboGenerateInput;
  path?: never;
  query?: never;
  url: "/bria/fibo/generate";
};

export type PostBriaFiboGenerateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBriaFiboGenerateResponse =
  PostBriaFiboGenerateResponses[keyof PostBriaFiboGenerateResponses];

export type GetBriaFiboGenerateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/bria/fibo/generate/requests/{request_id}";
};

export type GetBriaFiboGenerateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FiboGenerateOutput;
};

export type GetBriaFiboGenerateRequestsByRequestIdResponse =
  GetBriaFiboGenerateRequestsByRequestIdResponses[keyof GetBriaFiboGenerateRequestsByRequestIdResponses];

export type GetFalAiPiflowRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/piflow/requests/{request_id}/status";
};

export type GetFalAiPiflowRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPiflowRequestsByRequestIdStatusResponse =
  GetFalAiPiflowRequestsByRequestIdStatusResponses[keyof GetFalAiPiflowRequestsByRequestIdStatusResponses];

export type PutFalAiPiflowRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/piflow/requests/{request_id}/cancel";
};

export type PutFalAiPiflowRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPiflowRequestsByRequestIdCancelResponse =
  PutFalAiPiflowRequestsByRequestIdCancelResponses[keyof PutFalAiPiflowRequestsByRequestIdCancelResponses];

export type PostFalAiPiflowData = {
  body: PiflowInput;
  path?: never;
  query?: never;
  url: "/fal-ai/piflow";
};

export type PostFalAiPiflowResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPiflowResponse =
  PostFalAiPiflowResponses[keyof PostFalAiPiflowResponses];

export type GetFalAiPiflowRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/piflow/requests/{request_id}";
};

export type GetFalAiPiflowRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PiflowOutput;
};

export type GetFalAiPiflowRequestsByRequestIdResponse =
  GetFalAiPiflowRequestsByRequestIdResponses[keyof GetFalAiPiflowRequestsByRequestIdResponses];

export type GetFalAiGptImage1MiniRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1-mini/requests/{request_id}/status";
};

export type GetFalAiGptImage1MiniRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage1MiniRequestsByRequestIdStatusResponse =
  GetFalAiGptImage1MiniRequestsByRequestIdStatusResponses[keyof GetFalAiGptImage1MiniRequestsByRequestIdStatusResponses];

export type PutFalAiGptImage1MiniRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1-mini/requests/{request_id}/cancel";
};

export type PutFalAiGptImage1MiniRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage1MiniRequestsByRequestIdCancelResponse =
  PutFalAiGptImage1MiniRequestsByRequestIdCancelResponses[keyof PutFalAiGptImage1MiniRequestsByRequestIdCancelResponses];

export type PostFalAiGptImage1MiniData = {
  body: GptImage1MiniInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1-mini";
};

export type PostFalAiGptImage1MiniResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage1MiniResponse =
  PostFalAiGptImage1MiniResponses[keyof PostFalAiGptImage1MiniResponses];

export type GetFalAiGptImage1MiniRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1-mini/requests/{request_id}";
};

export type GetFalAiGptImage1MiniRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage1MiniOutput;
};

export type GetFalAiGptImage1MiniRequestsByRequestIdResponse =
  GetFalAiGptImage1MiniRequestsByRequestIdResponses[keyof GetFalAiGptImage1MiniRequestsByRequestIdResponses];

export type GetFalAiReveTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/reve/text-to-image/requests/{request_id}/status";
};

export type GetFalAiReveTextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiReveTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiReveTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiReveTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiReveTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiReveTextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiReveTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiReveTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiReveTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiReveTextToImageData = {
  body: ReveTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/reve/text-to-image";
};

export type PostFalAiReveTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiReveTextToImageResponse =
  PostFalAiReveTextToImageResponses[keyof PostFalAiReveTextToImageResponses];

export type GetFalAiReveTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/reve/text-to-image/requests/{request_id}";
};

export type GetFalAiReveTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ReveTextToImageOutput;
};

export type GetFalAiReveTextToImageRequestsByRequestIdResponse =
  GetFalAiReveTextToImageRequestsByRequestIdResponses[keyof GetFalAiReveTextToImageRequestsByRequestIdResponses];

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hunyuan-image/v3/text-to-image/requests/{request_id}/status";
};

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiHunyuanImageV3TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiHunyuanImageV3TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiHunyuanImageV3TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanImageV3TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanImageV3TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiHunyuanImageV3TextToImageData = {
  body: HunyuanImageV3TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/text-to-image";
};

export type PostFalAiHunyuanImageV3TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHunyuanImageV3TextToImageResponse =
  PostFalAiHunyuanImageV3TextToImageResponses[keyof PostFalAiHunyuanImageV3TextToImageResponses];

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v3/text-to-image/requests/{request_id}";
};

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HunyuanImageV3TextToImageOutput;
};

export type GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdResponse =
  GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdResponses[keyof GetFalAiHunyuanImageV3TextToImageRequestsByRequestIdResponses];

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan-25-preview/text-to-image/requests/{request_id}/status";
};

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiWan25PreviewTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiWan25PreviewTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiWan25PreviewTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan-25-preview/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiWan25PreviewTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiWan25PreviewTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiWan25PreviewTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiWan25PreviewTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiWan25PreviewTextToImageData = {
  body: Wan25PreviewTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan-25-preview/text-to-image";
};

export type PostFalAiWan25PreviewTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWan25PreviewTextToImageResponse =
  PostFalAiWan25PreviewTextToImageResponses[keyof PostFalAiWan25PreviewTextToImageResponses];

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan-25-preview/text-to-image/requests/{request_id}";
};

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Wan25PreviewTextToImageOutput;
};

export type GetFalAiWan25PreviewTextToImageRequestsByRequestIdResponse =
  GetFalAiWan25PreviewTextToImageRequestsByRequestIdResponses[keyof GetFalAiWan25PreviewTextToImageRequestsByRequestIdResponses];

export type GetFalAiFluxSrpoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/srpo/requests/{request_id}/status";
};

export type GetFalAiFluxSrpoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxSrpoRequestsByRequestIdStatusResponse =
  GetFalAiFluxSrpoRequestsByRequestIdStatusResponses[keyof GetFalAiFluxSrpoRequestsByRequestIdStatusResponses];

export type PutFalAiFluxSrpoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/srpo/requests/{request_id}/cancel";
};

export type PutFalAiFluxSrpoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxSrpoRequestsByRequestIdCancelResponse =
  PutFalAiFluxSrpoRequestsByRequestIdCancelResponses[keyof PutFalAiFluxSrpoRequestsByRequestIdCancelResponses];

export type PostFalAiFluxSrpoData = {
  body: FluxSrpoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/srpo";
};

export type PostFalAiFluxSrpoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxSrpoResponse =
  PostFalAiFluxSrpoResponses[keyof PostFalAiFluxSrpoResponses];

export type GetFalAiFluxSrpoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/srpo/requests/{request_id}";
};

export type GetFalAiFluxSrpoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxSrpoOutput;
};

export type GetFalAiFluxSrpoRequestsByRequestIdResponse =
  GetFalAiFluxSrpoRequestsByRequestIdResponses[keyof GetFalAiFluxSrpoRequestsByRequestIdResponses];

export type GetFalAiFlux1SrpoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/srpo/requests/{request_id}/status";
};

export type GetFalAiFlux1SrpoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1SrpoRequestsByRequestIdStatusResponse =
  GetFalAiFlux1SrpoRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1SrpoRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1SrpoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/srpo/requests/{request_id}/cancel";
};

export type PutFalAiFlux1SrpoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1SrpoRequestsByRequestIdCancelResponse =
  PutFalAiFlux1SrpoRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1SrpoRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1SrpoData = {
  body: Flux1SrpoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/srpo";
};

export type PostFalAiFlux1SrpoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1SrpoResponse =
  PostFalAiFlux1SrpoResponses[keyof PostFalAiFlux1SrpoResponses];

export type GetFalAiFlux1SrpoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/srpo/requests/{request_id}";
};

export type GetFalAiFlux1SrpoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1SrpoOutput;
};

export type GetFalAiFlux1SrpoRequestsByRequestIdResponse =
  GetFalAiFlux1SrpoRequestsByRequestIdResponses[keyof GetFalAiFlux1SrpoRequestsByRequestIdResponses];

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/hunyuan-image/v2.1/text-to-image/requests/{request_id}/status";
};

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiHunyuanImageV21TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v2.1/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiHunyuanImageV21TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiHunyuanImageV21TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiHunyuanImageV21TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiHunyuanImageV21TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiHunyuanImageV21TextToImageData = {
  body: HunyuanImageV21TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/hunyuan-image/v2.1/text-to-image";
};

export type PostFalAiHunyuanImageV21TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiHunyuanImageV21TextToImageResponse =
  PostFalAiHunyuanImageV21TextToImageResponses[keyof PostFalAiHunyuanImageV21TextToImageResponses];

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/hunyuan-image/v2.1/text-to-image/requests/{request_id}";
};

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: HunyuanImageV21TextToImageOutput;
};

export type GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdResponse =
  GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdResponses[keyof GetFalAiHunyuanImageV21TextToImageRequestsByRequestIdResponses];

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/bytedance/seedream/v4/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/bytedance/seedream/v4/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceSeedreamV4TextToImageData = {
  body: BytedanceSeedreamV4TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4/text-to-image";
};

export type PostFalAiBytedanceSeedreamV4TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceSeedreamV4TextToImageResponse =
  PostFalAiBytedanceSeedreamV4TextToImageResponses[keyof PostFalAiBytedanceSeedreamV4TextToImageResponses];

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v4/text-to-image/requests/{request_id}";
};

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: BytedanceSeedreamV4TextToImageOutput;
  };

export type GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedreamV4TextToImageRequestsByRequestIdResponses];

export type GetFalAiGemini25FlashImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gemini-25-flash-image/requests/{request_id}/status";
};

export type GetFalAiGemini25FlashImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGemini25FlashImageRequestsByRequestIdStatusResponse =
  GetFalAiGemini25FlashImageRequestsByRequestIdStatusResponses[keyof GetFalAiGemini25FlashImageRequestsByRequestIdStatusResponses];

export type PutFalAiGemini25FlashImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-25-flash-image/requests/{request_id}/cancel";
};

export type PutFalAiGemini25FlashImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGemini25FlashImageRequestsByRequestIdCancelResponse =
  PutFalAiGemini25FlashImageRequestsByRequestIdCancelResponses[keyof PutFalAiGemini25FlashImageRequestsByRequestIdCancelResponses];

export type PostFalAiGemini25FlashImageData = {
  body: Gemini25FlashImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gemini-25-flash-image";
};

export type PostFalAiGemini25FlashImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGemini25FlashImageResponse =
  PostFalAiGemini25FlashImageResponses[keyof PostFalAiGemini25FlashImageResponses];

export type GetFalAiGemini25FlashImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gemini-25-flash-image/requests/{request_id}";
};

export type GetFalAiGemini25FlashImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Gemini25FlashImageOutput;
};

export type GetFalAiGemini25FlashImageRequestsByRequestIdResponse =
  GetFalAiGemini25FlashImageRequestsByRequestIdResponses[keyof GetFalAiGemini25FlashImageRequestsByRequestIdResponses];

export type GetFalAiNanoBananaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nano-banana/requests/{request_id}/status";
};

export type GetFalAiNanoBananaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNanoBananaRequestsByRequestIdStatusResponse =
  GetFalAiNanoBananaRequestsByRequestIdStatusResponses[keyof GetFalAiNanoBananaRequestsByRequestIdStatusResponses];

export type PutFalAiNanoBananaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana/requests/{request_id}/cancel";
};

export type PutFalAiNanoBananaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNanoBananaRequestsByRequestIdCancelResponse =
  PutFalAiNanoBananaRequestsByRequestIdCancelResponses[keyof PutFalAiNanoBananaRequestsByRequestIdCancelResponses];

export type PostFalAiNanoBananaData = {
  body: NanoBananaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nano-banana";
};

export type PostFalAiNanoBananaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNanoBananaResponse =
  PostFalAiNanoBananaResponses[keyof PostFalAiNanoBananaResponses];

export type GetFalAiNanoBananaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nano-banana/requests/{request_id}";
};

export type GetFalAiNanoBananaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NanoBananaOutput;
};

export type GetFalAiNanoBananaRequestsByRequestIdResponse =
  GetFalAiNanoBananaRequestsByRequestIdResponses[keyof GetFalAiNanoBananaRequestsByRequestIdResponses];

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/bytedance/dreamina/v3.1/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/bytedance/dreamina/v3.1/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceDreaminaV31TextToImageData = {
  body: BytedanceDreaminaV31TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/dreamina/v3.1/text-to-image";
};

export type PostFalAiBytedanceDreaminaV31TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceDreaminaV31TextToImageResponse =
  PostFalAiBytedanceDreaminaV31TextToImageResponses[keyof PostFalAiBytedanceDreaminaV31TextToImageResponses];

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/dreamina/v3.1/text-to-image/requests/{request_id}";
};

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: BytedanceDreaminaV31TextToImageOutput;
  };

export type GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdResponse =
  GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdResponses[keyof GetFalAiBytedanceDreaminaV31TextToImageRequestsByRequestIdResponses];

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/lora/requests/{request_id}/status";
};

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdStatusResponses];

export type PutFalAiWanV22A14bTextToImageLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/lora/requests/{request_id}/cancel";
};

export type PutFalAiWanV22A14bTextToImageLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiWanV22A14bTextToImageLoraRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bTextToImageLoraRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bTextToImageLoraRequestsByRequestIdCancelResponses];

export type PostFalAiWanV22A14bTextToImageLoraData = {
  body: WanV22A14bTextToImageLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/lora";
};

export type PostFalAiWanV22A14bTextToImageLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWanV22A14bTextToImageLoraResponse =
  PostFalAiWanV22A14bTextToImageLoraResponses[keyof PostFalAiWanV22A14bTextToImageLoraResponses];

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/lora/requests/{request_id}";
};

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: WanV22A14bTextToImageLoraOutput;
};

export type GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdResponse =
  GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bTextToImageLoraRequestsByRequestIdResponses];

export type GetFalAiWanV225bTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan/v2.2-5b/text-to-image/requests/{request_id}/status";
};

export type GetFalAiWanV225bTextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiWanV225bTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiWanV225bTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiWanV225bTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiWanV225bTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-5b/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiWanV225bTextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiWanV225bTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiWanV225bTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiWanV225bTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiWanV225bTextToImageData = {
  body: WanV225bTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan/v2.2-5b/text-to-image";
};

export type PostFalAiWanV225bTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWanV225bTextToImageResponse =
  PostFalAiWanV225bTextToImageResponses[keyof PostFalAiWanV225bTextToImageResponses];

export type GetFalAiWanV225bTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-5b/text-to-image/requests/{request_id}";
};

export type GetFalAiWanV225bTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: WanV225bTextToImageOutput;
};

export type GetFalAiWanV225bTextToImageRequestsByRequestIdResponse =
  GetFalAiWanV225bTextToImageRequestsByRequestIdResponses[keyof GetFalAiWanV225bTextToImageRequestsByRequestIdResponses];

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/requests/{request_id}/status";
};

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiWanV22A14bTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiWanV22A14bTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiWanV22A14bTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiWanV22A14bTextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiWanV22A14bTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiWanV22A14bTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiWanV22A14bTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiWanV22A14bTextToImageData = {
  body: WanV22A14bTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image";
};

export type PostFalAiWanV22A14bTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiWanV22A14bTextToImageResponse =
  PostFalAiWanV22A14bTextToImageResponses[keyof PostFalAiWanV22A14bTextToImageResponses];

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/wan/v2.2-a14b/text-to-image/requests/{request_id}";
};

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: WanV22A14bTextToImageOutput;
};

export type GetFalAiWanV22A14bTextToImageRequestsByRequestIdResponse =
  GetFalAiWanV22A14bTextToImageRequestsByRequestIdResponses[keyof GetFalAiWanV22A14bTextToImageRequestsByRequestIdResponses];

export type GetFalAiQwenImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-image/requests/{request_id}/status";
};

export type GetFalAiQwenImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwenImageRequestsByRequestIdStatusResponse =
  GetFalAiQwenImageRequestsByRequestIdStatusResponses[keyof GetFalAiQwenImageRequestsByRequestIdStatusResponses];

export type PutFalAiQwenImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image/requests/{request_id}/cancel";
};

export type PutFalAiQwenImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwenImageRequestsByRequestIdCancelResponse =
  PutFalAiQwenImageRequestsByRequestIdCancelResponses[keyof PutFalAiQwenImageRequestsByRequestIdCancelResponses];

export type PostFalAiQwenImageData = {
  body: QwenImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-image";
};

export type PostFalAiQwenImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwenImageResponse =
  PostFalAiQwenImageResponses[keyof PostFalAiQwenImageResponses];

export type GetFalAiQwenImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-image/requests/{request_id}";
};

export type GetFalAiQwenImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: QwenImageOutput;
};

export type GetFalAiQwenImageRequestsByRequestIdResponse =
  GetFalAiQwenImageRequestsByRequestIdResponses[keyof GetFalAiQwenImageRequestsByRequestIdResponses];

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-krea-lora/stream/requests/{request_id}/status";
};

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaLoraStreamRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaLoraStreamRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaLoraStreamRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/stream/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaLoraStreamRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaLoraStreamRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaLoraStreamRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaLoraStreamRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaLoraStreamData = {
  body: FluxKreaLoraStreamInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-krea-lora/stream";
};

export type PostFalAiFluxKreaLoraStreamResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaLoraStreamResponse =
  PostFalAiFluxKreaLoraStreamResponses[keyof PostFalAiFluxKreaLoraStreamResponses];

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/stream/requests/{request_id}";
};

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaLoraStreamOutput;
};

export type GetFalAiFluxKreaLoraStreamRequestsByRequestIdResponse =
  GetFalAiFluxKreaLoraStreamRequestsByRequestIdResponses[keyof GetFalAiFluxKreaLoraStreamRequestsByRequestIdResponses];

export type GetFalAiFluxKreaLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-krea-lora/requests/{request_id}/status";
};

export type GetFalAiFluxKreaLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaLoraRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaLoraRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaLoraRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaLoraRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaLoraRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaLoraRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaLoraData = {
  body: FluxKreaLoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-krea-lora";
};

export type PostFalAiFluxKreaLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaLoraResponse =
  PostFalAiFluxKreaLoraResponses[keyof PostFalAiFluxKreaLoraResponses];

export type GetFalAiFluxKreaLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-krea-lora/requests/{request_id}";
};

export type GetFalAiFluxKreaLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaLoraOutput;
};

export type GetFalAiFluxKreaLoraRequestsByRequestIdResponse =
  GetFalAiFluxKreaLoraRequestsByRequestIdResponses[keyof GetFalAiFluxKreaLoraRequestsByRequestIdResponses];

export type GetFalAiFluxKreaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/krea/requests/{request_id}/status";
};

export type GetFalAiFluxKreaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxKreaRequestsByRequestIdStatusResponse =
  GetFalAiFluxKreaRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKreaRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKreaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/requests/{request_id}/cancel";
};

export type PutFalAiFluxKreaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxKreaRequestsByRequestIdCancelResponse =
  PutFalAiFluxKreaRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKreaRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKreaData = {
  body: FluxKreaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/krea";
};

export type PostFalAiFluxKreaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKreaResponse =
  PostFalAiFluxKreaResponses[keyof PostFalAiFluxKreaResponses];

export type GetFalAiFluxKreaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/krea/requests/{request_id}";
};

export type GetFalAiFluxKreaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKreaOutput;
};

export type GetFalAiFluxKreaRequestsByRequestIdResponse =
  GetFalAiFluxKreaRequestsByRequestIdResponses[keyof GetFalAiFluxKreaRequestsByRequestIdResponses];

export type GetFalAiFlux1KreaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/krea/requests/{request_id}/status";
};

export type GetFalAiFlux1KreaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1KreaRequestsByRequestIdStatusResponse =
  GetFalAiFlux1KreaRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1KreaRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1KreaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/requests/{request_id}/cancel";
};

export type PutFalAiFlux1KreaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1KreaRequestsByRequestIdCancelResponse =
  PutFalAiFlux1KreaRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1KreaRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1KreaData = {
  body: Flux1KreaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/krea";
};

export type PostFalAiFlux1KreaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1KreaResponse =
  PostFalAiFlux1KreaResponses[keyof PostFalAiFlux1KreaResponses];

export type GetFalAiFlux1KreaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/krea/requests/{request_id}";
};

export type GetFalAiFlux1KreaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1KreaOutput;
};

export type GetFalAiFlux1KreaRequestsByRequestIdResponse =
  GetFalAiFlux1KreaRequestsByRequestIdResponses[keyof GetFalAiFlux1KreaRequestsByRequestIdResponses];

export type GetFalAiSkyRaccoonRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sky-raccoon/requests/{request_id}/status";
};

export type GetFalAiSkyRaccoonRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSkyRaccoonRequestsByRequestIdStatusResponse =
  GetFalAiSkyRaccoonRequestsByRequestIdStatusResponses[keyof GetFalAiSkyRaccoonRequestsByRequestIdStatusResponses];

export type PutFalAiSkyRaccoonRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sky-raccoon/requests/{request_id}/cancel";
};

export type PutFalAiSkyRaccoonRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSkyRaccoonRequestsByRequestIdCancelResponse =
  PutFalAiSkyRaccoonRequestsByRequestIdCancelResponses[keyof PutFalAiSkyRaccoonRequestsByRequestIdCancelResponses];

export type PostFalAiSkyRaccoonData = {
  body: SkyRaccoonInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sky-raccoon";
};

export type PostFalAiSkyRaccoonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSkyRaccoonResponse =
  PostFalAiSkyRaccoonResponses[keyof PostFalAiSkyRaccoonResponses];

export type GetFalAiSkyRaccoonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sky-raccoon/requests/{request_id}";
};

export type GetFalAiSkyRaccoonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SkyRaccoonOutput;
};

export type GetFalAiSkyRaccoonRequestsByRequestIdResponse =
  GetFalAiSkyRaccoonRequestsByRequestIdResponses[keyof GetFalAiSkyRaccoonRequestsByRequestIdResponses];

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-kontext-lora/text-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxKontextLoraTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxKontextLoraTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxKontextLoraTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxKontextLoraTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxKontextLoraTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxKontextLoraTextToImageData = {
  body: FluxKontextLoraTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-kontext-lora/text-to-image";
};

export type PostFalAiFluxKontextLoraTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxKontextLoraTextToImageResponse =
  PostFalAiFluxKontextLoraTextToImageResponses[keyof PostFalAiFluxKontextLoraTextToImageResponses];

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-kontext-lora/text-to-image/requests/{request_id}";
};

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxKontextLoraTextToImageOutput;
};

export type GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdResponse =
  GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdResponses[keyof GetFalAiFluxKontextLoraTextToImageRequestsByRequestIdResponses];

export type GetFalAiOmnigenV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/omnigen-v2/requests/{request_id}/status";
};

export type GetFalAiOmnigenV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiOmnigenV2RequestsByRequestIdStatusResponse =
  GetFalAiOmnigenV2RequestsByRequestIdStatusResponses[keyof GetFalAiOmnigenV2RequestsByRequestIdStatusResponses];

export type PutFalAiOmnigenV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omnigen-v2/requests/{request_id}/cancel";
};

export type PutFalAiOmnigenV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiOmnigenV2RequestsByRequestIdCancelResponse =
  PutFalAiOmnigenV2RequestsByRequestIdCancelResponses[keyof PutFalAiOmnigenV2RequestsByRequestIdCancelResponses];

export type PostFalAiOmnigenV2Data = {
  body: OmnigenV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/omnigen-v2";
};

export type PostFalAiOmnigenV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiOmnigenV2Response =
  PostFalAiOmnigenV2Responses[keyof PostFalAiOmnigenV2Responses];

export type GetFalAiOmnigenV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omnigen-v2/requests/{request_id}";
};

export type GetFalAiOmnigenV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: OmnigenV2Output;
};

export type GetFalAiOmnigenV2RequestsByRequestIdResponse =
  GetFalAiOmnigenV2RequestsByRequestIdResponses[keyof GetFalAiOmnigenV2RequestsByRequestIdResponses];

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/bytedance/seedream/v3/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/bytedance/seedream/v3/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiBytedanceSeedreamV3TextToImageData = {
  body: BytedanceSeedreamV3TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bytedance/seedream/v3/text-to-image";
};

export type PostFalAiBytedanceSeedreamV3TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBytedanceSeedreamV3TextToImageResponse =
  PostFalAiBytedanceSeedreamV3TextToImageResponses[keyof PostFalAiBytedanceSeedreamV3TextToImageResponses];

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bytedance/seedream/v3/text-to-image/requests/{request_id}";
};

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: BytedanceSeedreamV3TextToImageOutput;
  };

export type GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdResponse =
  GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdResponses[keyof GetFalAiBytedanceSeedreamV3TextToImageRequestsByRequestIdResponses];

export type GetFalAiFlux1SchnellRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/schnell/requests/{request_id}/status";
};

export type GetFalAiFlux1SchnellRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1SchnellRequestsByRequestIdStatusResponse =
  GetFalAiFlux1SchnellRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1SchnellRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1SchnellRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/schnell/requests/{request_id}/cancel";
};

export type PutFalAiFlux1SchnellRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1SchnellRequestsByRequestIdCancelResponse =
  PutFalAiFlux1SchnellRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1SchnellRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1SchnellData = {
  body: Flux1SchnellInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/schnell";
};

export type PostFalAiFlux1SchnellResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1SchnellResponse =
  PostFalAiFlux1SchnellResponses[keyof PostFalAiFlux1SchnellResponses];

export type GetFalAiFlux1SchnellRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/schnell/requests/{request_id}";
};

export type GetFalAiFlux1SchnellRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1SchnellOutput;
};

export type GetFalAiFlux1SchnellRequestsByRequestIdResponse =
  GetFalAiFlux1SchnellRequestsByRequestIdResponses[keyof GetFalAiFlux1SchnellRequestsByRequestIdResponses];

export type GetFalAiFlux1DevRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-1/dev/requests/{request_id}/status";
};

export type GetFalAiFlux1DevRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFlux1DevRequestsByRequestIdStatusResponse =
  GetFalAiFlux1DevRequestsByRequestIdStatusResponses[keyof GetFalAiFlux1DevRequestsByRequestIdStatusResponses];

export type PutFalAiFlux1DevRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/requests/{request_id}/cancel";
};

export type PutFalAiFlux1DevRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFlux1DevRequestsByRequestIdCancelResponse =
  PutFalAiFlux1DevRequestsByRequestIdCancelResponses[keyof PutFalAiFlux1DevRequestsByRequestIdCancelResponses];

export type PostFalAiFlux1DevData = {
  body: Flux1DevInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-1/dev";
};

export type PostFalAiFlux1DevResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFlux1DevResponse =
  PostFalAiFlux1DevResponses[keyof PostFalAiFlux1DevResponses];

export type GetFalAiFlux1DevRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-1/dev/requests/{request_id}";
};

export type GetFalAiFlux1DevRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Flux1DevOutput;
};

export type GetFalAiFlux1DevRequestsByRequestIdResponse =
  GetFalAiFlux1DevRequestsByRequestIdResponses[keyof GetFalAiFlux1DevRequestsByRequestIdResponses];

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/flux-pro/kontext/max/text-to-image/requests/{request_id}/status";
  };

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextMaxTextToImageRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/flux-pro/kontext/max/text-to-image/requests/{request_id}/cancel";
  };

export type PutFalAiFluxProKontextMaxTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxProKontextMaxTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextMaxTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextMaxTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextMaxTextToImageData = {
  body: FluxProKontextMaxTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/text-to-image";
};

export type PostFalAiFluxProKontextMaxTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextMaxTextToImageResponse =
  PostFalAiFluxProKontextMaxTextToImageResponses[keyof PostFalAiFluxProKontextMaxTextToImageResponses];

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/max/text-to-image/requests/{request_id}";
};

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextMaxTextToImageOutput;
};

export type GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdResponse =
  GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextMaxTextToImageRequestsByRequestIdResponses];

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/kontext/text-to-image/requests/{request_id}/status";
};

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdStatusResponse =
  GetFalAiFluxProKontextTextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProKontextTextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProKontextTextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFluxProKontextTextToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxProKontextTextToImageRequestsByRequestIdCancelResponse =
  PutFalAiFluxProKontextTextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProKontextTextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProKontextTextToImageData = {
  body: FluxProKontextTextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/kontext/text-to-image";
};

export type PostFalAiFluxProKontextTextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProKontextTextToImageResponse =
  PostFalAiFluxProKontextTextToImageResponses[keyof PostFalAiFluxProKontextTextToImageResponses];

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/kontext/text-to-image/requests/{request_id}";
};

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProKontextTextToImageOutput;
};

export type GetFalAiFluxProKontextTextToImageRequestsByRequestIdResponse =
  GetFalAiFluxProKontextTextToImageRequestsByRequestIdResponses[keyof GetFalAiFluxProKontextTextToImageRequestsByRequestIdResponses];

export type GetFalAiBagelRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bagel/requests/{request_id}/status";
};

export type GetFalAiBagelRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBagelRequestsByRequestIdStatusResponse =
  GetFalAiBagelRequestsByRequestIdStatusResponses[keyof GetFalAiBagelRequestsByRequestIdStatusResponses];

export type PutFalAiBagelRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bagel/requests/{request_id}/cancel";
};

export type PutFalAiBagelRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBagelRequestsByRequestIdCancelResponse =
  PutFalAiBagelRequestsByRequestIdCancelResponses[keyof PutFalAiBagelRequestsByRequestIdCancelResponses];

export type PostFalAiBagelData = {
  body: BagelInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bagel";
};

export type PostFalAiBagelResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBagelResponse =
  PostFalAiBagelResponses[keyof PostFalAiBagelResponses];

export type GetFalAiBagelRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bagel/requests/{request_id}";
};

export type GetFalAiBagelRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BagelOutput;
};

export type GetFalAiBagelRequestsByRequestIdResponse =
  GetFalAiBagelRequestsByRequestIdResponses[keyof GetFalAiBagelRequestsByRequestIdResponses];

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imagen4/preview/ultra/requests/{request_id}/status";
};

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdStatusResponse =
  GetFalAiImagen4PreviewUltraRequestsByRequestIdStatusResponses[keyof GetFalAiImagen4PreviewUltraRequestsByRequestIdStatusResponses];

export type PutFalAiImagen4PreviewUltraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/ultra/requests/{request_id}/cancel";
};

export type PutFalAiImagen4PreviewUltraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagen4PreviewUltraRequestsByRequestIdCancelResponse =
  PutFalAiImagen4PreviewUltraRequestsByRequestIdCancelResponses[keyof PutFalAiImagen4PreviewUltraRequestsByRequestIdCancelResponses];

export type PostFalAiImagen4PreviewUltraData = {
  body: Imagen4PreviewUltraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imagen4/preview/ultra";
};

export type PostFalAiImagen4PreviewUltraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagen4PreviewUltraResponse =
  PostFalAiImagen4PreviewUltraResponses[keyof PostFalAiImagen4PreviewUltraResponses];

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen4/preview/ultra/requests/{request_id}";
};

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Imagen4PreviewUltraOutput;
};

export type GetFalAiImagen4PreviewUltraRequestsByRequestIdResponse =
  GetFalAiImagen4PreviewUltraRequestsByRequestIdResponses[keyof GetFalAiImagen4PreviewUltraRequestsByRequestIdResponses];

export type GetFalAiDreamoRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dreamo/requests/{request_id}/status";
};

export type GetFalAiDreamoRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDreamoRequestsByRequestIdStatusResponse =
  GetFalAiDreamoRequestsByRequestIdStatusResponses[keyof GetFalAiDreamoRequestsByRequestIdStatusResponses];

export type PutFalAiDreamoRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamo/requests/{request_id}/cancel";
};

export type PutFalAiDreamoRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDreamoRequestsByRequestIdCancelResponse =
  PutFalAiDreamoRequestsByRequestIdCancelResponses[keyof PutFalAiDreamoRequestsByRequestIdCancelResponses];

export type PostFalAiDreamoData = {
  body: DreamoInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dreamo";
};

export type PostFalAiDreamoResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDreamoResponse =
  PostFalAiDreamoResponses[keyof PostFalAiDreamoResponses];

export type GetFalAiDreamoRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamo/requests/{request_id}";
};

export type GetFalAiDreamoRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DreamoOutput;
};

export type GetFalAiDreamoRequestsByRequestIdResponse =
  GetFalAiDreamoRequestsByRequestIdResponses[keyof GetFalAiDreamoRequestsByRequestIdResponses];

export type GetFalAiFluxLoraStreamRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora/stream/requests/{request_id}/status";
};

export type GetFalAiFluxLoraStreamRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraStreamRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraStreamRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraStreamRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraStreamRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/stream/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraStreamRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraStreamRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraStreamRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraStreamRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraStreamData = {
  body: FluxLoraStreamInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora/stream";
};

export type PostFalAiFluxLoraStreamResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraStreamResponse =
  PostFalAiFluxLoraStreamResponses[keyof PostFalAiFluxLoraStreamResponses];

export type GetFalAiFluxLoraStreamRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/stream/requests/{request_id}";
};

export type GetFalAiFluxLoraStreamRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraStreamOutput;
};

export type GetFalAiFluxLoraStreamRequestsByRequestIdResponse =
  GetFalAiFluxLoraStreamRequestsByRequestIdResponses[keyof GetFalAiFluxLoraStreamRequestsByRequestIdResponses];

export type GetFalAiMinimaxImage01RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/image-01/requests/{request_id}/status";
};

export type GetFalAiMinimaxImage01RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxImage01RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxImage01RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxImage01RequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxImage01RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/image-01/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxImage01RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxImage01RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxImage01RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxImage01RequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxImage01Data = {
  body: MinimaxImage01Input;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/image-01";
};

export type PostFalAiMinimaxImage01Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxImage01Response =
  PostFalAiMinimaxImage01Responses[keyof PostFalAiMinimaxImage01Responses];

export type GetFalAiMinimaxImage01RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/image-01/requests/{request_id}";
};

export type GetFalAiMinimaxImage01RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxImage01Output;
};

export type GetFalAiMinimaxImage01RequestsByRequestIdResponse =
  GetFalAiMinimaxImage01RequestsByRequestIdResponses[keyof GetFalAiMinimaxImage01RequestsByRequestIdResponses];

export type GetFalAiPonyV7RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/pony-v7/requests/{request_id}/status";
};

export type GetFalAiPonyV7RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPonyV7RequestsByRequestIdStatusResponse =
  GetFalAiPonyV7RequestsByRequestIdStatusResponses[keyof GetFalAiPonyV7RequestsByRequestIdStatusResponses];

export type PutFalAiPonyV7RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pony-v7/requests/{request_id}/cancel";
};

export type PutFalAiPonyV7RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPonyV7RequestsByRequestIdCancelResponse =
  PutFalAiPonyV7RequestsByRequestIdCancelResponses[keyof PutFalAiPonyV7RequestsByRequestIdCancelResponses];

export type PostFalAiPonyV7Data = {
  body: PonyV7Input;
  path?: never;
  query?: never;
  url: "/fal-ai/pony-v7";
};

export type PostFalAiPonyV7Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPonyV7Response =
  PostFalAiPonyV7Responses[keyof PostFalAiPonyV7Responses];

export type GetFalAiPonyV7RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pony-v7/requests/{request_id}";
};

export type GetFalAiPonyV7RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PonyV7Output;
};

export type GetFalAiPonyV7RequestsByRequestIdResponse =
  GetFalAiPonyV7RequestsByRequestIdResponses[keyof GetFalAiPonyV7RequestsByRequestIdResponses];

export type GetFalAiIdeogramV3RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v3/requests/{request_id}/status";
};

export type GetFalAiIdeogramV3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV3RequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV3RequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV3RequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV3RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV3RequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV3RequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV3RequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV3Data = {
  body: IdeogramV3Input;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v3";
};

export type PostFalAiIdeogramV3Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV3Response =
  PostFalAiIdeogramV3Responses[keyof PostFalAiIdeogramV3Responses];

export type GetFalAiIdeogramV3RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v3/requests/{request_id}";
};

export type GetFalAiIdeogramV3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV3Output;
};

export type GetFalAiIdeogramV3RequestsByRequestIdResponse =
  GetFalAiIdeogramV3RequestsByRequestIdResponses[keyof GetFalAiIdeogramV3RequestsByRequestIdResponses];

export type GetFalAiFLiteStandardRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/f-lite/standard/requests/{request_id}/status";
};

export type GetFalAiFLiteStandardRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFLiteStandardRequestsByRequestIdStatusResponse =
  GetFalAiFLiteStandardRequestsByRequestIdStatusResponses[keyof GetFalAiFLiteStandardRequestsByRequestIdStatusResponses];

export type PutFalAiFLiteStandardRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f-lite/standard/requests/{request_id}/cancel";
};

export type PutFalAiFLiteStandardRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFLiteStandardRequestsByRequestIdCancelResponse =
  PutFalAiFLiteStandardRequestsByRequestIdCancelResponses[keyof PutFalAiFLiteStandardRequestsByRequestIdCancelResponses];

export type PostFalAiFLiteStandardData = {
  body: FLiteStandardInput;
  path?: never;
  query?: never;
  url: "/fal-ai/f-lite/standard";
};

export type PostFalAiFLiteStandardResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFLiteStandardResponse =
  PostFalAiFLiteStandardResponses[keyof PostFalAiFLiteStandardResponses];

export type GetFalAiFLiteStandardRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f-lite/standard/requests/{request_id}";
};

export type GetFalAiFLiteStandardRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FLiteStandardOutput;
};

export type GetFalAiFLiteStandardRequestsByRequestIdResponse =
  GetFalAiFLiteStandardRequestsByRequestIdResponses[keyof GetFalAiFLiteStandardRequestsByRequestIdResponses];

export type GetFalAiFLiteTextureRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/f-lite/texture/requests/{request_id}/status";
};

export type GetFalAiFLiteTextureRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFLiteTextureRequestsByRequestIdStatusResponse =
  GetFalAiFLiteTextureRequestsByRequestIdStatusResponses[keyof GetFalAiFLiteTextureRequestsByRequestIdStatusResponses];

export type PutFalAiFLiteTextureRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f-lite/texture/requests/{request_id}/cancel";
};

export type PutFalAiFLiteTextureRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFLiteTextureRequestsByRequestIdCancelResponse =
  PutFalAiFLiteTextureRequestsByRequestIdCancelResponses[keyof PutFalAiFLiteTextureRequestsByRequestIdCancelResponses];

export type PostFalAiFLiteTextureData = {
  body: FLiteTextureInput;
  path?: never;
  query?: never;
  url: "/fal-ai/f-lite/texture";
};

export type PostFalAiFLiteTextureResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFLiteTextureResponse =
  PostFalAiFLiteTextureResponses[keyof PostFalAiFLiteTextureResponses];

export type GetFalAiFLiteTextureRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f-lite/texture/requests/{request_id}";
};

export type GetFalAiFLiteTextureRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FLiteTextureOutput;
};

export type GetFalAiFLiteTextureRequestsByRequestIdResponse =
  GetFalAiFLiteTextureRequestsByRequestIdResponses[keyof GetFalAiFLiteTextureRequestsByRequestIdResponses];

export type GetFalAiGptImage1TextToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/gpt-image-1/text-to-image/requests/{request_id}/status";
};

export type GetFalAiGptImage1TextToImageRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiGptImage1TextToImageRequestsByRequestIdStatusResponse =
  GetFalAiGptImage1TextToImageRequestsByRequestIdStatusResponses[keyof GetFalAiGptImage1TextToImageRequestsByRequestIdStatusResponses];

export type PutFalAiGptImage1TextToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1/text-to-image/requests/{request_id}/cancel";
};

export type PutFalAiGptImage1TextToImageRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiGptImage1TextToImageRequestsByRequestIdCancelResponse =
  PutFalAiGptImage1TextToImageRequestsByRequestIdCancelResponses[keyof PutFalAiGptImage1TextToImageRequestsByRequestIdCancelResponses];

export type PostFalAiGptImage1TextToImageData = {
  body: GptImage1TextToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/gpt-image-1/text-to-image";
};

export type PostFalAiGptImage1TextToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiGptImage1TextToImageResponse =
  PostFalAiGptImage1TextToImageResponses[keyof PostFalAiGptImage1TextToImageResponses];

export type GetFalAiGptImage1TextToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/gpt-image-1/text-to-image/requests/{request_id}";
};

export type GetFalAiGptImage1TextToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: GptImage1TextToImageOutput;
};

export type GetFalAiGptImage1TextToImageRequestsByRequestIdResponse =
  GetFalAiGptImage1TextToImageRequestsByRequestIdResponses[keyof GetFalAiGptImage1TextToImageRequestsByRequestIdResponses];

export type GetFalAiSanaV1516bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sana/v1.5/1.6b/requests/{request_id}/status";
};

export type GetFalAiSanaV1516bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSanaV1516bRequestsByRequestIdStatusResponse =
  GetFalAiSanaV1516bRequestsByRequestIdStatusResponses[keyof GetFalAiSanaV1516bRequestsByRequestIdStatusResponses];

export type PutFalAiSanaV1516bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/v1.5/1.6b/requests/{request_id}/cancel";
};

export type PutFalAiSanaV1516bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSanaV1516bRequestsByRequestIdCancelResponse =
  PutFalAiSanaV1516bRequestsByRequestIdCancelResponses[keyof PutFalAiSanaV1516bRequestsByRequestIdCancelResponses];

export type PostFalAiSanaV1516bData = {
  body: SanaV1516bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sana/v1.5/1.6b";
};

export type PostFalAiSanaV1516bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSanaV1516bResponse =
  PostFalAiSanaV1516bResponses[keyof PostFalAiSanaV1516bResponses];

export type GetFalAiSanaV1516bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/v1.5/1.6b/requests/{request_id}";
};

export type GetFalAiSanaV1516bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SanaV1516bOutput;
};

export type GetFalAiSanaV1516bRequestsByRequestIdResponse =
  GetFalAiSanaV1516bRequestsByRequestIdResponses[keyof GetFalAiSanaV1516bRequestsByRequestIdResponses];

export type GetFalAiSanaV1548bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sana/v1.5/4.8b/requests/{request_id}/status";
};

export type GetFalAiSanaV1548bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSanaV1548bRequestsByRequestIdStatusResponse =
  GetFalAiSanaV1548bRequestsByRequestIdStatusResponses[keyof GetFalAiSanaV1548bRequestsByRequestIdStatusResponses];

export type PutFalAiSanaV1548bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/v1.5/4.8b/requests/{request_id}/cancel";
};

export type PutFalAiSanaV1548bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSanaV1548bRequestsByRequestIdCancelResponse =
  PutFalAiSanaV1548bRequestsByRequestIdCancelResponses[keyof PutFalAiSanaV1548bRequestsByRequestIdCancelResponses];

export type PostFalAiSanaV1548bData = {
  body: SanaV1548bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sana/v1.5/4.8b";
};

export type PostFalAiSanaV1548bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSanaV1548bResponse =
  PostFalAiSanaV1548bResponses[keyof PostFalAiSanaV1548bResponses];

export type GetFalAiSanaV1548bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/v1.5/4.8b/requests/{request_id}";
};

export type GetFalAiSanaV1548bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SanaV1548bOutput;
};

export type GetFalAiSanaV1548bRequestsByRequestIdResponse =
  GetFalAiSanaV1548bRequestsByRequestIdResponses[keyof GetFalAiSanaV1548bRequestsByRequestIdResponses];

export type GetFalAiSanaSprintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sana/sprint/requests/{request_id}/status";
};

export type GetFalAiSanaSprintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSanaSprintRequestsByRequestIdStatusResponse =
  GetFalAiSanaSprintRequestsByRequestIdStatusResponses[keyof GetFalAiSanaSprintRequestsByRequestIdStatusResponses];

export type PutFalAiSanaSprintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/sprint/requests/{request_id}/cancel";
};

export type PutFalAiSanaSprintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSanaSprintRequestsByRequestIdCancelResponse =
  PutFalAiSanaSprintRequestsByRequestIdCancelResponses[keyof PutFalAiSanaSprintRequestsByRequestIdCancelResponses];

export type PostFalAiSanaSprintData = {
  body: SanaSprintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sana/sprint";
};

export type PostFalAiSanaSprintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSanaSprintResponse =
  PostFalAiSanaSprintResponses[keyof PostFalAiSanaSprintResponses];

export type GetFalAiSanaSprintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/sprint/requests/{request_id}";
};

export type GetFalAiSanaSprintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SanaSprintOutput;
};

export type GetFalAiSanaSprintRequestsByRequestIdResponse =
  GetFalAiSanaSprintRequestsByRequestIdResponses[keyof GetFalAiSanaSprintRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux-lora/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxLoraRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux-lora/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxLoraRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxLoraRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxLoraRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxLoraRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxLoraData = {
  body: JuggernautFluxLoraInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux-lora";
};

export type PostRundiffusionFalJuggernautFluxLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxLoraResponse =
  PostRundiffusionFalJuggernautFluxLoraResponses[keyof PostRundiffusionFalJuggernautFluxLoraResponses];

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux-lora/requests/{request_id}";
};

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: JuggernautFluxLoraOutput;
};

export type GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxLoraRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux/base/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxBaseRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/base/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxBaseRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxBaseRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxBaseRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxBaseRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxBaseData = {
  body: JuggernautFluxBaseInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/base";
};

export type PostRundiffusionFalJuggernautFluxBaseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxBaseResponse =
  PostRundiffusionFalJuggernautFluxBaseResponses[keyof PostRundiffusionFalJuggernautFluxBaseResponses];

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/base/requests/{request_id}";
};

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: JuggernautFluxBaseOutput;
};

export type GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxBaseRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/juggernaut-flux/lightning/requests/{request_id}/status";
  };

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxLightningRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/juggernaut-flux/lightning/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalJuggernautFluxLightningRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxLightningRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxLightningRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxLightningRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxLightningData = {
  body: JuggernautFluxLightningInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/lightning";
};

export type PostRundiffusionFalJuggernautFluxLightningResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxLightningResponse =
  PostRundiffusionFalJuggernautFluxLightningResponses[keyof PostRundiffusionFalJuggernautFluxLightningResponses];

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/lightning/requests/{request_id}";
};

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: JuggernautFluxLightningOutput;
  };

export type GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxLightningRequestsByRequestIdResponses];

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/rundiffusion-fal/juggernaut-flux/pro/requests/{request_id}/status";
};

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdStatusResponse =
  GetRundiffusionFalJuggernautFluxProRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalJuggernautFluxProRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalJuggernautFluxProRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/pro/requests/{request_id}/cancel";
};

export type PutRundiffusionFalJuggernautFluxProRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalJuggernautFluxProRequestsByRequestIdCancelResponse =
  PutRundiffusionFalJuggernautFluxProRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalJuggernautFluxProRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalJuggernautFluxProData = {
  body: JuggernautFluxProInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/pro";
};

export type PostRundiffusionFalJuggernautFluxProResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalJuggernautFluxProResponse =
  PostRundiffusionFalJuggernautFluxProResponses[keyof PostRundiffusionFalJuggernautFluxProResponses];

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/juggernaut-flux/pro/requests/{request_id}";
};

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: JuggernautFluxProOutput;
};

export type GetRundiffusionFalJuggernautFluxProRequestsByRequestIdResponse =
  GetRundiffusionFalJuggernautFluxProRequestsByRequestIdResponses[keyof GetRundiffusionFalJuggernautFluxProRequestsByRequestIdResponses];

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/rundiffusion-fal/rundiffusion-photo-flux/requests/{request_id}/status";
  };

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdStatusResponse =
  GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdStatusResponses[keyof GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdStatusResponses];

export type PutRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/rundiffusion-fal/rundiffusion-photo-flux/requests/{request_id}/cancel";
  };

export type PutRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdCancelResponse =
  PutRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdCancelResponses[keyof PutRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdCancelResponses];

export type PostRundiffusionFalRundiffusionPhotoFluxData = {
  body: RundiffusionPhotoFluxInput;
  path?: never;
  query?: never;
  url: "/rundiffusion-fal/rundiffusion-photo-flux";
};

export type PostRundiffusionFalRundiffusionPhotoFluxResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostRundiffusionFalRundiffusionPhotoFluxResponse =
  PostRundiffusionFalRundiffusionPhotoFluxResponses[keyof PostRundiffusionFalRundiffusionPhotoFluxResponses];

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/rundiffusion-fal/rundiffusion-photo-flux/requests/{request_id}";
};

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: RundiffusionPhotoFluxOutput;
  };

export type GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdResponse =
  GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdResponses[keyof GetRundiffusionFalRundiffusionPhotoFluxRequestsByRequestIdResponses];

export type GetFalAiCogview4RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/cogview4/requests/{request_id}/status";
};

export type GetFalAiCogview4RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCogview4RequestsByRequestIdStatusResponse =
  GetFalAiCogview4RequestsByRequestIdStatusResponses[keyof GetFalAiCogview4RequestsByRequestIdStatusResponses];

export type PutFalAiCogview4RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cogview4/requests/{request_id}/cancel";
};

export type PutFalAiCogview4RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCogview4RequestsByRequestIdCancelResponse =
  PutFalAiCogview4RequestsByRequestIdCancelResponses[keyof PutFalAiCogview4RequestsByRequestIdCancelResponses];

export type PostFalAiCogview4Data = {
  body: Cogview4Input;
  path?: never;
  query?: never;
  url: "/fal-ai/cogview4";
};

export type PostFalAiCogview4Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCogview4Response =
  PostFalAiCogview4Responses[keyof PostFalAiCogview4Responses];

export type GetFalAiCogview4RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/cogview4/requests/{request_id}";
};

export type GetFalAiCogview4RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Cogview4Output;
};

export type GetFalAiCogview4RequestsByRequestIdResponse =
  GetFalAiCogview4RequestsByRequestIdResponses[keyof GetFalAiCogview4RequestsByRequestIdResponses];

export type GetFalAiIdeogramV2aRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2a/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2aRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2aRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2aRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2aRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2aRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2aRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2aRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2aRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2aRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2aData = {
  body: IdeogramV2aInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2a";
};

export type PostFalAiIdeogramV2aResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2aResponse =
  PostFalAiIdeogramV2aResponses[keyof PostFalAiIdeogramV2aResponses];

export type GetFalAiIdeogramV2aRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/requests/{request_id}";
};

export type GetFalAiIdeogramV2aRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2aOutput;
};

export type GetFalAiIdeogramV2aRequestsByRequestIdResponse =
  GetFalAiIdeogramV2aRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2aRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2a/turbo/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2aTurboRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2aTurboRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2aTurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2aTurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2aTurboRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2aTurboRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2aTurboRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2aTurboData = {
  body: IdeogramV2aTurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo";
};

export type PostFalAiIdeogramV2aTurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2aTurboResponse =
  PostFalAiIdeogramV2aTurboResponses[keyof PostFalAiIdeogramV2aTurboResponses];

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2a/turbo/requests/{request_id}";
};

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2aTurboOutput;
};

export type GetFalAiIdeogramV2aTurboRequestsByRequestIdResponse =
  GetFalAiIdeogramV2aTurboRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2aTurboRequestsByRequestIdResponses];

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-control-lora-canny/requests/{request_id}/status";
};

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdStatusResponse =
  GetFalAiFluxControlLoraCannyRequestsByRequestIdStatusResponses[keyof GetFalAiFluxControlLoraCannyRequestsByRequestIdStatusResponses];

export type PutFalAiFluxControlLoraCannyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-canny/requests/{request_id}/cancel";
};

export type PutFalAiFluxControlLoraCannyRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxControlLoraCannyRequestsByRequestIdCancelResponse =
  PutFalAiFluxControlLoraCannyRequestsByRequestIdCancelResponses[keyof PutFalAiFluxControlLoraCannyRequestsByRequestIdCancelResponses];

export type PostFalAiFluxControlLoraCannyData = {
  body: FluxControlLoraCannyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-control-lora-canny";
};

export type PostFalAiFluxControlLoraCannyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxControlLoraCannyResponse =
  PostFalAiFluxControlLoraCannyResponses[keyof PostFalAiFluxControlLoraCannyResponses];

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-canny/requests/{request_id}";
};

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxControlLoraCannyOutput;
};

export type GetFalAiFluxControlLoraCannyRequestsByRequestIdResponse =
  GetFalAiFluxControlLoraCannyRequestsByRequestIdResponses[keyof GetFalAiFluxControlLoraCannyRequestsByRequestIdResponses];

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-control-lora-depth/requests/{request_id}/status";
};

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdStatusResponse =
  GetFalAiFluxControlLoraDepthRequestsByRequestIdStatusResponses[keyof GetFalAiFluxControlLoraDepthRequestsByRequestIdStatusResponses];

export type PutFalAiFluxControlLoraDepthRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-depth/requests/{request_id}/cancel";
};

export type PutFalAiFluxControlLoraDepthRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxControlLoraDepthRequestsByRequestIdCancelResponse =
  PutFalAiFluxControlLoraDepthRequestsByRequestIdCancelResponses[keyof PutFalAiFluxControlLoraDepthRequestsByRequestIdCancelResponses];

export type PostFalAiFluxControlLoraDepthData = {
  body: FluxControlLoraDepthInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-control-lora-depth";
};

export type PostFalAiFluxControlLoraDepthResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxControlLoraDepthResponse =
  PostFalAiFluxControlLoraDepthResponses[keyof PostFalAiFluxControlLoraDepthResponses];

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-control-lora-depth/requests/{request_id}";
};

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxControlLoraDepthOutput;
};

export type GetFalAiFluxControlLoraDepthRequestsByRequestIdResponse =
  GetFalAiFluxControlLoraDepthRequestsByRequestIdResponses[keyof GetFalAiFluxControlLoraDepthRequestsByRequestIdResponses];

export type GetFalAiImagen3FastRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imagen3/fast/requests/{request_id}/status";
};

export type GetFalAiImagen3FastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagen3FastRequestsByRequestIdStatusResponse =
  GetFalAiImagen3FastRequestsByRequestIdStatusResponses[keyof GetFalAiImagen3FastRequestsByRequestIdStatusResponses];

export type PutFalAiImagen3FastRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen3/fast/requests/{request_id}/cancel";
};

export type PutFalAiImagen3FastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagen3FastRequestsByRequestIdCancelResponse =
  PutFalAiImagen3FastRequestsByRequestIdCancelResponses[keyof PutFalAiImagen3FastRequestsByRequestIdCancelResponses];

export type PostFalAiImagen3FastData = {
  body: Imagen3FastInput;
  path?: never;
  query?: never;
  url: "/fal-ai/imagen3/fast";
};

export type PostFalAiImagen3FastResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagen3FastResponse =
  PostFalAiImagen3FastResponses[keyof PostFalAiImagen3FastResponses];

export type GetFalAiImagen3FastRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen3/fast/requests/{request_id}";
};

export type GetFalAiImagen3FastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Imagen3FastOutput;
};

export type GetFalAiImagen3FastRequestsByRequestIdResponse =
  GetFalAiImagen3FastRequestsByRequestIdResponses[keyof GetFalAiImagen3FastRequestsByRequestIdResponses];

export type GetFalAiImagen3RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/imagen3/requests/{request_id}/status";
};

export type GetFalAiImagen3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiImagen3RequestsByRequestIdStatusResponse =
  GetFalAiImagen3RequestsByRequestIdStatusResponses[keyof GetFalAiImagen3RequestsByRequestIdStatusResponses];

export type PutFalAiImagen3RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen3/requests/{request_id}/cancel";
};

export type PutFalAiImagen3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiImagen3RequestsByRequestIdCancelResponse =
  PutFalAiImagen3RequestsByRequestIdCancelResponses[keyof PutFalAiImagen3RequestsByRequestIdCancelResponses];

export type PostFalAiImagen3Data = {
  body: Imagen3Input;
  path?: never;
  query?: never;
  url: "/fal-ai/imagen3";
};

export type PostFalAiImagen3Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiImagen3Response =
  PostFalAiImagen3Responses[keyof PostFalAiImagen3Responses];

export type GetFalAiImagen3RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/imagen3/requests/{request_id}";
};

export type GetFalAiImagen3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Imagen3Output;
};

export type GetFalAiImagen3RequestsByRequestIdResponse =
  GetFalAiImagen3RequestsByRequestIdResponses[keyof GetFalAiImagen3RequestsByRequestIdResponses];

export type GetFalAiLuminaImageV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lumina-image/v2/requests/{request_id}/status";
};

export type GetFalAiLuminaImageV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLuminaImageV2RequestsByRequestIdStatusResponse =
  GetFalAiLuminaImageV2RequestsByRequestIdStatusResponses[keyof GetFalAiLuminaImageV2RequestsByRequestIdStatusResponses];

export type PutFalAiLuminaImageV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lumina-image/v2/requests/{request_id}/cancel";
};

export type PutFalAiLuminaImageV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLuminaImageV2RequestsByRequestIdCancelResponse =
  PutFalAiLuminaImageV2RequestsByRequestIdCancelResponses[keyof PutFalAiLuminaImageV2RequestsByRequestIdCancelResponses];

export type PostFalAiLuminaImageV2Data = {
  body: LuminaImageV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/lumina-image/v2";
};

export type PostFalAiLuminaImageV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLuminaImageV2Response =
  PostFalAiLuminaImageV2Responses[keyof PostFalAiLuminaImageV2Responses];

export type GetFalAiLuminaImageV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lumina-image/v2/requests/{request_id}";
};

export type GetFalAiLuminaImageV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LuminaImageV2Output;
};

export type GetFalAiLuminaImageV2RequestsByRequestIdResponse =
  GetFalAiLuminaImageV2RequestsByRequestIdResponses[keyof GetFalAiLuminaImageV2RequestsByRequestIdResponses];

export type GetFalAiJanusRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/janus/requests/{request_id}/status";
};

export type GetFalAiJanusRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiJanusRequestsByRequestIdStatusResponse =
  GetFalAiJanusRequestsByRequestIdStatusResponses[keyof GetFalAiJanusRequestsByRequestIdStatusResponses];

export type PutFalAiJanusRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/janus/requests/{request_id}/cancel";
};

export type PutFalAiJanusRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiJanusRequestsByRequestIdCancelResponse =
  PutFalAiJanusRequestsByRequestIdCancelResponses[keyof PutFalAiJanusRequestsByRequestIdCancelResponses];

export type PostFalAiJanusData = {
  body: JanusInput;
  path?: never;
  query?: never;
  url: "/fal-ai/janus";
};

export type PostFalAiJanusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiJanusResponse =
  PostFalAiJanusResponses[keyof PostFalAiJanusResponses];

export type GetFalAiJanusRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/janus/requests/{request_id}";
};

export type GetFalAiJanusRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: JanusOutput;
};

export type GetFalAiJanusRequestsByRequestIdResponse =
  GetFalAiJanusRequestsByRequestIdResponses[keyof GetFalAiJanusRequestsByRequestIdResponses];

export type GetFalAiFluxProV11RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1.1/requests/{request_id}/status";
};

export type GetFalAiFluxProV11RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxProV11RequestsByRequestIdStatusResponse =
  GetFalAiFluxProV11RequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV11RequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV11RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV11RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxProV11RequestsByRequestIdCancelResponse =
  PutFalAiFluxProV11RequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV11RequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV11Data = {
  body: FluxProV11Input;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1.1";
};

export type PostFalAiFluxProV11Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV11Response =
  PostFalAiFluxProV11Responses[keyof PostFalAiFluxProV11Responses];

export type GetFalAiFluxProV11RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1/requests/{request_id}";
};

export type GetFalAiFluxProV11RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV11Output;
};

export type GetFalAiFluxProV11RequestsByRequestIdResponse =
  GetFalAiFluxProV11RequestsByRequestIdResponses[keyof GetFalAiFluxProV11RequestsByRequestIdResponses];

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-pro/v1.1-ultra-finetuned/requests/{request_id}/status";
};

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdStatusResponse =
  GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdStatusResponses[keyof GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdStatusResponses];

export type PutFalAiFluxProV11UltraFinetunedRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra-finetuned/requests/{request_id}/cancel";
};

export type PutFalAiFluxProV11UltraFinetunedRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFluxProV11UltraFinetunedRequestsByRequestIdCancelResponse =
  PutFalAiFluxProV11UltraFinetunedRequestsByRequestIdCancelResponses[keyof PutFalAiFluxProV11UltraFinetunedRequestsByRequestIdCancelResponses];

export type PostFalAiFluxProV11UltraFinetunedData = {
  body: FluxProV11UltraFinetunedInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra-finetuned";
};

export type PostFalAiFluxProV11UltraFinetunedResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxProV11UltraFinetunedResponse =
  PostFalAiFluxProV11UltraFinetunedResponses[keyof PostFalAiFluxProV11UltraFinetunedResponses];

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-pro/v1.1-ultra-finetuned/requests/{request_id}";
};

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxProV11UltraFinetunedOutput;
};

export type GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdResponse =
  GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdResponses[keyof GetFalAiFluxProV11UltraFinetunedRequestsByRequestIdResponses];

export type GetFalAiSwittiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/switti/requests/{request_id}/status";
};

export type GetFalAiSwittiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSwittiRequestsByRequestIdStatusResponse =
  GetFalAiSwittiRequestsByRequestIdStatusResponses[keyof GetFalAiSwittiRequestsByRequestIdStatusResponses];

export type PutFalAiSwittiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/switti/requests/{request_id}/cancel";
};

export type PutFalAiSwittiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSwittiRequestsByRequestIdCancelResponse =
  PutFalAiSwittiRequestsByRequestIdCancelResponses[keyof PutFalAiSwittiRequestsByRequestIdCancelResponses];

export type PostFalAiSwittiData = {
  body: SwittiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/switti";
};

export type PostFalAiSwittiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSwittiResponse =
  PostFalAiSwittiResponses[keyof PostFalAiSwittiResponses];

export type GetFalAiSwittiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/switti/requests/{request_id}";
};

export type GetFalAiSwittiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SwittiOutput;
};

export type GetFalAiSwittiRequestsByRequestIdResponse =
  GetFalAiSwittiRequestsByRequestIdResponses[keyof GetFalAiSwittiRequestsByRequestIdResponses];

export type GetFalAiSwitti512RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/switti/512/requests/{request_id}/status";
};

export type GetFalAiSwitti512RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSwitti512RequestsByRequestIdStatusResponse =
  GetFalAiSwitti512RequestsByRequestIdStatusResponses[keyof GetFalAiSwitti512RequestsByRequestIdStatusResponses];

export type PutFalAiSwitti512RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/switti/512/requests/{request_id}/cancel";
};

export type PutFalAiSwitti512RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSwitti512RequestsByRequestIdCancelResponse =
  PutFalAiSwitti512RequestsByRequestIdCancelResponses[keyof PutFalAiSwitti512RequestsByRequestIdCancelResponses];

export type PostFalAiSwitti512Data = {
  body: Switti512Input;
  path?: never;
  query?: never;
  url: "/fal-ai/switti/512";
};

export type PostFalAiSwitti512Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSwitti512Response =
  PostFalAiSwitti512Responses[keyof PostFalAiSwitti512Responses];

export type GetFalAiSwitti512RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/switti/512/requests/{request_id}";
};

export type GetFalAiSwitti512RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Switti512Output;
};

export type GetFalAiSwitti512RequestsByRequestIdResponse =
  GetFalAiSwitti512RequestsByRequestIdResponses[keyof GetFalAiSwitti512RequestsByRequestIdResponses];

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/text-to-image/base/requests/{request_id}/status";
};

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdStatusResponse =
  GetFalAiBriaTextToImageBaseRequestsByRequestIdStatusResponses[keyof GetFalAiBriaTextToImageBaseRequestsByRequestIdStatusResponses];

export type PutFalAiBriaTextToImageBaseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/base/requests/{request_id}/cancel";
};

export type PutFalAiBriaTextToImageBaseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaTextToImageBaseRequestsByRequestIdCancelResponse =
  PutFalAiBriaTextToImageBaseRequestsByRequestIdCancelResponses[keyof PutFalAiBriaTextToImageBaseRequestsByRequestIdCancelResponses];

export type PostFalAiBriaTextToImageBaseData = {
  body: BriaTextToImageBaseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/text-to-image/base";
};

export type PostFalAiBriaTextToImageBaseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaTextToImageBaseResponse =
  PostFalAiBriaTextToImageBaseResponses[keyof PostFalAiBriaTextToImageBaseResponses];

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/base/requests/{request_id}";
};

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaTextToImageBaseOutput;
};

export type GetFalAiBriaTextToImageBaseRequestsByRequestIdResponse =
  GetFalAiBriaTextToImageBaseRequestsByRequestIdResponses[keyof GetFalAiBriaTextToImageBaseRequestsByRequestIdResponses];

export type GetFalAiBriaTextToImageFastRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/text-to-image/fast/requests/{request_id}/status";
};

export type GetFalAiBriaTextToImageFastRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaTextToImageFastRequestsByRequestIdStatusResponse =
  GetFalAiBriaTextToImageFastRequestsByRequestIdStatusResponses[keyof GetFalAiBriaTextToImageFastRequestsByRequestIdStatusResponses];

export type PutFalAiBriaTextToImageFastRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/fast/requests/{request_id}/cancel";
};

export type PutFalAiBriaTextToImageFastRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaTextToImageFastRequestsByRequestIdCancelResponse =
  PutFalAiBriaTextToImageFastRequestsByRequestIdCancelResponses[keyof PutFalAiBriaTextToImageFastRequestsByRequestIdCancelResponses];

export type PostFalAiBriaTextToImageFastData = {
  body: BriaTextToImageFastInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/text-to-image/fast";
};

export type PostFalAiBriaTextToImageFastResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaTextToImageFastResponse =
  PostFalAiBriaTextToImageFastResponses[keyof PostFalAiBriaTextToImageFastResponses];

export type GetFalAiBriaTextToImageFastRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/fast/requests/{request_id}";
};

export type GetFalAiBriaTextToImageFastRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaTextToImageFastOutput;
};

export type GetFalAiBriaTextToImageFastRequestsByRequestIdResponse =
  GetFalAiBriaTextToImageFastRequestsByRequestIdResponses[keyof GetFalAiBriaTextToImageFastRequestsByRequestIdResponses];

export type GetFalAiBriaTextToImageHdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/bria/text-to-image/hd/requests/{request_id}/status";
};

export type GetFalAiBriaTextToImageHdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiBriaTextToImageHdRequestsByRequestIdStatusResponse =
  GetFalAiBriaTextToImageHdRequestsByRequestIdStatusResponses[keyof GetFalAiBriaTextToImageHdRequestsByRequestIdStatusResponses];

export type PutFalAiBriaTextToImageHdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/hd/requests/{request_id}/cancel";
};

export type PutFalAiBriaTextToImageHdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiBriaTextToImageHdRequestsByRequestIdCancelResponse =
  PutFalAiBriaTextToImageHdRequestsByRequestIdCancelResponses[keyof PutFalAiBriaTextToImageHdRequestsByRequestIdCancelResponses];

export type PostFalAiBriaTextToImageHdData = {
  body: BriaTextToImageHdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/bria/text-to-image/hd";
};

export type PostFalAiBriaTextToImageHdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiBriaTextToImageHdResponse =
  PostFalAiBriaTextToImageHdResponses[keyof PostFalAiBriaTextToImageHdResponses];

export type GetFalAiBriaTextToImageHdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/bria/text-to-image/hd/requests/{request_id}";
};

export type GetFalAiBriaTextToImageHdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: BriaTextToImageHdOutput;
};

export type GetFalAiBriaTextToImageHdRequestsByRequestIdResponse =
  GetFalAiBriaTextToImageHdRequestsByRequestIdResponses[keyof GetFalAiBriaTextToImageHdRequestsByRequestIdResponses];

export type GetFalAiRecraft20bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/recraft-20b/requests/{request_id}/status";
};

export type GetFalAiRecraft20bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRecraft20bRequestsByRequestIdStatusResponse =
  GetFalAiRecraft20bRequestsByRequestIdStatusResponses[keyof GetFalAiRecraft20bRequestsByRequestIdStatusResponses];

export type PutFalAiRecraft20bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft-20b/requests/{request_id}/cancel";
};

export type PutFalAiRecraft20bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRecraft20bRequestsByRequestIdCancelResponse =
  PutFalAiRecraft20bRequestsByRequestIdCancelResponses[keyof PutFalAiRecraft20bRequestsByRequestIdCancelResponses];

export type PostFalAiRecraft20bData = {
  body: Recraft20bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/recraft-20b";
};

export type PostFalAiRecraft20bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRecraft20bResponse =
  PostFalAiRecraft20bResponses[keyof PostFalAiRecraft20bResponses];

export type GetFalAiRecraft20bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/recraft-20b/requests/{request_id}";
};

export type GetFalAiRecraft20bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Recraft20bOutput;
};

export type GetFalAiRecraft20bRequestsByRequestIdResponse =
  GetFalAiRecraft20bRequestsByRequestIdResponses[keyof GetFalAiRecraft20bRequestsByRequestIdResponses];

export type GetFalAiIdeogramV2TurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ideogram/v2/turbo/requests/{request_id}/status";
};

export type GetFalAiIdeogramV2TurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIdeogramV2TurboRequestsByRequestIdStatusResponse =
  GetFalAiIdeogramV2TurboRequestsByRequestIdStatusResponses[keyof GetFalAiIdeogramV2TurboRequestsByRequestIdStatusResponses];

export type PutFalAiIdeogramV2TurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/requests/{request_id}/cancel";
};

export type PutFalAiIdeogramV2TurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIdeogramV2TurboRequestsByRequestIdCancelResponse =
  PutFalAiIdeogramV2TurboRequestsByRequestIdCancelResponses[keyof PutFalAiIdeogramV2TurboRequestsByRequestIdCancelResponses];

export type PostFalAiIdeogramV2TurboData = {
  body: IdeogramV2TurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo";
};

export type PostFalAiIdeogramV2TurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIdeogramV2TurboResponse =
  PostFalAiIdeogramV2TurboResponses[keyof PostFalAiIdeogramV2TurboResponses];

export type GetFalAiIdeogramV2TurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ideogram/v2/turbo/requests/{request_id}";
};

export type GetFalAiIdeogramV2TurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IdeogramV2TurboOutput;
};

export type GetFalAiIdeogramV2TurboRequestsByRequestIdResponse =
  GetFalAiIdeogramV2TurboRequestsByRequestIdResponses[keyof GetFalAiIdeogramV2TurboRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonFlashRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/flash/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonFlashRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonFlashRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonFlashRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonFlashRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonFlashRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonFlashRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonFlashRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonFlashRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonFlashRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonFlashData = {
  body: LumaPhotonFlashInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon/flash";
};

export type PostFalAiLumaPhotonFlashResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonFlashResponse =
  PostFalAiLumaPhotonFlashResponses[keyof PostFalAiLumaPhotonFlashResponses];

export type GetFalAiLumaPhotonFlashRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/flash/requests/{request_id}";
};

export type GetFalAiLumaPhotonFlashRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonFlashOutput;
};

export type GetFalAiLumaPhotonFlashRequestsByRequestIdResponse =
  GetFalAiLumaPhotonFlashRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonFlashRequestsByRequestIdResponses];

export type GetFalAiAuraFlowRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/aura-flow/requests/{request_id}/status";
};

export type GetFalAiAuraFlowRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAuraFlowRequestsByRequestIdStatusResponse =
  GetFalAiAuraFlowRequestsByRequestIdStatusResponses[keyof GetFalAiAuraFlowRequestsByRequestIdStatusResponses];

export type PutFalAiAuraFlowRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/aura-flow/requests/{request_id}/cancel";
};

export type PutFalAiAuraFlowRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAuraFlowRequestsByRequestIdCancelResponse =
  PutFalAiAuraFlowRequestsByRequestIdCancelResponses[keyof PutFalAiAuraFlowRequestsByRequestIdCancelResponses];

export type PostFalAiAuraFlowData = {
  body: AuraFlowInput;
  path?: never;
  query?: never;
  url: "/fal-ai/aura-flow";
};

export type PostFalAiAuraFlowResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAuraFlowResponse =
  PostFalAiAuraFlowResponses[keyof PostFalAiAuraFlowResponses];

export type GetFalAiAuraFlowRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/aura-flow/requests/{request_id}";
};

export type GetFalAiAuraFlowRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AuraFlowOutput;
};

export type GetFalAiAuraFlowRequestsByRequestIdResponse =
  GetFalAiAuraFlowRequestsByRequestIdResponses[keyof GetFalAiAuraFlowRequestsByRequestIdResponses];

export type GetFalAiOmnigenV1RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/omnigen-v1/requests/{request_id}/status";
};

export type GetFalAiOmnigenV1RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiOmnigenV1RequestsByRequestIdStatusResponse =
  GetFalAiOmnigenV1RequestsByRequestIdStatusResponses[keyof GetFalAiOmnigenV1RequestsByRequestIdStatusResponses];

export type PutFalAiOmnigenV1RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omnigen-v1/requests/{request_id}/cancel";
};

export type PutFalAiOmnigenV1RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiOmnigenV1RequestsByRequestIdCancelResponse =
  PutFalAiOmnigenV1RequestsByRequestIdCancelResponses[keyof PutFalAiOmnigenV1RequestsByRequestIdCancelResponses];

export type PostFalAiOmnigenV1Data = {
  body: OmnigenV1Input;
  path?: never;
  query?: never;
  url: "/fal-ai/omnigen-v1";
};

export type PostFalAiOmnigenV1Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiOmnigenV1Response =
  PostFalAiOmnigenV1Responses[keyof PostFalAiOmnigenV1Responses];

export type GetFalAiOmnigenV1RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/omnigen-v1/requests/{request_id}";
};

export type GetFalAiOmnigenV1RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: OmnigenV1Output;
};

export type GetFalAiOmnigenV1RequestsByRequestIdResponse =
  GetFalAiOmnigenV1RequestsByRequestIdResponses[keyof GetFalAiOmnigenV1RequestsByRequestIdResponses];

export type GetFalAiFluxSchnellRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux/schnell/requests/{request_id}/status";
};

export type GetFalAiFluxSchnellRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxSchnellRequestsByRequestIdStatusResponse =
  GetFalAiFluxSchnellRequestsByRequestIdStatusResponses[keyof GetFalAiFluxSchnellRequestsByRequestIdStatusResponses];

export type PutFalAiFluxSchnellRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/schnell/requests/{request_id}/cancel";
};

export type PutFalAiFluxSchnellRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxSchnellRequestsByRequestIdCancelResponse =
  PutFalAiFluxSchnellRequestsByRequestIdCancelResponses[keyof PutFalAiFluxSchnellRequestsByRequestIdCancelResponses];

export type PostFalAiFluxSchnellData = {
  body: FluxSchnellInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux/schnell";
};

export type PostFalAiFluxSchnellResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxSchnellResponse =
  PostFalAiFluxSchnellResponses[keyof PostFalAiFluxSchnellResponses];

export type GetFalAiFluxSchnellRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux/schnell/requests/{request_id}";
};

export type GetFalAiFluxSchnellRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxSchnellOutput;
};

export type GetFalAiFluxSchnellRequestsByRequestIdResponse =
  GetFalAiFluxSchnellRequestsByRequestIdResponses[keyof GetFalAiFluxSchnellRequestsByRequestIdResponses];

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-diffusion-v35-medium/requests/{request_id}/status";
};

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdStatusResponse =
  GetFalAiStableDiffusionV35MediumRequestsByRequestIdStatusResponses[keyof GetFalAiStableDiffusionV35MediumRequestsByRequestIdStatusResponses];

export type PutFalAiStableDiffusionV35MediumRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-medium/requests/{request_id}/cancel";
};

export type PutFalAiStableDiffusionV35MediumRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableDiffusionV35MediumRequestsByRequestIdCancelResponse =
  PutFalAiStableDiffusionV35MediumRequestsByRequestIdCancelResponses[keyof PutFalAiStableDiffusionV35MediumRequestsByRequestIdCancelResponses];

export type PostFalAiStableDiffusionV35MediumData = {
  body: StableDiffusionV35MediumInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-medium";
};

export type PostFalAiStableDiffusionV35MediumResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableDiffusionV35MediumResponse =
  PostFalAiStableDiffusionV35MediumResponses[keyof PostFalAiStableDiffusionV35MediumResponses];

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v35-medium/requests/{request_id}";
};

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableDiffusionV35MediumOutput;
};

export type GetFalAiStableDiffusionV35MediumRequestsByRequestIdResponse =
  GetFalAiStableDiffusionV35MediumRequestsByRequestIdResponses[keyof GetFalAiStableDiffusionV35MediumRequestsByRequestIdResponses];

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-lora/inpainting/requests/{request_id}/status";
};

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdStatusResponse =
  GetFalAiFluxLoraInpaintingRequestsByRequestIdStatusResponses[keyof GetFalAiFluxLoraInpaintingRequestsByRequestIdStatusResponses];

export type PutFalAiFluxLoraInpaintingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/inpainting/requests/{request_id}/cancel";
};

export type PutFalAiFluxLoraInpaintingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxLoraInpaintingRequestsByRequestIdCancelResponse =
  PutFalAiFluxLoraInpaintingRequestsByRequestIdCancelResponses[keyof PutFalAiFluxLoraInpaintingRequestsByRequestIdCancelResponses];

export type PostFalAiFluxLoraInpaintingData = {
  body: FluxLoraInpaintingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-lora/inpainting";
};

export type PostFalAiFluxLoraInpaintingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxLoraInpaintingResponse =
  PostFalAiFluxLoraInpaintingResponses[keyof PostFalAiFluxLoraInpaintingResponses];

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-lora/inpainting/requests/{request_id}";
};

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxLoraInpaintingOutput;
};

export type GetFalAiFluxLoraInpaintingRequestsByRequestIdResponse =
  GetFalAiFluxLoraInpaintingRequestsByRequestIdResponses[keyof GetFalAiFluxLoraInpaintingRequestsByRequestIdResponses];

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-diffusion-v3-medium/requests/{request_id}/status";
};

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdStatusResponse =
  GetFalAiStableDiffusionV3MediumRequestsByRequestIdStatusResponses[keyof GetFalAiStableDiffusionV3MediumRequestsByRequestIdStatusResponses];

export type PutFalAiStableDiffusionV3MediumRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v3-medium/requests/{request_id}/cancel";
};

export type PutFalAiStableDiffusionV3MediumRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableDiffusionV3MediumRequestsByRequestIdCancelResponse =
  PutFalAiStableDiffusionV3MediumRequestsByRequestIdCancelResponses[keyof PutFalAiStableDiffusionV3MediumRequestsByRequestIdCancelResponses];

export type PostFalAiStableDiffusionV3MediumData = {
  body: StableDiffusionV3MediumInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-diffusion-v3-medium";
};

export type PostFalAiStableDiffusionV3MediumResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableDiffusionV3MediumResponse =
  PostFalAiStableDiffusionV3MediumResponses[keyof PostFalAiStableDiffusionV3MediumResponses];

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v3-medium/requests/{request_id}";
};

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableDiffusionV3MediumOutput;
};

export type GetFalAiStableDiffusionV3MediumRequestsByRequestIdResponse =
  GetFalAiStableDiffusionV3MediumRequestsByRequestIdResponses[keyof GetFalAiStableDiffusionV3MediumRequestsByRequestIdResponses];

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fooocus/upscale-or-vary/requests/{request_id}/status";
};

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdStatusResponse =
  GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdStatusResponses[keyof GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdStatusResponses];

export type PutFalAiFooocusUpscaleOrVaryRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/upscale-or-vary/requests/{request_id}/cancel";
};

export type PutFalAiFooocusUpscaleOrVaryRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFooocusUpscaleOrVaryRequestsByRequestIdCancelResponse =
  PutFalAiFooocusUpscaleOrVaryRequestsByRequestIdCancelResponses[keyof PutFalAiFooocusUpscaleOrVaryRequestsByRequestIdCancelResponses];

export type PostFalAiFooocusUpscaleOrVaryData = {
  body: FooocusUpscaleOrVaryInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fooocus/upscale-or-vary";
};

export type PostFalAiFooocusUpscaleOrVaryResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFooocusUpscaleOrVaryResponse =
  PostFalAiFooocusUpscaleOrVaryResponses[keyof PostFalAiFooocusUpscaleOrVaryResponses];

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/upscale-or-vary/requests/{request_id}";
};

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FooocusUpscaleOrVaryOutput;
};

export type GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdResponse =
  GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdResponses[keyof GetFalAiFooocusUpscaleOrVaryRequestsByRequestIdResponses];

export type GetFalAiSanaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sana/requests/{request_id}/status";
};

export type GetFalAiSanaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSanaRequestsByRequestIdStatusResponse =
  GetFalAiSanaRequestsByRequestIdStatusResponses[keyof GetFalAiSanaRequestsByRequestIdStatusResponses];

export type PutFalAiSanaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/requests/{request_id}/cancel";
};

export type PutFalAiSanaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSanaRequestsByRequestIdCancelResponse =
  PutFalAiSanaRequestsByRequestIdCancelResponses[keyof PutFalAiSanaRequestsByRequestIdCancelResponses];

export type PostFalAiSanaData = {
  body: SanaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sana";
};

export type PostFalAiSanaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSanaResponse =
  PostFalAiSanaResponses[keyof PostFalAiSanaResponses];

export type GetFalAiSanaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sana/requests/{request_id}";
};

export type GetFalAiSanaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SanaOutput;
};

export type GetFalAiSanaRequestsByRequestIdResponse =
  GetFalAiSanaRequestsByRequestIdResponses[keyof GetFalAiSanaRequestsByRequestIdResponses];

export type GetFalAiPixartSigmaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/pixart-sigma/requests/{request_id}/status";
};

export type GetFalAiPixartSigmaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPixartSigmaRequestsByRequestIdStatusResponse =
  GetFalAiPixartSigmaRequestsByRequestIdStatusResponses[keyof GetFalAiPixartSigmaRequestsByRequestIdStatusResponses];

export type PutFalAiPixartSigmaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pixart-sigma/requests/{request_id}/cancel";
};

export type PutFalAiPixartSigmaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPixartSigmaRequestsByRequestIdCancelResponse =
  PutFalAiPixartSigmaRequestsByRequestIdCancelResponses[keyof PutFalAiPixartSigmaRequestsByRequestIdCancelResponses];

export type PostFalAiPixartSigmaData = {
  body: PixartSigmaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/pixart-sigma";
};

export type PostFalAiPixartSigmaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPixartSigmaResponse =
  PostFalAiPixartSigmaResponses[keyof PostFalAiPixartSigmaResponses];

export type GetFalAiPixartSigmaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/pixart-sigma/requests/{request_id}";
};

export type GetFalAiPixartSigmaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PixartSigmaOutput;
};

export type GetFalAiPixartSigmaRequestsByRequestIdResponse =
  GetFalAiPixartSigmaRequestsByRequestIdResponses[keyof GetFalAiPixartSigmaRequestsByRequestIdResponses];

export type GetFalAiFluxSubjectRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/flux-subject/requests/{request_id}/status";
};

export type GetFalAiFluxSubjectRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFluxSubjectRequestsByRequestIdStatusResponse =
  GetFalAiFluxSubjectRequestsByRequestIdStatusResponses[keyof GetFalAiFluxSubjectRequestsByRequestIdStatusResponses];

export type PutFalAiFluxSubjectRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-subject/requests/{request_id}/cancel";
};

export type PutFalAiFluxSubjectRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFluxSubjectRequestsByRequestIdCancelResponse =
  PutFalAiFluxSubjectRequestsByRequestIdCancelResponses[keyof PutFalAiFluxSubjectRequestsByRequestIdCancelResponses];

export type PostFalAiFluxSubjectData = {
  body: FluxSubjectInput;
  path?: never;
  query?: never;
  url: "/fal-ai/flux-subject";
};

export type PostFalAiFluxSubjectResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFluxSubjectResponse =
  PostFalAiFluxSubjectResponses[keyof PostFalAiFluxSubjectResponses];

export type GetFalAiFluxSubjectRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/flux-subject/requests/{request_id}";
};

export type GetFalAiFluxSubjectRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FluxSubjectOutput;
};

export type GetFalAiFluxSubjectRequestsByRequestIdResponse =
  GetFalAiFluxSubjectRequestsByRequestIdResponses[keyof GetFalAiFluxSubjectRequestsByRequestIdResponses];

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sdxl-controlnet-union/requests/{request_id}/status";
};

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdStatusResponse =
  GetFalAiSdxlControlnetUnionRequestsByRequestIdStatusResponses[keyof GetFalAiSdxlControlnetUnionRequestsByRequestIdStatusResponses];

export type PutFalAiSdxlControlnetUnionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/requests/{request_id}/cancel";
};

export type PutFalAiSdxlControlnetUnionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSdxlControlnetUnionRequestsByRequestIdCancelResponse =
  PutFalAiSdxlControlnetUnionRequestsByRequestIdCancelResponses[keyof PutFalAiSdxlControlnetUnionRequestsByRequestIdCancelResponses];

export type PostFalAiSdxlControlnetUnionData = {
  body: SdxlControlnetUnionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union";
};

export type PostFalAiSdxlControlnetUnionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSdxlControlnetUnionResponse =
  PostFalAiSdxlControlnetUnionResponses[keyof PostFalAiSdxlControlnetUnionResponses];

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sdxl-controlnet-union/requests/{request_id}";
};

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SdxlControlnetUnionOutput;
};

export type GetFalAiSdxlControlnetUnionRequestsByRequestIdResponse =
  GetFalAiSdxlControlnetUnionRequestsByRequestIdResponses[keyof GetFalAiSdxlControlnetUnionRequestsByRequestIdResponses];

export type GetFalAiKolorsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kolors/requests/{request_id}/status";
};

export type GetFalAiKolorsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKolorsRequestsByRequestIdStatusResponse =
  GetFalAiKolorsRequestsByRequestIdStatusResponses[keyof GetFalAiKolorsRequestsByRequestIdStatusResponses];

export type PutFalAiKolorsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kolors/requests/{request_id}/cancel";
};

export type PutFalAiKolorsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKolorsRequestsByRequestIdCancelResponse =
  PutFalAiKolorsRequestsByRequestIdCancelResponses[keyof PutFalAiKolorsRequestsByRequestIdCancelResponses];

export type PostFalAiKolorsData = {
  body: KolorsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kolors";
};

export type PostFalAiKolorsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKolorsResponse =
  PostFalAiKolorsResponses[keyof PostFalAiKolorsResponses];

export type GetFalAiKolorsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kolors/requests/{request_id}";
};

export type GetFalAiKolorsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KolorsOutput;
};

export type GetFalAiKolorsRequestsByRequestIdResponse =
  GetFalAiKolorsRequestsByRequestIdResponses[keyof GetFalAiKolorsRequestsByRequestIdResponses];

export type GetFalAiStableCascadeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-cascade/requests/{request_id}/status";
};

export type GetFalAiStableCascadeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStableCascadeRequestsByRequestIdStatusResponse =
  GetFalAiStableCascadeRequestsByRequestIdStatusResponses[keyof GetFalAiStableCascadeRequestsByRequestIdStatusResponses];

export type PutFalAiStableCascadeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-cascade/requests/{request_id}/cancel";
};

export type PutFalAiStableCascadeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStableCascadeRequestsByRequestIdCancelResponse =
  PutFalAiStableCascadeRequestsByRequestIdCancelResponses[keyof PutFalAiStableCascadeRequestsByRequestIdCancelResponses];

export type PostFalAiStableCascadeData = {
  body: StableCascadeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-cascade";
};

export type PostFalAiStableCascadeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableCascadeResponse =
  PostFalAiStableCascadeResponses[keyof PostFalAiStableCascadeResponses];

export type GetFalAiStableCascadeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-cascade/requests/{request_id}";
};

export type GetFalAiStableCascadeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableCascadeOutput;
};

export type GetFalAiStableCascadeRequestsByRequestIdResponse =
  GetFalAiStableCascadeRequestsByRequestIdResponses[keyof GetFalAiStableCascadeRequestsByRequestIdResponses];

export type GetFalAiFastSdxlRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-sdxl/requests/{request_id}/status";
};

export type GetFalAiFastSdxlRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastSdxlRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/requests/{request_id}/cancel";
};

export type PutFalAiFastSdxlRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastSdxlRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlData = {
  body: FastSdxlInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl";
};

export type PostFalAiFastSdxlResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlResponse =
  PostFalAiFastSdxlResponses[keyof PostFalAiFastSdxlResponses];

export type GetFalAiFastSdxlRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl/requests/{request_id}";
};

export type GetFalAiFastSdxlRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastSdxlOutput;
};

export type GetFalAiFastSdxlRequestsByRequestIdResponse =
  GetFalAiFastSdxlRequestsByRequestIdResponses[keyof GetFalAiFastSdxlRequestsByRequestIdResponses];

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-cascade/sote-diffusion/requests/{request_id}/status";
};

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiStableCascadeSoteDiffusionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-cascade/sote-diffusion/requests/{request_id}/cancel";
};

export type PutFalAiStableCascadeSoteDiffusionRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableCascadeSoteDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiStableCascadeSoteDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiStableCascadeSoteDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiStableCascadeSoteDiffusionData = {
  body: StableCascadeSoteDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-cascade/sote-diffusion";
};

export type PostFalAiStableCascadeSoteDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableCascadeSoteDiffusionResponse =
  PostFalAiStableCascadeSoteDiffusionResponses[keyof PostFalAiStableCascadeSoteDiffusionResponses];

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-cascade/sote-diffusion/requests/{request_id}";
};

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableCascadeSoteDiffusionOutput;
};

export type GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdResponse =
  GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdResponses[keyof GetFalAiStableCascadeSoteDiffusionRequestsByRequestIdResponses];

export type GetFalAiLumaPhotonRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/luma-photon/requests/{request_id}/status";
};

export type GetFalAiLumaPhotonRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLumaPhotonRequestsByRequestIdStatusResponse =
  GetFalAiLumaPhotonRequestsByRequestIdStatusResponses[keyof GetFalAiLumaPhotonRequestsByRequestIdStatusResponses];

export type PutFalAiLumaPhotonRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/requests/{request_id}/cancel";
};

export type PutFalAiLumaPhotonRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLumaPhotonRequestsByRequestIdCancelResponse =
  PutFalAiLumaPhotonRequestsByRequestIdCancelResponses[keyof PutFalAiLumaPhotonRequestsByRequestIdCancelResponses];

export type PostFalAiLumaPhotonData = {
  body: LumaPhotonInput;
  path?: never;
  query?: never;
  url: "/fal-ai/luma-photon";
};

export type PostFalAiLumaPhotonResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLumaPhotonResponse =
  PostFalAiLumaPhotonResponses[keyof PostFalAiLumaPhotonResponses];

export type GetFalAiLumaPhotonRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/luma-photon/requests/{request_id}";
};

export type GetFalAiLumaPhotonRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LumaPhotonOutput;
};

export type GetFalAiLumaPhotonRequestsByRequestIdResponse =
  GetFalAiLumaPhotonRequestsByRequestIdResponses[keyof GetFalAiLumaPhotonRequestsByRequestIdResponses];

export type GetFalAiLightningModelsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lightning-models/requests/{request_id}/status";
};

export type GetFalAiLightningModelsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLightningModelsRequestsByRequestIdStatusResponse =
  GetFalAiLightningModelsRequestsByRequestIdStatusResponses[keyof GetFalAiLightningModelsRequestsByRequestIdStatusResponses];

export type PutFalAiLightningModelsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lightning-models/requests/{request_id}/cancel";
};

export type PutFalAiLightningModelsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLightningModelsRequestsByRequestIdCancelResponse =
  PutFalAiLightningModelsRequestsByRequestIdCancelResponses[keyof PutFalAiLightningModelsRequestsByRequestIdCancelResponses];

export type PostFalAiLightningModelsData = {
  body: LightningModelsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lightning-models";
};

export type PostFalAiLightningModelsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLightningModelsResponse =
  PostFalAiLightningModelsResponses[keyof PostFalAiLightningModelsResponses];

export type GetFalAiLightningModelsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lightning-models/requests/{request_id}";
};

export type GetFalAiLightningModelsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LightningModelsOutput;
};

export type GetFalAiLightningModelsRequestsByRequestIdResponse =
  GetFalAiLightningModelsRequestsByRequestIdResponses[keyof GetFalAiLightningModelsRequestsByRequestIdResponses];

export type GetFalAiPlaygroundV25RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/playground-v25/requests/{request_id}/status";
};

export type GetFalAiPlaygroundV25RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiPlaygroundV25RequestsByRequestIdStatusResponse =
  GetFalAiPlaygroundV25RequestsByRequestIdStatusResponses[keyof GetFalAiPlaygroundV25RequestsByRequestIdStatusResponses];

export type PutFalAiPlaygroundV25RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/requests/{request_id}/cancel";
};

export type PutFalAiPlaygroundV25RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiPlaygroundV25RequestsByRequestIdCancelResponse =
  PutFalAiPlaygroundV25RequestsByRequestIdCancelResponses[keyof PutFalAiPlaygroundV25RequestsByRequestIdCancelResponses];

export type PostFalAiPlaygroundV25Data = {
  body: PlaygroundV25Input;
  path?: never;
  query?: never;
  url: "/fal-ai/playground-v25";
};

export type PostFalAiPlaygroundV25Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiPlaygroundV25Response =
  PostFalAiPlaygroundV25Responses[keyof PostFalAiPlaygroundV25Responses];

export type GetFalAiPlaygroundV25RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/playground-v25/requests/{request_id}";
};

export type GetFalAiPlaygroundV25RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: PlaygroundV25Output;
};

export type GetFalAiPlaygroundV25RequestsByRequestIdResponse =
  GetFalAiPlaygroundV25RequestsByRequestIdResponses[keyof GetFalAiPlaygroundV25RequestsByRequestIdResponses];

export type GetFalAiRealisticVisionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/realistic-vision/requests/{request_id}/status";
};

export type GetFalAiRealisticVisionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiRealisticVisionRequestsByRequestIdStatusResponse =
  GetFalAiRealisticVisionRequestsByRequestIdStatusResponses[keyof GetFalAiRealisticVisionRequestsByRequestIdStatusResponses];

export type PutFalAiRealisticVisionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/realistic-vision/requests/{request_id}/cancel";
};

export type PutFalAiRealisticVisionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiRealisticVisionRequestsByRequestIdCancelResponse =
  PutFalAiRealisticVisionRequestsByRequestIdCancelResponses[keyof PutFalAiRealisticVisionRequestsByRequestIdCancelResponses];

export type PostFalAiRealisticVisionData = {
  body: RealisticVisionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/realistic-vision";
};

export type PostFalAiRealisticVisionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiRealisticVisionResponse =
  PostFalAiRealisticVisionResponses[keyof PostFalAiRealisticVisionResponses];

export type GetFalAiRealisticVisionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/realistic-vision/requests/{request_id}";
};

export type GetFalAiRealisticVisionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: RealisticVisionOutput;
};

export type GetFalAiRealisticVisionRequestsByRequestIdResponse =
  GetFalAiRealisticVisionRequestsByRequestIdResponses[keyof GetFalAiRealisticVisionRequestsByRequestIdResponses];

export type GetFalAiDreamshaperRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dreamshaper/requests/{request_id}/status";
};

export type GetFalAiDreamshaperRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDreamshaperRequestsByRequestIdStatusResponse =
  GetFalAiDreamshaperRequestsByRequestIdStatusResponses[keyof GetFalAiDreamshaperRequestsByRequestIdStatusResponses];

export type PutFalAiDreamshaperRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamshaper/requests/{request_id}/cancel";
};

export type PutFalAiDreamshaperRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDreamshaperRequestsByRequestIdCancelResponse =
  PutFalAiDreamshaperRequestsByRequestIdCancelResponses[keyof PutFalAiDreamshaperRequestsByRequestIdCancelResponses];

export type PostFalAiDreamshaperData = {
  body: DreamshaperInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dreamshaper";
};

export type PostFalAiDreamshaperResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDreamshaperResponse =
  PostFalAiDreamshaperResponses[keyof PostFalAiDreamshaperResponses];

export type GetFalAiDreamshaperRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dreamshaper/requests/{request_id}";
};

export type GetFalAiDreamshaperRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DreamshaperOutput;
};

export type GetFalAiDreamshaperRequestsByRequestIdResponse =
  GetFalAiDreamshaperRequestsByRequestIdResponses[keyof GetFalAiDreamshaperRequestsByRequestIdResponses];

export type GetFalAiStableDiffusionV15RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-diffusion-v15/requests/{request_id}/status";
};

export type GetFalAiStableDiffusionV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStableDiffusionV15RequestsByRequestIdStatusResponse =
  GetFalAiStableDiffusionV15RequestsByRequestIdStatusResponses[keyof GetFalAiStableDiffusionV15RequestsByRequestIdStatusResponses];

export type PutFalAiStableDiffusionV15RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v15/requests/{request_id}/cancel";
};

export type PutFalAiStableDiffusionV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStableDiffusionV15RequestsByRequestIdCancelResponse =
  PutFalAiStableDiffusionV15RequestsByRequestIdCancelResponses[keyof PutFalAiStableDiffusionV15RequestsByRequestIdCancelResponses];

export type PostFalAiStableDiffusionV15Data = {
  body: StableDiffusionV15Input;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-diffusion-v15";
};

export type PostFalAiStableDiffusionV15Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableDiffusionV15Response =
  PostFalAiStableDiffusionV15Responses[keyof PostFalAiStableDiffusionV15Responses];

export type GetFalAiStableDiffusionV15RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-diffusion-v15/requests/{request_id}";
};

export type GetFalAiStableDiffusionV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableDiffusionV15Output;
};

export type GetFalAiStableDiffusionV15RequestsByRequestIdResponse =
  GetFalAiStableDiffusionV15RequestsByRequestIdResponses[keyof GetFalAiStableDiffusionV15RequestsByRequestIdResponses];

export type GetFalAiLayerDiffusionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/layer-diffusion/requests/{request_id}/status";
};

export type GetFalAiLayerDiffusionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLayerDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiLayerDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiLayerDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiLayerDiffusionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/layer-diffusion/requests/{request_id}/cancel";
};

export type PutFalAiLayerDiffusionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLayerDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiLayerDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiLayerDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiLayerDiffusionData = {
  body: LayerDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/layer-diffusion";
};

export type PostFalAiLayerDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLayerDiffusionResponse =
  PostFalAiLayerDiffusionResponses[keyof PostFalAiLayerDiffusionResponses];

export type GetFalAiLayerDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/layer-diffusion/requests/{request_id}";
};

export type GetFalAiLayerDiffusionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LayerDiffusionOutput;
};

export type GetFalAiLayerDiffusionRequestsByRequestIdResponse =
  GetFalAiLayerDiffusionRequestsByRequestIdResponses[keyof GetFalAiLayerDiffusionRequestsByRequestIdResponses];

export type GetFalAiFastLightningSdxlRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-lightning-sdxl/requests/{request_id}/status";
};

export type GetFalAiFastLightningSdxlRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastLightningSdxlRequestsByRequestIdStatusResponse =
  GetFalAiFastLightningSdxlRequestsByRequestIdStatusResponses[keyof GetFalAiFastLightningSdxlRequestsByRequestIdStatusResponses];

export type PutFalAiFastLightningSdxlRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/requests/{request_id}/cancel";
};

export type PutFalAiFastLightningSdxlRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastLightningSdxlRequestsByRequestIdCancelResponse =
  PutFalAiFastLightningSdxlRequestsByRequestIdCancelResponses[keyof PutFalAiFastLightningSdxlRequestsByRequestIdCancelResponses];

export type PostFalAiFastLightningSdxlData = {
  body: FastLightningSdxlInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl";
};

export type PostFalAiFastLightningSdxlResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLightningSdxlResponse =
  PostFalAiFastLightningSdxlResponses[keyof PostFalAiFastLightningSdxlResponses];

export type GetFalAiFastLightningSdxlRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lightning-sdxl/requests/{request_id}";
};

export type GetFalAiFastLightningSdxlRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastLightningSdxlOutput;
};

export type GetFalAiFastLightningSdxlRequestsByRequestIdResponse =
  GetFalAiFastLightningSdxlRequestsByRequestIdResponses[keyof GetFalAiFastLightningSdxlRequestsByRequestIdResponses];

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-fooocus-sdxl/image-to-image/requests/{request_id}/status";
};

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdStatusResponse =
  GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdStatusResponses[keyof GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdStatusResponses];

export type PutFalAiFastFooocusSdxlImageToImageRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl/image-to-image/requests/{request_id}/cancel";
};

export type PutFalAiFastFooocusSdxlImageToImageRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastFooocusSdxlImageToImageRequestsByRequestIdCancelResponse =
  PutFalAiFastFooocusSdxlImageToImageRequestsByRequestIdCancelResponses[keyof PutFalAiFastFooocusSdxlImageToImageRequestsByRequestIdCancelResponses];

export type PostFalAiFastFooocusSdxlImageToImageData = {
  body: FastFooocusSdxlImageToImageInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl/image-to-image";
};

export type PostFalAiFastFooocusSdxlImageToImageResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastFooocusSdxlImageToImageResponse =
  PostFalAiFastFooocusSdxlImageToImageResponses[keyof PostFalAiFastFooocusSdxlImageToImageResponses];

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl/image-to-image/requests/{request_id}";
};

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastFooocusSdxlImageToImageOutput;
};

export type GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdResponse =
  GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdResponses[keyof GetFalAiFastFooocusSdxlImageToImageRequestsByRequestIdResponses];

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-sdxl-controlnet-canny/requests/{request_id}/status";
};

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdStatusResponse =
  GetFalAiFastSdxlControlnetCannyRequestsByRequestIdStatusResponses[keyof GetFalAiFastSdxlControlnetCannyRequestsByRequestIdStatusResponses];

export type PutFalAiFastSdxlControlnetCannyRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny/requests/{request_id}/cancel";
};

export type PutFalAiFastSdxlControlnetCannyRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiFastSdxlControlnetCannyRequestsByRequestIdCancelResponse =
  PutFalAiFastSdxlControlnetCannyRequestsByRequestIdCancelResponses[keyof PutFalAiFastSdxlControlnetCannyRequestsByRequestIdCancelResponses];

export type PostFalAiFastSdxlControlnetCannyData = {
  body: FastSdxlControlnetCannyInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny";
};

export type PostFalAiFastSdxlControlnetCannyResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastSdxlControlnetCannyResponse =
  PostFalAiFastSdxlControlnetCannyResponses[keyof PostFalAiFastSdxlControlnetCannyResponses];

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-sdxl-controlnet-canny/requests/{request_id}";
};

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastSdxlControlnetCannyOutput;
};

export type GetFalAiFastSdxlControlnetCannyRequestsByRequestIdResponse =
  GetFalAiFastSdxlControlnetCannyRequestsByRequestIdResponses[keyof GetFalAiFastSdxlControlnetCannyRequestsByRequestIdResponses];

export type GetFalAiFastLcmDiffusionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-lcm-diffusion/requests/{request_id}/status";
};

export type GetFalAiFastLcmDiffusionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastLcmDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiFastLcmDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiFastLcmDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiFastLcmDiffusionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/requests/{request_id}/cancel";
};

export type PutFalAiFastLcmDiffusionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastLcmDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiFastLcmDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiFastLcmDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiFastLcmDiffusionData = {
  body: FastLcmDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion";
};

export type PostFalAiFastLcmDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastLcmDiffusionResponse =
  PostFalAiFastLcmDiffusionResponses[keyof PostFalAiFastLcmDiffusionResponses];

export type GetFalAiFastLcmDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-lcm-diffusion/requests/{request_id}";
};

export type GetFalAiFastLcmDiffusionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastLcmDiffusionOutput;
};

export type GetFalAiFastLcmDiffusionRequestsByRequestIdResponse =
  GetFalAiFastLcmDiffusionRequestsByRequestIdResponses[keyof GetFalAiFastLcmDiffusionRequestsByRequestIdResponses];

export type GetFalAiFastFooocusSdxlRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fast-fooocus-sdxl/requests/{request_id}/status";
};

export type GetFalAiFastFooocusSdxlRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFastFooocusSdxlRequestsByRequestIdStatusResponse =
  GetFalAiFastFooocusSdxlRequestsByRequestIdStatusResponses[keyof GetFalAiFastFooocusSdxlRequestsByRequestIdStatusResponses];

export type PutFalAiFastFooocusSdxlRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl/requests/{request_id}/cancel";
};

export type PutFalAiFastFooocusSdxlRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFastFooocusSdxlRequestsByRequestIdCancelResponse =
  PutFalAiFastFooocusSdxlRequestsByRequestIdCancelResponses[keyof PutFalAiFastFooocusSdxlRequestsByRequestIdCancelResponses];

export type PostFalAiFastFooocusSdxlData = {
  body: FastFooocusSdxlInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl";
};

export type PostFalAiFastFooocusSdxlResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFastFooocusSdxlResponse =
  PostFalAiFastFooocusSdxlResponses[keyof PostFalAiFastFooocusSdxlResponses];

export type GetFalAiFastFooocusSdxlRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fast-fooocus-sdxl/requests/{request_id}";
};

export type GetFalAiFastFooocusSdxlRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FastFooocusSdxlOutput;
};

export type GetFalAiFastFooocusSdxlRequestsByRequestIdResponse =
  GetFalAiFastFooocusSdxlRequestsByRequestIdResponses[keyof GetFalAiFastFooocusSdxlRequestsByRequestIdResponses];

export type GetFalAiIllusionDiffusionRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/illusion-diffusion/requests/{request_id}/status";
};

export type GetFalAiIllusionDiffusionRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIllusionDiffusionRequestsByRequestIdStatusResponse =
  GetFalAiIllusionDiffusionRequestsByRequestIdStatusResponses[keyof GetFalAiIllusionDiffusionRequestsByRequestIdStatusResponses];

export type PutFalAiIllusionDiffusionRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/illusion-diffusion/requests/{request_id}/cancel";
};

export type PutFalAiIllusionDiffusionRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIllusionDiffusionRequestsByRequestIdCancelResponse =
  PutFalAiIllusionDiffusionRequestsByRequestIdCancelResponses[keyof PutFalAiIllusionDiffusionRequestsByRequestIdCancelResponses];

export type PostFalAiIllusionDiffusionData = {
  body: IllusionDiffusionInput;
  path?: never;
  query?: never;
  url: "/fal-ai/illusion-diffusion";
};

export type PostFalAiIllusionDiffusionResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIllusionDiffusionResponse =
  PostFalAiIllusionDiffusionResponses[keyof PostFalAiIllusionDiffusionResponses];

export type GetFalAiIllusionDiffusionRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/illusion-diffusion/requests/{request_id}";
};

export type GetFalAiIllusionDiffusionRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IllusionDiffusionOutput;
};

export type GetFalAiIllusionDiffusionRequestsByRequestIdResponse =
  GetFalAiIllusionDiffusionRequestsByRequestIdResponses[keyof GetFalAiIllusionDiffusionRequestsByRequestIdResponses];

export type GetFalAiFooocusImagePromptRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fooocus/image-prompt/requests/{request_id}/status";
};

export type GetFalAiFooocusImagePromptRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFooocusImagePromptRequestsByRequestIdStatusResponse =
  GetFalAiFooocusImagePromptRequestsByRequestIdStatusResponses[keyof GetFalAiFooocusImagePromptRequestsByRequestIdStatusResponses];

export type PutFalAiFooocusImagePromptRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/image-prompt/requests/{request_id}/cancel";
};

export type PutFalAiFooocusImagePromptRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFooocusImagePromptRequestsByRequestIdCancelResponse =
  PutFalAiFooocusImagePromptRequestsByRequestIdCancelResponses[keyof PutFalAiFooocusImagePromptRequestsByRequestIdCancelResponses];

export type PostFalAiFooocusImagePromptData = {
  body: FooocusImagePromptInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fooocus/image-prompt";
};

export type PostFalAiFooocusImagePromptResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFooocusImagePromptResponse =
  PostFalAiFooocusImagePromptResponses[keyof PostFalAiFooocusImagePromptResponses];

export type GetFalAiFooocusImagePromptRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/image-prompt/requests/{request_id}";
};

export type GetFalAiFooocusImagePromptRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FooocusImagePromptOutput;
};

export type GetFalAiFooocusImagePromptRequestsByRequestIdResponse =
  GetFalAiFooocusImagePromptRequestsByRequestIdResponses[keyof GetFalAiFooocusImagePromptRequestsByRequestIdResponses];

export type GetFalAiFooocusInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fooocus/inpaint/requests/{request_id}/status";
};

export type GetFalAiFooocusInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFooocusInpaintRequestsByRequestIdStatusResponse =
  GetFalAiFooocusInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiFooocusInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiFooocusInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiFooocusInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFooocusInpaintRequestsByRequestIdCancelResponse =
  PutFalAiFooocusInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiFooocusInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiFooocusInpaintData = {
  body: FooocusInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fooocus/inpaint";
};

export type PostFalAiFooocusInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFooocusInpaintResponse =
  PostFalAiFooocusInpaintResponses[keyof PostFalAiFooocusInpaintResponses];

export type GetFalAiFooocusInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/inpaint/requests/{request_id}";
};

export type GetFalAiFooocusInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FooocusInpaintOutput;
};

export type GetFalAiFooocusInpaintRequestsByRequestIdResponse =
  GetFalAiFooocusInpaintRequestsByRequestIdResponses[keyof GetFalAiFooocusInpaintRequestsByRequestIdResponses];

export type GetFalAiLcmRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lcm/requests/{request_id}/status";
};

export type GetFalAiLcmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLcmRequestsByRequestIdStatusResponse =
  GetFalAiLcmRequestsByRequestIdStatusResponses[keyof GetFalAiLcmRequestsByRequestIdStatusResponses];

export type PutFalAiLcmRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lcm/requests/{request_id}/cancel";
};

export type PutFalAiLcmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLcmRequestsByRequestIdCancelResponse =
  PutFalAiLcmRequestsByRequestIdCancelResponses[keyof PutFalAiLcmRequestsByRequestIdCancelResponses];

export type PostFalAiLcmData = {
  body: LcmInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lcm";
};

export type PostFalAiLcmResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLcmResponse =
  PostFalAiLcmResponses[keyof PostFalAiLcmResponses];

export type GetFalAiLcmRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lcm/requests/{request_id}";
};

export type GetFalAiLcmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LcmOutput;
};

export type GetFalAiLcmRequestsByRequestIdResponse =
  GetFalAiLcmRequestsByRequestIdResponses[keyof GetFalAiLcmRequestsByRequestIdResponses];

export type GetFalAiDiffusionEdgeRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/diffusion-edge/requests/{request_id}/status";
};

export type GetFalAiDiffusionEdgeRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDiffusionEdgeRequestsByRequestIdStatusResponse =
  GetFalAiDiffusionEdgeRequestsByRequestIdStatusResponses[keyof GetFalAiDiffusionEdgeRequestsByRequestIdStatusResponses];

export type PutFalAiDiffusionEdgeRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/diffusion-edge/requests/{request_id}/cancel";
};

export type PutFalAiDiffusionEdgeRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDiffusionEdgeRequestsByRequestIdCancelResponse =
  PutFalAiDiffusionEdgeRequestsByRequestIdCancelResponses[keyof PutFalAiDiffusionEdgeRequestsByRequestIdCancelResponses];

export type PostFalAiDiffusionEdgeData = {
  body: DiffusionEdgeInput;
  path?: never;
  query?: never;
  url: "/fal-ai/diffusion-edge";
};

export type PostFalAiDiffusionEdgeResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDiffusionEdgeResponse =
  PostFalAiDiffusionEdgeResponses[keyof PostFalAiDiffusionEdgeResponses];

export type GetFalAiDiffusionEdgeRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/diffusion-edge/requests/{request_id}";
};

export type GetFalAiDiffusionEdgeRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DiffusionEdgeOutput;
};

export type GetFalAiDiffusionEdgeRequestsByRequestIdResponse =
  GetFalAiDiffusionEdgeRequestsByRequestIdResponses[keyof GetFalAiDiffusionEdgeRequestsByRequestIdResponses];

export type GetFalAiFooocusRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/fooocus/requests/{request_id}/status";
};

export type GetFalAiFooocusRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFooocusRequestsByRequestIdStatusResponse =
  GetFalAiFooocusRequestsByRequestIdStatusResponses[keyof GetFalAiFooocusRequestsByRequestIdStatusResponses];

export type PutFalAiFooocusRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/requests/{request_id}/cancel";
};

export type PutFalAiFooocusRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFooocusRequestsByRequestIdCancelResponse =
  PutFalAiFooocusRequestsByRequestIdCancelResponses[keyof PutFalAiFooocusRequestsByRequestIdCancelResponses];

export type PostFalAiFooocusData = {
  body: FooocusInput;
  path?: never;
  query?: never;
  url: "/fal-ai/fooocus";
};

export type PostFalAiFooocusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFooocusResponse =
  PostFalAiFooocusResponses[keyof PostFalAiFooocusResponses];

export type GetFalAiFooocusRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/fooocus/requests/{request_id}";
};

export type GetFalAiFooocusRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FooocusOutput;
};

export type GetFalAiFooocusRequestsByRequestIdResponse =
  GetFalAiFooocusRequestsByRequestIdResponses[keyof GetFalAiFooocusRequestsByRequestIdResponses];

export type GetFalAiLoraRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lora/requests/{request_id}/status";
};

export type GetFalAiLoraRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLoraRequestsByRequestIdStatusResponse =
  GetFalAiLoraRequestsByRequestIdStatusResponses[keyof GetFalAiLoraRequestsByRequestIdStatusResponses];

export type PutFalAiLoraRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/requests/{request_id}/cancel";
};

export type PutFalAiLoraRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLoraRequestsByRequestIdCancelResponse =
  PutFalAiLoraRequestsByRequestIdCancelResponses[keyof PutFalAiLoraRequestsByRequestIdCancelResponses];

export type PostFalAiLoraData = {
  body: LoraInput;
  path?: never;
  query?: never;
  url: "/fal-ai/lora";
};

export type PostFalAiLoraResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLoraResponse =
  PostFalAiLoraResponses[keyof PostFalAiLoraResponses];

export type GetFalAiLoraRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lora/requests/{request_id}";
};

export type GetFalAiLoraRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: LoraOutput;
};

export type GetFalAiLoraRequestsByRequestIdResponse =
  GetFalAiLoraRequestsByRequestIdResponses[keyof GetFalAiLoraRequestsByRequestIdResponses];
