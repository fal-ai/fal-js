// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: "https://queue.fal.run" | (string & {});
};

/**
 * Audio
 */
export type Audio = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
};

/**
 * AudioOutput
 */
export type SfxV1VideoToAudioOutput = {
  /**
   * Audio
   *
   * The generated sound effects audio
   */
  audio: Array<Audio>;
};

/**
 * Input
 */
export type SfxV1VideoToAudioInput = {
  /**
   * Num Samples
   *
   * The number of samples to generate from the model
   */
  num_samples?: number | unknown;
  /**
   * Video Url
   *
   * A video url that can accessed from the API to process and add sound effects
   */
  video_url: string;
  /**
   * Duration
   *
   * The duration of the generated audio in seconds
   */
  duration?: number | unknown;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used
   */
  seed?: number | unknown;
  /**
   * Text Prompt
   *
   * Additional description to guide the model
   */
  text_prompt?: string | unknown;
};

/**
 * VideoToAudioOutput
 */
export type KlingVideoVideoToAudioOutput = {
  /**
   * Video
   *
   * The original video with dubbed audio applied
   */
  video: File;
  /**
   * Audio
   *
   * The extracted/generated audio from the video in MP3 format
   */
  audio: File;
};

/**
 * File
 */
export type File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * VideoToAudioInput
 */
export type KlingVideoVideoToAudioInput = {
  /**
   * Video Url
   *
   * The video URL to extract audio from. Only .mp4/.mov formats are supported. File size does not exceed 100MB. Video duration between 3.0s and 20.0s.
   */
  video_url: string;
  /**
   * Asmr Mode
   *
   * Enable ASMR mode. This mode enhances detailed sound effects and is suitable for highly immersive content scenarios.
   */
  asmr_mode?: boolean;
  /**
   * Background Music Prompt
   *
   * Background music prompt. Cannot exceed 200 characters.
   */
  background_music_prompt?: string;
  /**
   * Sound Effect Prompt
   *
   * Sound effect prompt. Cannot exceed 200 characters.
   */
  sound_effect_prompt?: string;
};

/**
 * Audio
 */
export type AudioOutput = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
};

/**
 * AudioOutput
 */
export type SfxV15VideoToAudioOutput = {
  /**
   * Audio
   *
   * The generated sound effects audio
   */
  audio: Array<AudioOutput>;
};

/**
 * Input
 */
export type SfxV15VideoToAudioInput = {
  /**
   * Num Samples
   *
   * The number of samples to generate from the model
   */
  num_samples?: number | unknown;
  /**
   * Duration
   *
   * The duration of the generated audio in seconds
   */
  duration?: number | unknown;
  /**
   * Start Offset
   *
   * The start offset in seconds to start the audio generation from
   */
  start_offset?: number | unknown;
  /**
   * Video Url
   *
   * A video url that can accessed from the API to process and add sound effects
   */
  video_url: string;
  /**
   * Seed
   *
   * The seed to use for the generation. If not provided, a random seed will be used
   */
  seed?: number | unknown;
  /**
   * Text Prompt
   *
   * Additional description to guide the model
   */
  text_prompt?: string | unknown;
};

/**
 * SAMAudioVisualSeparateOutput
 *
 * Output for visual-prompted audio separation.
 */
export type SamAudioVisualSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: File;
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number;
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number;
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: File;
};

/**
 * SAMAudioVisualInput
 *
 * Input for visual-prompted audio separation.
 */
export type SamAudioVisualSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt to assist with separation. Use natural language to describe the target sound.
   */
  prompt?: string;
  /**
   * Video Url
   *
   * URL of the video file to process (MP4, MOV, etc.)
   */
  video_url: string;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "fast" | "balanced" | "quality";
  /**
   * Mask Video Url
   *
   * URL of the mask video (binary mask indicating target object). Black=target, White=background.
   */
  mask_video_url?: string;
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: "wav" | "mp3";
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost.
   */
  reranking_candidates?: number;
};

/**
 * Output
 */
export type StableAudioOutput = {
  audio_file: FileType2;
};

/**
 * File
 */
export type FileType2 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
};

/**
 * Input
 */
export type StableAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string;
  /**
   * Steps
   *
   * The number of steps to denoise the audio for
   */
  steps?: number;
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number;
  /**
   * Seconds Start
   *
   * The start point of the audio clip to generate
   */
  seconds_start?: number;
};

/**
 * TTSOutput
 */
export type F5TtsOutput = {
  audio_url: AudioFileType2;
};

/**
 * AudioFile
 */
export type AudioFileType2 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   */
  file_name?: string;
  /**
   * Content Type
   */
  content_type?: string;
  /**
   * Url
   */
  url: string;
};

/**
 * TTSInput
 */
export type F5TtsInput = {
  /**
   * Reference Text for the Reference Audio
   *
   * The reference text to be used for TTS. If not provided, an ASR (Automatic Speech Recognition) model will be used to generate the reference text.
   */
  ref_text?: string;
  /**
   * Remove Silence
   *
   * Whether to remove the silence from the audio file.
   */
  remove_silence?: boolean;
  /**
   * Text to be converted to speech
   *
   * The text to be converted to speech.
   */
  gen_text: string;
  /**
   * Model Type
   *
   * The name of the model to be used for TTS.
   */
  model_type: "F5-TTS" | "E2-TTS";
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio file.
   */
  ref_audio_url: string;
};

/**
 * MusicOutput
 */
export type MinimaxMusicOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * TextToMusicRequest
 */
export type MinimaxMusicInput = {
  /**
   * Prompt
   *
   * Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.
   */
  prompt: string;
  /**
   * Reference Audio Url
   *
   * Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.
   */
  reference_audio_url: string;
};

/**
 * AudioOutput
 */
export type MmaudioV2TextToAudioOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: File;
};

/**
 * AudioInput
 */
export type MmaudioV2TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate the audio for.
   */
  prompt: string;
  /**
   * Num Steps
   *
   * The number of steps to generate the audio for.
   */
  num_steps?: number;
  /**
   * Duration
   *
   * The duration of the audio to generate.
   */
  duration?: number;
  /**
   * Cfg Strength
   *
   * The strength of Classifier Free Guidance.
   */
  cfg_strength?: number;
  /**
   * Seed
   *
   * The seed for the random number generator
   */
  seed?: number;
  /**
   * Mask Away Clip
   *
   * Whether to mask away the clip.
   */
  mask_away_clip?: boolean;
  /**
   * Negative Prompt
   *
   * The negative prompt to generate the audio for.
   */
  negative_prompt?: string;
};

/**
 * Output
 */
export type YueOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: File;
};

/**
 * TextToMusicInput
 */
export type YueInput = {
  /**
   * Lyrics
   *
   * The prompt to generate an image from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string;
  /**
   * Genres
   *
   * The genres (separated by a space ' ') to guide the music generation.
   */
  genres: string;
};

/**
 * SpanishOutput
 */
export type KokoroSpanishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * SpanishRequest
 */
export type KokoroSpanishInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "ef_dora" | "em_alex" | "em_santa";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * MandarinOutput
 */
export type KokoroMandarinChineseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * MandarinRequest
 */
export type KokoroMandarinChineseInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | "zf_xiaobei"
    | "zf_xiaoni"
    | "zf_xiaoxiao"
    | "zf_xiaoyi"
    | "zm_yunjian"
    | "zm_yunxi"
    | "zm_yunxia"
    | "zm_yunyang";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * JapaneseOutput
 */
export type KokoroJapaneseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * JapaneseRequest
 */
export type KokoroJapaneseInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "jf_alpha" | "jf_gongitsune" | "jf_nezumi" | "jf_tebukuro" | "jm_kumo";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * FrenchOutput
 */
export type KokoroFrenchOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * FrenchRequest
 */
export type KokoroFrenchInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "ff_siwis";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * BrPortugeseOutput
 */
export type KokoroBrazilianPortugueseOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * BrPortugueseRequest
 */
export type KokoroBrazilianPortugueseInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "pf_dora" | "pm_alex" | "pm_santa";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * ItalianOutput
 */
export type KokoroItalianOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * ItalianRequest
 */
export type KokoroItalianInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "if_sara" | "im_nicola";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * ZonosOutput
 */
export type ZonosOutput = {
  /**
   * Audio
   *
   * The generated audio
   */
  audio: File;
};

/**
 * ZonosInput
 */
export type ZonosInput = {
  /**
   * Prompt
   *
   * The content generated using cloned voice.
   */
  prompt: string;
  /**
   * Reference Audio Url
   *
   * The reference audio.
   */
  reference_audio_url: string;
};

/**
 * AmEngOutput
 */
export type KokoroAmericanEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * AmEnglishRequest
 */
export type KokoroAmericanEnglishInput = {
  /**
   * Prompt
   */
  prompt?: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice?:
    | "af_heart"
    | "af_alloy"
    | "af_aoede"
    | "af_bella"
    | "af_jessica"
    | "af_kore"
    | "af_nicole"
    | "af_nova"
    | "af_river"
    | "af_sarah"
    | "af_sky"
    | "am_adam"
    | "am_echo"
    | "am_eric"
    | "am_fenrir"
    | "am_liam"
    | "am_michael"
    | "am_onyx"
    | "am_puck"
    | "am_santa";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * BrEngOutput
 */
export type KokoroBritishEnglishOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * BrEnglishRequest
 */
export type KokoroBritishEnglishInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice:
    | "bf_alice"
    | "bf_emma"
    | "bf_isabella"
    | "bf_lily"
    | "bm_daniel"
    | "bm_fable"
    | "bm_george"
    | "bm_lewis";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * HindiOutput
 */
export type KokoroHindiOutput = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * HindiRequest
 */
export type KokoroHindiInput = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice: "hf_alpha" | "hf_beta" | "hm_omega" | "hm_psi";
  /**
   * Speed
   *
   * Speed of the generated audio. Default is 1.0.
   */
  speed?: number;
};

/**
 * TTSOutput
 */
export type ElevenlabsTtsMultilingualV2Output = {
  audio: FileType2;
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown;
};

/**
 * TextToSpeechRequest
 */
export type ElevenlabsTtsMultilingualV2Input = {
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string;
  /**
   * Next Text
   *
   * The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  next_text?: string | unknown;
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number;
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number;
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number;
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean;
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number;
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string;
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown;
  /**
   * Apply Text Normalization
   *
   * This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.
   */
  apply_text_normalization?: "auto" | "on" | "off";
  /**
   * Previous Text
   *
   * The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  previous_text?: string | unknown;
};

/**
 * Output
 */
export type DiffrhythmOutput = {
  /**
   * Audio
   *
   * Generated music file.
   */
  audio: File;
};

/**
 * TextToMusicInput
 */
export type DiffrhythmInput = {
  /**
   * Lyrics
   *
   * The prompt to generate the song from. Must have two sections. Sections start with either [chorus] or a [verse].
   */
  lyrics: string;
  /**
   * CFG Strength
   *
   * The CFG strength to use for the music generation.
   */
  cfg_strength?: number;
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio to use for the music generation.
   */
  reference_audio_url?: string;
  /**
   * Music Duration
   *
   * The duration of the music to generate.
   */
  music_duration?: "95s" | "285s";
  /**
   * Scheduler
   *
   * The scheduler to use for the music generation.
   */
  scheduler?: "euler" | "midpoint" | "rk4" | "implicit_adams";
  /**
   * Number of Inference Steps
   *
   * The number of inference steps to use for the music generation.
   */
  num_inference_steps?: number;
  /**
   * Style Prompt
   *
   * The style prompt to use for the music generation.
   */
  style_prompt?: string;
};

/**
 * Speaker
 */
export type Speaker = {
  /**
   * Prompt
   */
  prompt: string;
  /**
   * Audio Url
   */
  audio_url: string;
  /**
   * Speaker Id
   */
  speaker_id: number;
};

/**
 * Turn
 */
export type Turn = {
  /**
   * Text
   */
  text: string;
  /**
   * Speaker Id
   */
  speaker_id: number;
};

/**
 * Output
 */
export type Csm1bOutput = {
  /**
   * Audio
   *
   * The generated audio.
   */
  audio: FileType2 | Blob | File;
};

/**
 * Input
 */
export type Csm1bInput = {
  /**
   * Scene
   *
   * The text to generate an audio from.
   */
  scene: Array<Turn>;
  /**
   * Context
   *
   * The context to generate an audio from.
   */
  context?: Array<Speaker>;
};

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type MusicGeneratorOutput = {
  audio_file: FileType2;
};

/**
 * Input
 */
export type MusicGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate music from.
   */
  prompt: string;
  /**
   * Duration
   *
   * The duration of the generated music in seconds.
   */
  duration: number;
};

/**
 * AudioOutput
 *
 * Example Pydantic model showing how to include a File in the output.
 */
export type SoundEffectsGeneratorOutput = {
  audio_file: FileType2;
};

/**
 * Input
 */
export type SoundEffectsGeneratorInput = {
  /**
   * Prompt
   *
   * The prompt to generate SFX.
   */
  prompt: string;
  /**
   * Duration
   *
   * The duration of the generated SFX in seconds.
   */
  duration: number;
};

/**
 * ACEStepResponse
 */
export type AceStepOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string;
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: File;
};

/**
 * ACEStepTextToAudioRequest
 */
export type AceStepInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number;
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number;
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string;
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number;
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string;
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number;
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: "euler" | "heun";
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number;
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: "cfg" | "apg" | "cfg_star";
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number;
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number;
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number;
};

/**
 * ACEStepResponse
 */
export type AceStepPromptToAudioOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string;
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: File;
};

/**
 * ACEStepPromptToAudioRequest
 */
export type AceStepPromptToAudioInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number;
  /**
   * Duration
   *
   * The duration of the generated audio in seconds.
   */
  duration?: number;
  /**
   * Prompt
   *
   * Prompt to control the style of the generated audio. This will be used to generate tags and lyrics.
   */
  prompt: string;
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number;
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number;
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: "euler" | "heun";
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number;
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: "cfg" | "apg" | "cfg_star";
  /**
   * Instrumental
   *
   * Whether to generate an instrumental version of the audio.
   */
  instrumental?: boolean;
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number;
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number;
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number;
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number;
};

/**
 * TextToMusicOutput
 */
export type Lyria2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * TextToMusicInput
 */
export type Lyria2Input = {
  /**
   * Prompt
   *
   * The text prompt describing the music you want to generate
   */
  prompt: string;
  /**
   * Seed
   *
   * A seed for deterministic generation. If provided, the model will attempt to produce the same audio given the same prompt and other parameters.
   */
  seed?: number;
  /**
   * Negative Prompt
   *
   * A description of what to exclude from the generated audio
   */
  negative_prompt?: string;
};

/**
 * TTSOutput
 */
export type ElevenlabsTtsElevenV3Output = {
  audio: FileType2;
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown;
};

/**
 * TextToSpeechRequestV3
 *
 * Request model for eleven_v3 which doesn't support previous_text/next_text
 */
export type ElevenlabsTtsElevenV3Input = {
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string;
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number;
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number;
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number;
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean;
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number;
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string;
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model.
   */
  language_code?: string | unknown;
  /**
   * Apply Text Normalization
   *
   * This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.
   */
  apply_text_normalization?: "auto" | "on" | "off";
};

/**
 * GenerateOutput
 */
export type V2TextToMusicOutput = {
  /**
   * Tags
   *
   * The style tags used for generation.
   */
  tags?: Array<string> | unknown;
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number;
  /**
   * Lyrics
   *
   * The lyrics used for generation.
   */
  lyrics?: string | unknown;
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<FileType2>;
};

/**
 * GenerateInput
 */
export type V2TextToMusicInput = {
  /**
   * Prompt
   *
   * A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.
   */
  prompt?: string | unknown;
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt?: string | unknown;
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string> | unknown;
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number;
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown;
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number;
  /**
   * Output Format
   */
  output_format?: "flac" | "mp3" | "wav" | "ogg" | "m4a";
  /**
   * Bpm
   *
   * The beats per minute of the song. This can be set to an integer or the literal string "auto" to pick a suitable bpm based on the tags. Set bpm to null to not condition the model on bpm information.
   */
  bpm?: number | string | unknown;
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number;
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown;
};

/**
 * InpaintSection
 */
export type InpaintSection = {
  /**
   * End
   *
   * End time in seconds of the section to inpaint.
   */
  end: number;
  /**
   * Start
   *
   * Start time in seconds of the section to inpaint.
   */
  start: number;
};

/**
 * InpaintOutput
 */
export type V2InpaintOutput = {
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<FileType2>;
};

/**
 * InpaintInput
 */
export type V2InpaintInput = {
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt: string;
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string>;
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number;
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown;
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number;
  /**
   * Output Format
   */
  output_format?: "flac" | "mp3" | "wav" | "ogg" | "m4a";
  /**
   * Selection Crop
   *
   * Crop to the selected region
   */
  selection_crop?: boolean;
  /**
   * Sections
   *
   * List of sections to inpaint. Currently, only one section is supported so the list length must be 1.
   */
  sections: Array<InpaintSection>;
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number;
  /**
   * Audio Url
   *
   * The URL of the audio file to alter. Must be a valid publicly accessible URL.
   */
  audio_url: string;
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown;
};

/**
 * SoundEffectOutput
 *
 * Output format for generated sound effects
 */
export type ElevenlabsSoundEffectsV2Output = {
  audio: FileType2;
};

/**
 * SoundEffectRequestV2
 */
export type ElevenlabsSoundEffectsV2Input = {
  /**
   * Text
   *
   * The text describing the sound effect to generate
   */
  text: string;
  /**
   * Loop
   *
   * Whether to create a sound effect that loops smoothly.
   */
  loop?: boolean;
  /**
   * Prompt Influence
   *
   * How closely to follow the prompt (0-1). Higher values mean less variation.
   */
  prompt_influence?: number;
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | "mp3_22050_32"
    | "mp3_44100_32"
    | "mp3_44100_64"
    | "mp3_44100_96"
    | "mp3_44100_128"
    | "mp3_44100_192"
    | "pcm_8000"
    | "pcm_16000"
    | "pcm_22050"
    | "pcm_24000"
    | "pcm_44100"
    | "pcm_48000"
    | "ulaw_8000"
    | "alaw_8000"
    | "opus_48000_32"
    | "opus_48000_64"
    | "opus_48000_96"
    | "opus_48000_128"
    | "opus_48000_192";
  /**
   * Duration Seconds
   *
   * Duration in seconds (0.5-22). If None, optimal duration will be determined from prompt.
   */
  duration_seconds?: number | unknown;
};

/**
 * PronunciationDictionaryLocator
 */
export type PronunciationDictionaryLocator = {
  /**
   * Version Id
   *
   * The ID of the version of the pronunciation dictionary. If not provided, the latest version will be used.
   */
  version_id?: string | unknown;
  /**
   * Pronunciation Dictionary Id
   *
   * The ID of the pronunciation dictionary.
   */
  pronunciation_dictionary_id: string | unknown;
};

/**
 * DialogueBlock
 */
export type DialogueBlock = {
  /**
   * Text
   *
   * The dialogue text
   */
  text: string;
  /**
   * Voice
   *
   * The name or the ID of the voice to be used for the generation.
   */
  voice: string;
};

/**
 * TextToDialogueOutput
 */
export type ElevenlabsTextToDialogueElevenV3Output = {
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed: number;
  audio: FileType2;
};

/**
 * TextToDialogueRequest
 */
export type ElevenlabsTextToDialogueElevenV3Input = {
  /**
   * Stability
   *
   * Determines how stable the voice is and the randomness between each generation. Lower values introduce broader emotional range for the voice. Higher values can result in a monotonous voice with limited emotion. Must be one of 0.0, 0.5, 1.0, else it will be rounded to the nearest value.
   */
  stability?: number | unknown;
  /**
   * Inputs
   *
   * A list of dialogue inputs, each containing text and a voice ID which will be converted into speech.
   */
  inputs: Array<DialogueBlock>;
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number | unknown;
  /**
   * Use Speaker Boost
   *
   * This setting boosts the similarity to the original speaker. Using this setting requires a slightly higher computational load, which in turn increases latency.
   */
  use_speaker_boost?: boolean | unknown;
  /**
   * Pronunciation Dictionary Locators
   *
   * A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request
   */
  pronunciation_dictionary_locators?: Array<PronunciationDictionaryLocator>;
};

/**
 * TextToAudioOutput
 */
export type StableAudio25TextToAudioOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: File;
};

/**
 * TextToAudioInput
 */
export type StableAudio25TextToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to generate audio from
   */
  prompt: string;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate
   */
  seconds_total?: number;
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number;
  /**
   * Seed
   */
  seed?: number;
};

/**
 * MusicV15Output
 */
export type MinimaxMusicV15Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * TextToMusic15Request
 */
export type MinimaxMusicV15Input = {
  /**
   * Prompt
   *
   * Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.
   */
  prompt: string;
  /**
   * Lyrics Prompt
   *
   * Control music generation. 10-3000 characters.
   */
  lyrics_prompt: string;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * AudioSetting
 */
export type AudioSetting = {
  /**
   * Format
   *
   * Audio format
   */
  format?: "mp3" | "pcm" | "flac";
  /**
   * Sample Rate
   *
   * Sample rate of generated audio
   */
  sample_rate?: 8000 | 16000 | 22050 | 24000 | 32000 | 44100;
  /**
   * Bitrate
   *
   * Bitrate of generated audio
   */
  bitrate?: 32000 | 64000 | 128000 | 256000;
};

/**
 * MusicGenerationOutput
 *
 * Output schema for music generation.
 */
export type MusicGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string;
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown;
  };
  audio: FileType2;
};

/**
 * MusicGenerationInput
 *
 * Input schema for music generation with form controls for the playground.
 */
export type MusicGenerationInput = {
  /**
   * Prompt
   *
   * Describe the music you want to generate
   */
  prompt: string;
  /**
   * Duration
   *
   * Length of the generated music in seconds
   */
  duration?: number;
  /**
   * Refinement
   *
   * Refinement level - higher values may improve quality but take longer
   */
  refinement?: number;
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown;
  /**
   * Negative Prompt
   *
   * Describe what you want to avoid in the music (instruments, styles, moods). Leave blank for none.
   */
  negative_prompt?: string;
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number;
};

/**
 * SoundEffectGenerationOutput
 *
 * Output schema for sound effect generation.
 */
export type SoundEffectGenerationOutput = {
  /**
   * Prompt
   *
   * The processed prompt used for generation
   */
  prompt: string;
  /**
   * Metadata
   *
   * Generation metadata including duration, sample rate, and parameters
   */
  metadata: {
    [key: string]: unknown;
  };
  audio: FileType2;
};

/**
 * SoundEffectGenerationInput
 *
 * Input schema for sound effect generation with form controls for the playground.
 */
export type SoundEffectGenerationInput = {
  /**
   * Prompt
   *
   * Describe the sound effect you want to generate
   */
  prompt: string;
  /**
   * Duration
   *
   * Length of the generated sound effect in seconds
   */
  duration?: number;
  /**
   * Refinement
   *
   * Refinement level - Higher values may improve quality but take longer
   */
  refinement?: number;
  /**
   * Seed
   *
   * Random seed for reproducible results - leave empty for random generation
   */
  seed?: number | unknown;
  /**
   * Negative Prompt
   *
   * Describe the types of sounds you don't want to generate in the output, avoid double-negatives, compare with positive prompts
   */
  negative_prompt?: string;
  /**
   * Creativity
   *
   * Creativity level - higher values allow more creative interpretation of the prompt
   */
  creativity?: number;
};

/**
 * MusicV15Output
 */
export type MinimaxMusicV2Output = {
  /**
   * Audio
   *
   * The generated music
   */
  audio: File;
};

/**
 * TextToMusic20Request
 */
export type MinimaxMusicV2Input = {
  /**
   * Prompt
   *
   * A description of the music, specifying style, mood, and scenario. 10-300 characters.
   */
  prompt: string;
  /**
   * Lyrics Prompt
   *
   * Lyrics of the song. Use n to separate lines. You may add structure tags like [Intro], [Verse], [Chorus], [Bridge], [Outro] to enhance the arrangement. 10-3000 characters.
   */
  lyrics_prompt: string;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * MusicSection
 */
export type MusicSection = {
  /**
   * Positive Local Styles
   *
   * The styles that should be present in this section.
   */
  positive_local_styles: Array<string>;
  /**
   * Lines
   *
   * The lyrics of the section. Each line must be at most 200 characters long.
   */
  lines: Array<string>;
  /**
   * Negative Local Styles
   *
   * The styles that should not be present in this section.
   */
  negative_local_styles: Array<string>;
  /**
   * Duration Ms
   *
   * The duration of the section in milliseconds. Must be between 3000ms and 120000ms.
   */
  duration_ms: number;
  /**
   * Section Name
   *
   * The name of the section. Must be between 1 and 100 characters.
   */
  section_name: string;
};

/**
 * MusicCompositionPlan
 */
export type MusicCompositionPlan = {
  /**
   * Negative Global Styles
   *
   * The styles that should not be present in the entire song.
   */
  negative_global_styles: Array<string>;
  /**
   * Sections
   *
   * The sections of the song.
   */
  sections: Array<MusicSection>;
  /**
   * Positive Global Styles
   *
   * The styles that should be present in the entire song.
   */
  positive_global_styles: Array<string>;
};

/**
 * MusicOutput
 */
export type ElevenlabsMusicOutput = {
  audio: FileType2;
};

/**
 * MusicRequest
 *
 * Request format for Elevenlabs Music API
 */
export type ElevenlabsMusicInput = {
  /**
   * Prompt
   *
   * The text prompt describing the music to generate
   */
  prompt?: string | unknown;
  /**
   * The composition plan for the music
   */
  composition_plan?: MusicCompositionPlan | unknown;
  /**
   * Music Length Ms
   *
   * The length of the song to generate in milliseconds. Used only in conjunction with prompt. Must be between 3000ms and 600000ms. Optional - if not provided, the model will choose a length based on the prompt.
   */
  music_length_ms?: number | unknown;
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the Î¼-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
   */
  output_format?:
    | "mp3_22050_32"
    | "mp3_44100_32"
    | "mp3_44100_64"
    | "mp3_44100_96"
    | "mp3_44100_128"
    | "mp3_44100_192"
    | "pcm_8000"
    | "pcm_16000"
    | "pcm_22050"
    | "pcm_24000"
    | "pcm_44100"
    | "pcm_48000"
    | "ulaw_8000"
    | "alaw_8000"
    | "opus_48000_32"
    | "opus_48000_64"
    | "opus_48000_96"
    | "opus_48000_128"
    | "opus_48000_192";
  /**
   * Respect Sections Durations
   *
   * Controls how strictly section durations in the composition_plan are enforced. It will only have an effect if it is used with composition_plan. When set to true, the model will precisely respect each section's duration_ms from the plan. When set to false, the model may adjust individual section durations which will generally lead to better generation quality and improved latency, while always preserving the total song duration from the plan.
   */
  respect_sections_durations?: boolean;
  /**
   * Force Instrumental
   *
   * If true, guarantees that the generated song will be instrumental. If false, the song may or may not be instrumental depending on the prompt. Can only be used with prompt.
   */
  force_instrumental?: boolean;
};

/**
 * TTSOutput
 */
export type ElevenlabsAudioIsolationOutput = {
  audio: FileType2;
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown;
};

/**
 * AudioIsolationRequest
 */
export type ElevenlabsAudioIsolationInput = {
  /**
   * Video Url
   *
   * Video file to use for audio isolation. Either `audio_url` or `video_url` must be provided.
   */
  video_url?: string | unknown;
  /**
   * Audio Url
   *
   * URL of the audio file to isolate voice from
   */
  audio_url?: string | unknown;
};

/**
 * DiaCloneOutput
 */
export type DiaTtsVoiceCloneOutput = {
  /**
   * The generated speech audio
   */
  audio: FileType2;
};

/**
 * CloneRequest
 */
export type DiaTtsVoiceCloneInput = {
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string;
  /**
   * Reference Text for the Reference Audio
   *
   * The reference text to be used for TTS.
   */
  ref_text: string;
  /**
   * Reference Audio URL
   *
   * The URL of the reference audio file.
   */
  ref_audio_url: string;
};

/**
 * ACEStepAudioToAudioResponse
 */
export type AceStepAudioToAudioOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string;
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: File;
};

/**
 * ACEStepAudioToAudioRequest
 */
export type AceStepAudioToAudioInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number;
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string;
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number;
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string;
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number;
  /**
   * Original Lyrics
   *
   * Original lyrics of the audio file.
   */
  original_lyrics?: string;
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: "euler" | "heun";
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number;
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: "cfg" | "apg" | "cfg_star";
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number;
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number;
  /**
   * Edit Mode
   *
   * Whether to edit the lyrics only or remix the audio.
   */
  edit_mode?: "lyrics" | "remix";
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number;
  /**
   * Audio Url
   *
   * URL of the audio file to be outpainted.
   */
  audio_url: string;
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number;
  /**
   * Original Tags
   *
   * Original tags of the audio file.
   */
  original_tags: string;
  /**
   * Original Seed
   *
   * Original seed of the audio file.
   */
  original_seed?: number;
};

/**
 * ACEStepAudioInpaintResponse
 */
export type AceStepAudioInpaintOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string;
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: File;
};

/**
 * ACEStepAudioInpaintRequest
 */
export type AceStepAudioInpaintInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number;
  /**
   * Start Time
   *
   * start time in seconds for the inpainting process.
   */
  start_time?: number;
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string;
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number;
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string;
  /**
   * End Time Relative To
   *
   * Whether the end time is relative to the start or end of the audio.
   */
  end_time_relative_to?: "start" | "end";
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number;
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: "euler" | "heun";
  /**
   * End Time
   *
   * end time in seconds for the inpainting process.
   */
  end_time?: number;
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: "cfg" | "apg" | "cfg_star";
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number;
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number;
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number;
  /**
   * Variance
   *
   * Variance for the inpainting process. Higher values can lead to more diverse results.
   */
  variance?: number;
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number;
  /**
   * Start Time Relative To
   *
   * Whether the start time is relative to the start or end of the audio.
   */
  start_time_relative_to?: "start" | "end";
  /**
   * Audio Url
   *
   * URL of the audio file to be inpainted.
   */
  audio_url: string;
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number;
};

/**
 * ACEStepResponse
 */
export type AceStepAudioOutpaintOutput = {
  /**
   * Tags
   *
   * The genre tags used in the generation process.
   */
  tags: string;
  /**
   * Lyrics
   *
   * The lyrics used in the generation process.
   */
  lyrics: string;
  /**
   * Seed
   *
   * The random seed used for the generation process.
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: File;
};

/**
 * ACEStepAudioOutpaintRequest
 */
export type AceStepAudioOutpaintInput = {
  /**
   * Number Of Steps
   *
   * Number of steps to generate the audio.
   */
  number_of_steps?: number;
  /**
   * Tags
   *
   * Comma-separated list of genre tags to control the style of the generated audio.
   */
  tags: string;
  /**
   * Minimum Guidance Scale
   *
   * Minimum guidance scale for the generation after the decay.
   */
  minimum_guidance_scale?: number;
  /**
   * Extend After Duration
   *
   * Duration in seconds to extend the audio from the end.
   */
  extend_after_duration?: number;
  /**
   * Lyrics
   *
   * Lyrics to be sung in the audio. If not provided or if [inst] or [instrumental] is the content of this field, no lyrics will be sung. Use control structures like [verse], [chorus] and [bridge] to control the structure of the song.
   */
  lyrics?: string;
  /**
   * Tag Guidance Scale
   *
   * Tag guidance scale for the generation.
   */
  tag_guidance_scale?: number;
  /**
   * Scheduler
   *
   * Scheduler to use for the generation process.
   */
  scheduler?: "euler" | "heun";
  /**
   * Extend Before Duration
   *
   * Duration in seconds to extend the audio from the start.
   */
  extend_before_duration?: number;
  /**
   * Guidance Type
   *
   * Type of CFG to use for the generation process.
   */
  guidance_type?: "cfg" | "apg" | "cfg_star";
  /**
   * Guidance Scale
   *
   * Guidance scale for the generation.
   */
  guidance_scale?: number;
  /**
   * Lyric Guidance Scale
   *
   * Lyric guidance scale for the generation.
   */
  lyric_guidance_scale?: number;
  /**
   * Guidance Interval
   *
   * Guidance interval for the generation. 0.5 means only apply guidance in the middle steps (0.25 * infer_steps to 0.75 * infer_steps)
   */
  guidance_interval?: number;
  /**
   * Guidance Interval Decay
   *
   * Guidance interval decay for the generation. Guidance scale will decay from guidance_scale to min_guidance_scale in the interval. 0.0 means no decay.
   */
  guidance_interval_decay?: number;
  /**
   * Audio Url
   *
   * URL of the audio file to be outpainted.
   */
  audio_url: string;
  /**
   * Seed
   *
   * Random seed for reproducibility. If not provided, a random seed will be used.
   */
  seed?: number;
  /**
   * Granularity Scale
   *
   * Granularity scale for the generation process. Higher values can reduce artifacts.
   */
  granularity_scale?: number;
};

/**
 * ExtendOutput
 */
export type V2ExtendOutput = {
  /**
   * Tags
   *
   * The style tags used for generation.
   */
  tags?: Array<string> | unknown;
  /**
   * Seed
   *
   * The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.
   */
  seed: number;
  /**
   * Extend Duration
   *
   * The duration in seconds that the song was extended by.
   */
  extend_duration: number;
  /**
   * Audio
   *
   * The generated audio files.
   */
  audio: Array<FileType2>;
  /**
   * Lyrics
   *
   * The lyrics used for generation.
   */
  lyrics?: string | unknown;
};

/**
 * ExtendInput
 */
export type V2ExtendInput = {
  /**
   * Prompt
   *
   * A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.
   */
  prompt?: string | unknown;
  /**
   * Lyrics Prompt
   *
   * The lyrics sung in the generated song. An empty string will generate an instrumental track.
   */
  lyrics_prompt?: string | unknown;
  /**
   * Tags
   *
   * Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.
   */
  tags?: Array<string> | unknown;
  /**
   * Prompt Strength
   *
   * Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.)
   */
  prompt_strength?: number;
  /**
   * Output Bit Rate
   *
   * The bit rate to use for mp3 and m4a formats. Not available for other formats.
   */
  output_bit_rate?: 128 | 192 | 256 | 320 | unknown;
  /**
   * Num Songs
   *
   * Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed.
   */
  num_songs?: number;
  /**
   * Output Format
   */
  output_format?: "flac" | "mp3" | "wav" | "ogg" | "m4a";
  /**
   * Side
   *
   * Add more to the beginning (left) or end (right) of the song
   */
  side: "left" | "right";
  /**
   * Balance Strength
   *
   * Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7.
   */
  balance_strength?: number;
  /**
   * Crop Duration
   *
   * Duration in seconds to crop from the selected side before extending from that side.
   */
  crop_duration?: number;
  /**
   * Audio Url
   *
   * The URL of the audio file to alter. Must be a valid publicly accessible URL.
   */
  audio_url: string;
  /**
   * Seed
   *
   * The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.
   */
  seed?: number | unknown;
  /**
   * Extend Duration
   *
   * Duration in seconds to extend the song. If not provided, will attempt to automatically determine.
   */
  extend_duration?: number | unknown;
};

/**
 * InpaintOutput
 */
export type StableAudio25InpaintOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: File;
};

/**
 * InpaintInput
 */
export type StableAudio25InpaintInput = {
  /**
   * Prompt
   *
   * The prompt to guide the audio generation
   */
  prompt: string;
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number;
  /**
   * Mask End
   *
   * The end point of the audio mask
   */
  mask_end?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Audio Url
   *
   * The audio clip to inpaint
   */
  audio_url: string;
  /**
   * Seed
   */
  seed?: number;
  /**
   * Seconds Total
   *
   * The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.
   */
  seconds_total?: number;
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number;
  /**
   * Mask Start
   *
   * The start point of the audio mask
   */
  mask_start?: number;
};

/**
 * AudioToAudioOutput
 */
export type StableAudio25AudioToAudioOutput = {
  /**
   * Seed
   *
   * The random seed used for generation
   */
  seed: number;
  /**
   * Audio
   *
   * The generated audio clip
   */
  audio: File;
};

/**
 * AudioToAudioInput
 */
export type StableAudio25AudioToAudioInput = {
  /**
   * Prompt
   *
   * The prompt to guide the audio generation
   */
  prompt: string;
  /**
   * Strength
   *
   * Sometimes referred to as denoising, this parameter controls how much influence the `audio_url` parameter has on the generated audio. A value of 0 would yield audio that is identical to the input. A value of 1 would be as if you passed in no audio at all.
   */
  strength?: number;
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Audio Url
   *
   * The audio clip to transform
   */
  audio_url: string;
  /**
   * Num Inference Steps
   *
   * The number of steps to denoise the audio for
   */
  num_inference_steps?: number;
  /**
   * Guidance Scale
   *
   * How strictly the diffusion process adheres to the prompt text (higher values make your audio closer to your prompt).
   */
  guidance_scale?: number;
  /**
   * Seed
   */
  seed?: number;
  /**
   * Total Seconds
   *
   * The duration of the audio clip to generate. If not provided, it will be set to the duration of the input audio.
   */
  total_seconds?: number;
};

/**
 * AudioUnderstandingOutput
 */
export type AudioUnderstandingOutput = {
  /**
   * Output
   *
   * The analysis of the audio content based on the prompt
   */
  output: string;
};

/**
 * AudioUnderstandingInput
 */
export type AudioUnderstandingInput = {
  /**
   * Prompt
   *
   * The question or prompt about the audio content.
   */
  prompt: string;
  /**
   * Detailed Analysis
   *
   * Whether to request a more detailed analysis of the audio
   */
  detailed_analysis?: boolean;
  /**
   * Audio Url
   *
   * URL of the audio file to analyze
   */
  audio_url: string;
};

/**
 * DemucsOutput
 */
export type DemucsOutput = {
  /**
   * Separated vocals audio file
   */
  vocals?: FileType2 | unknown;
  /**
   * Separated guitar audio file (only available for 6s models)
   */
  guitar?: FileType2 | unknown;
  /**
   * Separated bass audio file
   */
  bass?: FileType2 | unknown;
  /**
   * Separated piano audio file (only available for 6s models)
   */
  piano?: FileType2 | unknown;
  /**
   * Separated other instruments audio file
   */
  other?: FileType2 | unknown;
  /**
   * Separated drums audio file
   */
  drums?: FileType2 | unknown;
};

/**
 * DemucsInput
 */
export type DemucsInput = {
  /**
   * Segment Length
   *
   * Length in seconds of each segment for processing. Smaller values use less memory but may reduce quality. Default is model-specific.
   */
  segment_length?: number | unknown;
  /**
   * Output Format
   *
   * Output audio format for the separated stems
   */
  output_format?: "wav" | "mp3";
  /**
   * Stems
   *
   * Specific stems to extract. If None, extracts all available stems. Available stems depend on model: vocals, drums, bass, other, guitar, piano (for 6s model)
   */
  stems?:
    | Array<"vocals" | "drums" | "bass" | "other" | "guitar" | "piano">
    | unknown;
  /**
   * Overlap
   *
   * Overlap between segments (0.0 to 1.0). Higher values may improve quality but increase processing time.
   */
  overlap?: number;
  /**
   * Model
   *
   * Demucs model to use for separation
   */
  model?:
    | "htdemucs"
    | "htdemucs_ft"
    | "htdemucs_6s"
    | "hdemucs_mmi"
    | "mdx"
    | "mdx_extra"
    | "mdx_q"
    | "mdx_extra_q";
  /**
   * Audio Url
   *
   * URL of the audio file to separate into stems
   */
  audio_url: string;
  /**
   * Shifts
   *
   * Number of random shifts for equivariant stabilization. Higher values improve quality but increase processing time.
   */
  shifts?: number;
};

/**
 * CreateVoiceOutput
 *
 * Response model for creating a custom voice.
 */
export type KlingVideoCreateVoiceOutput = {
  /**
   * Voice Id
   *
   * Unique identifier for the created voice
   */
  voice_id: string;
};

/**
 * CreateVoiceInput
 *
 * Request model for creating a custom voice.
 */
export type KlingVideoCreateVoiceInput = {
  /**
   * Voice Url
   *
   * URL of the voice audio file. Supports .mp3/.wav audio or .mp4/.mov video. Duration must be 5-30 seconds with clean, single-voice audio.
   */
  voice_url: string;
};

/**
 * MergeAudiosOutput
 */
export type FfmpegApiMergeAudiosOutput = {
  audio: FileType2;
};

/**
 * MergeAudiosInput
 */
export type FfmpegApiMergeAudiosInput = {
  /**
   * Audio Urls
   *
   * List of audio URLs to merge in order. The 0th stream of the audio will be considered as the merge candidate.
   */
  audio_urls: Array<string>;
  /**
   * Output Format
   *
   * Output format of the combined audio. If not used, will be determined automatically using FFMPEG. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | "mp3_22050_32"
    | "mp3_44100_32"
    | "mp3_44100_64"
    | "mp3_44100_96"
    | "mp3_44100_128"
    | "mp3_44100_192"
    | "pcm_8000"
    | "pcm_16000"
    | "pcm_22050"
    | "pcm_24000"
    | "pcm_44100"
    | "pcm_48000"
    | "ulaw_8000"
    | "alaw_8000"
    | "opus_48000_32"
    | "opus_48000_64"
    | "opus_48000_96"
    | "opus_48000_128"
    | "opus_48000_192"
    | unknown;
};

/**
 * AudioTimeSpan
 *
 * A time span indicating where the target sound occurs.
 */
export type AudioTimeSpan = {
  /**
   * End
   *
   * End time of the span in seconds
   */
  end: number;
  /**
   * Start
   *
   * Start time of the span in seconds
   */
  start: number;
  /**
   * Include
   *
   * Whether to include (True) or exclude (False) sounds in this span
   */
  include?: boolean;
};

/**
 * SAMAudioSpanSeparateOutput
 *
 * Output for span-based audio separation.
 */
export type SamAudioSpanSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: File;
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number;
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number;
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: File;
};

/**
 * SAMAudioSpanInput
 *
 * Input for temporal span-based audio separation.
 */
export type SamAudioSpanSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt describing the sound to isolate. Optional but recommended - helps the model identify what type of sound to extract from the span.
   */
  prompt?: string;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "fast" | "balanced" | "quality";
  /**
   * Spans
   *
   * Time spans where the target sound occurs which should be isolated.
   */
  spans: Array<AudioTimeSpan>;
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: "wav" | "mp3";
  /**
   * Trim To Span
   *
   * Trim output audio to only include the specified span time range. If False, returns the full audio length with the target sound isolated throughout.
   */
  trim_to_span?: boolean;
  /**
   * Audio Url
   *
   * URL of the audio file to process.
   */
  audio_url: string;
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost. Requires text prompt; ignored for span-only separation.
   */
  reranking_candidates?: number;
};

/**
 * SAMAudioSeparateOutput
 *
 * Output for text-based audio separation.
 */
export type SamAudioSeparateOutput = {
  /**
   * Target
   *
   * The isolated target sound.
   */
  target: File;
  /**
   * Duration
   *
   * Duration of the output audio in seconds.
   */
  duration: number;
  /**
   * Sample Rate
   *
   * Sample rate of the output audio in Hz.
   */
  sample_rate?: number;
  /**
   * Residual
   *
   * Everything else in the audio.
   */
  residual: File;
};

/**
 * SAMAudioInput
 *
 * Input for text-based audio separation.
 */
export type SamAudioSeparateInput = {
  /**
   * Prompt
   *
   * Text prompt describing the sound to isolate.
   */
  prompt: string;
  /**
   * Acceleration
   *
   * The acceleration level to use.
   */
  acceleration?: "fast" | "balanced" | "quality";
  /**
   * Audio Url
   *
   * URL of the audio file to process (WAV, MP3, FLAC supported)
   */
  audio_url: string;
  /**
   * Predict Spans
   *
   * Automatically predict temporal spans where the target sound occurs.
   */
  predict_spans?: boolean;
  /**
   * Output Format
   *
   * Output audio format.
   */
  output_format?: "wav" | "mp3";
  /**
   * Reranking Candidates
   *
   * Number of candidates to generate and rank. Higher improves quality but increases latency and cost.
   */
  reranking_candidates?: number;
};

/**
 * DeepFilterNetTimings
 */
export type DeepFilterNetTimings = {
  /**
   * Postprocess
   *
   * Postprocessing time.
   */
  postprocess: number;
  /**
   * Inference
   *
   * Inference time.
   */
  inference: number;
  /**
   * Preprocess
   *
   * Preprocessing time.
   */
  preprocess: number;
};

/**
 * DeepFilterNet3Output
 */
export type Deepfilternet3Output = {
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: DeepFilterNetTimings;
  /**
   * Audio File
   *
   * The audio file that was enhanced.
   */
  audio_file: AudioFile;
};

/**
 * AudioFile
 */
export type AudioFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Duration
   *
   * The duration of the audio
   */
  duration?: number;
  /**
   * Channels
   *
   * The number of channels in the audio
   */
  channels?: number;
  /**
   * Bitrate
   *
   * The bitrate of the audio (e.g., '192k' or 192000)
   */
  bitrate?: string | number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Sample Rate
   *
   * The sample rate of the audio
   */
  sample_rate?: number;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * DeepFilterNet3Input
 */
export type Deepfilternet3Input = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Audio Format
   *
   * The format for the output audio.
   */
  audio_format?: "mp3" | "aac" | "m4a" | "ogg" | "opus" | "flac" | "wav";
  /**
   * Audio URL
   *
   * The URL of the audio to enhance.
   */
  audio_url: string;
  /**
   * Bitrate
   *
   * The bitrate of the output audio.
   */
  bitrate?: string;
};

/**
 * NovaSRTimings
 */
export type NovaSrTimings = {
  /**
   * Postprocess
   *
   * Time taken to postprocess the audio in seconds.
   */
  postprocess: number;
  /**
   * Inference
   *
   * Time taken to run the inference in seconds.
   */
  inference: number;
  /**
   * Preprocess
   *
   * Time taken to preprocess the audio in seconds.
   */
  preprocess: number;
};

/**
 * NovaSROutput
 */
export type NovaSrOutput = {
  /**
   * Timings
   *
   * Timings for each step in the pipeline.
   */
  timings: NovaSrTimings;
  /**
   * Audio
   *
   * The enhanced audio file.
   */
  audio: AudioFile;
};

/**
 * NovaSRInput
 */
export type NovaSrInput = {
  /**
   * Sync Mode
   *
   * If `True`, the media will be returned as a data URI and the output data won't be available in the request history.
   */
  sync_mode?: boolean;
  /**
   * Bitrate
   *
   * The bitrate of the output audio.
   */
  bitrate?: string;
  /**
   * Audio URL
   *
   * The URL of the audio file to enhance.
   */
  audio_url: string;
  /**
   * Audio Format
   *
   * The format for the output audio.
   */
  audio_format?: "mp3" | "aac" | "m4a" | "ogg" | "opus" | "flac" | "wav";
};

/**
 * VoiceChangerOutput
 */
export type ElevenlabsVoiceChangerOutput = {
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed: number;
  audio: FileType2;
};

/**
 * VoiceChangerRequest
 */
export type ElevenlabsVoiceChangerInput = {
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string;
  /**
   * Audio Url
   *
   * The input audio file
   */
  audio_url: string;
  /**
   * Seed
   *
   * Random seed for reproducibility.
   */
  seed?: number;
  /**
   * Output Format
   *
   * Output format of the generated audio. Formatted as codec_sample_rate_bitrate.
   */
  output_format?:
    | "mp3_22050_32"
    | "mp3_44100_32"
    | "mp3_44100_64"
    | "mp3_44100_96"
    | "mp3_44100_128"
    | "mp3_44100_192"
    | "pcm_8000"
    | "pcm_16000"
    | "pcm_22050"
    | "pcm_24000"
    | "pcm_44100"
    | "pcm_48000"
    | "ulaw_8000"
    | "alaw_8000"
    | "opus_48000_32"
    | "opus_48000_64"
    | "opus_48000_96"
    | "opus_48000_128"
    | "opus_48000_192";
  /**
   * Remove Background Noise
   *
   * If set, will remove the background noise from your audio input using our audio isolation model.
   */
  remove_background_noise?: boolean;
};

export type QueueStatus = {
  status: "IN_QUEUE" | "IN_PROGRESS" | "COMPLETED";
  /**
   * The request id.
   */
  request_id: string;
  /**
   * The response url.
   */
  response_url?: string;
  /**
   * The status url.
   */
  status_url?: string;
  /**
   * The cancel url.
   */
  cancel_url?: string;
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown;
  };
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown;
  };
  /**
   * The queue position.
   */
  queue_position?: number;
};

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/voice-changer/requests/{request_id}/status";
};

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsVoiceChangerRequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/voice-changer/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsVoiceChangerRequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsVoiceChangerData = {
  body: ElevenlabsVoiceChangerInput;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/voice-changer";
};

export type PostFalAiElevenlabsVoiceChangerResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsVoiceChangerResponse =
  PostFalAiElevenlabsVoiceChangerResponses[keyof PostFalAiElevenlabsVoiceChangerResponses];

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/voice-changer/requests/{request_id}";
};

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsVoiceChangerOutput;
};

export type GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponse =
  GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses[keyof GetFalAiElevenlabsVoiceChangerRequestsByRequestIdResponses];

export type GetFalAiNovaSrRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/nova-sr/requests/{request_id}/status";
};

export type GetFalAiNovaSrRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiNovaSrRequestsByRequestIdStatusResponse =
  GetFalAiNovaSrRequestsByRequestIdStatusResponses[keyof GetFalAiNovaSrRequestsByRequestIdStatusResponses];

export type PutFalAiNovaSrRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nova-sr/requests/{request_id}/cancel";
};

export type PutFalAiNovaSrRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiNovaSrRequestsByRequestIdCancelResponse =
  PutFalAiNovaSrRequestsByRequestIdCancelResponses[keyof PutFalAiNovaSrRequestsByRequestIdCancelResponses];

export type PostFalAiNovaSrData = {
  body: NovaSrInput;
  path?: never;
  query?: never;
  url: "/fal-ai/nova-sr";
};

export type PostFalAiNovaSrResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiNovaSrResponse =
  PostFalAiNovaSrResponses[keyof PostFalAiNovaSrResponses];

export type GetFalAiNovaSrRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/nova-sr/requests/{request_id}";
};

export type GetFalAiNovaSrRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: NovaSrOutput;
};

export type GetFalAiNovaSrRequestsByRequestIdResponse =
  GetFalAiNovaSrRequestsByRequestIdResponses[keyof GetFalAiNovaSrRequestsByRequestIdResponses];

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/deepfilternet3/requests/{request_id}/status";
};

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDeepfilternet3RequestsByRequestIdStatusResponse =
  GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses[keyof GetFalAiDeepfilternet3RequestsByRequestIdStatusResponses];

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/deepfilternet3/requests/{request_id}/cancel";
};

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDeepfilternet3RequestsByRequestIdCancelResponse =
  PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses[keyof PutFalAiDeepfilternet3RequestsByRequestIdCancelResponses];

export type PostFalAiDeepfilternet3Data = {
  body: Deepfilternet3Input;
  path?: never;
  query?: never;
  url: "/fal-ai/deepfilternet3";
};

export type PostFalAiDeepfilternet3Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDeepfilternet3Response =
  PostFalAiDeepfilternet3Responses[keyof PostFalAiDeepfilternet3Responses];

export type GetFalAiDeepfilternet3RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/deepfilternet3/requests/{request_id}";
};

export type GetFalAiDeepfilternet3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Deepfilternet3Output;
};

export type GetFalAiDeepfilternet3RequestsByRequestIdResponse =
  GetFalAiDeepfilternet3RequestsByRequestIdResponses[keyof GetFalAiDeepfilternet3RequestsByRequestIdResponses];

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam-audio/separate/requests/{request_id}/status";
};

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioSeparateRequestsByRequestIdStatusResponses];

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/separate/requests/{request_id}/cancel";
};

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioSeparateRequestsByRequestIdCancelResponses];

export type PostFalAiSamAudioSeparateData = {
  body: SamAudioSeparateInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam-audio/separate";
};

export type PostFalAiSamAudioSeparateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSamAudioSeparateResponse =
  PostFalAiSamAudioSeparateResponses[keyof PostFalAiSamAudioSeparateResponses];

export type GetFalAiSamAudioSeparateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/separate/requests/{request_id}";
};

export type GetFalAiSamAudioSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SamAudioSeparateOutput;
};

export type GetFalAiSamAudioSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioSeparateRequestsByRequestIdResponses];

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam-audio/span-separate/requests/{request_id}/status";
};

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioSpanSeparateRequestsByRequestIdStatusResponses];

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/span-separate/requests/{request_id}/cancel";
};

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioSpanSeparateRequestsByRequestIdCancelResponses];

export type PostFalAiSamAudioSpanSeparateData = {
  body: SamAudioSpanSeparateInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam-audio/span-separate";
};

export type PostFalAiSamAudioSpanSeparateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSamAudioSpanSeparateResponse =
  PostFalAiSamAudioSpanSeparateResponses[keyof PostFalAiSamAudioSpanSeparateResponses];

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/span-separate/requests/{request_id}";
};

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SamAudioSpanSeparateOutput;
};

export type GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioSpanSeparateRequestsByRequestIdResponses];

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}/status";
};

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponse =
  GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses[keyof GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdStatusResponses];

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}/cancel";
};

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponse =
  PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses[keyof PutFalAiFfmpegApiMergeAudiosRequestsByRequestIdCancelResponses];

export type PostFalAiFfmpegApiMergeAudiosData = {
  body: FfmpegApiMergeAudiosInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ffmpeg-api/merge-audios";
};

export type PostFalAiFfmpegApiMergeAudiosResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiFfmpegApiMergeAudiosResponse =
  PostFalAiFfmpegApiMergeAudiosResponses[keyof PostFalAiFfmpegApiMergeAudiosResponses];

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ffmpeg-api/merge-audios/requests/{request_id}";
};

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: FfmpegApiMergeAudiosOutput;
};

export type GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponse =
  GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses[keyof GetFalAiFfmpegApiMergeAudiosRequestsByRequestIdResponses];

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kling-video/create-voice/requests/{request_id}/status";
};

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoCreateVoiceRequestsByRequestIdStatusResponses];

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/create-voice/requests/{request_id}/cancel";
};

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoCreateVoiceRequestsByRequestIdCancelResponses];

export type PostFalAiKlingVideoCreateVoiceData = {
  body: KlingVideoCreateVoiceInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kling-video/create-voice";
};

export type PostFalAiKlingVideoCreateVoiceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKlingVideoCreateVoiceResponse =
  PostFalAiKlingVideoCreateVoiceResponses[keyof PostFalAiKlingVideoCreateVoiceResponses];

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/create-voice/requests/{request_id}";
};

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KlingVideoCreateVoiceOutput;
};

export type GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponse =
  GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses[keyof GetFalAiKlingVideoCreateVoiceRequestsByRequestIdResponses];

export type GetFalAiDemucsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/demucs/requests/{request_id}/status";
};

export type GetFalAiDemucsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDemucsRequestsByRequestIdStatusResponse =
  GetFalAiDemucsRequestsByRequestIdStatusResponses[keyof GetFalAiDemucsRequestsByRequestIdStatusResponses];

export type PutFalAiDemucsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/demucs/requests/{request_id}/cancel";
};

export type PutFalAiDemucsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDemucsRequestsByRequestIdCancelResponse =
  PutFalAiDemucsRequestsByRequestIdCancelResponses[keyof PutFalAiDemucsRequestsByRequestIdCancelResponses];

export type PostFalAiDemucsData = {
  body: DemucsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/demucs";
};

export type PostFalAiDemucsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDemucsResponse =
  PostFalAiDemucsResponses[keyof PostFalAiDemucsResponses];

export type GetFalAiDemucsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/demucs/requests/{request_id}";
};

export type GetFalAiDemucsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DemucsOutput;
};

export type GetFalAiDemucsRequestsByRequestIdResponse =
  GetFalAiDemucsRequestsByRequestIdResponses[keyof GetFalAiDemucsRequestsByRequestIdResponses];

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/audio-understanding/requests/{request_id}/status";
};

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponse =
  GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses[keyof GetFalAiAudioUnderstandingRequestsByRequestIdStatusResponses];

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/audio-understanding/requests/{request_id}/cancel";
};

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponse =
  PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses[keyof PutFalAiAudioUnderstandingRequestsByRequestIdCancelResponses];

export type PostFalAiAudioUnderstandingData = {
  body: AudioUnderstandingInput;
  path?: never;
  query?: never;
  url: "/fal-ai/audio-understanding";
};

export type PostFalAiAudioUnderstandingResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAudioUnderstandingResponse =
  PostFalAiAudioUnderstandingResponses[keyof PostFalAiAudioUnderstandingResponses];

export type GetFalAiAudioUnderstandingRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/audio-understanding/requests/{request_id}";
};

export type GetFalAiAudioUnderstandingRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AudioUnderstandingOutput;
};

export type GetFalAiAudioUnderstandingRequestsByRequestIdResponse =
  GetFalAiAudioUnderstandingRequestsByRequestIdResponses[keyof GetFalAiAudioUnderstandingRequestsByRequestIdResponses];

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}/status";
};

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25AudioToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25AudioToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiStableAudio25AudioToAudioData = {
  body: StableAudio25AudioToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-audio-25/audio-to-audio";
};

export type PostFalAiStableAudio25AudioToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableAudio25AudioToAudioResponse =
  PostFalAiStableAudio25AudioToAudioResponses[keyof PostFalAiStableAudio25AudioToAudioResponses];

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/audio-to-audio/requests/{request_id}";
};

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableAudio25AudioToAudioOutput;
};

export type GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponse =
  GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudio25AudioToAudioRequestsByRequestIdResponses];

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-audio-25/inpaint/requests/{request_id}/status";
};

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25InpaintRequestsByRequestIdStatusResponses];

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/inpaint/requests/{request_id}/cancel";
};

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25InpaintRequestsByRequestIdCancelResponses];

export type PostFalAiStableAudio25InpaintData = {
  body: StableAudio25InpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-audio-25/inpaint";
};

export type PostFalAiStableAudio25InpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableAudio25InpaintResponse =
  PostFalAiStableAudio25InpaintResponses[keyof PostFalAiStableAudio25InpaintResponses];

export type GetFalAiStableAudio25InpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/inpaint/requests/{request_id}";
};

export type GetFalAiStableAudio25InpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableAudio25InpaintOutput;
};

export type GetFalAiStableAudio25InpaintRequestsByRequestIdResponse =
  GetFalAiStableAudio25InpaintRequestsByRequestIdResponses[keyof GetFalAiStableAudio25InpaintRequestsByRequestIdResponses];

export type GetSonautoV2ExtendRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/sonauto/v2/extend/requests/{request_id}/status";
};

export type GetSonautoV2ExtendRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetSonautoV2ExtendRequestsByRequestIdStatusResponse =
  GetSonautoV2ExtendRequestsByRequestIdStatusResponses[keyof GetSonautoV2ExtendRequestsByRequestIdStatusResponses];

export type PutSonautoV2ExtendRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/extend/requests/{request_id}/cancel";
};

export type PutSonautoV2ExtendRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutSonautoV2ExtendRequestsByRequestIdCancelResponse =
  PutSonautoV2ExtendRequestsByRequestIdCancelResponses[keyof PutSonautoV2ExtendRequestsByRequestIdCancelResponses];

export type PostSonautoV2ExtendData = {
  body: V2ExtendInput;
  path?: never;
  query?: never;
  url: "/sonauto/v2/extend";
};

export type PostSonautoV2ExtendResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostSonautoV2ExtendResponse =
  PostSonautoV2ExtendResponses[keyof PostSonautoV2ExtendResponses];

export type GetSonautoV2ExtendRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/extend/requests/{request_id}";
};

export type GetSonautoV2ExtendRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: V2ExtendOutput;
};

export type GetSonautoV2ExtendRequestsByRequestIdResponse =
  GetSonautoV2ExtendRequestsByRequestIdResponses[keyof GetSonautoV2ExtendRequestsByRequestIdResponses];

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ace-step/audio-outpaint/requests/{request_id}/status";
};

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioOutpaintRequestsByRequestIdStatusResponses];

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-outpaint/requests/{request_id}/cancel";
};

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioOutpaintRequestsByRequestIdCancelResponses];

export type PostFalAiAceStepAudioOutpaintData = {
  body: AceStepAudioOutpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ace-step/audio-outpaint";
};

export type PostFalAiAceStepAudioOutpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAceStepAudioOutpaintResponse =
  PostFalAiAceStepAudioOutpaintResponses[keyof PostFalAiAceStepAudioOutpaintResponses];

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-outpaint/requests/{request_id}";
};

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AceStepAudioOutpaintOutput;
};

export type GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponse =
  GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioOutpaintRequestsByRequestIdResponses];

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ace-step/audio-inpaint/requests/{request_id}/status";
};

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioInpaintRequestsByRequestIdStatusResponses];

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-inpaint/requests/{request_id}/cancel";
};

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioInpaintRequestsByRequestIdCancelResponses];

export type PostFalAiAceStepAudioInpaintData = {
  body: AceStepAudioInpaintInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ace-step/audio-inpaint";
};

export type PostFalAiAceStepAudioInpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAceStepAudioInpaintResponse =
  PostFalAiAceStepAudioInpaintResponses[keyof PostFalAiAceStepAudioInpaintResponses];

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-inpaint/requests/{request_id}";
};

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AceStepAudioInpaintOutput;
};

export type GetFalAiAceStepAudioInpaintRequestsByRequestIdResponse =
  GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioInpaintRequestsByRequestIdResponses];

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ace-step/audio-to-audio/requests/{request_id}/status";
};

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponse =
  GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepAudioToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponse =
  PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepAudioToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiAceStepAudioToAudioData = {
  body: AceStepAudioToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ace-step/audio-to-audio";
};

export type PostFalAiAceStepAudioToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAceStepAudioToAudioResponse =
  PostFalAiAceStepAudioToAudioResponses[keyof PostFalAiAceStepAudioToAudioResponses];

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/audio-to-audio/requests/{request_id}";
};

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AceStepAudioToAudioOutput;
};

export type GetFalAiAceStepAudioToAudioRequestsByRequestIdResponse =
  GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses[keyof GetFalAiAceStepAudioToAudioRequestsByRequestIdResponses];

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dia-tts/voice-clone/requests/{request_id}/status";
};

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponse =
  GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses[keyof GetFalAiDiaTtsVoiceCloneRequestsByRequestIdStatusResponses];

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dia-tts/voice-clone/requests/{request_id}/cancel";
};

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponse =
  PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses[keyof PutFalAiDiaTtsVoiceCloneRequestsByRequestIdCancelResponses];

export type PostFalAiDiaTtsVoiceCloneData = {
  body: DiaTtsVoiceCloneInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dia-tts/voice-clone";
};

export type PostFalAiDiaTtsVoiceCloneResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDiaTtsVoiceCloneResponse =
  PostFalAiDiaTtsVoiceCloneResponses[keyof PostFalAiDiaTtsVoiceCloneResponses];

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dia-tts/voice-clone/requests/{request_id}";
};

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DiaTtsVoiceCloneOutput;
};

export type GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponse =
  GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses[keyof GetFalAiDiaTtsVoiceCloneRequestsByRequestIdResponses];

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/audio-isolation/requests/{request_id}/status";
};

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsAudioIsolationRequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/audio-isolation/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsAudioIsolationRequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsAudioIsolationData = {
  body: ElevenlabsAudioIsolationInput;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/audio-isolation";
};

export type PostFalAiElevenlabsAudioIsolationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsAudioIsolationResponse =
  PostFalAiElevenlabsAudioIsolationResponses[keyof PostFalAiElevenlabsAudioIsolationResponses];

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/audio-isolation/requests/{request_id}";
};

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsAudioIsolationOutput;
};

export type GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponse =
  GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses[keyof GetFalAiElevenlabsAudioIsolationRequestsByRequestIdResponses];

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/music/requests/{request_id}/status";
};

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/music/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsMusicRequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsMusicData = {
  body: ElevenlabsMusicInput;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/music";
};

export type PostFalAiElevenlabsMusicResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsMusicResponse =
  PostFalAiElevenlabsMusicResponses[keyof PostFalAiElevenlabsMusicResponses];

export type GetFalAiElevenlabsMusicRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/music/requests/{request_id}";
};

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsMusicOutput;
};

export type GetFalAiElevenlabsMusicRequestsByRequestIdResponse =
  GetFalAiElevenlabsMusicRequestsByRequestIdResponses[keyof GetFalAiElevenlabsMusicRequestsByRequestIdResponses];

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax-music/v2/requests/{request_id}/status";
};

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/v2/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV2RequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxMusicV2Data = {
  body: MinimaxMusicV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax-music/v2";
};

export type PostFalAiMinimaxMusicV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxMusicV2Response =
  PostFalAiMinimaxMusicV2Responses[keyof PostFalAiMinimaxMusicV2Responses];

export type GetFalAiMinimaxMusicV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/v2/requests/{request_id}";
};

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxMusicV2Output;
};

export type GetFalAiMinimaxMusicV2RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV2RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV2RequestsByRequestIdResponses];

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/beatoven/sound-effect-generation/requests/{request_id}/status";
};

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdStatusResponses];

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/beatoven/sound-effect-generation/requests/{request_id}/cancel";
};

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenSoundEffectGenerationRequestsByRequestIdCancelResponses];

export type PostBeatovenSoundEffectGenerationData = {
  body: SoundEffectGenerationInput;
  path?: never;
  query?: never;
  url: "/beatoven/sound-effect-generation";
};

export type PostBeatovenSoundEffectGenerationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBeatovenSoundEffectGenerationResponse =
  PostBeatovenSoundEffectGenerationResponses[keyof PostBeatovenSoundEffectGenerationResponses];

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/beatoven/sound-effect-generation/requests/{request_id}";
};

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SoundEffectGenerationOutput;
};

export type GetBeatovenSoundEffectGenerationRequestsByRequestIdResponse =
  GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses[keyof GetBeatovenSoundEffectGenerationRequestsByRequestIdResponses];

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/beatoven/music-generation/requests/{request_id}/status";
};

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetBeatovenMusicGenerationRequestsByRequestIdStatusResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdStatusResponses];

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/beatoven/music-generation/requests/{request_id}/cancel";
};

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutBeatovenMusicGenerationRequestsByRequestIdCancelResponse =
  PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses[keyof PutBeatovenMusicGenerationRequestsByRequestIdCancelResponses];

export type PostBeatovenMusicGenerationData = {
  body: MusicGenerationInput;
  path?: never;
  query?: never;
  url: "/beatoven/music-generation";
};

export type PostBeatovenMusicGenerationResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostBeatovenMusicGenerationResponse =
  PostBeatovenMusicGenerationResponses[keyof PostBeatovenMusicGenerationResponses];

export type GetBeatovenMusicGenerationRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/beatoven/music-generation/requests/{request_id}";
};

export type GetBeatovenMusicGenerationRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MusicGenerationOutput;
};

export type GetBeatovenMusicGenerationRequestsByRequestIdResponse =
  GetBeatovenMusicGenerationRequestsByRequestIdResponses[keyof GetBeatovenMusicGenerationRequestsByRequestIdResponses];

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax-music/v1.5/requests/{request_id}/status";
};

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/v1.5/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicV15RequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxMusicV15Data = {
  body: MinimaxMusicV15Input;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax-music/v1.5";
};

export type PostFalAiMinimaxMusicV15Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxMusicV15Response =
  PostFalAiMinimaxMusicV15Responses[keyof PostFalAiMinimaxMusicV15Responses];

export type GetFalAiMinimaxMusicV15RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/v1.5/requests/{request_id}";
};

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxMusicV15Output;
};

export type GetFalAiMinimaxMusicV15RequestsByRequestIdResponse =
  GetFalAiMinimaxMusicV15RequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicV15RequestsByRequestIdResponses];

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/status";
};

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudio25TextToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiStableAudio25TextToAudioData = {
  body: StableAudio25TextToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-audio-25/text-to-audio";
};

export type PostFalAiStableAudio25TextToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableAudio25TextToAudioResponse =
  PostFalAiStableAudio25TextToAudioResponses[keyof PostFalAiStableAudio25TextToAudioResponses];

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio-25/text-to-audio/requests/{request_id}";
};

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableAudio25TextToAudioOutput;
};

export type GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponse =
  GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudio25TextToAudioRequestsByRequestIdResponses];

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/status";
  };

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}/cancel";
  };

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsTextToDialogueElevenV3Data = {
  body: ElevenlabsTextToDialogueElevenV3Input;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/text-to-dialogue/eleven-v3";
};

export type PostFalAiElevenlabsTextToDialogueElevenV3Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsTextToDialogueElevenV3Response =
  PostFalAiElevenlabsTextToDialogueElevenV3Responses[keyof PostFalAiElevenlabsTextToDialogueElevenV3Responses];

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/text-to-dialogue/eleven-v3/requests/{request_id}";
};

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ElevenlabsTextToDialogueElevenV3Output;
  };

export type GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTextToDialogueElevenV3RequestsByRequestIdResponses];

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/status";
};

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsSoundEffectsV2RequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsSoundEffectsV2Data = {
  body: ElevenlabsSoundEffectsV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/sound-effects/v2";
};

export type PostFalAiElevenlabsSoundEffectsV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsSoundEffectsV2Response =
  PostFalAiElevenlabsSoundEffectsV2Responses[keyof PostFalAiElevenlabsSoundEffectsV2Responses];

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/sound-effects/v2/requests/{request_id}";
};

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsSoundEffectsV2Output;
};

export type GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsSoundEffectsV2RequestsByRequestIdResponses];

export type GetSonautoV2InpaintRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/sonauto/v2/inpaint/requests/{request_id}/status";
};

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetSonautoV2InpaintRequestsByRequestIdStatusResponse =
  GetSonautoV2InpaintRequestsByRequestIdStatusResponses[keyof GetSonautoV2InpaintRequestsByRequestIdStatusResponses];

export type PutSonautoV2InpaintRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/inpaint/requests/{request_id}/cancel";
};

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutSonautoV2InpaintRequestsByRequestIdCancelResponse =
  PutSonautoV2InpaintRequestsByRequestIdCancelResponses[keyof PutSonautoV2InpaintRequestsByRequestIdCancelResponses];

export type PostSonautoV2InpaintData = {
  body: V2InpaintInput;
  path?: never;
  query?: never;
  url: "/sonauto/v2/inpaint";
};

export type PostSonautoV2InpaintResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostSonautoV2InpaintResponse =
  PostSonautoV2InpaintResponses[keyof PostSonautoV2InpaintResponses];

export type GetSonautoV2InpaintRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/inpaint/requests/{request_id}";
};

export type GetSonautoV2InpaintRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: V2InpaintOutput;
};

export type GetSonautoV2InpaintRequestsByRequestIdResponse =
  GetSonautoV2InpaintRequestsByRequestIdResponses[keyof GetSonautoV2InpaintRequestsByRequestIdResponses];

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/sonauto/v2/text-to-music/requests/{request_id}/status";
};

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetSonautoV2TextToMusicRequestsByRequestIdStatusResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdStatusResponses];

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/text-to-music/requests/{request_id}/cancel";
};

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutSonautoV2TextToMusicRequestsByRequestIdCancelResponse =
  PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses[keyof PutSonautoV2TextToMusicRequestsByRequestIdCancelResponses];

export type PostSonautoV2TextToMusicData = {
  body: V2TextToMusicInput;
  path?: never;
  query?: never;
  url: "/sonauto/v2/text-to-music";
};

export type PostSonautoV2TextToMusicResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostSonautoV2TextToMusicResponse =
  PostSonautoV2TextToMusicResponses[keyof PostSonautoV2TextToMusicResponses];

export type GetSonautoV2TextToMusicRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/sonauto/v2/text-to-music/requests/{request_id}";
};

export type GetSonautoV2TextToMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: V2TextToMusicOutput;
};

export type GetSonautoV2TextToMusicRequestsByRequestIdResponse =
  GetSonautoV2TextToMusicRequestsByRequestIdResponses[keyof GetSonautoV2TextToMusicRequestsByRequestIdResponses];

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/status";
};

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsElevenV3RequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsTtsElevenV3Data = {
  body: ElevenlabsTtsElevenV3Input;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/tts/eleven-v3";
};

export type PostFalAiElevenlabsTtsElevenV3Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsTtsElevenV3Response =
  PostFalAiElevenlabsTtsElevenV3Responses[keyof PostFalAiElevenlabsTtsElevenV3Responses];

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/eleven-v3/requests/{request_id}";
};

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsTtsElevenV3Output;
};

export type GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsElevenV3RequestsByRequestIdResponses];

export type GetFalAiLyria2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/lyria2/requests/{request_id}/status";
};

export type GetFalAiLyria2RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiLyria2RequestsByRequestIdStatusResponse =
  GetFalAiLyria2RequestsByRequestIdStatusResponses[keyof GetFalAiLyria2RequestsByRequestIdStatusResponses];

export type PutFalAiLyria2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lyria2/requests/{request_id}/cancel";
};

export type PutFalAiLyria2RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiLyria2RequestsByRequestIdCancelResponse =
  PutFalAiLyria2RequestsByRequestIdCancelResponses[keyof PutFalAiLyria2RequestsByRequestIdCancelResponses];

export type PostFalAiLyria2Data = {
  body: Lyria2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/lyria2";
};

export type PostFalAiLyria2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiLyria2Response =
  PostFalAiLyria2Responses[keyof PostFalAiLyria2Responses];

export type GetFalAiLyria2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/lyria2/requests/{request_id}";
};

export type GetFalAiLyria2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Lyria2Output;
};

export type GetFalAiLyria2RequestsByRequestIdResponse =
  GetFalAiLyria2RequestsByRequestIdResponses[keyof GetFalAiLyria2RequestsByRequestIdResponses];

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/status";
};

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/prompt-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponse =
  PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepPromptToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiAceStepPromptToAudioData = {
  body: AceStepPromptToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ace-step/prompt-to-audio";
};

export type PostFalAiAceStepPromptToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAceStepPromptToAudioResponse =
  PostFalAiAceStepPromptToAudioResponses[keyof PostFalAiAceStepPromptToAudioResponses];

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/prompt-to-audio/requests/{request_id}";
};

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AceStepPromptToAudioOutput;
};

export type GetFalAiAceStepPromptToAudioRequestsByRequestIdResponse =
  GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses[keyof GetFalAiAceStepPromptToAudioRequestsByRequestIdResponses];

export type GetFalAiAceStepRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/ace-step/requests/{request_id}/status";
};

export type GetFalAiAceStepRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiAceStepRequestsByRequestIdStatusResponse =
  GetFalAiAceStepRequestsByRequestIdStatusResponses[keyof GetFalAiAceStepRequestsByRequestIdStatusResponses];

export type PutFalAiAceStepRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/requests/{request_id}/cancel";
};

export type PutFalAiAceStepRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiAceStepRequestsByRequestIdCancelResponse =
  PutFalAiAceStepRequestsByRequestIdCancelResponses[keyof PutFalAiAceStepRequestsByRequestIdCancelResponses];

export type PostFalAiAceStepData = {
  body: AceStepInput;
  path?: never;
  query?: never;
  url: "/fal-ai/ace-step";
};

export type PostFalAiAceStepResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiAceStepResponse =
  PostFalAiAceStepResponses[keyof PostFalAiAceStepResponses];

export type GetFalAiAceStepRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/ace-step/requests/{request_id}";
};

export type GetFalAiAceStepRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: AceStepOutput;
};

export type GetFalAiAceStepRequestsByRequestIdResponse =
  GetFalAiAceStepRequestsByRequestIdResponses[keyof GetFalAiAceStepRequestsByRequestIdResponses];

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/cassetteai/sound-effects-generator/requests/{request_id}/status";
};

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdStatusResponses];

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/cassetteai/sound-effects-generator/requests/{request_id}/cancel";
};

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiSoundEffectsGeneratorRequestsByRequestIdCancelResponses];

export type PostCassetteaiSoundEffectsGeneratorData = {
  body: SoundEffectsGeneratorInput;
  path?: never;
  query?: never;
  url: "/cassetteai/sound-effects-generator";
};

export type PostCassetteaiSoundEffectsGeneratorResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostCassetteaiSoundEffectsGeneratorResponse =
  PostCassetteaiSoundEffectsGeneratorResponses[keyof PostCassetteaiSoundEffectsGeneratorResponses];

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/cassetteai/sound-effects-generator/requests/{request_id}";
};

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SoundEffectsGeneratorOutput;
};

export type GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponse =
  GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiSoundEffectsGeneratorRequestsByRequestIdResponses];

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/cassetteai/music-generator/requests/{request_id}/status";
};

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdStatusResponses];

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/cassetteai/music-generator/requests/{request_id}/cancel";
};

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponse =
  PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses[keyof PutCassetteaiMusicGeneratorRequestsByRequestIdCancelResponses];

export type PostCassetteaiMusicGeneratorData = {
  body: MusicGeneratorInput;
  path?: never;
  query?: never;
  url: "/cassetteai/music-generator";
};

export type PostCassetteaiMusicGeneratorResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostCassetteaiMusicGeneratorResponse =
  PostCassetteaiMusicGeneratorResponses[keyof PostCassetteaiMusicGeneratorResponses];

export type GetCassetteaiMusicGeneratorRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/cassetteai/music-generator/requests/{request_id}";
};

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MusicGeneratorOutput;
};

export type GetCassetteaiMusicGeneratorRequestsByRequestIdResponse =
  GetCassetteaiMusicGeneratorRequestsByRequestIdResponses[keyof GetCassetteaiMusicGeneratorRequestsByRequestIdResponses];

export type GetFalAiCsm1bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/csm-1b/requests/{request_id}/status";
};

export type GetFalAiCsm1bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiCsm1bRequestsByRequestIdStatusResponse =
  GetFalAiCsm1bRequestsByRequestIdStatusResponses[keyof GetFalAiCsm1bRequestsByRequestIdStatusResponses];

export type PutFalAiCsm1bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/csm-1b/requests/{request_id}/cancel";
};

export type PutFalAiCsm1bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiCsm1bRequestsByRequestIdCancelResponse =
  PutFalAiCsm1bRequestsByRequestIdCancelResponses[keyof PutFalAiCsm1bRequestsByRequestIdCancelResponses];

export type PostFalAiCsm1bData = {
  body: Csm1bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/csm-1b";
};

export type PostFalAiCsm1bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiCsm1bResponse =
  PostFalAiCsm1bResponses[keyof PostFalAiCsm1bResponses];

export type GetFalAiCsm1bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/csm-1b/requests/{request_id}";
};

export type GetFalAiCsm1bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Csm1bOutput;
};

export type GetFalAiCsm1bRequestsByRequestIdResponse =
  GetFalAiCsm1bRequestsByRequestIdResponses[keyof GetFalAiCsm1bRequestsByRequestIdResponses];

export type GetFalAiDiffrhythmRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/diffrhythm/requests/{request_id}/status";
};

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDiffrhythmRequestsByRequestIdStatusResponse =
  GetFalAiDiffrhythmRequestsByRequestIdStatusResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdStatusResponses];

export type PutFalAiDiffrhythmRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/diffrhythm/requests/{request_id}/cancel";
};

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDiffrhythmRequestsByRequestIdCancelResponse =
  PutFalAiDiffrhythmRequestsByRequestIdCancelResponses[keyof PutFalAiDiffrhythmRequestsByRequestIdCancelResponses];

export type PostFalAiDiffrhythmData = {
  body: DiffrhythmInput;
  path?: never;
  query?: never;
  url: "/fal-ai/diffrhythm";
};

export type PostFalAiDiffrhythmResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDiffrhythmResponse =
  PostFalAiDiffrhythmResponses[keyof PostFalAiDiffrhythmResponses];

export type GetFalAiDiffrhythmRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/diffrhythm/requests/{request_id}";
};

export type GetFalAiDiffrhythmRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DiffrhythmOutput;
};

export type GetFalAiDiffrhythmRequestsByRequestIdResponse =
  GetFalAiDiffrhythmRequestsByRequestIdResponses[keyof GetFalAiDiffrhythmRequestsByRequestIdResponses];

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/status";
};

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsTtsMultilingualV2Data = {
  body: ElevenlabsTtsMultilingualV2Input;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/tts/multilingual-v2";
};

export type PostFalAiElevenlabsTtsMultilingualV2Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsTtsMultilingualV2Response =
  PostFalAiElevenlabsTtsMultilingualV2Responses[keyof PostFalAiElevenlabsTtsMultilingualV2Responses];

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/multilingual-v2/requests/{request_id}";
};

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsTtsMultilingualV2Output;
};

export type GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsMultilingualV2RequestsByRequestIdResponses];

export type GetFalAiKokoroHindiRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/hindi/requests/{request_id}/status";
};

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroHindiRequestsByRequestIdStatusResponse =
  GetFalAiKokoroHindiRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroHindiRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/hindi/requests/{request_id}/cancel";
};

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroHindiRequestsByRequestIdCancelResponse =
  PutFalAiKokoroHindiRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroHindiRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroHindiData = {
  body: KokoroHindiInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/hindi";
};

export type PostFalAiKokoroHindiResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroHindiResponse =
  PostFalAiKokoroHindiResponses[keyof PostFalAiKokoroHindiResponses];

export type GetFalAiKokoroHindiRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/hindi/requests/{request_id}";
};

export type GetFalAiKokoroHindiRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroHindiOutput;
};

export type GetFalAiKokoroHindiRequestsByRequestIdResponse =
  GetFalAiKokoroHindiRequestsByRequestIdResponses[keyof GetFalAiKokoroHindiRequestsByRequestIdResponses];

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/british-english/requests/{request_id}/status";
};

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/british-english/requests/{request_id}/cancel";
};

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBritishEnglishRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroBritishEnglishData = {
  body: KokoroBritishEnglishInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/british-english";
};

export type PostFalAiKokoroBritishEnglishResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroBritishEnglishResponse =
  PostFalAiKokoroBritishEnglishResponses[keyof PostFalAiKokoroBritishEnglishResponses];

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/british-english/requests/{request_id}";
};

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroBritishEnglishOutput;
};

export type GetFalAiKokoroBritishEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroBritishEnglishRequestsByRequestIdResponses];

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/american-english/requests/{request_id}/status";
};

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/american-english/requests/{request_id}/cancel";
};

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroAmericanEnglishRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroAmericanEnglishData = {
  body: KokoroAmericanEnglishInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/american-english";
};

export type PostFalAiKokoroAmericanEnglishResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroAmericanEnglishResponse =
  PostFalAiKokoroAmericanEnglishResponses[keyof PostFalAiKokoroAmericanEnglishResponses];

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/american-english/requests/{request_id}";
};

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroAmericanEnglishOutput;
};

export type GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponse =
  GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses[keyof GetFalAiKokoroAmericanEnglishRequestsByRequestIdResponses];

export type GetFalAiZonosRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/zonos/requests/{request_id}/status";
};

export type GetFalAiZonosRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiZonosRequestsByRequestIdStatusResponse =
  GetFalAiZonosRequestsByRequestIdStatusResponses[keyof GetFalAiZonosRequestsByRequestIdStatusResponses];

export type PutFalAiZonosRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/zonos/requests/{request_id}/cancel";
};

export type PutFalAiZonosRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiZonosRequestsByRequestIdCancelResponse =
  PutFalAiZonosRequestsByRequestIdCancelResponses[keyof PutFalAiZonosRequestsByRequestIdCancelResponses];

export type PostFalAiZonosData = {
  body: ZonosInput;
  path?: never;
  query?: never;
  url: "/fal-ai/zonos";
};

export type PostFalAiZonosResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiZonosResponse =
  PostFalAiZonosResponses[keyof PostFalAiZonosResponses];

export type GetFalAiZonosRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/zonos/requests/{request_id}";
};

export type GetFalAiZonosRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ZonosOutput;
};

export type GetFalAiZonosRequestsByRequestIdResponse =
  GetFalAiZonosRequestsByRequestIdResponses[keyof GetFalAiZonosRequestsByRequestIdResponses];

export type GetFalAiKokoroItalianRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/italian/requests/{request_id}/status";
};

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroItalianRequestsByRequestIdStatusResponse =
  GetFalAiKokoroItalianRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroItalianRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/italian/requests/{request_id}/cancel";
};

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroItalianRequestsByRequestIdCancelResponse =
  PutFalAiKokoroItalianRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroItalianRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroItalianData = {
  body: KokoroItalianInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/italian";
};

export type PostFalAiKokoroItalianResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroItalianResponse =
  PostFalAiKokoroItalianResponses[keyof PostFalAiKokoroItalianResponses];

export type GetFalAiKokoroItalianRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/italian/requests/{request_id}";
};

export type GetFalAiKokoroItalianRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroItalianOutput;
};

export type GetFalAiKokoroItalianRequestsByRequestIdResponse =
  GetFalAiKokoroItalianRequestsByRequestIdResponses[keyof GetFalAiKokoroItalianRequestsByRequestIdResponses];

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/status";
};

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}/cancel";
};

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroBrazilianPortugueseRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroBrazilianPortugueseData = {
  body: KokoroBrazilianPortugueseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/brazilian-portuguese";
};

export type PostFalAiKokoroBrazilianPortugueseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroBrazilianPortugueseResponse =
  PostFalAiKokoroBrazilianPortugueseResponses[keyof PostFalAiKokoroBrazilianPortugueseResponses];

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/brazilian-portuguese/requests/{request_id}";
};

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroBrazilianPortugueseOutput;
};

export type GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponse =
  GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses[keyof GetFalAiKokoroBrazilianPortugueseRequestsByRequestIdResponses];

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/french/requests/{request_id}/status";
};

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroFrenchRequestsByRequestIdStatusResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/french/requests/{request_id}/cancel";
};

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroFrenchRequestsByRequestIdCancelResponse =
  PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroFrenchRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroFrenchData = {
  body: KokoroFrenchInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/french";
};

export type PostFalAiKokoroFrenchResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroFrenchResponse =
  PostFalAiKokoroFrenchResponses[keyof PostFalAiKokoroFrenchResponses];

export type GetFalAiKokoroFrenchRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/french/requests/{request_id}";
};

export type GetFalAiKokoroFrenchRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroFrenchOutput;
};

export type GetFalAiKokoroFrenchRequestsByRequestIdResponse =
  GetFalAiKokoroFrenchRequestsByRequestIdResponses[keyof GetFalAiKokoroFrenchRequestsByRequestIdResponses];

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/japanese/requests/{request_id}/status";
};

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/japanese/requests/{request_id}/cancel";
};

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroJapaneseRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroJapaneseData = {
  body: KokoroJapaneseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/japanese";
};

export type PostFalAiKokoroJapaneseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroJapaneseResponse =
  PostFalAiKokoroJapaneseResponses[keyof PostFalAiKokoroJapaneseResponses];

export type GetFalAiKokoroJapaneseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/japanese/requests/{request_id}";
};

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroJapaneseOutput;
};

export type GetFalAiKokoroJapaneseRequestsByRequestIdResponse =
  GetFalAiKokoroJapaneseRequestsByRequestIdResponses[keyof GetFalAiKokoroJapaneseRequestsByRequestIdResponses];

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/status";
};

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/mandarin-chinese/requests/{request_id}/cancel";
};

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponse =
  PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroMandarinChineseRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroMandarinChineseData = {
  body: KokoroMandarinChineseInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/mandarin-chinese";
};

export type PostFalAiKokoroMandarinChineseResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroMandarinChineseResponse =
  PostFalAiKokoroMandarinChineseResponses[keyof PostFalAiKokoroMandarinChineseResponses];

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/mandarin-chinese/requests/{request_id}";
};

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroMandarinChineseOutput;
};

export type GetFalAiKokoroMandarinChineseRequestsByRequestIdResponse =
  GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses[keyof GetFalAiKokoroMandarinChineseRequestsByRequestIdResponses];

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kokoro/spanish/requests/{request_id}/status";
};

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKokoroSpanishRequestsByRequestIdStatusResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdStatusResponses];

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/spanish/requests/{request_id}/cancel";
};

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKokoroSpanishRequestsByRequestIdCancelResponse =
  PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses[keyof PutFalAiKokoroSpanishRequestsByRequestIdCancelResponses];

export type PostFalAiKokoroSpanishData = {
  body: KokoroSpanishInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kokoro/spanish";
};

export type PostFalAiKokoroSpanishResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKokoroSpanishResponse =
  PostFalAiKokoroSpanishResponses[keyof PostFalAiKokoroSpanishResponses];

export type GetFalAiKokoroSpanishRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kokoro/spanish/requests/{request_id}";
};

export type GetFalAiKokoroSpanishRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KokoroSpanishOutput;
};

export type GetFalAiKokoroSpanishRequestsByRequestIdResponse =
  GetFalAiKokoroSpanishRequestsByRequestIdResponses[keyof GetFalAiKokoroSpanishRequestsByRequestIdResponses];

export type GetFalAiYueRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/yue/requests/{request_id}/status";
};

export type GetFalAiYueRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiYueRequestsByRequestIdStatusResponse =
  GetFalAiYueRequestsByRequestIdStatusResponses[keyof GetFalAiYueRequestsByRequestIdStatusResponses];

export type PutFalAiYueRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/yue/requests/{request_id}/cancel";
};

export type PutFalAiYueRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiYueRequestsByRequestIdCancelResponse =
  PutFalAiYueRequestsByRequestIdCancelResponses[keyof PutFalAiYueRequestsByRequestIdCancelResponses];

export type PostFalAiYueData = {
  body: YueInput;
  path?: never;
  query?: never;
  url: "/fal-ai/yue";
};

export type PostFalAiYueResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiYueResponse =
  PostFalAiYueResponses[keyof PostFalAiYueResponses];

export type GetFalAiYueRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/yue/requests/{request_id}";
};

export type GetFalAiYueRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: YueOutput;
};

export type GetFalAiYueRequestsByRequestIdResponse =
  GetFalAiYueRequestsByRequestIdResponses[keyof GetFalAiYueRequestsByRequestIdResponses];

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/status";
};

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponse =
  PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiMmaudioV2TextToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiMmaudioV2TextToAudioData = {
  body: MmaudioV2TextToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/mmaudio-v2/text-to-audio";
};

export type PostFalAiMmaudioV2TextToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMmaudioV2TextToAudioResponse =
  PostFalAiMmaudioV2TextToAudioResponses[keyof PostFalAiMmaudioV2TextToAudioResponses];

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/mmaudio-v2/text-to-audio/requests/{request_id}";
};

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MmaudioV2TextToAudioOutput;
};

export type GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponse =
  GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses[keyof GetFalAiMmaudioV2TextToAudioRequestsByRequestIdResponses];

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax-music/requests/{request_id}/status";
};

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxMusicRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxMusicRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxMusicRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxMusicData = {
  body: MinimaxMusicInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax-music";
};

export type PostFalAiMinimaxMusicResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxMusicResponse =
  PostFalAiMinimaxMusicResponses[keyof PostFalAiMinimaxMusicResponses];

export type GetFalAiMinimaxMusicRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax-music/requests/{request_id}";
};

export type GetFalAiMinimaxMusicRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxMusicOutput;
};

export type GetFalAiMinimaxMusicRequestsByRequestIdResponse =
  GetFalAiMinimaxMusicRequestsByRequestIdResponses[keyof GetFalAiMinimaxMusicRequestsByRequestIdResponses];

export type GetFalAiF5TtsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/f5-tts/requests/{request_id}/status";
};

export type GetFalAiF5TtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiF5TtsRequestsByRequestIdStatusResponse =
  GetFalAiF5TtsRequestsByRequestIdStatusResponses[keyof GetFalAiF5TtsRequestsByRequestIdStatusResponses];

export type PutFalAiF5TtsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f5-tts/requests/{request_id}/cancel";
};

export type PutFalAiF5TtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiF5TtsRequestsByRequestIdCancelResponse =
  PutFalAiF5TtsRequestsByRequestIdCancelResponses[keyof PutFalAiF5TtsRequestsByRequestIdCancelResponses];

export type PostFalAiF5TtsData = {
  body: F5TtsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/f5-tts";
};

export type PostFalAiF5TtsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiF5TtsResponse =
  PostFalAiF5TtsResponses[keyof PostFalAiF5TtsResponses];

export type GetFalAiF5TtsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/f5-tts/requests/{request_id}";
};

export type GetFalAiF5TtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: F5TtsOutput;
};

export type GetFalAiF5TtsRequestsByRequestIdResponse =
  GetFalAiF5TtsRequestsByRequestIdResponses[keyof GetFalAiF5TtsRequestsByRequestIdResponses];

export type GetFalAiStableAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/stable-audio/requests/{request_id}/status";
};

export type GetFalAiStableAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiStableAudioRequestsByRequestIdStatusResponse =
  GetFalAiStableAudioRequestsByRequestIdStatusResponses[keyof GetFalAiStableAudioRequestsByRequestIdStatusResponses];

export type PutFalAiStableAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio/requests/{request_id}/cancel";
};

export type PutFalAiStableAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiStableAudioRequestsByRequestIdCancelResponse =
  PutFalAiStableAudioRequestsByRequestIdCancelResponses[keyof PutFalAiStableAudioRequestsByRequestIdCancelResponses];

export type PostFalAiStableAudioData = {
  body: StableAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/stable-audio";
};

export type PostFalAiStableAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiStableAudioResponse =
  PostFalAiStableAudioResponses[keyof PostFalAiStableAudioResponses];

export type GetFalAiStableAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/stable-audio/requests/{request_id}";
};

export type GetFalAiStableAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: StableAudioOutput;
};

export type GetFalAiStableAudioRequestsByRequestIdResponse =
  GetFalAiStableAudioRequestsByRequestIdResponses[keyof GetFalAiStableAudioRequestsByRequestIdResponses];

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/sam-audio/visual-separate/requests/{request_id}/status";
};

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponse =
  GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses[keyof GetFalAiSamAudioVisualSeparateRequestsByRequestIdStatusResponses];

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/visual-separate/requests/{request_id}/cancel";
};

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponse =
  PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses[keyof PutFalAiSamAudioVisualSeparateRequestsByRequestIdCancelResponses];

export type PostFalAiSamAudioVisualSeparateData = {
  body: SamAudioVisualSeparateInput;
  path?: never;
  query?: never;
  url: "/fal-ai/sam-audio/visual-separate";
};

export type PostFalAiSamAudioVisualSeparateResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiSamAudioVisualSeparateResponse =
  PostFalAiSamAudioVisualSeparateResponses[keyof PostFalAiSamAudioVisualSeparateResponses];

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/sam-audio/visual-separate/requests/{request_id}";
};

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SamAudioVisualSeparateOutput;
};

export type GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponse =
  GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses[keyof GetFalAiSamAudioVisualSeparateRequestsByRequestIdResponses];

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}/status";
};

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponse =
  GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses[keyof GetMireloAiSfxV15VideoToAudioRequestsByRequestIdStatusResponses];

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}/cancel";
};

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponse =
  PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses[keyof PutMireloAiSfxV15VideoToAudioRequestsByRequestIdCancelResponses];

export type PostMireloAiSfxV15VideoToAudioData = {
  body: SfxV15VideoToAudioInput;
  path?: never;
  query?: never;
  url: "/mirelo-ai/sfx-v1.5/video-to-audio";
};

export type PostMireloAiSfxV15VideoToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostMireloAiSfxV15VideoToAudioResponse =
  PostMireloAiSfxV15VideoToAudioResponses[keyof PostMireloAiSfxV15VideoToAudioResponses];

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/mirelo-ai/sfx-v1.5/video-to-audio/requests/{request_id}";
};

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SfxV15VideoToAudioOutput;
};

export type GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponse =
  GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses[keyof GetMireloAiSfxV15VideoToAudioRequestsByRequestIdResponses];

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kling-video/video-to-audio/requests/{request_id}/status";
};

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoVideoToAudioRequestsByRequestIdStatusResponses];

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/video-to-audio/requests/{request_id}/cancel";
};

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoVideoToAudioRequestsByRequestIdCancelResponses];

export type PostFalAiKlingVideoVideoToAudioData = {
  body: KlingVideoVideoToAudioInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kling-video/video-to-audio";
};

export type PostFalAiKlingVideoVideoToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKlingVideoVideoToAudioResponse =
  PostFalAiKlingVideoVideoToAudioResponses[keyof PostFalAiKlingVideoVideoToAudioResponses];

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/video-to-audio/requests/{request_id}";
};

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KlingVideoVideoToAudioOutput;
};

export type GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponse =
  GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses[keyof GetFalAiKlingVideoVideoToAudioRequestsByRequestIdResponses];

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}/status";
};

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponse =
  GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses[keyof GetMireloAiSfxV1VideoToAudioRequestsByRequestIdStatusResponses];

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}/cancel";
};

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponse =
  PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses[keyof PutMireloAiSfxV1VideoToAudioRequestsByRequestIdCancelResponses];

export type PostMireloAiSfxV1VideoToAudioData = {
  body: SfxV1VideoToAudioInput;
  path?: never;
  query?: never;
  url: "/mirelo-ai/sfx-v1/video-to-audio";
};

export type PostMireloAiSfxV1VideoToAudioResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostMireloAiSfxV1VideoToAudioResponse =
  PostMireloAiSfxV1VideoToAudioResponses[keyof PostMireloAiSfxV1VideoToAudioResponses];

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/mirelo-ai/sfx-v1/video-to-audio/requests/{request_id}";
};

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: SfxV1VideoToAudioOutput;
};

export type GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponse =
  GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses[keyof GetMireloAiSfxV1VideoToAudioRequestsByRequestIdResponses];
