// This file is auto-generated by @hey-api/openapi-ts

import { z } from "zod";

/**
 * File
 */
export const zFileType2 = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
});

/**
 * AnimateDiffV2VOutput
 */
export const zFastAnimatediffVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * AnimateDiffV2VInput
 */
export const zFastAnimatediffVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to use for generating the image. Be as descriptive as possible for best results.",
  }),
  video_url: z.union([z.string(), z.string()]),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(4).register(z.globalRegistry, {
        description: "The first N number of seconds of video to animate.",
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Number of frames per second to extract from the video.",
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: "The strength of the input video in the final output.",
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
      }),
    )
    .default(7.5),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(25),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default("(bad quality, worst quality:1.2), ugly faces, bad anime"),
  motions: z.optional(
    z
      .array(
        z.enum([
          "zoom-out",
          "zoom-in",
          "pan-left",
          "pan-right",
          "tilt-up",
          "tilt-down",
        ]),
      )
      .register(z.globalRegistry, {
        description: "The motions to apply to the video.",
      }),
  ),
});

/**
 * AnimateDiffV2VOutput
 */
export const zFastAnimatediffTurboVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * AnimateDiffV2VTurboInput
 */
export const zFastAnimatediffTurboVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to use for generating the image. Be as descriptive as possible for best results.",
  }),
  video_url: z.union([z.string(), z.string()]),
  first_n_seconds: z
    .optional(
      z.int().gte(2).lte(12).register(z.globalRegistry, {
        description: "The first N number of seconds of video to animate.",
      }),
    )
    .default(3),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Number of frames per second to extract from the video.",
      }),
    )
    .default(8),
  strength: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description: "The strength of the input video in the final output.",
      }),
    )
    .default(0.7),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description:
          "The number of inference steps to perform. 4-12 is recommended for turbo mode.",
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default("(bad quality, worst quality:1.2), ugly faces, bad anime"),
  motions: z.optional(
    z
      .array(
        z.enum([
          "zoom-out",
          "zoom-in",
          "pan-left",
          "pan-right",
          "tilt-up",
          "tilt-down",
        ]),
      )
      .register(z.globalRegistry, {
        description: "The motions to apply to the video.",
      }),
  ),
});

/**
 * File
 */
export const zFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
});

/**
 * AMTInterpolationOutput
 */
export const zAmtInterpolationOutput = z.object({
  video: zFile,
});

/**
 * AMTInterpolationInput
 */
export const zAmtInterpolationInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Number of recursive interpolation passes",
      }),
    )
    .default(2),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Output frames per second",
      }),
    )
    .default(24),
});

/**
 * SAM2VideoOutput
 */
export const zSam2VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zFile),
  video: zFile,
});

/**
 * BoxPrompt
 */
export const zBoxPromptType2 = z.object({
  y_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Y Min Coordinate of the box",
      }),
    )
    .default(0),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "The frame index to interact with.",
      }),
    )
    .default(0),
  x_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "X Max Coordinate of the prompt",
      }),
    )
    .default(0),
  x_min: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "X Min Coordinate of the box",
      }),
    )
    .default(0),
  y_max: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Y Max Coordinate of the prompt",
      }),
    )
    .default(0),
});

/**
 * PointPrompt
 */
export const zPointPromptType2 = z.object({
  y: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Y Coordinate of the prompt",
      }),
    )
    .default(350),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: "Label of the prompt. 1 for foreground, 0 for background",
    }),
  ),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "The frame index to interact with.",
      }),
    )
    .default(0),
  x: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "X Coordinate of the prompt",
      }),
    )
    .default(305),
});

/**
 * SAM2VideoRLEInput
 */
export const zSam2VideoInput = z.object({
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Return per-frame bounding box overlays as a zip archive.",
      }),
    )
    .default(false),
  prompts: z
    .optional(
      z.array(zPointPromptType2).register(z.globalRegistry, {
        description: "List of prompts to segment the video",
      }),
    )
    .default([]),
  video_url: z.union([z.string(), z.string()]),
  box_prompts: z
    .optional(
      z.array(zBoxPromptType2).register(z.globalRegistry, {
        description: "Coordinates for boxes",
      }),
    )
    .default([]),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Apply the mask on the video.",
      }),
    )
    .default(false),
  mask_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * ControlNeXtOutput
 */
export const zControlnextOutput = z.object({
  video: zFileType2,
});

/**
 * ControlNeXtInput
 */
export const zControlnextInput = z.object({
  controlnext_cond_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: "Condition scale for ControlNeXt.",
      }),
    )
    .default(1),
  video_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "Frames per second for the output video.",
      }),
    )
    .default(7),
  max_frame_num: z
    .optional(
      z.int().gte(1).lte(1000).register(z.globalRegistry, {
        description: "Maximum number of frames to process.",
      }),
    )
    .default(240),
  width: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: "Width of the output video.",
      }),
    )
    .default(576),
  overlap: z
    .optional(
      z.int().gte(0).lte(20).register(z.globalRegistry, {
        description: "Number of overlapping frames between batches.",
      }),
    )
    .default(6),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(10).register(z.globalRegistry, {
        description: "Guidance scale for the diffusion process.",
      }),
    )
    .default(3),
  batch_frames: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "Number of frames to process in each batch.",
      }),
    )
    .default(24),
  height: z
    .optional(
      z.int().gte(64).lte(1024).register(z.globalRegistry, {
        description: "Height of the output video.",
      }),
    )
    .default(1024),
  sample_stride: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: "Stride for sampling frames from the input video.",
      }),
    )
    .default(2),
  image_url: z.union([z.string(), z.string()]),
  decode_chunk_size: z
    .optional(
      z.int().gte(1).lte(10).register(z.globalRegistry, {
        description: "Chunk size for decoding frames.",
      }),
    )
    .default(2),
  motion_bucket_id: z
    .optional(
      z.number().gte(0).lte(255).register(z.globalRegistry, {
        description: "Motion bucket ID for the pipeline.",
      }),
    )
    .default(127),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: "Number of inference steps.",
      }),
    )
    .default(25),
});

/**
 * Output
 */
export const zCogvideox5bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generating the video.",
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
  }),
  video: zFile,
});

/**
 * ImageSize
 */
export const zImageSize = z.object({
  height: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: "The height of the generated image.",
      }),
    )
    .default(512),
  width: z
    .optional(
      z.int().lte(14142).register(z.globalRegistry, {
        description: "The width of the generated image.",
      }),
    )
    .default(512),
});

/**
 * LoraWeight
 */
export const zLoraWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: "URL or the path to the LoRA weights.",
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ",
      }),
    )
    .default(1),
});

/**
 * VideoToVideoInput
 */
export const zCogvideox5bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  video_url: z.union([z.string(), z.string()]),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Use RIFE for video interpolation",
      }),
    )
    .default(true),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  strength: z
    .optional(
      z.number().gte(0.05).lte(1).register(z.globalRegistry, {
        description:
          "The strength to use for Video to Video.  1.0 completely remakes the video while 0.0 preserves the original.",
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: "The target FPS of the video",
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate video from",
      }),
    )
    .default(""),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
});

/**
 * Output
 */
export const zVideoUpscalerOutput = z.object({
  video: zFile,
});

/**
 * Input
 */
export const zVideoUpscalerInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  scale: z
    .optional(
      z.number().gte(1).lte(8).register(z.globalRegistry, {
        description: "The scale factor",
      }),
    )
    .default(2),
});

/**
 * OutputModel
 */
export const zDubbingOutput = z.object({
  video: zFile,
});

/**
 * InputModel
 */
export const zDubbingInput = z.object({
  do_lipsync: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to lip sync the audio to the video",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  target_language: z.optional(
    z.enum(["hindi", "turkish", "english"]).register(z.globalRegistry, {
      description: "Target language to dub the video to",
    }),
  ),
});

/**
 * Output
 */
export const zAutoCaptionOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: "URL to the caption .mp4 video.",
  }),
});

/**
 * CaptionInput
 */
export const zAutoCaptionInput = z.object({
  txt_font: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Font for generated captions. Choose one in 'Arial','Standard','Garamond', 'Times New Roman','Georgia', or pass a url to a .ttf file",
      }),
    )
    .default("Standard"),
  video_url: z.union([z.string(), z.string()]),
  top_align: z.optional(z.union([z.string(), z.number()])),
  txt_color: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Colour of the text. Can be a RGB tuple, a color name, or an hexadecimal notation.",
      }),
    )
    .default("white"),
  stroke_width: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Width of the text strokes in pixels",
      }),
    )
    .default(1),
  refresh_interval: z
    .optional(
      z.number().gte(0.5).lte(3).register(z.globalRegistry, {
        description:
          "Number of seconds the captions should stay on screen. A higher number will also result in more text being displayed at once.",
      }),
    )
    .default(1.5),
  font_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Size of text in generated captions.",
      }),
    )
    .default(24),
  left_align: z.optional(z.union([z.string(), z.number()])),
});

/**
 * LipSyncOutput
 */
export const zSyncLipsyncOutput = z.object({
  video: zFile,
});

/**
 * LipSyncInput
 */
export const zSyncLipsyncInput = z.object({
  model: z.optional(
    z
      .enum(["lipsync-1.8.0", "lipsync-1.7.1", "lipsync-1.9.0-beta"])
      .register(z.globalRegistry, {
        description: "The model to use for lipsyncing",
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  sync_mode: z.optional(
    z
      .enum(["cut_off", "loop", "bounce", "silence", "remap"])
      .register(z.globalRegistry, {
        description:
          "Lipsync mode when audio and video durations are out of sync.",
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * Keyframe
 */
export const zKeyframe = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "The duration in milliseconds of this keyframe",
  }),
  timestamp: z.number().register(z.globalRegistry, {
    description: "The timestamp in milliseconds where this keyframe starts",
  }),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where this keyframe's media file can be accessed",
  }),
});

/**
 * Track
 */
export const zTrack = z.object({
  type: z.string().register(z.globalRegistry, {
    description: "Type of track ('video' or 'audio')",
  }),
  id: z.string().register(z.globalRegistry, {
    description: "Unique identifier for the track",
  }),
  keyframes: z.array(zKeyframe).register(z.globalRegistry, {
    description: "List of keyframes that make up this track",
  }),
});

/**
 * ComposeOutput
 */
export const zFfmpegApiComposeOutput = z.object({
  video_url: z.string().register(z.globalRegistry, {
    description: "URL of the processed video file",
  }),
  thumbnail_url: z.string().register(z.globalRegistry, {
    description: "URL of the video's thumbnail image",
  }),
});

/**
 * Input
 */
export const zFfmpegApiComposeInput = z.object({
  tracks: z.array(zTrack).register(z.globalRegistry, {
    description: "List of tracks to be combined into the final media",
  }),
});

/**
 * HunyuanT2VResponse
 */
export const zHunyuanVideoVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanV2VRequest
 */
export const zHunyuanVideoVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: "Strength for Video-to-Video",
      }),
    )
    .default(0.85),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to run. Lower gets faster results, higher gets better results.",
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_frames: z.optional(
    z.enum(["129", "85"]).register(z.globalRegistry, {
      description: "The number of frames to generate.",
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
      }),
    )
    .default(false),
});

/**
 * HunyuanV2VResponse
 */
export const zHunyuanVideoLoraVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanV2VRequest
 */
export const zHunyuanVideoLoraVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
      }),
    )
    .default([]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description: "Strength of video-to-video",
      }),
    )
    .default(0.75),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_frames: z.optional(
    z.enum(["129", "85"]).register(z.globalRegistry, {
      description: "The number of frames to generate.",
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
      }),
    )
    .default(false),
});

/**
 * Ben2OutputVideo
 */
export const zBenV2VideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
  }),
  video: zFile,
});

/**
 * Ben2InputVideo
 */
export const zBenV2VideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for reproducible generation.",
    }),
  ),
  background_color: z.optional(
    z
      .tuple([z.unknown(), z.unknown(), z.unknown()])
      .register(z.globalRegistry, {
        description:
          "Optional RGB values (0-255) for the background color. If not provided, the background will be transparent. For ex: [0, 0, 0]",
      }),
  ),
});

/**
 * VideoUpscaleOutput
 */
export const zTopazUpscaleVideoOutput = z.object({
  video: zFile,
});

/**
 * VideoUpscaleRequest
 */
export const zTopazUpscaleVideoInput = z.object({
  H264_output: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use H264 codec for output video. Default is H265.",
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(4).register(z.globalRegistry, {
        description:
          "Factor to upscale the video by (e.g. 2.0 doubles width and height)",
      }),
    )
    .default(2),
  target_fps: z.optional(
    z.int().gte(16).lte(60).register(z.globalRegistry, {
      description:
        "Target FPS for frame interpolation. If set, frame interpolation will be enabled.",
    }),
  ),
});

/**
 * MulticonditioningVideoOutput
 */
export const zLtxVideoV095MulticonditioningOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * VideoConditioningInput
 */
export const zVideoConditioningInputType2 = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      "Frame number of the video from which the conditioning starts. Must be a multiple of 8.",
  }),
});

/**
 * ImageConditioningInput
 */
export const zImageConditioningInputType2 = z.object({
  start_frame_num: z.int().gte(0).lte(120).register(z.globalRegistry, {
    description:
      "Frame number of the image from which the conditioning starts. Must be a multiple of 8.",
  }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * MultiConditioningVideoInput
 */
export const zLtxVideoV095MulticonditioningInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  images: z
    .optional(
      z.array(zImageConditioningInputType2).register(z.globalRegistry, {
        description: "URL of images to use as conditioning",
      }),
    )
    .default([]),
  videos: z
    .optional(
      z.array(zVideoConditioningInputType2).register(z.globalRegistry, {
        description: "Videos to use as conditioning",
      }),
    )
    .default([]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps",
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
});

/**
 * ExtendVideoOutput
 */
export const zLtxVideoV095ExtendOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * ExtendVideoInput
 */
export const zLtxVideoV095ExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps",
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
  video: zVideoConditioningInputType2,
});

/**
 * PikadditionsOutput
 *
 * Output from Pikadditions generation
 */
export const zPikaV2PikadditionsOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output from Pikadditions generation",
  });

/**
 * PikadditionsRequest
 *
 * Request model for Pikadditions endpoint
 */
export const zPikaV2PikadditionsInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "Text prompt describing what to add",
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to guide the model",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Request model for Pikadditions endpoint",
  });

/**
 * Output
 */
export const zLatentsyncOutput = z.object({
  video: zFile,
});

/**
 * Input
 */
export const zLatentsyncInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(2).register(z.globalRegistry, {
        description: "Guidance scale for the model inference",
      }),
    )
    .default(1),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for generation. If None, a random seed will be used.",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  loop_mode: z.optional(
    z.enum(["pingpong", "loop"]).register(z.globalRegistry, {
      description:
        "Video loop mode when audio is longer than video. Options: pingpong, loop",
    }),
  ),
});

/**
 * LipSyncV2Output
 */
export const zSyncLipsyncV2Output = z.object({
  video: zFile,
});

/**
 * LipSyncV2Input
 */
export const zSyncLipsyncV2Input = z.object({
  model: z.optional(
    z.enum(["lipsync-2", "lipsync-2-pro"]).register(z.globalRegistry, {
      description:
        "The model to use for lipsyncing. `lipsync-2-pro` will cost roughly 1.67 times as much as `lipsync-2` for the same duration.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  sync_mode: z.optional(
    z
      .enum(["cut_off", "loop", "bounce", "silence", "remap"])
      .register(z.globalRegistry, {
        description:
          "Lipsync mode when audio and video durations are out of sync.",
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * VideoOutput
 *
 * Pydantic model for returning the re-sounded video back to the client.
 */
export const zVideoSoundEffectsGeneratorOutput = z
  .object({
    video: zFileType2,
  })
  .register(z.globalRegistry, {
    description:
      "Pydantic model for returning the re-sounded video back to the client.",
  });

/**
 * Video
 *
 * Represents a video file.
 */
export const zVideoType2 = z
  .object({
    file_size: z.optional(z.union([z.int(), z.unknown()])),
    file_name: z.optional(z.union([z.string(), z.unknown()])),
    content_type: z.optional(z.union([z.string(), z.unknown()])),
    url: z.string().register(z.globalRegistry, {
      description: "The URL where the file can be downloaded from.",
    }),
    file_data: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: "Represents a video file.",
  });

/**
 * VideoInput
 *
 * Pydantic model for receiving a video file to analyze and re-sound.
 */
export const zVideoSoundEffectsGeneratorInput = z
  .object({
    video_url: zVideoType2,
  })
  .register(z.globalRegistry, {
    description:
      "Pydantic model for receiving a video file to analyze and re-sound.",
  });

/**
 * WanT2VResponse
 */
export const zWanVaceOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanT2VRequest
 */
export const zWanVaceInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  video_url: z.optional(z.union([z.string(), z.string()])),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Urls to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  task: z.optional(
    z.enum(["depth", "inpainting"]).register(z.globalRegistry, {
      description: "Task type for the model.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  mask_image_url: z.optional(z.union([z.string(), z.string()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  aspect_ratio: z.optional(
    z.enum(["auto", "9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p,580p, or 720p).",
    }),
  ),
  mask_video_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * MagiVideoExtensionResponse
 */
export const zMagiDistilledExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiVideoExtensionRequest
 */
export const zMagiDistilledExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        "The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * MagiVideoExtensionResponse
 */
export const zMagiExtendVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiVideoExtensionRequest
 */
export const zMagiExtendVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  start_frame: z.optional(
    z.int().gte(0).register(z.globalRegistry, {
      description:
        "The frame to begin the generation from, with the remaining frames will be treated as the prefix video. The final video will contain the frames up until this number unchanged, followed by the generated frames. The default start frame is 32 frames before the end of the video, which gives optimal results.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * VideoCondition
 *
 * Video condition to use for generation.
 */
export const zVideoCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: "The strength of the condition.",
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: "The frame number to start the condition on.",
        }),
      )
      .default(0),
    video_url: z.string().register(z.globalRegistry, {
      description: "The URL of the video to use as input.",
    }),
  })
  .register(z.globalRegistry, {
    description: "Video condition to use for generation.",
  });

/**
 * ImageCondition
 *
 * Image condition to use for generation.
 */
export const zImageCondition = z
  .object({
    strength: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: "The strength of the condition.",
        }),
      )
      .default(1),
    start_frame_number: z
      .optional(
        z.int().gte(0).lte(160).register(z.globalRegistry, {
          description: "The frame number to start the condition on.",
        }),
      )
      .default(0),
    image_url: z.string().register(z.globalRegistry, {
      description: "The URL of the image to use as input.",
    }),
  })
  .register(z.globalRegistry, {
    description: "Image condition to use for generation.",
  });

/**
 * MulticonditioningVideoOutput
 */
export const zLtxVideoLoraMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LoRAWeight
 *
 * LoRA weight to use for generation.
 */
export const zLoRaWeightType3 = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: "URL or path to the LoRA weights.",
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description:
            "Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.",
        }),
      )
      .default(1),
    weight_name: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "LoRA weight to use for generation.",
  });

/**
 * MulticonditioningVideoInput
 *
 * Request model for text-to-video generation with multiple conditions.
 */
export const zLtxVideoLoraMulticonditioningInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: "The number of inference steps to use.",
        }),
      )
      .default(30),
    prompt: z.string().register(z.globalRegistry, {
      description: "The prompt to generate the video from.",
    }),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using the LLM.",
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(89),
    loras: z
      .optional(
        z.array(zLoRaWeightType3).register(z.globalRegistry, {
          description: "The LoRA weights to use for generation.",
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zImageCondition).register(z.globalRegistry, {
          description: "The image conditions to use for generation.",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The negative prompt to use.",
        }),
      )
      .default(
        "blurry, low quality, low resolution, inconsistent motion, jittery, distorted",
      ),
    aspect_ratio: z.optional(
      z.enum(["16:9", "1:1", "9:16", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "The resolution of the video.",
      }),
    ),
    videos: z
      .optional(
        z.array(zVideoCondition).register(z.globalRegistry, {
          description: "The video conditions to use for generation.",
        }),
      )
      .default([]),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed to use for generation.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      "Request model for text-to-video generation with multiple conditions.",
  });

/**
 * ExtendVideoOutput
 */
export const zLtxVideo13bDevExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * VideoConditioningInput
 */
export const zVideoConditioningInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_frame_num: z
    .optional(
      z.int().gte(0).lte(1440).register(z.globalRegistry, {
        description:
          "Frame number of the video from which the conditioning starts. Must be a multiple of 8.",
      }),
    )
    .default(0),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to reverse the video. This is useful for tasks where the video conditioning should be applied in reverse order.",
      }),
    )
    .default(false),
  limit_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to limit the number of frames used from the video. If True, the `max_num_frames` parameter will be used to limit the number of frames.",
      }),
    )
    .default(false),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to resample the video to a specific FPS. If True, the `target_fps` parameter will be used to resample the video.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Strength of the conditioning. 0.0 means no conditioning, 1.0 means full conditioning.",
      }),
    )
    .default(1),
  target_fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Target FPS to resample the video to. Only relevant if `resample_fps` is True.",
      }),
    )
    .default(24),
  max_num_frames: z
    .optional(
      z.int().gte(1).lte(1441).register(z.globalRegistry, {
        description:
          "Maximum number of frames to use from the video. If None, all frames will be used.",
      }),
    )
    .default(1441),
  conditioning_type: z.optional(
    z.enum(["rgb", "depth", "pose", "canny"]).register(z.globalRegistry, {
      description:
        "Type of conditioning this video provides. This is relevant to ensure in-context LoRA weights are applied correctly, as well as selecting the correct preprocessing pipeline, when enabled.",
    }),
  ),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the video. If True, the video will be preprocessed to match the conditioning type. This is a no-op for RGB conditioning.",
      }),
    )
    .default(false),
});

/**
 * LoRAWeight
 */
export const zLoRaWeight = z.object({
  path: z.string().register(z.globalRegistry, {
    description: "URL or path to the LoRA weights.",
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Scale of the LoRA weight. This is a multiplier applied to the LoRA weight when loading it.",
      }),
    )
    .default(1),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Name of the LoRA weight. Only used if `path` is a HuggingFace repository, and is only required when the repository contains multiple LoRA weights.",
    }),
  ),
});

/**
 * ExtendVideoInput
 */
export const zLtxVideo13bDevExtendInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the first pass.",
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the video.",
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to reverse the video.",
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the prompt using a language model.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeight).register(z.globalRegistry, {
        description: "LoRA weights to use for generation",
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the second pass.",
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: "The number of frames in the video.",
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  video: zVideoConditioningInput,
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video.",
    }),
  ),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
});

/**
 * MultiConditioningVideoOutput
 */
export const zLtxVideo13bDevMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * ImageConditioningInput
 */
export const zImageConditioningInput = z.object({
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Strength of the conditioning. 0.0 means no conditioning, 1.0 means full conditioning.",
      }),
    )
    .default(1),
  start_frame_num: z
    .optional(
      z.int().gte(0).lte(1440).register(z.globalRegistry, {
        description:
          "Frame number of the image from which the conditioning starts. Must be a multiple of 8.",
      }),
    )
    .default(0),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * MultiConditioningVideoInput
 */
export const zLtxVideo13bDevMulticonditioningInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the first pass.",
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the video.",
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to reverse the video.",
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the prompt using a language model.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeight).register(z.globalRegistry, {
        description: "LoRA weights to use for generation",
      }),
    )
    .default([]),
  images: z
    .optional(
      z.array(zImageConditioningInput).register(z.globalRegistry, {
        description: "URL of images to use as conditioning",
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: "The number of frames in the video.",
      }),
    )
    .default(121),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the second pass.",
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video.",
    }),
  ),
  videos: z
    .optional(
      z.array(zVideoConditioningInput).register(z.globalRegistry, {
        description: "Videos to use as conditioning",
      }),
    )
    .default([]),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
});

/**
 * MultiConditioningVideoOutput
 */
export const zLtxVideo13bDistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zLtxVideo13bDistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zImageConditioningInput).register(z.globalRegistry, {
          description: "URL of images to use as conditioning",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video (480p or 720p).",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    videos: z
      .optional(
        z.array(zVideoConditioningInput).register(z.globalRegistry, {
          description: "Videos to use as conditioning",
        }),
      )
      .default([]),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * ExtendVideoOutput
 */
export const zLtxVideo13bDistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zLtxVideo13bDistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    video: zVideoConditioningInput,
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video (480p or 720p).",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * VideoFile
 */
export const zVideoFile = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  duration: z.optional(z.union([z.number(), z.unknown()])),
  height: z.optional(z.union([z.int(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  fps: z.optional(z.union([z.number(), z.unknown()])),
  width: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * WanVACEResponse
 */
export const zWanVace14bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACERequest
 */
export const zWanVace14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.optional(z.union([z.string(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  task: z.optional(
    z
      .enum(["depth", "pose", "inpainting", "outpainting", "reframe"])
      .register(z.globalRegistry, {
        description: "Task type for the model.",
      }),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * LipsyncAppOutput
 */
export const zLipsyncOutput = z.object({
  video: zFileType2,
});

/**
 * LipsyncInput
 */
export const zLipsyncInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * ReframeOutput
 */
export const zLumaDreamMachineRay2ReframeOutput = z.object({
  video: zFile,
});

/**
 * ReframeVideoRequest
 */
export const zLumaDreamMachineRay2ReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: "Optional prompt for reframing",
    }),
  ),
  aspect_ratio: z
    .enum(["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
    .register(z.globalRegistry, {
      description: "The aspect ratio of the reframed video",
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Start Y coordinate for reframing",
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: "End X coordinate for reframing",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: "End Y coordinate for reframing",
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Start X coordinate for reframing",
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y position of the grid for reframing",
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X position of the grid for reframing",
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * ReframeOutput
 */
export const zLumaDreamMachineRay2FlashReframeOutput = z.object({
  video: zFile,
});

/**
 * ReframeVideoRequest
 */
export const zLumaDreamMachineRay2FlashReframeInput = z.object({
  prompt: z.optional(
    z.string().min(1).max(5000).register(z.globalRegistry, {
      description: "Optional prompt for reframing",
    }),
  ),
  aspect_ratio: z
    .enum(["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
    .register(z.globalRegistry, {
      description: "The aspect ratio of the reframed video",
    }),
  y_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Start Y coordinate for reframing",
    }),
  ),
  x_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: "End X coordinate for reframing",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  y_end: z.optional(
    z.int().register(z.globalRegistry, {
      description: "End Y coordinate for reframing",
    }),
  ),
  x_start: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Start X coordinate for reframing",
    }),
  ),
  grid_position_y: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y position of the grid for reframing",
    }),
  ),
  grid_position_x: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X position of the grid for reframing",
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * WanT2VResponse
 */
export const zWanVace13bOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanT2VRequest
 */
export const zWanVace13bInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  video_url: z.optional(z.union([z.string(), z.string()])),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  mask_image_url: z.optional(z.union([z.string(), z.string()])),
  task: z.optional(
    z.enum(["depth", "inpainting", "pose"]).register(z.globalRegistry, {
      description: "Task type for the model.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Urls to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(240).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive). Works only with only reference images as input if source video or mask video is provided output len would be same as source up to 241 frames",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p,580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  mask_video_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * CombineOutput
 */
export const zFfmpegApiMergeAudioVideoOutput = z.object({
  video: zFileType2,
});

/**
 * CombineInput
 */
export const zFfmpegApiMergeAudioVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_offset: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description:
          "Offset in seconds for when the audio should start relative to the video",
      }),
    )
    .default(0),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * DWPoseVideoOutput
 */
export const zDwposeVideoOutput = z.object({
  video: zFile,
});

/**
 * DWPoseVideoInput
 */
export const zDwposeVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  draw_mode: z.optional(
    z
      .enum([
        "full-pose",
        "body-pose",
        "face-pose",
        "hand-pose",
        "face-hand-mask",
        "face-mask",
        "hand-mask",
      ])
      .register(z.globalRegistry, {
        description:
          "Mode of drawing the pose on the video. Options are: 'full-pose', 'body-pose', 'face-pose', 'hand-pose', 'face-hand-mask', 'face-mask', 'hand-mask'.",
      }),
  ),
});

/**
 * WanVACEDepthResponse
 */
export const zWanVace14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEDepthRequest
 */
export const zWanVace14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEPoseResponse
 */
export const zWanVace14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEPoseRequest
 */
export const zWanVace14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEInpaintingResponse
 */
export const zWanVace14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEInpaintingRequest
 */
export const zWanVace14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Urls to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEOutpaintingResponse
 */
export const zWanVace14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEOutpaintingRequest
 */
export const zWanVace14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.",
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the bottom.",
      }),
    )
    .default(false),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the top.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the left.",
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the right.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEReframeResponse
 */
export const zWanVace14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEReframeRequest
 */
export const zWanVace14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The text prompt to guide video generation. Optional for reframing.",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to trim borders from the video.",
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
      }),
    )
    .default(0),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(true),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * ModifyOutput
 */
export const zLumaDreamMachineRay2ModifyOutput = z.object({
  video: zFile,
});

/**
 * ModifyVideoRequest
 */
export const zLumaDreamMachineRay2ModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: "Instruction for modifying the video",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  mode: z.optional(
    z
      .enum([
        "adhere_1",
        "adhere_2",
        "adhere_3",
        "flex_1",
        "flex_2",
        "flex_3",
        "reimagine_1",
        "reimagine_2",
        "reimagine_3",
      ])
      .register(z.globalRegistry, {
        description:
          "Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * LipsyncOutput
 */
export const zPixverseLipsyncOutput = z.object({
  video: zFile,
});

/**
 * LipsyncRequest
 */
export const zPixverseLipsyncInput = z.object({
  text: z.optional(
    z.string().register(z.globalRegistry, {
      description: "Text content for TTS when audio_url is not provided",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.optional(z.union([z.string(), z.string()])),
  voice_id: z.optional(
    z
      .enum([
        "Emily",
        "James",
        "Isabella",
        "Liam",
        "Chloe",
        "Adrian",
        "Harper",
        "Ava",
        "Sophia",
        "Julia",
        "Mason",
        "Jack",
        "Oliver",
        "Ethan",
        "Auto",
      ])
      .register(z.globalRegistry, {
        description: "Voice to use for TTS when audio_url is not provided",
      }),
  ),
});

/**
 * ExtendOutput
 */
export const zPixverseExtendOutput = z.object({
  video: zFile,
});

/**
 * ExtendRequest
 */
export const zPixverseExtendInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Prompt describing how to extend the video",
  }),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 1080p videos are limited to 5 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the extended video",
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum(["v3.5", "v4", "v4.5", "v5", "v5.5", "v5.6"])
      .register(z.globalRegistry, {
        description: "The model version to use for generation",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * ExtendOutput
 */
export const zPixverseExtendFastOutput = z.object({
  video: zFile,
});

/**
 * FastExtendRequest
 */
export const zPixverseExtendFastInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Prompt describing how to extend the video",
  }),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video. Fast mode doesn't support 1080p",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the extended video",
      }),
  ),
  model: z.optional(
    z
      .enum(["v3.5", "v4", "v4.5", "v5", "v5.5", "v5.6"])
      .register(z.globalRegistry, {
        description: "The model version to use for generation",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * Output
 */
export const zThinksoundOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used to generate the audio.",
  }),
  video: zFile,
});

/**
 * Input
 */
export const zThinksoundInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "A prompt to guide the audio generation. If not provided, it will be extracted from the video.",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: "The number of inference steps for audio generation.",
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: "The classifier-free guidance scale for audio generation.",
      }),
    )
    .default(5),
});

/**
 * AudioOutput
 */
export const zThinksoundAudioOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used to generate the audio.",
  }),
  audio: zFile,
});

/**
 * Input
 */
export const zThinksoundAudioInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "A prompt to guide the audio generation. If not provided, it will be extracted from the video.",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(100).register(z.globalRegistry, {
        description: "The number of inference steps for audio generation.",
      }),
    )
    .default(24),
  cfg_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: "The classifier-free guidance scale for audio generation.",
      }),
    )
    .default(5),
});

/**
 * SoundEffectOutput
 */
export const zPixverseSoundEffectsOutput = z.object({
  video: zFile,
});

/**
 * SoundEffectRequest
 */
export const zPixverseSoundEffectsInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Description of the sound effect to generate. If empty, a random sound effect will be generated",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to keep the original audio from the video",
      }),
    )
    .default(false),
});

/**
 * MultiConditioningVideoOutput
 */
export const zLtxv13B098DistilledMulticonditioningOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledMultiConditioningVideoInput
 *
 * Distilled model input
 */
export const zLtxv13B098DistilledMulticonditioningInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    images: z
      .optional(
        z.array(zImageConditioningInput).register(z.globalRegistry, {
          description: "URL of images to use as conditioning",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        }),
      )
      .default(0),
    videos: z
      .optional(
        z.array(zVideoConditioningInput).register(z.globalRegistry, {
          description: "Videos to use as conditioning",
        }),
      )
      .default([]),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * ModifyOutput
 */
export const zLumaDreamMachineRay2FlashModifyOutput = z.object({
  video: zFile,
});

/**
 * ModifyVideoRequest
 */
export const zLumaDreamMachineRay2FlashModifyInput = z.object({
  prompt: z.optional(
    z.string().min(3).max(5000).register(z.globalRegistry, {
      description: "Instruction for modifying the video",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  mode: z.optional(
    z
      .enum([
        "adhere_1",
        "adhere_2",
        "adhere_3",
        "flex_1",
        "flex_2",
        "flex_3",
        "reimagine_1",
        "reimagine_2",
        "reimagine_3",
      ])
      .register(z.globalRegistry, {
        description:
          "Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * VideoFile
 */
export const zVideoFileType2 = z.object({
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The height of the video",
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: "The duration of the video",
    }),
  ),
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  fps: z.optional(
    z.number().register(z.globalRegistry, {
      description: "The FPS of the video",
    }),
  ),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The width of the video",
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  num_frames: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The number of frames in the video",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
});

/**
 * FILMVideoOutput
 */
export const zFilmVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * FILMVideoInput
 */
export const zFilmVideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.",
      }),
    )
    .default(true),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.",
      }),
    )
    .default(false),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if use_calculated_fps is False.",
      }),
    )
    .default(8),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Only applicable if output_type is 'video'.",
    }),
  ),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          "The number of frames to generate between the input video frames.",
      }),
    )
    .default(1),
});

/**
 * RIFEVideoOutput
 */
export const zRifeVideoOutput = z.object({
  video: zFile,
});

/**
 * RIFEVideoInput
 */
export const zRifeVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  use_scene_detection: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the input video will be split into scenes before interpolation. This removes smear frames between scenes, but can result in false positives if the scene detection is not accurate. If False, the entire video will be treated as a single scene.",
      }),
    )
    .default(false),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the final frame will be looped back to the first frame to create a seamless loop. If False, the final frame will not loop back.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(1).lte(4).register(z.globalRegistry, {
        description:
          "The number of frames to generate between the input video frames.",
      }),
    )
    .default(1),
  use_calculated_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If True, the function will use the calculated FPS of the input video multiplied by the number of frames to determine the output FPS. If False, the passed FPS will be used.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if use_calculated_fps is False.",
      }),
    )
    .default(8),
});

/**
 * ExtendVideoConditioningInput
 */
export const zExtendVideoConditioningInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  start_frame_num: z
    .optional(
      z.int().gte(0).lte(1440).register(z.globalRegistry, {
        description:
          "Frame number of the video from which the conditioning starts. Must be a multiple of 8.",
      }),
    )
    .default(0),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to reverse the video. This is useful for tasks where the video conditioning should be applied in reverse order.",
      }),
    )
    .default(false),
  limit_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to limit the number of frames used from the video. If True, the `max_num_frames` parameter will be used to limit the number of frames.",
      }),
    )
    .default(false),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to resample the video to a specific FPS. If True, the `target_fps` parameter will be used to resample the video.",
      }),
    )
    .default(false),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Strength of the conditioning. 0.0 means no conditioning, 1.0 means full conditioning.",
      }),
    )
    .default(1),
  target_fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Target FPS to resample the video to. Only relevant if `resample_fps` is True.",
      }),
    )
    .default(24),
  max_num_frames: z
    .optional(
      z.int().gte(1).lte(1441).register(z.globalRegistry, {
        description:
          "Maximum number of frames to use from the video. If None, all frames will be used.",
      }),
    )
    .default(1441),
});

/**
 * ExtendVideoOutput
 */
export const zLtxv13B098DistilledExtendOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledExtendVideoInput
 *
 * Distilled model input
 */
export const zLtxv13B098DistilledExtendInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    video: zExtendVideoConditioningInput,
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        }),
      )
      .default(0),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * WanV2VResponse
 */
export const zWanV22A14bVideoToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanV2VRequest
 */
export const zWanV22A14bVideoToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(1),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resample_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the video will be resampled to the passed frames per second. If false, the video will not be resampled.",
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input video.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
      }),
    )
    .default(4),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Strength of the video transformation. A value of 1.0 means the output will be completely based on the prompt, while a value of 0.0 means the output will be identical to the input video.",
      }),
    )
    .default(0.9),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * MergeVideosOutput
 */
export const zFfmpegApiMergeVideosOutput = z.object({
  metadata: z.record(z.string(), z.unknown()).register(z.globalRegistry, {
    description:
      "Metadata about the merged video including original video info",
  }),
  video: zFileType2,
});

/**
 * MergeVideosInput
 */
export const zFfmpegApiMergeVideosInput = z.object({
  resolution: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
      z.unknown(),
    ]),
  ),
  video_urls: z.array(z.string()).min(2).register(z.globalRegistry, {
    description: "List of video URLs to merge in order",
  }),
  target_fps: z.optional(z.union([z.number().gte(1).lte(60), z.unknown()])),
});

/**
 * MareyOutput
 */
export const zMareyMotionTransferOutput = z.object({
  video: zFileType2,
});

/**
 * MareyInputMotionTransfer
 */
export const zMareyMotionTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate a video from",
  }),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * MareyOutput
 */
export const zMareyPoseTransferOutput = z.object({
  video: zFileType2,
});

/**
 * MareyInputPoseTransfer
 */
export const zMareyPoseTransferInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate a video from",
  }),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  reference_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
  first_frame_image_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * Video
 */
export const zVideo = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
});

/**
 * VideoOutput
 */
export const zSfxV1VideoToVideoOutput = z.object({
  video: z.array(zVideo).register(z.globalRegistry, {
    description: "The processed video with sound effects",
  }),
});

/**
 * Input
 */
export const zSfxV1VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  video_url: z.union([z.string(), z.string()]),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * AvatarSingleAudioResponse
 */
export const zInfinitalkOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * InfiniTalkSingleAudioRequest
 */
export const zInfinitalkInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(721).register(z.globalRegistry, {
        description: "Number of frames to generate. Must be between 41 to 721.",
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(42),
});

/**
 * OutputIncreaseResolutionModel
 */
export const zVideoIncreaseResolutionOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * InputIncreaseResolutionModel
 */
export const zVideoIncreaseResolutionInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "mov_h265",
        "mov_proresks",
        "mkv_h265",
        "mkv_h264",
        "mkv_vp9",
        "gif",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.",
      }),
  ),
  desired_increase: z.optional(
    z.enum(["2", "4"]).register(z.globalRegistry, {
      description: "desired_increase factor. Options: 2x, 4x.",
    }),
  ),
});

/**
 * WanFunControlResponse
 */
export const zWanFunControlOutput = z.object({
  video: zFile,
});

/**
 * WanFunControlRequest
 */
export const zWanFunControlInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video.",
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The shift for the scheduler.",
      }),
    )
    .default(5),
  preprocess_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the video. If True, the video will be preprocessed to depth or pose.",
      }),
    )
    .default(false),
  reference_image_url: z.optional(z.union([z.string(), z.string()])),
  fps: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "The fps to generate. Only used when match_input_fps is False.",
      }),
    )
    .default(16),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to match the number of frames in the input video.",
      }),
    )
    .default(true),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale.",
      }),
    )
    .default(6),
  preprocess_type: z.optional(
    z.enum(["depth", "pose"]).register(z.globalRegistry, {
      description:
        "The type of preprocess to apply to the video. Only used when preprocess_video is True.",
    }),
  ),
  control_video_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video.",
      }),
    )
    .default(""),
  num_frames: z
    .optional(
      z.int().gte(49).lte(121).register(z.globalRegistry, {
        description:
          "The number of frames to generate. Only used when match_input_num_frames is False.",
      }),
    )
    .default(81),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(27),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to match the fps in the input video.",
      }),
    )
    .default(true),
});

/**
 * LipSyncV2ProOutput
 */
export const zSyncLipsyncV2ProOutput = z.object({
  video: zFile,
});

/**
 * LipSyncV2ProInput
 */
export const zSyncLipsyncV2ProInput = z.object({
  sync_mode: z.optional(
    z
      .enum(["cut_off", "loop", "bounce", "silence", "remap"])
      .register(z.globalRegistry, {
        description:
          "Lipsync mode when audio and video durations are out of sync.",
      }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * HunyuanFoleyResponse
 */
export const zHunyuanVideoFoleyOutput = z.object({
  video: zFile,
});

/**
 * HunyuanFoleyRequest
 */
export const zHunyuanVideoFoleyInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Guidance scale for audio generation.",
      }),
    )
    .default(4.5),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: "Number of inference steps for generation.",
      }),
    )
    .default(50),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for reproducible generation.",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to avoid certain audio characteristics.",
      }),
    )
    .default("noisy, harsh"),
  text_prompt: z.string().register(z.globalRegistry, {
    description: "Text description of the desired audio (optional).",
  }),
});

/**
 * WanVACEPoseResponse
 */
export const zWan22VaceFunA14bPoseOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEPoseRequest
 */
export const zWan22VaceFunA14bPoseInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The text prompt to guide video generation. For pose task, the prompt should describe the desired pose and action of the subject in the video.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEDepthResponse
 */
export const zWan22VaceFunA14bDepthOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEDepthRequest
 */
export const zWan22VaceFunA14bDepthInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEInpaintingResponse
 */
export const zWan22VaceFunA14bInpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEInpaintingRequest
 */
export const zWan22VaceFunA14bInpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Urls to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  mask_video_url: z.union([z.string(), z.unknown()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  preprocess: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to preprocess the input video.",
      }),
    )
    .default(false),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  mask_image_url: z.optional(z.union([z.string(), z.unknown()])),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEOutpaintingResponse
 */
export const zWan22VaceFunA14bOutpaintingOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEOutpaintingRequest
 */
export const zWan22VaceFunA14bOutpaintingInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  ref_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs to source reference image. If provided, the model will use this image as reference.",
    }),
  ),
  expand_ratio: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Amount of expansion. This is a float value between 0 and 1, where 0.25 adds 25% to the original video size on the specified sides.",
      }),
    )
    .default(0.25),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  expand_bottom: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the bottom.",
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  expand_left: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the left.",
      }),
    )
    .default(false),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  expand_top: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the top.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  expand_right: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the video to the right.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * WanVACEReframeResponse
 */
export const zWan22VaceFunA14bReframeOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * WanVACEReframeRequest
 */
export const zWan22VaceFunA14bReframeInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The text prompt to guide video generation. Optional for reframing.",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  first_frame_url: z.optional(z.union([z.string(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to. This is used to help determine the auto downsample factor to try and find the lowest detail-preserving downsample factor. The default value is appropriate for most videos, if you are using a video with very fast motion, you may need to increase this value. If your video has a very low amount of motion, you could decrease this value to allow for higher downsampling and thus longer sequences.",
      }),
    )
    .default(15),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to trim borders from the video.",
      }),
    )
    .default(true),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
      }),
    )
    .default(0),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  last_frame_url: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * LucyEditDevOutput
 */
export const zLucyEditDevOutput = z.object({
  video: zFile,
});

/**
 * LucyEditDevInput
 */
export const zLucyEditDevInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enhance the prompt for better results.",
      }),
    )
    .default(true),
});

/**
 * LucyEditProOutput
 */
export const zLucyEditProOutput = z.object({
  video: zFile,
});

/**
 * LucyEditProInput
 */
export const zLucyEditProInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video",
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enhance the prompt for better results.",
      }),
    )
    .default(true),
});

/**
 * WanAnimateMoveResponse
 */
export const zWanV2214bAnimateMoveOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation (auto-generated by the model)",
  }),
  frames_zip: z.optional(zFile),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation",
  }),
  video: zFile,
});

/**
 * WanAnimateMoveRequest
 */
export const zWanV2214bAnimateMoveInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).",
      }),
    )
    .default(false),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(1),
});

/**
 * WanAnimateReplaceResponse
 */
export const zWanV2214bAnimateReplaceOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation (auto-generated by the model)",
  }),
  frames_zip: z.optional(zFile),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation",
  }),
  video: zFile,
});

/**
 * WanAnimateMoveRequest
 */
export const zWanV2214bAnimateReplaceInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP archive containing per-frame images generated on GPU (lossless).",
      }),
    )
    .default(false),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(20),
  use_turbo: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized for best results.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(1),
});

/**
 * WanVACEVideoEditResponse
 */
export const zWanVaceAppsVideoEditOutput = z.object({
  frames_zip: z.optional(zFile),
  video: zVideoFileType2,
});

/**
 * WanVACEVideoEditRequest
 */
export const zWanVaceAppsVideoEditInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Prompt to edit the video.",
  }),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(["none", "low", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the edited video.",
      }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to include a ZIP archive containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the edited video.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  video_type: z.optional(
    z.enum(["auto", "general", "human"]).register(z.globalRegistry, {
      description:
        "The type of video you're editing. Use 'general' for most videos, and 'human' for videos emphasizing human subjects and motions. The default value 'auto' means the model will guess based on the first frame of the video.",
    }),
  ),
  image_urls: z
    .optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "URLs of the input images to use as a reference for the generation.",
      }),
    )
    .default([]),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable automatic downsampling. If your video has a high frame rate or is long, enabling longer sequences to be generated. The video will be interpolated back to the original frame rate after generation.",
      }),
    )
    .default(true),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "The minimum frames per second to downsample the video to.",
      }),
    )
    .default(15),
});

/**
 * SeedVRVideoOutput
 */
export const zSeedvrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The random seed used for the generation process.",
  }),
  video: zFileType2,
});

/**
 * SeedVRVideoInput
 */
export const zSeedvrUpscaleVideoInput = z.object({
  upscale_mode: z.optional(
    z.enum(["target", "factor"]).register(z.globalRegistry, {
      description:
        "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  noise_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "The noise scale to use for the generation process.",
      }),
    )
    .default(0.1),
  output_format: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The format of the output video.",
      }),
  ),
  output_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the output video.",
    }),
  ),
  target_resolution: z.optional(
    z.enum(["720p", "1080p", "1440p", "2160p"]).register(z.globalRegistry, {
      description:
        "The target resolution to upscale to when `upscale_mode` is `target`.",
    }),
  ),
  output_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the output video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  upscale_factor: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.",
      }),
    )
    .default(2),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * InfinitalkVid2VidResponse
 */
export const zInfinitalkVideoToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * InfiniTalkVid2VidAudioRequest
 */
export const zInfinitalkVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(42),
});

/**
 * LongWanVACEReframeResponse
 */
export const zWanVaceAppsLongReframeOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LongWanVACEReframeRequest
 */
export const zWanVaceAppsLongReframeInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  video_url: z.union([z.string(), z.string()]),
  zoom_factor: z
    .optional(
      z.number().gte(0).lte(0.9).register(z.globalRegistry, {
        description:
          "Zoom factor for the video. When this value is greater than 0, the video will be zoomed in by this factor (in relation to the canvas size,) cutting off the edges of the video. A value of 0 means no zoom.",
      }),
    )
    .default(0),
  paste_back: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to paste back the reframed scene to the original video.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "low", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration to use for inference. Options are 'none' or 'regular'. Accelerated inference will very slightly affect output, but will be significantly faster.",
    }),
  ),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The text prompt to guide video generation. Optional for reframing.",
      }),
    )
    .default(""),
  scene_threshold: z
    .optional(
      z.number().gte(0).lte(100).register(z.globalRegistry, {
        description:
          "Threshold for scene detection sensitivity (0-100). Lower values detect more scenes.",
      }),
    )
    .default(30),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  auto_downsample_min_fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "Minimum FPS for auto downsample.",
      }),
    )
    .default(6),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  transparency_mode: z.optional(
    z.enum(["content_aware", "white", "black"]).register(z.globalRegistry, {
      description:
        "The transparency mode to apply to the first and last frames. This controls how the transparent areas of the first and last frames are filled.",
    }),
  ),
  trim_borders: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to trim borders from the video.",
      }),
    )
    .default(true),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  interpolator_model: z.optional(
    z.enum(["rife", "film"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. Options are 'rife' or 'film'.",
    }),
  ),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable auto downsample.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
});

/**
 * ImageFile
 */
export const zImageFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  height: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The height of the image",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  width: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The width of the image",
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
});

/**
 * RemixOutput
 */
export const zSora2VideoToVideoRemixOutput = z.object({
  spritesheet: z.optional(zImageFile),
  thumbnail: z.optional(zImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: "The ID of the generated video",
  }),
  video: zVideoFileType2,
});

/**
 * RemixInput
 */
export const zSora2VideoToVideoRemixInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "Updated text prompt that directs the remix generation",
  }),
  video_id: z.string().register(z.globalRegistry, {
    description:
      "The video_id from a previous Sora 2 generation. Note: You can only remix videos that were generated by Sora (via text-to-video or image-to-video endpoints), not arbitrary uploaded videos.",
  }),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
      }),
    )
    .default(true),
});

/**
 * VideoToVideoOutput
 */
export const zKreaWan14bVideoToVideoOutput = z.object({
  video: zFileType2,
});

/**
 * VideoToVideoInput
 */
export const zKreaWan14bVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Prompt for the video-to-video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          "Denoising strength for the video-to-video generation. 0.0 preserves the original, 1.0 completely remakes the video.",
      }),
    )
    .default(0.85),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * Video
 */
export const zVideoOutput = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
});

/**
 * VideoOutput
 */
export const zSfxV15VideoToVideoOutput = z.object({
  video: z.array(zVideoOutput).register(z.globalRegistry, {
    description: "The processed video with sound effects",
  }),
});

/**
 * Input
 */
export const zSfxV15VideoToVideoInput = z.object({
  num_samples: z.optional(z.union([z.int().gte(2).lte(8), z.unknown()])),
  duration: z.optional(z.union([z.number().gte(1).lte(10), z.unknown()])),
  start_offset: z.optional(z.union([z.number().gte(0), z.unknown()])),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int().gte(1), z.unknown()])),
  text_prompt: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * Q2VideoExtensionOutput
 */
export const zViduQ2VideoExtensionProOutput = z.object({
  video: zFile,
});

/**
 * Q2VideoExtensionRequest
 */
export const zViduQ2VideoExtensionProInput = z.object({
  prompt: z.optional(
    z.string().max(3000).register(z.globalRegistry, {
      description: "text prompt to guide the video extension",
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
      ])
      .register(z.globalRegistry, {
        description: "Duration of the extension in seconds",
      }),
  ),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
});

/**
 * VideoOutput
 */
export const zBirefnetV2VideoOutput = z.object({
  video: zVideoFileType2,
  mask_video: z.optional(zVideoFileType2),
});

/**
 * VideoInputV2
 */
export const zBirefnetV2VideoInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  operating_resolution: z.optional(
    z.enum(["1024x1024", "2048x2048", "2304x2304"]).register(z.globalRegistry, {
      description:
        "The resolution to operate on. The higher the resolution, the more accurate the output will be for high res input images. The '2304x2304' option is only available for the 'General Use (Dynamic)' model.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum([
        "General Use (Light)",
        "General Use (Light 2K)",
        "General Use (Heavy)",
        "Matting",
        "Portrait",
        "General Use (Dynamic)",
      ])
      .register(z.globalRegistry, {
        description:
          "\n            Model to use for background removal.\n            The 'General Use (Light)' model is the original model used in the BiRefNet repository.\n            The 'General Use (Light 2K)' model is the original model used in the BiRefNet repository but trained with 2K images.\n            The 'General Use (Heavy)' model is a slower but more accurate model.\n            The 'Matting' model is a model trained specifically for matting images.\n            The 'Portrait' model is a model trained specifically for portrait images.\n            The 'General Use (Dynamic)' model supports dynamic resolutions from 256x256 to 2304x2304.\n            The 'General Use (Light)' model is recommended for most use cases.\n\n            The corresponding models are as follows:\n            - 'General Use (Light)': BiRefNet\n            - 'General Use (Light 2K)': BiRefNet_lite-2K\n            - 'General Use (Heavy)': BiRefNet_lite\n            - 'Matting': BiRefNet-matting\n            - 'Portrait': BiRefNet-portrait\n            - 'General Use (Dynamic)': BiRefNet_dynamic\n        ",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  output_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to output the mask used to remove the background",
      }),
    )
    .default(false),
  refine_foreground: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to refine the foreground using the estimated mask",
      }),
    )
    .default(true),
});

/**
 * VideoEffectOutput
 */
export const zVideoAsPromptOutput = z.object({
  video: zFileType2,
});

/**
 * VideoEffectInputWan
 */
export const zVideoAsPromptInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate an image from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second for the output video. Only applicable if output_type is 'video'.",
      }),
    )
    .default(16),
  video_description: z.string().register(z.globalRegistry, {
    description: "A brief description of the input video content.",
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: "Guidance scale for generation.",
      }),
    )
    .default(5),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(49),
});

/**
 * UpscaleOutput
 */
export const zBytedanceUpscalerUpscaleVideoOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of audio input/video output as used for billing.",
  }),
  video: zFile,
});

/**
 * UpscaleInput
 */
export const zBytedanceUpscalerUpscaleVideoInput = z.object({
  target_fps: z.optional(
    z.enum(["30fps", "60fps"]).register(z.globalRegistry, {
      description: "The target FPS of the video to upscale.",
    }),
  ),
  video_url: z.union([z.string(), z.string()]),
  target_resolution: z.optional(
    z.enum(["1080p", "2k", "4k"]).register(z.globalRegistry, {
      description: "The target resolution of the video to upscale.",
    }),
  ),
});

/**
 * AutoSubtitleOutput
 *
 * Output model for video with automatic subtitles
 */
export const zWorkflowUtilitiesAutoSubtitleOutput = z
  .object({
    transcription: z.string().register(z.globalRegistry, {
      description: "Full transcription text",
    }),
    subtitle_count: z.int().register(z.globalRegistry, {
      description: "Number of subtitle segments generated",
    }),
    transcription_metadata: z.optional(
      z.record(z.string(), z.unknown()).register(z.globalRegistry, {
        description:
          "Additional transcription metadata from ElevenLabs (language, segments, etc.)",
      }),
    ),
    words: z.optional(
      z.array(z.record(z.string(), z.unknown())).register(z.globalRegistry, {
        description: "Word-level timing information from transcription service",
      }),
    ),
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for video with automatic subtitles",
  });

/**
 * AutoSubtitleInput
 *
 * Input model for automatic subtitle generation and styling
 */
export const zWorkflowUtilitiesAutoSubtitleInput = z
  .object({
    font_weight: z.optional(
      z.enum(["normal", "bold", "black"]).register(z.globalRegistry, {
        description: "Font weight (TikTok style typically uses bold or black)",
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    stroke_width: z
      .optional(
        z.int().gte(0).lte(10).register(z.globalRegistry, {
          description: "Text stroke/outline width in pixels (0 for no stroke)",
        }),
      )
      .default(3),
    font_color: z.optional(
      z
        .enum([
          "white",
          "black",
          "red",
          "green",
          "blue",
          "yellow",
          "orange",
          "purple",
          "pink",
          "brown",
          "gray",
          "cyan",
          "magenta",
        ])
        .register(z.globalRegistry, {
          description: "Subtitle text color for non-active words",
        }),
    ),
    font_size: z
      .optional(
        z.int().gte(20).lte(150).register(z.globalRegistry, {
          description:
            "Font size for subtitles (TikTok style uses larger text)",
        }),
      )
      .default(100),
    language: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Language code for transcription (e.g., 'en', 'es', 'fr', 'de', 'it', 'pt', 'nl', 'ja', 'zh', 'ko') or 3-letter ISO code (e.g., 'eng', 'spa', 'fra')",
        }),
      )
      .default("en"),
    y_offset: z
      .optional(
        z.int().gte(-200).lte(200).register(z.globalRegistry, {
          description:
            "Vertical offset in pixels (positive = move down, negative = move up)",
        }),
      )
      .default(75),
    background_opacity: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "Background opacity (0.0 = fully transparent, 1.0 = fully opaque)",
        }),
      )
      .default(0),
    stroke_color: z.optional(
      z
        .enum([
          "black",
          "white",
          "red",
          "green",
          "blue",
          "yellow",
          "orange",
          "purple",
          "pink",
          "brown",
          "gray",
          "cyan",
          "magenta",
        ])
        .register(z.globalRegistry, {
          description: "Text stroke/outline color",
        }),
    ),
    highlight_color: z.optional(
      z
        .enum([
          "white",
          "black",
          "red",
          "green",
          "blue",
          "yellow",
          "orange",
          "purple",
          "pink",
          "brown",
          "gray",
          "cyan",
          "magenta",
        ])
        .register(z.globalRegistry, {
          description:
            "Color for the currently speaking word (karaoke-style highlight)",
        }),
    ),
    enable_animation: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Enable animation effects for subtitles (bounce style entrance)",
        }),
      )
      .default(true),
    font_name: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Any Google Font name from fonts.google.com (e.g., 'Montserrat', 'Poppins', 'BBH Sans Hegarty')",
        }),
      )
      .default("Montserrat"),
    position: z.optional(
      z.enum(["top", "center", "bottom"]).register(z.globalRegistry, {
        description: "Vertical position of subtitles",
      }),
    ),
    words_per_subtitle: z
      .optional(
        z.int().gte(1).lte(12).register(z.globalRegistry, {
          description:
            "Maximum number of words per subtitle segment. Use 1 for single-word display, 2-3 for short phrases, or 8-12 for full sentences.",
        }),
      )
      .default(3),
    background_color: z.optional(
      z
        .enum([
          "black",
          "white",
          "red",
          "green",
          "blue",
          "yellow",
          "orange",
          "purple",
          "pink",
          "brown",
          "gray",
          "cyan",
          "magenta",
          "none",
          "transparent",
        ])
        .register(z.globalRegistry, {
          description:
            "Background color behind text ('none' or 'transparent' for no background)",
        }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input model for automatic subtitle generation and styling",
  });

/**
 * FlashVSRPlusVideoOutput
 */
export const zFlashvsrUpscaleVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The random seed used for the generation process.",
  }),
  video: zFile,
});

/**
 * FlashVSRPlusVideoInput
 *
 * Input fields common to FlashVSR+ image/video endpoints.
 */
export const zFlashvsrUpscaleVideoInput = z
  .object({
    video_url: z.union([z.string(), z.string()]),
    acceleration: z.optional(
      z.enum(["regular", "high", "full"]).register(z.globalRegistry, {
        description:
          "Acceleration mode for VAE decoding. Options: regular (best quality), high (balanced), full (fastest). More accerleation means longer duration videos can be processed too.",
      }),
    ),
    quality: z
      .optional(
        z.int().gte(0).lte(100).register(z.globalRegistry, {
          description:
            "Quality level for tile blending (0-100). Controls overlap between tiles to prevent grid artifacts. Higher values provide better quality with more overlap. Recommended: 70-85 for high-res videos, 50-70 for faster processing.",
        }),
      )
      .default(70),
    output_format: z.optional(
      z
        .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
        .register(z.globalRegistry, {
          description: "The format of the output video.",
        }),
    ),
    color_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Color correction enabled.",
        }),
      )
      .default(true),
    output_write_mode: z.optional(
      z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
        description: "The write mode of the output video.",
      }),
    ),
    sync_mode: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If `True`, the media will be returned inline and not stored in history.",
        }),
      )
      .default(false),
    output_quality: z.optional(
      z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
        description: "The quality of the output video.",
      }),
    ),
    upscale_factor: z
      .optional(
        z.number().gte(1).lte(4).register(z.globalRegistry, {
          description: "Upscaling factor to be used.",
        }),
      )
      .default(2),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Copy the original audio tracks into the upscaled video using FFmpeg when possible.",
        }),
      )
      .default(false),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The random seed used for the generation process.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input fields common to FlashVSR+ image/video endpoints.",
  });

/**
 * EdittoOutput
 */
export const zEdittoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  frames_zip: z.optional(z.union([zFileType2, z.unknown()])),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFile,
});

/**
 * EdittoInput
 */
export const zEdittoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.union([z.enum(["none", "low", "regular"]), z.unknown()]),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between the original frames. A value of 0 means no interpolation.",
      }),
    )
    .default(0),
  temporal_downsample_factor: z
    .optional(
      z.int().gte(0).lte(5).register(z.globalRegistry, {
        description:
          "Temporal downsample factor for the video. This is an integer value that determines how many frames to skip in the video. A value of 0 means no downsampling. For each downsample factor, one upsample factor will automatically be applied.",
      }),
    )
    .default(0),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  frames_per_second: z.optional(z.union([z.int().gte(5).lte(30), z.unknown()])),
  match_input_num_frames: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames in the generated video will match the number of frames in the input video. If false, the number of frames will be determined by the num_frames parameter.",
      }),
    )
    .default(false),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images closely related to the text prompt.",
      }),
    )
    .default(5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 241 (inclusive).",
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "letterboxing, borders, black bars, bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "Sampler to use for video generation.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["auto", "240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  return_frames_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, also return a ZIP file containing all generated frames.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  match_input_frames_per_second: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the frames per second of the generated video will match the input video. If false, the frames per second will be determined by the frames_per_second parameter.",
      }),
    )
    .default(false),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_auto_downsample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the model will automatically temporally downsample the video to an appropriate frame length for the model, then will interpolate it back to the original frame length.",
      }),
    )
    .default(false),
});

/**
 * PointPromptBase
 */
export const zPointPromptBase = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Coordinate of the prompt",
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Coordinate of the prompt",
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Optional object identifier. Prompts sharing an object id refine the same object.",
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: "1 for foreground, 0 for background",
    }),
  ),
});

/**
 * BoxPromptBase
 */
export const zBoxPromptBase = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Min Coordinate of the box",
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Optional object identifier. Boxes sharing an object id refine the same object.",
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Max Coordinate of the box",
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Min Coordinate of the box",
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Max Coordinate of the box",
    }),
  ),
});

/**
 * SAM3VideoOutput
 */
export const zSam3VideoOutput = z.object({
  boundingbox_frames_zip: z.optional(zFile),
  video: zFile,
});

/**
 * SAM3VideoInput
 */
export const zSam3VideoInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  detection_threshold: z
    .optional(
      z.number().gte(0.1).lte(1).register(z.globalRegistry, {
        description:
          "Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. ",
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zBoxPromptBase).register(z.globalRegistry, {
        description:
          "List of box prompt coordinates (x_min, y_min, x_max, y_max).",
      }),
    )
    .default([]),
  point_prompts: z
    .optional(
      z.array(zPointPromptBase).register(z.globalRegistry, {
        description: "List of point prompts",
      }),
    )
    .default([]),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Apply the mask on the video.",
      }),
    )
    .default(true),
  text_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "[DEPRECATED] Use 'prompt' instead. Kept for backward compatibility.",
    }),
  ),
});

/**
 * PointPrompt
 */
export const zPointPrompt = z.object({
  y: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Coordinate of the prompt",
    }),
  ),
  x: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Coordinate of the prompt",
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Optional object identifier. Prompts sharing an object id refine the same object.",
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The frame index to interact with.",
    }),
  ),
  label: z.optional(
    z.union([z.literal(0), z.literal(1)]).register(z.globalRegistry, {
      description: "1 for foreground, 0 for background",
    }),
  ),
});

/**
 * BoxPrompt
 */
export const zBoxPrompt = z.object({
  y_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Min Coordinate of the box",
    }),
  ),
  object_id: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Optional object identifier. Boxes sharing an object id refine the same object.",
    }),
  ),
  frame_index: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The frame index to interact with.",
    }),
  ),
  x_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Max Coordinate of the box",
    }),
  ),
  x_min: z.optional(
    z.int().register(z.globalRegistry, {
      description: "X Min Coordinate of the box",
    }),
  ),
  y_max: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Y Max Coordinate of the box",
    }),
  ),
});

/**
 * SAM3VideoOutput
 */
export const zSam3VideoRleOutput = z.object({
  boundingbox_frames_zip: z.optional(zFile),
  video: zFile,
});

/**
 * SAM3VideoRLEInput
 */
export const zSam3VideoRleInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Text prompt for segmentation. Use commas to track multiple objects (e.g., 'person, cloth').",
      }),
    )
    .default(""),
  video_url: z.union([z.string(), z.string()]),
  detection_threshold: z
    .optional(
      z.number().gte(0.01).lte(1).register(z.globalRegistry, {
        description:
          "Detection confidence threshold (0.0-1.0). Lower = more detections but less precise. Defaults: 0.5 for existing, 0.7 for new objects. Try 0.2-0.3 if text prompts fail.",
      }),
    )
    .default(0.5),
  box_prompts: z
    .optional(
      z.array(zBoxPrompt).register(z.globalRegistry, {
        description: "List of box prompts with optional frame_index.",
      }),
    )
    .default([]),
  boundingbox_zip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Return per-frame bounding box overlays as a zip archive.",
      }),
    )
    .default(false),
  point_prompts: z
    .optional(
      z.array(zPointPrompt).register(z.globalRegistry, {
        description: "List of point prompts with frame indices.",
      }),
    )
    .default([]),
  frame_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Frame index used for initial interaction when mask_url is provided.",
      }),
    )
    .default(0),
  mask_url: z.optional(z.union([z.string(), z.string()])),
  apply_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Apply the mask on the video.",
      }),
    )
    .default(false),
});

/**
 * LucyEditFastOutput
 */
export const zLucyEditFastOutput = z.object({
  video: zFile,
});

/**
 * LucyEditFastInput
 */
export const zLucyEditFastInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enhance the prompt for better results.",
      }),
    )
    .default(true),
});

/**
 * LTXRetakeVideoResponse
 */
export const zLtx2RetakeVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LTXRetakeVideoRequest
 */
export const zLtx2RetakeVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The prompt to retake the video with",
  }),
  video_url: z.union([z.string(), z.string()]),
  start_time: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: "The start time of the video to retake in seconds",
      }),
    )
    .default(0),
  duration: z
    .optional(
      z.number().gte(2).lte(20).register(z.globalRegistry, {
        description: "The duration of the video to retake in seconds",
      }),
    )
    .default(5),
  retake_mode: z.optional(
    z
      .enum(["replace_audio", "replace_video", "replace_audio_and_video"])
      .register(z.globalRegistry, {
        description: "The retake mode to use for the retake",
      }),
  ),
});

/**
 * GreenScreenRembgOutput
 */
export const zVideoBackgroundRemovalGreenScreenOutput = z.object({
  video: z.array(zFileType2),
});

/**
 * GreenScreenRembgInput
 */
export const zVideoBackgroundRemovalGreenScreenInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  output_codec: z.optional(
    z.enum(["vp9", "h264"]).register(z.globalRegistry, {
      description:
        "Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.",
    }),
  ),
  spill_suppression_strength: z.optional(
    z.union([z.number().gte(0).lte(1), z.unknown()]),
  ),
});

/**
 * OmniV2VReferenceOutput
 */
export const zKlingVideoO1VideoToVideoReferenceOutput = z.object({
  video: zFile,
});

/**
 * OmniVideoElementInput
 */
export const zOmniVideoElementInput = z.object({
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "Additional reference images from different angles. 1-3 images supported. At least one image is required.",
    }),
  ),
  frontal_image_url: z.union([z.string(), z.string()]),
});

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zKlingVideoO1VideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    video_url: z.union([z.string(), z.string()]),
    aspect_ratio: z.optional(
      z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
        .register(z.globalRegistry, {
          description: "Video duration in seconds.",
        }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to keep the original audio from the video.",
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input for video editing or video-as-reference generation.",
  });

/**
 * OmniV2VEditOutput
 */
export const zKlingVideoO1VideoToVideoEditOutput = z.object({
  video: zFile,
});

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zKlingVideoO1VideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    video_url: z.union([z.string(), z.string()]),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to keep the original audio from the video.",
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: "Input for video editing or video-as-reference generation.",
  });

/**
 * FastGeneralRembgOutput
 */
export const zVideoBackgroundRemovalFastOutput = z.object({
  video: z.array(zFileType2),
});

/**
 * FastGeneralRembgInput
 */
export const zVideoBackgroundRemovalFastInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Set to False if the subject is not a person.",
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(["vp9", "h264"]).register(z.globalRegistry, {
      description:
        "Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.",
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
});

/**
 * React1Output
 */
export const zSyncLipsyncReact1Output = z.object({
  video: zVideoFileType2,
});

/**
 * React1Input
 */
export const zSyncLipsyncReact1Input = z.object({
  emotion: z
    .enum(["happy", "angry", "sad", "neutral", "disgusted", "surprised"])
    .register(z.globalRegistry, {
      description:
        "Emotion prompt for the generation. Currently supports single-word emotions only.",
    }),
  video_url: z.union([z.string(), z.string()]),
  lipsync_mode: z.optional(
    z
      .enum(["cut_off", "loop", "bounce", "silence", "remap"])
      .register(z.globalRegistry, {
        description:
          "Lipsync mode when audio and video durations are out of sync.",
      }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Controls the expresiveness of the lipsync.",
      }),
    )
    .default(0.5),
  model_mode: z.optional(
    z.enum(["lips", "face", "head"]).register(z.globalRegistry, {
      description:
        "Controls the edit region and movement scope for the model. Available options:\n- `lips`: Only lipsync using react-1 (minimal facial changes).\n- `face`: Lipsync + facial expressions without head movements.\n- `head`: Lipsync + facial expressions + natural talking head movements.",
    }),
  ),
});

/**
 * Output
 *
 * Output from Wan Vision Enhancer
 */
export const zWanVisionEnhancerOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation.",
    }),
    timings: z.record(z.string(), z.number()).register(z.globalRegistry, {
      description: "The timings of the different steps in the workflow.",
    }),
    video: zFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output from Wan Vision Enhancer",
  });

/**
 * Input
 *
 * Input parameters for Wan Vision Enhancer (Video-to-Video)
 */
export const zWanVisionEnhancerInput = z
  .object({
    prompt: z.optional(z.union([z.string(), z.unknown()])),
    video_url: z.union([z.string(), z.string()]),
    seed: z.optional(z.union([z.int(), z.unknown()])),
    target_resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description:
          "Target output resolution for the enhanced video. 720p (native, fast) or 1080p (upscaled, slower). Processing is always done at 720p, then upscaled if 1080p selected.",
      }),
    ),
    negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
    creativity: z
      .optional(
        z.int().gte(0).lte(4).register(z.globalRegistry, {
          description:
            "Controls how much the model enhances/changes the video. 0 = Minimal change (preserves original), 1 = Subtle enhancement (default), 2 = Medium enhancement, 3 = Strong enhancement, 4 = Maximum enhancement.",
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description: "Input parameters for Wan Vision Enhancer (Video-to-Video)",
  });

/**
 * OneToALLAnimationResponse
 */
export const zOneToAllAnimation14bOutput = z.object({
  video: zFile,
});

/**
 * OneToALLAnimationRequest
 */
export const zOneToAllAnimation14bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "The image guidance scale to use for the video generation.",
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The pose guidance scale to use for the video generation.",
      }),
    )
    .default(1.5),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: "The negative prompt to generate the video from.",
  }),
});

/**
 * OneToALLAnimationResponse
 */
export const zOneToAllAnimation13bOutput = z.object({
  video: zFile,
});

/**
 * OneToALLAnimationRequest
 */
export const zOneToAllAnimation13bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  image_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "The image guidance scale to use for the video generation.",
      }),
    )
    .default(2),
  pose_guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The pose guidance scale to use for the video generation.",
      }),
    )
    .default(1.5),
  video_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(30),
  negative_prompt: z.string().register(z.globalRegistry, {
    description: "The negative prompt to generate the video from.",
  }),
});

/**
 * SteadyDancerResponse
 *
 * Response model for SteadyDancer.
 */
export const zSteadyDancerOutput = z
  .object({
    num_frames: z.int().register(z.globalRegistry, {
      description:
        "The actual number of frames generated (aligned to 4k+1 pattern).",
    }),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation.",
    }),
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Response model for SteadyDancer.",
  });

/**
 * SteadyDancerRequest
 *
 * Request model for SteadyDancer human animation.
 */
export const zSteadyDancerInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Text prompt describing the desired animation.",
        }),
      )
      .default("A person dancing with smooth and natural movements."),
    video_url: z.optional(z.union([z.string(), z.string()])),
    acceleration: z.optional(
      z.enum(["light", "moderate", "aggressive"]).register(z.globalRegistry, {
        description: "Acceleration levels.",
      }),
    ),
    pose_guidance_scale: z
      .optional(
        z.number().gte(0.5).lte(3).register(z.globalRegistry, {
          description: "Pose guidance scale for pose control strength.",
        }),
      )
      .default(1),
    shift: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: "Shift parameter for video generation.",
        }),
      )
      .default(5),
    pose_guidance_end: z
      .optional(
        z.number().gte(0.2).lte(1).register(z.globalRegistry, {
          description:
            "End ratio for pose guidance. Controls when pose guidance ends.",
        }),
      )
      .default(0.4),
    frames_per_second: z.optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24. If not specified, uses the FPS from the input video.",
      }),
    ),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(6).register(z.globalRegistry, {
          description: "Classifier-free guidance scale for prompt adherence.",
        }),
      )
      .default(1),
    num_frames: z.optional(
      z.int().gte(5).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. If not specified, uses the frame count from the input video (capped at 241). Will be adjusted to nearest valid value (must satisfy 4k+1 pattern).",
      }),
    ),
    use_turbo: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If true, applies quality enhancement for faster generation with improved quality. When enabled, parameters are automatically optimized (num_inference_steps=6, guidance_scale=1.0) and uses the LightX2V distillation LoRA.",
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for video generation.",
        }),
      )
      .default(
        "blurred, distorted face, bad anatomy, extra limbs, poorly drawn hands, poorly drawn feet, disfigured, out of frame, duplicate, watermark, signature, text",
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description:
          "Aspect ratio of the generated video. If 'auto', will be determined from the reference image.",
      }),
    ),
    pose_guidance_start: z
      .optional(
        z.number().gte(0).lte(0.5).register(z.globalRegistry, {
          description:
            "Start ratio for pose guidance. Controls when pose guidance begins.",
        }),
      )
      .default(0.1),
    resolution: z.optional(
      z.enum(["480p", "576p", "720p"]).register(z.globalRegistry, {
        description:
          "Resolution of the generated video. 576p is default, 720p for higher quality. 480p is lower quality.",
      }),
    ),
    image_url: z.optional(z.union([z.string(), z.string()])),
    preserve_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If enabled, copies audio from the input driving video to the output video.",
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    num_inference_steps: z
      .optional(
        z.int().gte(4).lte(50).register(z.globalRegistry, {
          description:
            "Number of inference steps for sampling. Higher values give better quality but take longer.",
        }),
      )
      .default(6),
  })
  .register(z.globalRegistry, {
    description: "Request model for SteadyDancer human animation.",
  });

/**
 * OmniV2VEditOutput
 */
export const zKlingVideoO1StandardVideoToVideoEditOutput = z.object({
  video: zFile,
});

/**
 * OmniV2VEditInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zKlingVideoO1StandardVideoToVideoEditInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    video_url: z.union([z.string(), z.string()]),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to keep the original audio from the video.",
        }),
      )
      .default(false),
  })
  .register(z.globalRegistry, {
    description: "Input for video editing or video-as-reference generation.",
  });

/**
 * OmniV2VReferenceOutput
 */
export const zKlingVideoO1StandardVideoToVideoReferenceOutput = z.object({
  video: zFile,
});

/**
 * OmniV2VReferenceInput
 *
 * Input for video editing or video-as-reference generation.
 */
export const zKlingVideoO1StandardVideoToVideoReferenceInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Use @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    video_url: z.union([z.string(), z.string()]),
    aspect_ratio: z.optional(
      z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video frame. If 'auto', the aspect ratio will be determined automatically based on the input video, and the closest aspect ratio to the input video will be used.",
      }),
    ),
    duration: z.optional(
      z
        .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
        .register(z.globalRegistry, {
          description: "Video duration in seconds.",
        }),
    ),
    keep_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to keep the original audio from the video.",
        }),
      )
      .default(false),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include. Reference in prompt as @Element1, @Element2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 4 total (elements + reference images) when using video.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input for video editing or video-as-reference generation.",
  });

/**
 * Veo31VideoToVideoOutput
 */
export const zVeo31ExtendVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zVeo31ExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        "The text prompt describing how the video should be extended",
    }),
    duration: z.optional(
      z.enum(["7s"]).register(z.globalRegistry, {
        description: "The duration of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video.",
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to generate audio for the video.",
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
        }),
      )
      .default(false),
    video_url: z.union([z.string(), z.string()]),
    resolution: z.optional(
      z.enum(["720p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video.",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator.",
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "A negative prompt to guide the video generation.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input for video extension/video-to-video generation.",
  });

/**
 * Veo31VideoToVideoOutput
 */
export const zVeo31FastExtendVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31VideoToVideoInput
 *
 * Input for video extension/video-to-video generation.
 */
export const zVeo31FastExtendVideoInput = z
  .object({
    prompt: z.string().max(20000).register(z.globalRegistry, {
      description:
        "The text prompt describing how the video should be extended",
    }),
    duration: z.optional(
      z.enum(["7s"]).register(z.globalRegistry, {
        description: "The duration of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video.",
      }),
    ),
    generate_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to generate audio for the video.",
        }),
      )
      .default(true),
    auto_fix: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
        }),
      )
      .default(false),
    video_url: z.union([z.string(), z.string()]),
    resolution: z.optional(
      z.enum(["720p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video.",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator.",
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "A negative prompt to guide the video generation.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input for video extension/video-to-video generation.",
  });

/**
 * ReferenceToVideoOutput
 *
 * Output for reference-to-video generation
 */
export const zV26ReferenceToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output for reference-to-video generation",
  });

/**
 * ReferenceToVideoInput
 *
 * Input for Wan 2.6 reference-to-video generation (R2V)
 */
export const zV26ReferenceToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "Use @Video1, @Video2, @Video3 to reference subjects from your videos. Works for people, animals, or objects. For multi-shot prompts: '[0-3s] Shot 1. [3-6s] Shot 2.' Max 800 characters.",
    }),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description:
          "Video resolution tier. R2V only supports 720p and 1080p (no 480p).",
      }),
    ),
    video_urls: z.array(z.string()).register(z.globalRegistry, {
      description:
        "Reference videos for subject consistency (1-3 videos). Videos' FPS must be at least 16 FPS.Reference in prompt as @Video1, @Video2, @Video3. Works for people, animals, or objects.",
    }),
    aspect_ratio: z.optional(
      z.enum(["16:9", "9:16", "1:1", "4:3", "3:4"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video.",
      }),
    ),
    duration: z.optional(
      z.enum(["5", "10"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. R2V supports only 5 or 10 seconds (no 15s).",
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable prompt rewriting using LLM.",
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true (default), enables intelligent multi-shot segmentation for coherent narrative videos with multiple shots. When false, generates single continuous shot. Only active when enable_prompt_expansion is True.",
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Negative prompt to describe content to avoid. Max 500 characters.",
        }),
      )
      .default(""),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for Wan 2.6 reference-to-video generation (R2V)",
  });

/**
 * VideoOutput
 */
export const zBriaVideoEraserErasePromptOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseByPromptInputModel
 */
export const zBriaVideoEraserErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: "Input prompt to detect object to erase",
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * VideoOutput
 */
export const zBriaVideoEraserEraseKeypointsOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseByKeyPointsInputModel
 */
export const zBriaVideoEraserEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * VideoOutput
 */
export const zBriaVideoEraserEraseMaskOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseInputModel
 */
export const zBriaVideoEraserEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  mask_video_url: z.union([z.string(), z.string()]),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * CrystalVideoUpscaleOutput
 */
export const zCrystalVideoUpscalerOutput = z.object({
  video: zVideoFileType2,
});

/**
 * CrystalVideoUpscaleInput
 */
export const zCrystalVideoUpscalerInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  scale_factor: z
    .optional(
      z.number().gte(1).lte(200).register(z.globalRegistry, {
        description:
          "Scale factor. The scale factor must be chosen such that the upscaled video does not exceed 5K resolution.",
      }),
    )
    .default(2),
});

/**
 * ScailResponse
 */
export const zScailOutput = z.object({
  video: zFile,
});

/**
 * ScailRequest
 */
export const zScailInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide video generation.",
  }),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(["512p"]).register(z.globalRegistry, {
      description:
        "Output resolution. Outputs 896x512 (landscape) or 512x896 (portrait) based on the input image aspect ratio.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(28),
  multi_character: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Enable multi-character mode. Use when driving video has multiple people.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * LucyRestyleOutput
 */
export const zLucyRestyleOutput = z.object({
  video: zFile,
});

/**
 * LucyRestyleInput
 */
export const zLucyRestyleInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the function will wait for the video to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the video directly\n            in the response without going through the CDN.\n        ",
      }),
    )
    .default(false),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video",
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Seed for video generation",
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enhance the prompt for better results.",
      }),
    )
    .default(true),
});

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zKlingVideoV26ProMotionControlOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for motion control video generation.",
  });

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zKlingVideoV26ProMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.union([z.string(), z.string()]),
    character_orientation: z
      .enum(["image", "video"])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to keep the original sound from the reference video.",
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Request model for motion control video generation.",
  });

/**
 * MotionControlOutput
 *
 * Output model for motion control video generation.
 */
export const zKlingVideoV26StandardMotionControlOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for motion control video generation.",
  });

/**
 * MotionControlRequest
 *
 * Request model for motion control video generation.
 */
export const zKlingVideoV26StandardMotionControlInput = z
  .object({
    prompt: z.optional(z.string().max(2500)),
    video_url: z.union([z.string(), z.string()]),
    character_orientation: z
      .enum(["image", "video"])
      .register(z.globalRegistry, {
        description:
          "Controls whether the output character's orientation matches the reference image or video. 'video': orientation matches reference video - better for complex motions (max 30s). 'image': orientation matches reference image - better for following camera movements (max 10s).",
      }),
    keep_original_sound: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to keep the original sound from the reference video.",
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Request model for motion control video generation.",
  });

/**
 * TrajectoryParameters
 *
 * Camera trajectory parameters for re-camera operations.
 *
 * Each list represents interpolation values across frames:
 * - theta: Horizontal rotation angles (degrees)
 * - phi: Vertical rotation angles (degrees)
 * - radius: Camera distance scaling factors
 */
export const zTrajectoryParameters = z
  .object({
    theta: z.array(z.number()).register(z.globalRegistry, {
      description: "Horizontal rotation angles (degrees) for each keyframe.",
    }),
    radius: z.array(z.number()).register(z.globalRegistry, {
      description: "Camera distance scaling factors for each keyframe.",
    }),
    phi: z.array(z.number()).register(z.globalRegistry, {
      description: "Vertical rotation angles (degrees) for each keyframe.",
    }),
  })
  .register(z.globalRegistry, {
    description:
      "Camera trajectory parameters for re-camera operations.\n\nEach list represents interpolation values across frames:\n- theta: Horizontal rotation angles (degrees)\n- phi: Vertical rotation angles (degrees)\n- radius: Camera distance scaling factors",
  });

/**
 * LightXOutput
 */
export const zLightxRecameraOutput = z.object({
  viz_video: z.optional(zFile),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  input_video: z.optional(zFile),
  video: zFile,
});

/**
 * LightXRecameraRequest
 *
 * Re-camera-only request (minimal schema).
 */
export const zLightxRecameraInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Optional text prompt. If omitted, Light-X will auto-caption the video.",
      }),
    ),
    trajectory: z.optional(zTrajectoryParameters),
    video_url: z.union([z.string(), z.string()]),
    camera: z.optional(
      z.enum(["traj", "target"]).register(z.globalRegistry, {
        description: "Camera control mode.",
      }),
    ),
    target_pose: z.optional(
      z.array(z.number()).register(z.globalRegistry, {
        description:
          "Target camera pose [theta, phi, radius, x, y] (required when camera='target').",
      }),
    ),
    mode: z.optional(
      z
        .enum(["gradual", "bullet", "direct", "dolly-zoom"])
        .register(z.globalRegistry, {
          description: "Camera motion mode.",
        }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Re-camera-only request (minimal schema).",
  });

/**
 * RelightParameters
 *
 * Relighting parameters for video relighting operations.
 *
 * Used with relight_condition_type 'ic' (intrinsic conditioning).
 */
export const zRelightParameters = z
  .object({
    relight_prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt describing the desired lighting condition.",
    }),
    bg_source: z.optional(
      z.enum(["Left", "Right", "Top", "Bottom"]).register(z.globalRegistry, {
        description: "Direction of the light source (used for IC-light).",
      }),
    ),
    use_sky_mask: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to use sky masking for outdoor scenes.",
        }),
      )
      .default(false),
    cfg: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: "Classifier-free guidance scale for relighting.",
        }),
      )
      .default(2),
  })
  .register(z.globalRegistry, {
    description:
      "Relighting parameters for video relighting operations.\n\nUsed with relight_condition_type 'ic' (intrinsic conditioning).",
  });

/**
 * LightXOutput
 */
export const zLightxRelightOutput = z.object({
  viz_video: z.optional(zFile),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  input_video: z.optional(zFile),
  video: zFile,
});

/**
 * LightXRelightRequest
 *
 * Relighting-only request (minimal schema).
 */
export const zLightxRelightInput = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Optional text prompt. If omitted, Light-X will auto-caption the video.",
      }),
    ),
    video_url: z.union([z.string(), z.string()]),
    relight_parameters: z.optional(zRelightParameters),
    ref_id: z
      .optional(
        z.int().gte(0).register(z.globalRegistry, {
          description:
            "Frame index to use as referencen to relight the video with reference.",
        }),
      )
      .default(0),
    relit_cond_img_url: z.optional(z.union([z.string(), z.string()])),
    relit_cond_type: z.optional(
      z.enum(["ic", "ref", "hdr", "bg"]).register(z.globalRegistry, {
        description: "Relight condition type.",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Relighting-only request (minimal schema).",
  });

/**
 * VideoOutput
 */
export const zVideoEraseMaskOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseInputModel
 */
export const zVideoEraseMaskInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  mask_video_url: z.union([z.string(), z.string()]),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * VideoOutput
 */
export const zVideoErasePromptOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseByPromptInputModel
 */
export const zVideoErasePromptInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: "Input prompt to detect object to erase",
  }),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * VideoOutput
 */
export const zVideoEraseKeypointsOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * EraseByKeyPointsInputModel
 */
export const zVideoEraseKeypointsInput = z.object({
  preserve_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, audio will be preserved in the output video.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "gif",
        "mov_h264",
        "mov_h265",
        "mov_proresks",
        "mkv_h264",
        "mkv_h265",
        "mkv_vp9",
        "mkv_mpeg4",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, gif, mov_h264, mov_h265, mov_proresks, mkv_h264, mkv_h265, mkv_vp9, mkv_mpeg4.",
      }),
  ),
  keypoints: z.array(z.string()).register(z.globalRegistry, {
    description:
      "Input keypoints [x,y] to erase or keep from the video. Format like so: {'x':100, 'y':100, 'type':'positive/negative'}",
  }),
  auto_trim: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "auto trim the video, to working duration ( 5s )",
      }),
    )
    .default(true),
});

/**
 * LTX2ExtendVideoOutput
 */
export const zLtx219bExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2ExtendVideoInput
 */
export const zLtx219bExtendVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  extend_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          "The number of frames to use as context for the extension.",
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2ExtendVideoOutput
 */
export const zLtx219bExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LoRAInput
 *
 * LoRA weight configuration.
 */
export const zLoRaInput = z
  .object({
    path: z.string().register(z.globalRegistry, {
      description: "URL, HuggingFace repo ID (owner/repo) to lora weights.",
    }),
    scale: z
      .optional(
        z.number().gte(0).lte(4).register(z.globalRegistry, {
          description: "Scale factor for LoRA application (0.0 to 4.0).",
        }),
      )
      .default(1),
    weight_name: z.optional(z.union([z.string(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: "LoRA weight configuration.",
  });

/**
 * LTX2LoRAExtendVideoInput
 */
export const zLtx219bExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  extend_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          "The number of frames to use as context for the extension.",
      }),
    )
    .default(25),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
});

/**
 * LTX2ExtendVideoOutput
 */
export const zLtx219bDistilledExtendVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2DistilledExtendVideoInput
 */
export const zLtx219bDistilledExtendVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  extend_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          "The number of frames to use as context for the extension.",
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2ExtendVideoOutput
 */
export const zLtx219bDistilledExtendVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRADistilledExtendVideoInput
 */
export const zLtx219bDistilledExtendVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  extend_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "Direction to extend the video. 'forward' extends from the end of the video, 'backward' extends from the beginning.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  num_context_frames: z
    .optional(
      z.int().gte(0).lte(121).register(z.globalRegistry, {
        description:
          "The number of frames to use as context for the extension.",
      }),
    )
    .default(25),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2VideoToVideoOutput
 */
export const zLtx219bVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2VideoToVideoInput
 */
export const zLtx219bVideoToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.",
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  preprocessor: z.optional(
    z.enum(["depth", "canny", "pose", "none"]).register(z.globalRegistry, {
      description:
        "The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        "match_preprocessor",
        "canny",
        "depth",
        "pose",
        "detailer",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)",
      }),
  ),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2VideoToVideoOutput
 */
export const zLtx219bVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRAVideoToVideoInput
 */
export const zLtx219bVideoToVideoLoraInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.",
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  preprocessor: z.optional(
    z.enum(["depth", "canny", "pose", "none"]).register(z.globalRegistry, {
      description:
        "The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        "match_preprocessor",
        "canny",
        "depth",
        "pose",
        "detailer",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)",
      }),
  ),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2VideoToVideoOutput
 */
export const zLtx219bDistilledVideoToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2DistilledVideoToVideoInput
 */
export const zLtx219bDistilledVideoToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  video_url: z.union([z.string(), z.string()]),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.",
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  preprocessor: z.optional(
    z.enum(["depth", "canny", "pose", "none"]).register(z.globalRegistry, {
      description:
        "The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        "match_preprocessor",
        "canny",
        "depth",
        "pose",
        "detailer",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)",
      }),
  ),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
});

/**
 * LTX2VideoToVideoOutput
 */
export const zLtx219bDistilledVideoToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRADistilledVideoToVideoInput
 */
export const zLtx219bDistilledVideoToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  video_url: z.union([z.string(), z.string()]),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  ic_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the IC-LoRA to use. This allows you to control the strength of the IC-LoRA.",
      }),
    )
    .default(1),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  video_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Video conditioning strength. Lower values represent more freedom given to the model to change the video content.",
      }),
    )
    .default(1),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  match_video_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the video duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  preprocessor: z.optional(
    z.enum(["depth", "canny", "pose", "none"]).register(z.globalRegistry, {
      description:
        "The preprocessor to use for the video. When a preprocessor is used and `ic_lora_type` is set to `match_preprocessor`, the IC-LoRA will be loaded based on the preprocessor type.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  ic_lora: z.optional(
    z
      .enum([
        "match_preprocessor",
        "canny",
        "depth",
        "pose",
        "detailer",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The type of IC-LoRA to load. In-Context LoRA weights are used to condition the video based on edge, depth, or pose videos. Only change this from `match_preprocessor` if your videos are already preprocessed (or you are using the detailer.)",
      }),
  ),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Lower values represent more freedom given to the model to change the audio content.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  match_input_fps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When true, match the output FPS to the input video's FPS instead of using the default target FPS.",
      }),
    )
    .default(true),
});

/**
 * FaceFusionVideoOutput
 *
 * FaceFusion output payload when video content is generated
 */
export const zAiFaceSwapFaceswapvideoOutput = z
  .object({
    warning: z.optional(z.union([z.string(), z.unknown()])),
    video: zVideo,
    processing_time_ms: z.optional(z.union([z.int(), z.unknown()])),
  })
  .register(z.globalRegistry, {
    description: "FaceFusion output payload when video content is generated",
  });

/**
 * FaceSwapInputVideo
 *
 * Input schema for image  video face swap
 */
export const zAiFaceSwapFaceswapvideoInput = z
  .object({
    enable_occlusion_prevention: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Enable occlusion prevention for handling faces covered by hands/objects. Warning: Enabling this runs an occlusion-aware model which costs 2x more.",
        }),
      )
      .default(false),
    source_face_url: z.union([z.string(), z.string()]),
    target_video_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Input schema for image  video face swap",
  });

/**
 * XAIVideoEditOutput
 */
export const zGrokImagineVideoEditVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * XAIVideoEditInput
 */
export const zGrokImagineVideoEditVideoInput = z.object({
  prompt: z.string().max(4096).register(z.globalRegistry, {
    description: "Text description of the desired edit.",
  }),
  video_url: z.union([z.string(), z.string()]),
  resolution: z.optional(
    z.enum(["auto", "480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the output video.",
    }),
  ),
});

/**
 * Output
 */
export const zMmaudioV2Output = z.object({
  video: zFile,
});

/**
 * BaseInput
 */
export const zMmaudioV2Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the audio for.",
  }),
  video_url: z.union([z.string(), z.string()]),
  num_steps: z
    .optional(
      z.int().gte(4).lte(50).register(z.globalRegistry, {
        description: "The number of steps to generate the audio for.",
      }),
    )
    .default(25),
  duration: z
    .optional(
      z.number().gte(1).lte(30).register(z.globalRegistry, {
        description: "The duration of the audio to generate.",
      }),
    )
    .default(8),
  cfg_strength: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: "The strength of Classifier Free Guidance.",
      }),
    )
    .default(4.5),
  seed: z.optional(
    z.int().gte(0).lte(65535).register(z.globalRegistry, {
      description: "The seed for the random number generator",
    }),
  ),
  mask_away_clip: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to mask away the clip.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the audio for.",
      }),
    )
    .default(""),
});

/**
 * GeneralRembgOutput
 */
export const zVideoBackgroundRemovalOutputType2 = z.object({
  video: z.array(zFileType2),
});

/**
 * OutputRemoveBackgroundModel
 */
export const zVideoBackgroundRemovalOutput = z.object({
  video: z.union([zVideo, zFileType2]),
});

/**
 * GeneralRembgInput
 */
export const zVideoBackgroundRemovalInputType2 = z.object({
  video_url: z.union([z.string(), z.string()]),
  subject_is_person: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Set to False if the subject is not a person.",
      }),
    )
    .default(true),
  output_codec: z.optional(
    z.enum(["vp9", "h264"]).register(z.globalRegistry, {
      description:
        "Single VP9 video with alpha channel or two videos (rgb and alpha) in H264 format. H264 is recommended for better RGB quality.",
    }),
  ),
  refine_foreground_edges: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Improves the quality of the extracted object's edges.",
      }),
    )
    .default(true),
});

/**
 * InputRemoveBackgroundModel
 */
export const zVideoBackgroundRemovalInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  output_container_and_codec: z.optional(
    z
      .enum([
        "mp4_h265",
        "mp4_h264",
        "webm_vp9",
        "mov_h265",
        "mov_proresks",
        "mkv_h265",
        "mkv_h264",
        "mkv_vp9",
        "gif",
      ])
      .register(z.globalRegistry, {
        description:
          "Output container and codec. Options: mp4_h265, mp4_h264, webm_vp9, mov_h265, mov_proresks, mkv_h265, mkv_h264, mkv_vp9, gif.",
      }),
  ),
  background_color: z.optional(
    z
      .enum([
        "Transparent",
        "Black",
        "White",
        "Gray",
        "Red",
        "Green",
        "Blue",
        "Yellow",
        "Cyan",
        "Magenta",
        "Orange",
      ])
      .register(z.globalRegistry, {
        description:
          "Background color. Options: Transparent, Black, White, Gray, Red, Green, Blue, Yellow, Cyan, Magenta, Orange.",
      }),
  ),
});

/**
 * File
 */
export const zFileType3 = z.object({
  file_size: z.int().register(z.globalRegistry, {
    description: "The size of the file in bytes.",
  }),
  file_name: z.string().register(z.globalRegistry, {
    description:
      "The name of the file. It will be auto-generated if not provided.",
  }),
  content_type: z.string().register(z.globalRegistry, {
    description: "The mime type of the file.",
  }),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
});

/**
 * AnimatediffLCMOutput
 */
export const zAnimatediffSparsectrlLcmOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used to generate the video.",
  }),
  video: zFileType3,
});

/**
 * AnimatediffLCMInput
 */
export const zAnimatediffSparsectrlLcmInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to use for generating the image. Be as descriptive as possible for best results.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n        The same seed and the same prompt given to the same version of Stable\n        Diffusion will output the same image every time.\n        ",
    }),
  ),
  controlnet_type: z.optional(
    z.enum(["scribble", "rgb"]).register(z.globalRegistry, {
      description:
        "The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.",
    }),
  ),
  keyframe_2_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "The frame index of the third keyframe to use for the generation.",
      }),
    )
    .default(0),
  keyframe_0_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "The frame index of the first keyframe to use for the generation.",
      }),
    )
    .default(0),
  keyframe_1_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
  keyframe_1_index: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "The frame index of the second keyframe to use for the generation.",
      }),
    )
    .default(0),
  guidance_scale: z
    .optional(
      z.int().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
      }),
    )
    .default(1),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description:
          "Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.",
      }),
    )
    .default(4),
  keyframe_2_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to specify what you don't want.\n        ",
      }),
    )
    .default(""),
  keyframe_0_image_url: z.optional(z.union([z.string(), z.string(), z.null()])),
});

/**
 * VideoOutput
 */
export const zMinimaxVideo01Output = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zMinimaxVideo01Input = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * AnimateDiffT2VOutput
 */
export const zFastAnimatediffTurboTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * AnimateDiffT2VTurboInput
 */
export const zFastAnimatediffTurboTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to use for generating the video. Be as descriptive as possible for best results.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Number of frames per second to extract from the video.",
      }),
    )
    .default(8),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(1).lte(64).register(z.globalRegistry, {
        description: "The number of frames to generate for the video.",
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          "The number of inference steps to perform. 4-12 is recommended for turbo mode.",
      }),
    )
    .default(4),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default("(bad quality, worst quality:1.2), ugly faces, bad anime"),
  motions: z.optional(
    z
      .array(
        z.enum([
          "zoom-out",
          "zoom-in",
          "pan-left",
          "pan-right",
          "tilt-up",
          "tilt-down",
        ]),
      )
      .register(z.globalRegistry, {
        description: "The motions to apply to the video.",
      }),
  ),
});

/**
 * AnimateDiffT2VOutput
 */
export const zFastAnimatediffTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * AnimateDiffT2VInput
 */
export const zFastAnimatediffTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description:
      "The prompt to use for generating the video. Be as descriptive as possible for best results.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Number of frames per second to extract from the video.",
      }),
    )
    .default(8),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
      }),
    )
    .default(7.5),
  num_frames: z
    .optional(
      z.int().gte(1).lte(32).register(z.globalRegistry, {
        description: "The number of frames to generate for the video.",
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(25),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
      }),
    )
    .default("(bad quality, worst quality:1.2), ugly faces, bad anime"),
  motions: z.optional(
    z
      .array(
        z.enum([
          "zoom-out",
          "zoom-in",
          "pan-left",
          "pan-right",
          "tilt-up",
          "tilt-down",
        ]),
      )
      .register(z.globalRegistry, {
        description: "The motions to apply to the video.",
      }),
  ),
});

/**
 * Output
 */
export const zT2vTurboOutput = z.object({
  video: zFileType2,
});

/**
 * Input
 */
export const zT2vTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate images from",
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0.1).lte(30).register(z.globalRegistry, {
        description: "The guidance scale",
      }),
    )
    .default(7.5),
  seed: z.optional(z.union([z.int().gte(0).lte(203279), z.unknown()])),
  export_fps: z
    .optional(
      z.int().gte(1).lte(24).register(z.globalRegistry, {
        description: "The FPS of the exported video",
      }),
    )
    .default(8),
  num_frames: z
    .optional(
      z.int().gte(16).lte(32).register(z.globalRegistry, {
        description: "The number of frames to generate",
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(12).register(z.globalRegistry, {
        description: "The number of steps to sample",
      }),
    )
    .default(4),
});

/**
 * FastSVDOutput
 */
export const zFastSvdLcmTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ",
  }),
  video: zFile,
});

/**
 * FastSVDTextInput
 */
export const zFastSvdLcmTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to use as a starting point for the generation.",
  }),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
      }),
    )
    .default(0.02),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
      }),
    )
    .default(10),
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
      }),
    )
    .default(127),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
      }),
    )
    .default(4),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
});

/**
 * FastSVDOutput
 */
export const zFastSvdTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ",
  }),
  video: zFile,
});

/**
 * FastSVDTextInput
 */
export const zFastSvdTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to use as a starting point for the generation.",
  }),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
      }),
    )
    .default(0.02),
  deep_cache: z.optional(
    z.enum(["none", "minimum", "medium", "high"]).register(z.globalRegistry, {
      description:
        "\n            Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution\n            faster, but might sometimes degrade overall quality. The higher the setting, the\n            faster the execution will be, but the more quality might be lost.\n        ",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
      }),
    )
    .default(10),
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
      }),
    )
    .default(127),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  steps: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
      }),
    )
    .default(20),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt to use as a starting point for the generation.",
      }),
    )
    .default(
      "unrealistic, saturated, high contrast, big nose, painting, drawing, sketch, cartoon, anime, manga, render, CG, 3d, watermark, signature, label",
    ),
});

/**
 * Output
 */
export const zLtxVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for random number generation.",
  }),
  video: zFile,
});

/**
 * TextToVideoInput
 */
export const zLtxVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  guidance_scale: z
    .optional(
      z.number().lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for random number generation.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to take.",
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
    ),
});

/**
 * HunyuanT2VResponse
 */
export const zHunyuanVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanVideoRequest
 */
export const zHunyuanVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to run. Lower gets faster results, higher gets better results.",
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_frames: z.optional(
    z.enum(["129", "85"]).register(z.globalRegistry, {
      description: "The number of frames to generate.",
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
      }),
    )
    .default(false),
});

/**
 * MochiT2VOutput
 */
export const zMochiV1Output = z.object({
  video: zFile,
});

/**
 * MochiT2VInput
 */
export const zMochiV1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate a video from.",
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt for the video.",
      }),
    )
    .default(""),
});

/**
 * T2VOutput
 */
export const zKlingVideoV15ProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zKlingVideoV15ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * CameraControl
 */
export const zCameraControl = z.object({
  movement_type: z
    .enum(["horizontal", "vertical", "pan", "tilt", "roll", "zoom"])
    .register(z.globalRegistry, {
      description: "The type of camera movement",
    }),
  movement_value: z.int().gte(-10).lte(10).register(z.globalRegistry, {
    description: "The value of the camera movement",
  }),
});

/**
 * T2VOutput
 */
export const zKlingVideoV1StandardTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * V1TextToVideoRequest
 */
export const zKlingVideoV1StandardTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  advanced_camera_control: z.optional(zCameraControl),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  camera_control: z.optional(
    z
      .enum([
        "down_back",
        "forward_up",
        "right_turn_forward",
        "left_turn_forward",
      ])
      .register(z.globalRegistry, {
        description: "Camera control parameters",
      }),
  ),
});

/**
 * T2VLiveOutput
 */
export const zMinimaxVideo01LiveOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoLiveRequest
 */
export const zMinimaxVideo01LiveInput = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * T2VOutput
 */
export const zKlingVideoV16StandardTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zKlingVideoV16StandardTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * Output
 */
export const zCogvideox5bOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generating the video.",
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
  }),
  video: zFile,
});

/**
 * BaseInput
 */
export const zCogvideox5bInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Use RIFE for video interpolation",
      }),
    )
    .default(true),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: "The target FPS of the video",
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate video from",
      }),
    )
    .default(""),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
});

/**
 * Output
 */
export const zTranspixarOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generating the video.",
  }),
  videos: z.array(zFileType2).register(z.globalRegistry, {
    description: "The URL to the generated video",
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
  }),
});

/**
 * BaseInput
 */
export const zTranspixarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(24),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: "The target FPS of the video",
      }),
    )
    .default(8),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate video from",
      }),
    )
    .default(""),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * HunyuanT2VResponse
 */
export const zHunyuanVideoLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanT2VRequest
 */
export const zHunyuanVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
      }),
    )
    .default([]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_frames: z.optional(
    z.enum(["129", "85"]).register(z.globalRegistry, {
      description: "The number of frames to generate.",
    }),
  ),
  pro_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
      }),
    )
    .default(false),
});

/**
 * Ray2T2VOutput
 */
export const zLumaDreamMachineRay2Output = z.object({
  video: zFile,
});

/**
 * Ray2TextToVideoRequest
 */
export const zLumaDreamMachineRay2Input = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(["16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  resolution: z.optional(
    z.enum(["540p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether the video should loop (end of video is blended with the beginning)",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["5s", "9s"]).register(z.globalRegistry, {
      description: "The duration of the generated video (9s costs 2x more)",
    }),
  ),
});

/**
 * VideoOutput
 */
export const zPixverseV35TextToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastTextToVideoRequest
 */
export const zPixverseV35TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * VideoOutput
 */
export const zPixverseV35TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zPixverseV35TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * T2VDirectorOutput
 */
export const zMinimaxVideo01DirectorOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoDirectorRequest
 */
export const zMinimaxVideo01DirectorInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description:
      "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645",
  }),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * TextToVideoOutput
 */
export const zVeo2Output = z.object({
  video: zFile,
});

/**
 * TextToVideoInput
 */
export const zVeo2Input = z.object({
  prompt: z.string().min(1).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["5s", "6s", "7s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "A seed to use for the video generation",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation",
    }),
  ),
  enhance_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enhance the video generation",
      }),
    )
    .default(true),
});

/**
 * WanT2VResponse
 */
export const zWanT2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanT2VRequest
 */
export const zWanT2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive).",
      }),
    )
    .default(81),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * T2VOutput
 */
export const zKlingVideoV16ProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zKlingVideoV16ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * TextToVideoOutput
 */
export const zLtxVideoV095Output = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * TextToVideoInput
 */
export const zLtxVideoV095Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to expand the prompt using the model's own capabilities.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps",
      }),
    )
    .default(40),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
});

/**
 * VideoEffectsOutput
 */
export const zKlingVideoV1StandardEffectsOutput = z.object({
  video: zFile,
});

/**
 * VideoEffectsRequest
 */
export const zKlingVideoV1StandardEffectsInput = z.object({
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URL of images to be used for hug, kiss or heart_gesture video.",
    }),
  ),
  effect_scene: z
    .enum([
      "hug",
      "kiss",
      "heart_gesture",
      "squish",
      "expansion",
      "fuzzyfuzzy",
      "bloombloom",
      "dizzydizzy",
      "jelly_press",
      "jelly_slice",
      "jelly_squish",
      "jelly_jiggle",
      "pixelpixel",
      "yearbook",
      "instant_film",
      "anime_figure",
      "rocketrocket",
      "fly_fly",
      "disappear",
      "lightning_power",
      "bullet_time",
      "bullet_time_360",
      "media_interview",
      "day_to_night",
      "let's_ride",
      "jumpdrop",
      "swish_swish",
      "running_man",
      "jazz_jazz",
      "swing_swing",
      "skateskate",
      "building_sweater",
      "pure_white_wings",
      "black_wings",
      "golden_wing",
      "pink_pink_wings",
      "rampage_ape",
      "a_list_look",
      "countdown_teleport",
      "firework_2026",
      "instant_christmas",
      "birthday_star",
      "firework",
      "celebration",
      "tiger_hug_pro",
      "pet_lion_pro",
      "guardian_spirit",
      "squeeze_scream",
      "inner_voice",
      "memory_alive",
      "guess_what",
      "eagle_snatch",
      "hug_from_past",
      "instant_kid",
      "dollar_rain",
      "cry_cry",
      "building_collapse",
      "mushroom",
      "jesus_hug",
      "shark_alert",
      "lie_flat",
      "polar_bear_hug",
      "brown_bear_hug",
      "office_escape_plow",
      "watermelon_bomb",
      "boss_coming",
      "wig_out",
      "car_explosion",
      "tiger_hug",
      "siblings",
      "construction_worker",
      "snatched",
      "felt_felt",
      "plushcut",
      "drunk_dance",
      "drunk_dance_pet",
      "daoma_dance",
      "bouncy_dance",
      "smooth_sailing_dance",
      "new_year_greeting",
      "lion_dance",
      "prosperity",
      "great_success",
      "golden_horse_fortune",
      "red_packet_box",
      "lucky_horse_year",
      "lucky_red_packet",
      "lucky_money_come",
      "lion_dance_pet",
      "dumpling_making_pet",
      "fish_making_pet",
      "pet_red_packet",
      "lantern_glow",
      "expression_challenge",
      "overdrive",
      "heart_gesture_dance",
      "poping",
      "martial_arts",
      "running",
      "nezha",
      "motorcycle_dance",
      "subject_3_dance",
      "ghost_step_dance",
      "phantom_jewel",
      "zoom_out",
      "cheers_2026",
      "kiss_pro",
      "fight_pro",
      "hug_pro",
      "heart_gesture_pro",
      "dollar_rain_pro",
      "pet_bee_pro",
      "santa_random_surprise",
      "magic_match_tree",
      "happy_birthday",
      "thumbs_up_pro",
      "surprise_bouquet",
      "bouquet_drop",
      "3d_cartoon_1_pro",
      "glamour_photo_shoot",
      "box_of_joy",
      "first_toast_of_the_year",
      "my_santa_pic",
      "santa_gift",
      "steampunk_christmas",
      "snowglobe",
      "christmas_photo_shoot",
      "ornament_crash",
      "santa_express",
      "particle_santa_surround",
      "coronation_of_frost",
      "spark_in_the_snow",
      "scarlet_and_snow",
      "cozy_toon_wrap",
      "bullet_time_lite",
      "magic_cloak",
      "balloon_parade",
      "jumping_ginger_joy",
      "c4d_cartoon_pro",
      "venomous_spider",
      "throne_of_king",
      "luminous_elf",
      "woodland_elf",
      "japanese_anime_1",
      "american_comics",
      "snowboarding",
      "witch_transform",
      "vampire_transform",
      "pumpkin_head_transform",
      "demon_transform",
      "mummy_transform",
      "zombie_transform",
      "cute_pumpkin_transform",
      "cute_ghost_transform",
      "knock_knock_halloween",
      "halloween_escape",
      "baseball",
      "trampoline",
      "trampoline_night",
      "pucker_up",
      "feed_mooncake",
      "flyer",
      "dishwasher",
      "pet_chinese_opera",
      "magic_fireball",
      "gallery_ring",
      "pet_moto_rider",
      "muscle_pet",
      "pet_delivery",
      "mythic_style",
      "steampunk",
      "3d_cartoon_2",
      "pet_chef",
      "santa_gifts",
      "santa_hug",
      "girlfriend",
      "boyfriend",
      "heart_gesture_1",
      "pet_wizard",
      "smoke_smoke",
      "gun_shot",
      "double_gun",
      "pet_warrior",
      "long_hair",
      "pet_dance",
      "wool_curly",
      "pet_bee",
      "marry_me",
      "piggy_morph",
      "ski_ski",
      "magic_broom",
      "splashsplash",
      "surfsurf",
      "fairy_wing",
      "angel_wing",
      "dark_wing",
      "emoji",
    ])
    .register(z.globalRegistry, {
      description: "The effect scene to use for the video generation",
    }),
});

/**
 * VideoEffectsOutput
 */
export const zKlingVideoV15ProEffectsOutput = z.object({
  video: zFile,
});

/**
 * VideoEffectsRequest
 */
export const zKlingVideoV15ProEffectsInput = z.object({
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URL of images to be used for hug, kiss or heart_gesture video.",
    }),
  ),
  effect_scene: z
    .enum([
      "hug",
      "kiss",
      "heart_gesture",
      "squish",
      "expansion",
      "fuzzyfuzzy",
      "bloombloom",
      "dizzydizzy",
      "jelly_press",
      "jelly_slice",
      "jelly_squish",
      "jelly_jiggle",
      "pixelpixel",
      "yearbook",
      "instant_film",
      "anime_figure",
      "rocketrocket",
      "fly_fly",
      "disappear",
      "lightning_power",
      "bullet_time",
      "bullet_time_360",
      "media_interview",
      "day_to_night",
      "let's_ride",
      "jumpdrop",
      "swish_swish",
      "running_man",
      "jazz_jazz",
      "swing_swing",
      "skateskate",
      "building_sweater",
      "pure_white_wings",
      "black_wings",
      "golden_wing",
      "pink_pink_wings",
      "rampage_ape",
      "a_list_look",
      "countdown_teleport",
      "firework_2026",
      "instant_christmas",
      "birthday_star",
      "firework",
      "celebration",
      "tiger_hug_pro",
      "pet_lion_pro",
      "guardian_spirit",
      "squeeze_scream",
      "inner_voice",
      "memory_alive",
      "guess_what",
      "eagle_snatch",
      "hug_from_past",
      "instant_kid",
      "dollar_rain",
      "cry_cry",
      "building_collapse",
      "mushroom",
      "jesus_hug",
      "shark_alert",
      "lie_flat",
      "polar_bear_hug",
      "brown_bear_hug",
      "office_escape_plow",
      "watermelon_bomb",
      "boss_coming",
      "wig_out",
      "car_explosion",
      "tiger_hug",
      "siblings",
      "construction_worker",
      "snatched",
      "felt_felt",
      "plushcut",
      "drunk_dance",
      "drunk_dance_pet",
      "daoma_dance",
      "bouncy_dance",
      "smooth_sailing_dance",
      "new_year_greeting",
      "lion_dance",
      "prosperity",
      "great_success",
      "golden_horse_fortune",
      "red_packet_box",
      "lucky_horse_year",
      "lucky_red_packet",
      "lucky_money_come",
      "lion_dance_pet",
      "dumpling_making_pet",
      "fish_making_pet",
      "pet_red_packet",
      "lantern_glow",
      "expression_challenge",
      "overdrive",
      "heart_gesture_dance",
      "poping",
      "martial_arts",
      "running",
      "nezha",
      "motorcycle_dance",
      "subject_3_dance",
      "ghost_step_dance",
      "phantom_jewel",
      "zoom_out",
      "cheers_2026",
      "kiss_pro",
      "fight_pro",
      "hug_pro",
      "heart_gesture_pro",
      "dollar_rain_pro",
      "pet_bee_pro",
      "santa_random_surprise",
      "magic_match_tree",
      "happy_birthday",
      "thumbs_up_pro",
      "surprise_bouquet",
      "bouquet_drop",
      "3d_cartoon_1_pro",
      "glamour_photo_shoot",
      "box_of_joy",
      "first_toast_of_the_year",
      "my_santa_pic",
      "santa_gift",
      "steampunk_christmas",
      "snowglobe",
      "christmas_photo_shoot",
      "ornament_crash",
      "santa_express",
      "particle_santa_surround",
      "coronation_of_frost",
      "spark_in_the_snow",
      "scarlet_and_snow",
      "cozy_toon_wrap",
      "bullet_time_lite",
      "magic_cloak",
      "balloon_parade",
      "jumping_ginger_joy",
      "c4d_cartoon_pro",
      "venomous_spider",
      "throne_of_king",
      "luminous_elf",
      "woodland_elf",
      "japanese_anime_1",
      "american_comics",
      "snowboarding",
      "witch_transform",
      "vampire_transform",
      "pumpkin_head_transform",
      "demon_transform",
      "mummy_transform",
      "zombie_transform",
      "cute_pumpkin_transform",
      "cute_ghost_transform",
      "knock_knock_halloween",
      "halloween_escape",
      "baseball",
      "trampoline",
      "trampoline_night",
      "pucker_up",
      "feed_mooncake",
      "flyer",
      "dishwasher",
      "pet_chinese_opera",
      "magic_fireball",
      "gallery_ring",
      "pet_moto_rider",
      "muscle_pet",
      "pet_delivery",
      "mythic_style",
      "steampunk",
      "3d_cartoon_2",
      "pet_chef",
      "santa_gifts",
      "santa_hug",
      "girlfriend",
      "boyfriend",
      "heart_gesture_1",
      "pet_wizard",
      "smoke_smoke",
      "gun_shot",
      "double_gun",
      "pet_warrior",
      "long_hair",
      "pet_dance",
      "wool_curly",
      "pet_bee",
      "marry_me",
      "piggy_morph",
      "ski_ski",
      "magic_broom",
      "splashsplash",
      "surfsurf",
      "fairy_wing",
      "angel_wing",
      "dark_wing",
      "emoji",
    ])
    .register(z.globalRegistry, {
      description: "The effect scene to use for the video generation",
    }),
});

/**
 * VideoEffectsOutput
 */
export const zKlingVideoV16StandardEffectsOutput = z.object({
  video: zFile,
});

/**
 * VideoEffectsRequest
 */
export const zKlingVideoV16StandardEffectsInput = z.object({
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URL of images to be used for hug, kiss or heart_gesture video.",
    }),
  ),
  effect_scene: z
    .enum([
      "hug",
      "kiss",
      "heart_gesture",
      "squish",
      "expansion",
      "fuzzyfuzzy",
      "bloombloom",
      "dizzydizzy",
      "jelly_press",
      "jelly_slice",
      "jelly_squish",
      "jelly_jiggle",
      "pixelpixel",
      "yearbook",
      "instant_film",
      "anime_figure",
      "rocketrocket",
      "fly_fly",
      "disappear",
      "lightning_power",
      "bullet_time",
      "bullet_time_360",
      "media_interview",
      "day_to_night",
      "let's_ride",
      "jumpdrop",
      "swish_swish",
      "running_man",
      "jazz_jazz",
      "swing_swing",
      "skateskate",
      "building_sweater",
      "pure_white_wings",
      "black_wings",
      "golden_wing",
      "pink_pink_wings",
      "rampage_ape",
      "a_list_look",
      "countdown_teleport",
      "firework_2026",
      "instant_christmas",
      "birthday_star",
      "firework",
      "celebration",
      "tiger_hug_pro",
      "pet_lion_pro",
      "guardian_spirit",
      "squeeze_scream",
      "inner_voice",
      "memory_alive",
      "guess_what",
      "eagle_snatch",
      "hug_from_past",
      "instant_kid",
      "dollar_rain",
      "cry_cry",
      "building_collapse",
      "mushroom",
      "jesus_hug",
      "shark_alert",
      "lie_flat",
      "polar_bear_hug",
      "brown_bear_hug",
      "office_escape_plow",
      "watermelon_bomb",
      "boss_coming",
      "wig_out",
      "car_explosion",
      "tiger_hug",
      "siblings",
      "construction_worker",
      "snatched",
      "felt_felt",
      "plushcut",
      "drunk_dance",
      "drunk_dance_pet",
      "daoma_dance",
      "bouncy_dance",
      "smooth_sailing_dance",
      "new_year_greeting",
      "lion_dance",
      "prosperity",
      "great_success",
      "golden_horse_fortune",
      "red_packet_box",
      "lucky_horse_year",
      "lucky_red_packet",
      "lucky_money_come",
      "lion_dance_pet",
      "dumpling_making_pet",
      "fish_making_pet",
      "pet_red_packet",
      "lantern_glow",
      "expression_challenge",
      "overdrive",
      "heart_gesture_dance",
      "poping",
      "martial_arts",
      "running",
      "nezha",
      "motorcycle_dance",
      "subject_3_dance",
      "ghost_step_dance",
      "phantom_jewel",
      "zoom_out",
      "cheers_2026",
      "kiss_pro",
      "fight_pro",
      "hug_pro",
      "heart_gesture_pro",
      "dollar_rain_pro",
      "pet_bee_pro",
      "santa_random_surprise",
      "magic_match_tree",
      "happy_birthday",
      "thumbs_up_pro",
      "surprise_bouquet",
      "bouquet_drop",
      "3d_cartoon_1_pro",
      "glamour_photo_shoot",
      "box_of_joy",
      "first_toast_of_the_year",
      "my_santa_pic",
      "santa_gift",
      "steampunk_christmas",
      "snowglobe",
      "christmas_photo_shoot",
      "ornament_crash",
      "santa_express",
      "particle_santa_surround",
      "coronation_of_frost",
      "spark_in_the_snow",
      "scarlet_and_snow",
      "cozy_toon_wrap",
      "bullet_time_lite",
      "magic_cloak",
      "balloon_parade",
      "jumping_ginger_joy",
      "c4d_cartoon_pro",
      "venomous_spider",
      "throne_of_king",
      "luminous_elf",
      "woodland_elf",
      "japanese_anime_1",
      "american_comics",
      "snowboarding",
      "witch_transform",
      "vampire_transform",
      "pumpkin_head_transform",
      "demon_transform",
      "mummy_transform",
      "zombie_transform",
      "cute_pumpkin_transform",
      "cute_ghost_transform",
      "knock_knock_halloween",
      "halloween_escape",
      "baseball",
      "trampoline",
      "trampoline_night",
      "pucker_up",
      "feed_mooncake",
      "flyer",
      "dishwasher",
      "pet_chinese_opera",
      "magic_fireball",
      "gallery_ring",
      "pet_moto_rider",
      "muscle_pet",
      "pet_delivery",
      "mythic_style",
      "steampunk",
      "3d_cartoon_2",
      "pet_chef",
      "santa_gifts",
      "santa_hug",
      "girlfriend",
      "boyfriend",
      "heart_gesture_1",
      "pet_wizard",
      "smoke_smoke",
      "gun_shot",
      "double_gun",
      "pet_warrior",
      "long_hair",
      "pet_dance",
      "wool_curly",
      "pet_bee",
      "marry_me",
      "piggy_morph",
      "ski_ski",
      "magic_broom",
      "splashsplash",
      "surfsurf",
      "fairy_wing",
      "angel_wing",
      "dark_wing",
      "emoji",
    ])
    .register(z.globalRegistry, {
      description: "The effect scene to use for the video generation",
    }),
});

/**
 * VideoEffectsOutput
 */
export const zKlingVideoV16ProEffectsOutput = z.object({
  video: zFile,
});

/**
 * VideoEffectsRequest
 */
export const zKlingVideoV16ProEffectsInput = z.object({
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URL of images to be used for hug, kiss or heart_gesture video.",
    }),
  ),
  effect_scene: z
    .enum([
      "hug",
      "kiss",
      "heart_gesture",
      "squish",
      "expansion",
      "fuzzyfuzzy",
      "bloombloom",
      "dizzydizzy",
      "jelly_press",
      "jelly_slice",
      "jelly_squish",
      "jelly_jiggle",
      "pixelpixel",
      "yearbook",
      "instant_film",
      "anime_figure",
      "rocketrocket",
      "fly_fly",
      "disappear",
      "lightning_power",
      "bullet_time",
      "bullet_time_360",
      "media_interview",
      "day_to_night",
      "let's_ride",
      "jumpdrop",
      "swish_swish",
      "running_man",
      "jazz_jazz",
      "swing_swing",
      "skateskate",
      "building_sweater",
      "pure_white_wings",
      "black_wings",
      "golden_wing",
      "pink_pink_wings",
      "rampage_ape",
      "a_list_look",
      "countdown_teleport",
      "firework_2026",
      "instant_christmas",
      "birthday_star",
      "firework",
      "celebration",
      "tiger_hug_pro",
      "pet_lion_pro",
      "guardian_spirit",
      "squeeze_scream",
      "inner_voice",
      "memory_alive",
      "guess_what",
      "eagle_snatch",
      "hug_from_past",
      "instant_kid",
      "dollar_rain",
      "cry_cry",
      "building_collapse",
      "mushroom",
      "jesus_hug",
      "shark_alert",
      "lie_flat",
      "polar_bear_hug",
      "brown_bear_hug",
      "office_escape_plow",
      "watermelon_bomb",
      "boss_coming",
      "wig_out",
      "car_explosion",
      "tiger_hug",
      "siblings",
      "construction_worker",
      "snatched",
      "felt_felt",
      "plushcut",
      "drunk_dance",
      "drunk_dance_pet",
      "daoma_dance",
      "bouncy_dance",
      "smooth_sailing_dance",
      "new_year_greeting",
      "lion_dance",
      "prosperity",
      "great_success",
      "golden_horse_fortune",
      "red_packet_box",
      "lucky_horse_year",
      "lucky_red_packet",
      "lucky_money_come",
      "lion_dance_pet",
      "dumpling_making_pet",
      "fish_making_pet",
      "pet_red_packet",
      "lantern_glow",
      "expression_challenge",
      "overdrive",
      "heart_gesture_dance",
      "poping",
      "martial_arts",
      "running",
      "nezha",
      "motorcycle_dance",
      "subject_3_dance",
      "ghost_step_dance",
      "phantom_jewel",
      "zoom_out",
      "cheers_2026",
      "kiss_pro",
      "fight_pro",
      "hug_pro",
      "heart_gesture_pro",
      "dollar_rain_pro",
      "pet_bee_pro",
      "santa_random_surprise",
      "magic_match_tree",
      "happy_birthday",
      "thumbs_up_pro",
      "surprise_bouquet",
      "bouquet_drop",
      "3d_cartoon_1_pro",
      "glamour_photo_shoot",
      "box_of_joy",
      "first_toast_of_the_year",
      "my_santa_pic",
      "santa_gift",
      "steampunk_christmas",
      "snowglobe",
      "christmas_photo_shoot",
      "ornament_crash",
      "santa_express",
      "particle_santa_surround",
      "coronation_of_frost",
      "spark_in_the_snow",
      "scarlet_and_snow",
      "cozy_toon_wrap",
      "bullet_time_lite",
      "magic_cloak",
      "balloon_parade",
      "jumping_ginger_joy",
      "c4d_cartoon_pro",
      "venomous_spider",
      "throne_of_king",
      "luminous_elf",
      "woodland_elf",
      "japanese_anime_1",
      "american_comics",
      "snowboarding",
      "witch_transform",
      "vampire_transform",
      "pumpkin_head_transform",
      "demon_transform",
      "mummy_transform",
      "zombie_transform",
      "cute_pumpkin_transform",
      "cute_ghost_transform",
      "knock_knock_halloween",
      "halloween_escape",
      "baseball",
      "trampoline",
      "trampoline_night",
      "pucker_up",
      "feed_mooncake",
      "flyer",
      "dishwasher",
      "pet_chinese_opera",
      "magic_fireball",
      "gallery_ring",
      "pet_moto_rider",
      "muscle_pet",
      "pet_delivery",
      "mythic_style",
      "steampunk",
      "3d_cartoon_2",
      "pet_chef",
      "santa_gifts",
      "santa_hug",
      "girlfriend",
      "boyfriend",
      "heart_gesture_1",
      "pet_wizard",
      "smoke_smoke",
      "gun_shot",
      "double_gun",
      "pet_warrior",
      "long_hair",
      "pet_dance",
      "wool_curly",
      "pet_bee",
      "marry_me",
      "piggy_morph",
      "ski_ski",
      "magic_broom",
      "splashsplash",
      "surfsurf",
      "fairy_wing",
      "angel_wing",
      "dark_wing",
      "emoji",
    ])
    .register(z.globalRegistry, {
      description: "The effect scene to use for the video generation",
    }),
});

/**
 * WanProT2VResponse
 */
export const zWanProTextToVideoOutput = z.object({
  video: zFileType2,
});

/**
 * WanProT2VRequest
 */
export const zWanProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video",
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * TurboTextToVideoOutput
 *
 * Output from text-to-video generation
 */
export const zPikaV2TurboTextToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output from text-to-video generation",
  });

/**
 * TextToVideoTurboInput
 *
 * Base request for text-to-video generation
 */
export const zPikaV2TurboTextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(["16:9", "9:16", "1:1", "4:5", "5:4", "3:2", "2:3"])
        .register(z.globalRegistry, {
          description: "The aspect ratio of the generated video",
        }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: "The duration of the generated video in seconds",
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default(""),
  })
  .register(z.globalRegistry, {
    description: "Base request for text-to-video generation",
  });

/**
 * Pika22TextToVideoOutput
 *
 * Output model for Pika 2.2 text-to-video generation
 */
export const zPikaV22TextToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for Pika 2.2 text-to-video generation",
  });

/**
 * Pika22TextToVideoRequest
 *
 * Request model for Pika 2.2 text-to-video generation
 */
export const zPikaV22TextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["1080p", "720p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(["16:9", "9:16", "1:1", "4:5", "5:4", "3:2", "2:3"])
        .register(z.globalRegistry, {
          description: "The aspect ratio of the generated video",
        }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: "The duration of the generated video in seconds",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default("ugly, bad, terrible"),
  })
  .register(z.globalRegistry, {
    description: "Request model for Pika 2.2 text-to-video generation",
  });

/**
 * TextToVideoV21Output
 *
 * Output from text-to-video generation
 */
export const zPikaV21TextToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output from text-to-video generation",
  });

/**
 * TextToVideov21Input
 *
 * Base request for text-to-video generation
 */
export const zPikaV21TextToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(["16:9", "9:16", "1:1", "4:5", "5:4", "3:2", "2:3"])
        .register(z.globalRegistry, {
          description: "The aspect ratio of the generated video",
        }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: "The duration of the generated video in seconds",
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default(""),
  })
  .register(z.globalRegistry, {
    description: "Base request for text-to-video generation",
  });

/**
 * Ray2T2VOutput
 */
export const zLumaDreamMachineRay2FlashOutput = z.object({
  video: zFile,
});

/**
 * Ray2TextToVideoRequest
 */
export const zLumaDreamMachineRay2FlashInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(["16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  resolution: z.optional(
    z.enum(["540p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether the video should loop (end of video is blended with the beginning)",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["5s", "9s"]).register(z.globalRegistry, {
      description: "The duration of the generated video (9s costs 2x more)",
    }),
  ),
});

/**
 * WanT2VResponse
 */
export const zWanT2vLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LoraWeight
 */
export const zLoraWeightType2 = z.object({
  path: z.string().register(z.globalRegistry, {
    description: "URL or the path to the LoRA weights.",
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ",
      }),
    )
    .default(1),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.",
    }),
  ),
});

/**
 * WanLoRARequest
 */
export const zWanT2vLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p,580p, or 720p).",
    }),
  ),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, the video will be reversed.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  loras: z
    .optional(
      z.array(zLoraWeightType2).register(z.globalRegistry, {
        description: "LoRA weights to be used in the inference.",
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive).",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * LipsyncOutput
 */
export const zKlingVideoLipsyncTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * LipsyncT2VRequest
 */
export const zKlingVideoLipsyncTextToVideoInput = z.object({
  text: z.string().max(120).register(z.globalRegistry, {
    description:
      "Text content for lip-sync video generation. Max 120 characters.",
  }),
  video_url: z.union([z.string(), z.string()]),
  voice_id: z
    .enum([
      "genshin_vindi2",
      "zhinen_xuesheng",
      "AOT",
      "ai_shatang",
      "genshin_klee2",
      "genshin_kirara",
      "ai_kaiya",
      "oversea_male1",
      "ai_chenjiahao_712",
      "girlfriend_4_speech02",
      "chat1_female_new-3",
      "chat_0407_5-1",
      "cartoon-boy-07",
      "uk_boy1",
      "cartoon-girl-01",
      "PeppaPig_platform",
      "ai_huangzhong_712",
      "ai_huangyaoshi_712",
      "ai_laoguowang_712",
      "chengshu_jiejie",
      "you_pingjing",
      "calm_story1",
      "uk_man2",
      "laopopo_speech02",
      "heainainai_speech02",
      "reader_en_m-v1",
      "commercial_lady_en_f-v1",
      "tiyuxi_xuedi",
      "tiexin_nanyou",
      "girlfriend_1_speech02",
      "girlfriend_2_speech02",
      "zhuxi_speech02",
      "uk_oldman3",
      "dongbeilaotie_speech02",
      "chongqingxiaohuo_speech02",
      "chuanmeizi_speech02",
      "chaoshandashu_speech02",
      "ai_taiwan_man2_speech02",
      "xianzhanggui_speech02",
      "tianjinjiejie_speech02",
      "diyinnansang_DB_CN_M_04-v2",
      "yizhipiannan-v1",
      "guanxiaofang-v2",
      "tianmeixuemei-v1",
      "daopianyansang-v1",
      "mengwa-v1",
    ])
    .register(z.globalRegistry, {
      description: "Voice ID to use for speech synthesis",
    }),
  voice_language: z.optional(
    z.enum(["zh", "en"]).register(z.globalRegistry, {
      description: "The voice language corresponding to the Voice ID",
    }),
  ),
  voice_speed: z
    .optional(
      z.number().gte(0.8).lte(2).register(z.globalRegistry, {
        description: "Speech rate for Text to Video generation",
      }),
    )
    .default(1),
});

/**
 * LipsyncA2VOutput
 */
export const zKlingVideoLipsyncAudioToVideoOutput = z.object({
  video: zFile,
});

/**
 * LipsyncA2VRequest
 */
export const zKlingVideoLipsyncAudioToVideoInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * VideoOutputV4
 */
export const zPixverseV4TextToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastTextToVideoRequest
 */
export const zPixverseV4TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * VideoOutputV4
 */
export const zPixverseV4TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zPixverseV4TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * MagiResponse
 */
export const zMagiDistilledOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiTextToVideoRequest
 */
export const zMagiDistilledInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * MagiResponse
 */
export const zMagiOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiTextToVideoRequest
 */
export const zMagiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * Q1TextToVideoOutput
 */
export const zViduQ1TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q1TextToVideoRequest
 */
export const zViduQ1TextToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  style: z.optional(
    z.enum(["general", "anime"]).register(z.globalRegistry, {
      description: "The style of output video",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Seed for the random number generator",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
});

/**
 * VideoOutputV4
 */
export const zPixverseV45TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zPixverseV45TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * VideoOutputV4
 */
export const zPixverseV45TextToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastTextToVideoRequest
 */
export const zPixverseV45TextToVideoFastInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * TextToVideoOutput
 */
export const zLtxVideo13bDistilledOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export const zLtxVideo13bDistilledInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video (480p or 720p).",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9"]).register(z.globalRegistry, {
        description: "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
      }),
    ),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * TextToVideoOutput
 */
export const zLtxVideo13bDevOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * TextToVideoInput
 */
export const zLtxVideo13bDevInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the first pass.",
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the video.",
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to reverse the video.",
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the prompt using a language model.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeight).register(z.globalRegistry, {
        description: "LoRA weights to use for generation",
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the second pass.",
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: "The number of frames in the video.",
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "1:1", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
    }),
  ),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
});

/**
 * TextToVideoV21MasterOutput
 */
export const zKlingVideoV21MasterTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoV21MasterRequest
 */
export const zKlingVideoV21MasterTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * SeedanceVideoOutput
 */
export const zBytedanceSeedanceV1LiteTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceTextToVideoInput
 */
export const zBytedanceSeedanceV1LiteTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for higher quality",
    }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "9:21"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
});

/**
 * SeedanceProT2VVideoOutput
 */
export const zBytedanceSeedanceV1ProTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProTextToVideoInput
 */
export const zBytedanceSeedanceV1ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
});

/**
 * TextToVideoHailuo02Output
 */
export const zMinimaxHailuo02ProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProTextToVideoHailuo02Input
 */
export const zMinimaxHailuo02ProTextToVideoInput = z.object({
  prompt: z.string().min(1).max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * TextToVideoOutput
 */
export const zLtxv13B098DistilledOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledTextToVideoInput
 *
 * Distilled model input
 */
export const zLtxv13B098DistilledInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9"]).register(z.globalRegistry, {
        description: "Aspect ratio of the generated video.",
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        }),
      )
      .default(0),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * WanT2VResponse
 */
export const zWanV22A14bTextToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanT2VRequest
 */
export const zWanV22A14bTextToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * WanSmallT2VResponse
 */
export const zWanV225bTextToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanSmallT2VRequest
 */
export const zWanV225bTextToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (580p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * WanTurboT2VResponse
 */
export const zWanV22A14bTextToVideoTurboOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanTurboT2VRequest
 */
export const zWanV22A14bTextToVideoTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
});

/**
 * WanSmallFastVideoT2VResponse
 */
export const zWanV225bTextToVideoFastWanOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanSmallFastVideoT2VRequest
 */
export const zWanV225bTextToVideoFastWanInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(24),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (580p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
});

/**
 * WanSmallT2VResponse
 */
export const zWanV225bTextToVideoDistillOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanDistillT2VRequest
 */
export const zWanV225bTextToVideoDistillInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(24),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (580p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * WanT2VResponse
 */
export const zWanV22A14bTextToVideoLoraOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LoRAWeight
 */
export const zLoRaWeightType2 = z.object({
  path: z.string().register(z.globalRegistry, {
    description: "URL or the path to the LoRA weights.",
  }),
  scale: z
    .optional(
      z.number().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "\n            The scale of the LoRA weight. This is used to scale the LoRA weight\n            before merging it with the base model.\n        ",
      }),
    )
    .default(1),
  transformer: z.optional(
    z.enum(["high", "low", "both"]).register(z.globalRegistry, {
      description:
        "Specifies the transformer to load the lora weight into. 'high' loads into the high-noise transformer, 'low' loads it into the low-noise transformer, while 'both' loads the LoRA into both transformers.",
    }),
  ),
  weight_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Name of the LoRA weight. Used only if `path` is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.",
    }),
  ),
});

/**
 * WanLoRAT2VRequest
 */
export const zWanV22A14bTextToVideoLoraInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, the video will be reversed.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeightType2).register(z.globalRegistry, {
        description: "LoRA weights to be used in the inference.",
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9 or 9:16).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
      }),
    )
    .default(4),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * MareyOutput
 */
export const zMareyT2vOutput = z.object({
  video: zFileType2,
});

/**
 * MareyInputT2V
 */
export const zMareyT2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate a video from",
  }),
  duration: z.optional(
    z.enum(["5s", "10s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  dimensions: z.optional(
    z
      .enum(["1920x1080", "1152x1152", "1536x1152", "1152x1536"])
      .register(z.globalRegistry, {
        description:
          "The dimensions of the generated video in width x height format.",
      }),
  ),
  guidance_scale: z.optional(z.union([z.number(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * AvatarSingleTextResponse
 */
export const zInfinitalkSingleTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * InfiniTalkSingleTextRequest
 */
export const zInfinitalkSingleTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  text_input: z.string().register(z.globalRegistry, {
    description: "The text input to guide video generation.",
  }),
  image_url: z.union([z.string(), z.string()]),
  voice: z
    .enum([
      "Aria",
      "Roger",
      "Sarah",
      "Laura",
      "Charlie",
      "George",
      "Callum",
      "River",
      "Liam",
      "Charlotte",
      "Alice",
      "Matilda",
      "Will",
      "Jessica",
      "Eric",
      "Chris",
      "Brian",
      "Daniel",
      "Lily",
      "Bill",
    ])
    .register(z.globalRegistry, {
      description: "The voice to use for speech generation",
    }),
  num_frames: z
    .optional(
      z.int().gte(41).lte(721).register(z.globalRegistry, {
        description: "Number of frames to generate. Must be between 41 to 721.",
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(42),
});

/**
 * VideoOutputV5
 */
export const zPixverseV5TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequest
 */
export const zPixverseV5TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * AvatarsAppOutput
 */
export const zAvatarsTextToVideoOutputType2 = z.object({
  video: zFileType2,
});

/**
 * InferenceResult
 */
export const zAvatarsTextToVideoOutput = z.object({
  moderation_transcription: z.optional(z.union([z.string(), z.unknown()])),
  moderation_error: z.optional(z.union([z.string(), z.unknown()])),
  moderation_flagged: z.optional(z.boolean()).default(false),
  video: z.optional(z.union([zVideo, z.unknown()])),
});

/**
 * Text2VideoInput
 */
export const zAvatarsTextToVideoInputType2 = z.object({
  text: z.string(),
  avatar_id: z
    .enum([
      "emily_vertical_primary",
      "emily_vertical_secondary",
      "marcus_vertical_primary",
      "marcus_vertical_secondary",
      "mira_vertical_primary",
      "mira_vertical_secondary",
      "jasmine_vertical_primary",
      "jasmine_vertical_secondary",
      "jasmine_vertical_walking",
      "aisha_vertical_walking",
      "elena_vertical_primary",
      "elena_vertical_secondary",
      "any_male_vertical_primary",
      "any_female_vertical_primary",
      "any_male_vertical_secondary",
      "any_female_vertical_secondary",
      "any_female_vertical_walking",
      "emily_primary",
      "emily_side",
      "marcus_primary",
      "marcus_side",
      "aisha_walking",
      "elena_primary",
      "elena_side",
      "any_male_primary",
      "any_female_primary",
      "any_male_side",
      "any_female_side",
    ])
    .register(z.globalRegistry, {
      description: "The avatar to use for the video",
    }),
});

/**
 * TextToVideoRequest
 */
export const zAvatarsTextToVideoInput = z.object({
  text: z.string(),
  voice: z.enum([
    "Rachel",
    "Clyde",
    "Roger",
    "Sarah",
    "Laura",
    "Thomas",
    "Charlie",
    "George",
    "Callum",
    "River",
    "Harry",
    "Liam",
    "Alice",
    "Matilda",
    "Will",
    "Jessica",
    "Lilly",
    "Bill",
    "Oxley",
    "Luna",
  ]),
  remove_background: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Enabling the remove background feature will result in a 50% increase in the price.",
      }),
    )
    .default(false),
  avatar: z.enum([
    "Mia outdoor (UGC)",
    "Lara (Masterclass)",
    "Ines (UGC)",
    "Maria (Masterclass)",
    "Emma (UGC)",
    "Sienna (Masterclass)",
    "Elena (UGC)",
    "Jasmine (Masterclass)",
    "Amara (Masterclass)",
    "Ryan podcast (UGC)",
    "Tyler (Masterclass)",
    "Jayse (Masterclass)",
    "Paul (Masterclass)",
    "Matteo (UGC)",
    "Daniel car (UGC)",
    "Dario (Masterclass)",
    "Viva (Masterclass)",
    "Chen (Masterclass)",
    "Alex (Masterclass)",
    "Vanessa (UGC)",
    "Laurent (UGC)",
    "Noemie car (UGC)",
    "Brandon (UGC)",
    "Byron (Masterclass)",
    "Calista (Masterclass)",
    "Milo (Masterclass)",
    "Fabien (Masterclass)",
    "Rose (UGC)",
  ]),
});

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export const zWan25PreviewTextToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Base output for video generation",
  });

/**
 * TextToVideoInput
 *
 * Input for text-to-video generation
 */
export const zWan25PreviewTextToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt for video generation. Supports Chinese and English, max 800 characters.",
    }),
    duration: z.optional(
      z.enum(["5", "10"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
    ),
    resolution: z.optional(
      z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
        description: "Video resolution tier",
      }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
        }),
      )
      .default(true),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Negative prompt to describe content to avoid. Max 500 characters.",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for text-to-video generation",
  });

/**
 * OviT2VResponse
 */
export const zOviOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: z.optional(z.union([zFileType2, z.unknown()])),
});

/**
 * OviT2VRequest
 */
export const zOviInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z
      .enum([
        "512x992",
        "992x512",
        "960x512",
        "512x960",
        "720x720",
        "448x1120",
        "1120x448",
      ])
      .register(z.globalRegistry, {
        description:
          "Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).",
      }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(30),
  audio_negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for audio generation.",
      }),
    )
    .default("robotic, muffled, echo, distorted"),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default("jitter, bad hands, blur, distortion"),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * TextToVideoOutput
 */
export const zSora2TextToVideoOutput = z.object({
  spritesheet: z.optional(zImageFile),
  thumbnail: z.optional(zImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: "The ID of the generated video",
  }),
  video: zVideoFileType2,
});

/**
 * TextToVideoInput
 */
export const zSora2TextToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: "Duration of the generated video in seconds",
      }),
  ),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  model: z.optional(
    z
      .enum(["sora-2", "sora-2-2025-12-08", "sora-2-2025-10-06"])
      .register(z.globalRegistry, {
        description:
          "The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.",
      }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
      }),
    )
    .default(true),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
});

/**
 * ProTextToVideoOutput
 */
export const zSora2TextToVideoProOutput = z.object({
  spritesheet: z.optional(zImageFile),
  thumbnail: z.optional(zImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: "The ID of the generated video",
  }),
  video: zVideoFileType2,
});

/**
 * ProTextToVideoInput
 */
export const zSora2TextToVideoProInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: "Duration of the generated video in seconds",
      }),
  ),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
      }),
    )
    .default(true),
});

/**
 * Veo31TextToVideoOutput
 */
export const zVeo31Output = z.object({
  video: zFile,
});

/**
 * Veo31TextToVideoInput
 */
export const zVeo31Input = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * Veo31TextToVideoOutput
 */
export const zVeo31FastOutput = z.object({
  video: zFile,
});

/**
 * Veo31TextToVideoInput
 */
export const zVeo31FastInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * KandinskyT2VResponse
 */
export const zKandinsky5TextToVideoOutput = z.object({
  video: z.optional(zFile),
});

/**
 * KandinskyT2VRequest
 */
export const zKandinsky5TextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["768x512"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
    }),
  ),
  duration: z.optional(
    z.enum(["5s", "10s"]).register(z.globalRegistry, {
      description: "The length of the video to generate (5s or 10s)",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["3:2", "1:1", "2:3"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(30),
});

/**
 * KandinskyT2VResponse
 */
export const zKandinsky5TextToVideoDistillOutput = z.object({
  video: z.optional(zFile),
});

/**
 * KandinskyT2VDistillRequest
 */
export const zKandinsky5TextToVideoDistillInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  duration: z.optional(
    z.enum(["5s", "10s"]).register(z.globalRegistry, {
      description: "The length of the video to generate (5s or 10s)",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["3:2", "1:1", "2:3"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
    }),
  ),
  resolution: z.optional(
    z.enum(["768x512"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
    }),
  ),
});

/**
 * WanAlphaResponse
 */
export const zWanAlphaOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  image: z.optional(zVideoFileType2),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  mask: z.optional(zVideoFileType2),
  video: z.optional(zVideoFileType2),
});

/**
 * WanAlphaRequest
 */
export const zWanAlphaInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide the video generation.",
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(15).register(z.globalRegistry, {
        description: "The shift of the generated video.",
      }),
    )
    .default(10.5),
  mask_clamp_upper: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "The upper bound of the mask clamping.",
      }),
    )
    .default(0.75),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(16),
  mask_clamp_lower: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "The lower bound of the mask clamping.",
      }),
    )
    .default(0.1),
  num_frames: z
    .optional(
      z.int().gte(17).lte(121).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(81),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  mask_binarization_threshold: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.",
      }),
    )
    .default(0.8),
  sampler: z.optional(
    z.enum(["unipc", "dpm++", "euler"]).register(z.globalRegistry, {
      description: "The sampler to use.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  resolution: z.optional(
    z
      .enum(["240p", "360p", "480p", "580p", "720p"])
      .register(z.globalRegistry, {
        description: "The resolution of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "1:1", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  binarize_mask: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to binarize the mask.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
});

/**
 * VideoToVideoOutput
 */
export const zKreaWan14bTextToVideoOutput = z.object({
  video: zFileType2,
});

/**
 * TextToVideoInput
 */
export const zKreaWan14bTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Prompt for the video-to-video generation.",
  }),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(18).lte(162).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.",
      }),
    )
    .default(78),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * Q2TextToVideoOutput
 */
export const zViduQ2TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q2TextToVideoRequest
 */
export const zViduQ2TextToVideoInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 3000 characters",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "520p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to add background music to the video (only for 4-second videos)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
});

/**
 * SeedanceFastT2VVideoOutput
 */
export const zBytedanceSeedanceV1ProFastTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProFastTextToVideoInput
 */
export const zBytedanceSeedanceV1ProFastTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
});

/**
 * ProTextToVideoHailuo23Output
 */
export const zMinimaxHailuo23ProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProTextToVideoHailuo23Input
 */
export const zMinimaxHailuo23ProTextToVideoInput = z.object({
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation",
  }),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * StandardTextToVideoHailuo23Output
 */
export const zMinimaxHailuo23StandardTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * StandardTextToVideoHailuo23Input
 */
export const zMinimaxHailuo23StandardTextToVideoInput = z.object({
  prompt: z.string().min(1).max(2000),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description: "The duration of the video in seconds.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * LongCatVideoResponse
 */
export const zLongcatVideoDistilledTextToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCatVideoRequest
 */
export const zLongcatVideoDistilledTextToVideo480pInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide the video generation.",
  }),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(15),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * LongCatVideoResponse
 */
export const zLongcatVideoDistilledTextToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCat720PVideoRequest
 */
export const zLongcatVideoDistilledTextToVideo720pInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide the video generation.",
  }),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(30),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use for refinement.",
      }),
    )
    .default(12),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * LongCatVideoResponse
 */
export const zLongcatVideoTextToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCatCFGVideoRequest
 */
export const zLongcatVideoTextToVideo480pInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide the video generation.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "The acceleration level to use for the video generation.",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to use for the video generation.",
      }),
    )
    .default(
      "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(40),
});

/**
 * LongCatVideoResponse
 */
export const zLongcatVideoTextToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCat720PCFGVideoRequest
 */
export const zLongcatVideoTextToVideo720pInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to guide the video generation.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "The acceleration level to use for the video generation.",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(30),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use for refinement.",
      }),
    )
    .default(40),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to use for the video generation.",
      }),
    )
    .default(
      "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
});

/**
 * SanaVideoOutput
 */
export const zSanaVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The random seed used for the generation process",
  }),
  video: zFile,
});

/**
 * SanaVideoInput
 */
export const zSanaVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt describing the video to generate",
  }),
  resolution: z.optional(
    z.enum(["480p"]).register(z.globalRegistry, {
      description: "The resolution of the output video",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(8).lte(30).register(z.globalRegistry, {
        description: "Frames per second for the output video",
      }),
    )
    .default(16),
  motion_score: z
    .optional(
      z.int().gte(0).lte(100).register(z.globalRegistry, {
        description: "Motion intensity score (higher = more motion)",
      }),
    )
    .default(30),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          "Guidance scale for generation (higher = more prompt adherence)",
      }),
    )
    .default(6),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "Number of denoising steps",
      }),
    )
    .default(28),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducible generation. If not provided, a random seed will be used.",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "The negative prompt describing what to avoid in the generation",
      }),
    )
    .default(
      "A chaotic sequence with misshapen, deformed limbs in heavy motion blur, sudden disappearance, jump cuts, jerky movements, rapid shot changes, frames out of sync, inconsistent character shapes, temporal artifacts, jitter, and ghosting effects, creating a disorienting visual experience.",
    ),
  num_frames: z
    .optional(
      z.int().gte(16).lte(200).register(z.globalRegistry, {
        description: "Number of frames to generate",
      }),
    )
    .default(81),
});

/**
 * GenerationOutput
 *
 * Output model for text-to-video generation
 */
export const zInfinityStarTextToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for text-to-video generation",
  });

/**
 * GenerationInput
 *
 * Input model for text-to-video generation
 */
export const zInfinityStarTextToVideoInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt for generating the video",
    }),
    aspect_ratio: z.optional(
      z.enum(["16:9", "1:1", "9:16"]).register(z.globalRegistry, {
        description: "Aspect ratio of the generated output",
      }),
    ),
    enhance_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to use an LLM to enhance the prompt.",
        }),
      )
      .default(true),
    use_apg: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to use APG",
        }),
      )
      .default(true),
    guidance_scale: z
      .optional(
        z.number().gte(1).lte(40).register(z.globalRegistry, {
          description: "Guidance scale for generation",
        }),
      )
      .default(7.5),
    num_inference_steps: z
      .optional(
        z.int().gte(1).lte(100).register(z.globalRegistry, {
          description: "Number of inference steps",
        }),
      )
      .default(50),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. Leave empty for random generation.",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt to guide what to avoid in generation",
        }),
      )
      .default(""),
    tau_video: z
      .optional(
        z.number().gte(0.1).lte(1).register(z.globalRegistry, {
          description: "Tau value for video scale",
        }),
      )
      .default(0.4),
  })
  .register(z.globalRegistry, {
    description: "Input model for text-to-video generation",
  });

/**
 * HunyuanVideo15Response
 */
export const zHunyuanVideoV15TextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * HunyuanVideo15T2VRequest
 */
export const zHunyuanVideoV15TextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p"]).register(z.globalRegistry, {
      description: "The resolution of the video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable prompt expansion to enhance the input prompt.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for reproducibility.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to guide what not to generate.",
      }),
    )
    .default(""),
  num_frames: z
    .optional(
      z.int().gte(1).lte(121).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
});

/**
 * LTXVTextToVideoResponse
 */
export const zLtx2TextToVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LTXVTextToVideoRequest
 */
export const zLtx2TextToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The prompt to generate the video from",
  }),
  resolution: z.optional(
    z.enum(["1080p", "1440p", "2160p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the generated video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .union([z.literal(6), z.literal(8), z.literal(10)])
      .register(z.globalRegistry, {
        description: "The duration of the generated video in seconds",
      }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: "The frames per second of the generated video",
    }),
  ),
});

/**
 * LTXVTextToVideoResponse
 */
export const zLtx2TextToVideoFastOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LTXVTextToVideoFastRequest
 */
export const zLtx2TextToVideoFastInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The prompt to generate the video from",
  }),
  resolution: z.optional(
    z.enum(["1080p", "1440p", "2160p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the generated video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .union([
        z.literal(6),
        z.literal(8),
        z.literal(10),
        z.literal(12),
        z.literal(14),
        z.literal(16),
        z.literal(18),
        z.literal(20),
      ])
      .register(z.globalRegistry, {
        description:
          "The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.",
      }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: "The frames per second of the generated video",
    }),
  ),
});

/**
 * VideoOutputV5_5
 */
export const zPixverseV55TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequestV5_5
 */
export const zPixverseV55TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  generate_multi_clip_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable multi-clip generation with dynamic camera changes",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * TextToVideoV26ProOutput
 */
export const zKlingVideoV26ProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoV26ProRequest
 */
export const zKlingVideoV26ProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * FabricOneTextOutput
 */
export const zFabric10TextOutput = z.object({
  video: zFileType2,
});

/**
 * FabricOneTextInput
 */
export const zFabric10TextInput = z.object({
  text: z.string().min(1).max(2000),
  resolution: z.enum(["720p", "480p"]).register(z.globalRegistry, {
    description: "Resolution",
  }),
  voice_description: z.optional(z.union([z.string(), z.unknown()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * TextToVideoOutput
 *
 * Output for text-to-video generation
 */
export const zV26TextToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output for text-to-video generation",
  });

/**
 * TextToVideoInput
 *
 * Input for Wan 2.6 text-to-video generation
 */
export const zV26TextToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt for video generation. Supports Chinese and English, max 800 characters. For multi-shot videos, use format: 'Overall description. First shot [0-3s] content. Second shot [3-5s] content.'",
    }),
    duration: z.optional(
      z.enum(["5", "10", "15"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. Choose between 5, 10, or 15 seconds.",
      }),
    ),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description:
          "Video resolution tier. Wan 2.6 T2V only supports 720p and 1080p (no 480p).",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["16:9", "9:16", "1:1", "4:3", "3:4"]).register(z.globalRegistry, {
        description:
          "The aspect ratio of the generated video. Wan 2.6 supports additional ratios.",
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
        }),
      )
      .default(true),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true, enables intelligent multi-shot segmentation for coherent narrative videos. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.",
        }),
      )
      .default(true),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Negative prompt to describe content to avoid. Max 500 characters.",
        }),
      )
      .default(""),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for Wan 2.6 text-to-video generation",
  });

/**
 * SeedanceProv15T2VVideoOutput
 */
export const zBytedanceSeedanceV15ProTextToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProv15TextToVideoInput
 */
export const zBytedanceSeedanceV15ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .enum(["4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * KandinskyT2VResponse
 */
export const zKandinsky5ProTextToVideoOutput = z.object({
  video: z.optional(zFile),
});

/**
 * KandinskyT2VRequest
 */
export const zKandinsky5ProTextToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["512P", "1024P"]).register(z.globalRegistry, {
      description: "Video resolution: 512p or 1024p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "Acceleration level for faster generation.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["3:2", "1:1", "2:3"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(28),
  duration: z.optional(
    z.enum(["5s"]).register(z.globalRegistry, {
      description: "The length of the video to generate (5s or 10s)",
    }),
  ),
});

/**
 * LTX2TextToVideoOutput
 */
export const zLtx219bTextToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2TextToVideoInput
 */
export const zLtx219bTextToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2TextToVideoOutput
 */
export const zLtx219bTextToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRATextToVideoInput
 */
export const zLtx219bTextToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2TextToVideoOutput
 */
export const zLtx219bDistilledTextToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2DistilledTextToVideoInput
 */
export const zLtx219bDistilledTextToVideoInput = z.object({
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2TextToVideoOutput
 */
export const zLtx219bDistilledTextToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRADistilledTextToVideoInput
 */
export const zLtx219bDistilledTextToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * VideoOutputV5_5
 */
export const zPixverseV56TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoRequestV5_6
 */
export const zPixverseV56TextToVideoInput = z.object({
  prompt: z.string(),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * XAITextToVideoOutput
 */
export const zGrokImagineVideoTextToVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * XAITextToVideoInput
 */
export const zGrokImagineVideoTextToVideoInput = z.object({
  prompt: z.string().max(4096).register(z.globalRegistry, {
    description: "Text description of the desired video.",
  }),
  duration: z
    .optional(
      z.int().gte(1).lte(15).register(z.globalRegistry, {
        description: "Video duration in seconds.",
      }),
    )
    .default(6),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the output video.",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["16:9", "4:3", "3:2", "1:1", "2:3", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "Aspect ratio of the generated video.",
      }),
  ),
});

/**
 * Q3TextToVideoOutput
 */
export const zViduQ3TextToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q3TextToVideoRequest
 */
export const zViduQ3TextToVideoInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 2000 characters",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "4:3", "3:4", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  duration: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
    )
    .default(5),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use direct audio-video generation. When true, outputs video with sound.",
      }),
    )
    .default(true),
});

/**
 * TextToVideoV2MasterOutput
 */
export const zKlingVideoV2MasterTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoV2MasterRequest
 */
export const zKlingVideoV2MasterTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * Veo3TextToVideoOutput
 */
export const zVeo3Output = z.object({
  video: zFile,
});

/**
 * Veo3TextToVideoInput
 */
export const zVeo3Input = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * TextToVideoHailuo02Output
 */
export const zMinimaxHailuo02StandardTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * StandardTextToVideoHailuo02Input
 */
export const zMinimaxHailuo02StandardTextToVideoInput = z.object({
  prompt: z.string().min(1).max(2000),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
});

/**
 * Veo3TextToVideoOutput
 */
export const zVeo3FastOutput = z.object({
  video: zFile,
});

/**
 * Veo3TextToVideoInput
 */
export const zVeo3FastInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * TextToVideoV25ProOutput
 */
export const zKlingVideoV25TurboProTextToVideoOutput = z.object({
  video: zFile,
});

/**
 * TextToVideoV25ProRequest
 */
export const zKlingVideoV25TurboProTextToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * FastSVDOutput
 */
export const zFastSvdLcmOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n\n        ",
  }),
  video: zFile,
});

/**
 * FastSVDImageInput
 */
export const zFastSvdLcmInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(1).lte(25).register(z.globalRegistry, {
        description:
          "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
      }),
    )
    .default(10),
  steps: z
    .optional(
      z.int().gte(1).lte(20).register(z.globalRegistry, {
        description:
          "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
      }),
    )
    .default(4),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * SadTalkerOutput
 */
export const zSadtalkerOutput = z.object({
  video: zFile,
});

/**
 * SadTalkerInput
 */
export const zSadtalkerInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: "The style of the pose",
      }),
    )
    .default(0),
  source_image_url: z.union([z.string(), z.string()]),
  driven_audio_url: z.union([z.string(), z.string()]),
  face_enhancer: z.optional(
    z.enum(["gfpgan"]).register(z.globalRegistry, {
      description: "The type of face enhancer to use",
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: "The scale of the expression",
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(["256", "512"]).register(z.globalRegistry, {
      description: "The resolution of the face model",
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(["crop", "extcrop", "resize", "full", "extfull"])
      .register(z.globalRegistry, {
        description: "The type of preprocessing to use",
      }),
  ),
});

/**
 * MuseTalkOutput
 */
export const zMusetalkOutput = z.object({
  video: zFile,
});

/**
 * MuseTalkInput
 */
export const zMusetalkInput = z.object({
  source_video_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * LivePortraitOutput
 */
export const zLivePortraitOutput = z.object({
  video: zFile,
});

/**
 * LivePortraitInput
 */
export const zLivePortraitInput = z.object({
  smile: z
    .optional(
      z.number().gte(-2).lte(2).register(z.globalRegistry, {
        description: "Amount to smile",
      }),
    )
    .default(0),
  video_url: z.union([z.string(), z.string()]),
  eyebrow: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: "Amount to raise or lower eyebrows",
      }),
    )
    .default(0),
  flag_stitching: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable stitching. Recommended to set to True.",
      }),
    )
    .default(true),
  wink: z
    .optional(
      z.number().gte(0).lte(25).register(z.globalRegistry, {
        description: "Amount to wink",
      }),
    )
    .default(0),
  rotate_pitch: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: "Amount to rotate the face in pitch",
      }),
    )
    .default(0),
  blink: z
    .optional(
      z.number().gte(-30).lte(30).register(z.globalRegistry, {
        description: "Amount to blink the eyes",
      }),
    )
    .default(0),
  scale: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: "Scaling factor for the face crop.",
      }),
    )
    .default(2.3),
  eee: z
    .optional(
      z.number().gte(-40).lte(40).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'eee' position",
      }),
    )
    .default(0),
  flag_pasteback: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.",
      }),
    )
    .default(true),
  pupil_y: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: "Amount to move pupils vertically",
      }),
    )
    .default(0),
  rotate_yaw: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: "Amount to rotate the face in yaw",
      }),
    )
    .default(0),
  flag_do_rot: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to conduct the rotation when flag_do_crop is True.",
      }),
    )
    .default(true),
  woo: z
    .optional(
      z.number().gte(-100).lte(100).register(z.globalRegistry, {
        description: "Amount to shape mouth in 'woo' position",
      }),
    )
    .default(0),
  aaa: z
    .optional(
      z.number().gte(-200).lte(200).register(z.globalRegistry, {
        description: "Amount to open mouth in 'aaa' shape",
      }),
    )
    .default(0),
  image_url: z.union([z.string(), z.string()]),
  flag_relative: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use relative motion.",
      }),
    )
    .default(true),
  flag_eye_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable eye retargeting.",
      }),
    )
    .default(false),
  flag_lip_zero: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.",
      }),
    )
    .default(true),
  batch_size: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.",
      }),
    )
    .default(32),
  rotate_roll: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: "Amount to rotate the face in roll",
      }),
    )
    .default(0),
  pupil_x: z
    .optional(
      z.number().gte(-45).lte(45).register(z.globalRegistry, {
        description: "Amount to move pupils horizontally",
      }),
    )
    .default(0),
  vy_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description:
          "Vertical offset ratio for face crop. Positive values move up, negative values move down.",
      }),
    )
    .default(-0.125),
  dsize: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Size of the output image.",
      }),
    )
    .default(512),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ",
      }),
    )
    .default(false),
  vx_ratio: z
    .optional(
      z.number().register(z.globalRegistry, {
        description: "Horizontal offset ratio for face crop.",
      }),
    )
    .default(0),
  flag_lip_retargeting: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable lip retargeting.",
      }),
    )
    .default(false),
  flag_do_crop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to crop the source portrait to the face-cropping space.",
      }),
    )
    .default(true),
});

/**
 * Frame
 */
export const zFrame = z.object({
  url: z.string().register(z.globalRegistry, {
    description: "URL of the frame",
  }),
});

/**
 * AMTInterpolationOutput
 */
export const zAmtInterpolationFrameInterpolationOutput = z.object({
  video: zFile,
});

/**
 * AMTFrameInterpolationInput
 */
export const zAmtInterpolationFrameInterpolationInput = z.object({
  frames: z.array(zFrame).register(z.globalRegistry, {
    description: "Frames to interpolate",
  }),
  recursive_interpolation_passes: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Number of recursive interpolation passes",
      }),
    )
    .default(4),
  output_fps: z
    .optional(
      z.int().register(z.globalRegistry, {
        description: "Output frames per second",
      }),
    )
    .default(24),
});

/**
 * VideoOutput
 */
export const zStableVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed for random number generator",
  }),
  video: zFile,
});

/**
 * ImageInput
 */
export const zStableVideoInput = z.object({
  motion_bucket_id: z
    .optional(
      z.int().gte(1).lte(255).register(z.globalRegistry, {
        description:
          "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
      }),
    )
    .default(127),
  fps: z
    .optional(
      z.int().gte(10).lte(100).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  cond_aug: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
      }),
    )
    .default(0.02),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * KlingV1I2VOutput
 */
export const zKlingVideoV1StandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Trajectory
 */
export const zTrajectory = z.object({
  y: z.int().register(z.globalRegistry, {
    description: "Y coordinate of the motion trajectory",
  }),
  x: z.int().register(z.globalRegistry, {
    description: "X coordinate of the motion trajectory",
  }),
});

/**
 * DynamicMask
 */
export const zDynamicMask = z.object({
  trajectories: z.optional(
    z.array(zTrajectory).register(z.globalRegistry, {
      description: "List of trajectories",
    }),
  ),
  mask_url: z.string().register(z.globalRegistry, {
    description:
      "URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)",
  }),
});

/**
 * V1ImageToVideoRequest
 */
export const zKlingVideoV1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description: "The prompt for the video",
  }),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
  static_mask_url: z.optional(z.union([z.string(), z.string()])),
  dynamic_masks: z.optional(
    z.array(zDynamicMask).register(z.globalRegistry, {
      description: "List of dynamic masks",
    }),
  ),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * I2VOutput
 */
export const zKlingVideoV15ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * KlingV15ProImageToVideoRequest
 */
export const zKlingVideoV15ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
  static_mask_url: z.optional(z.union([z.string(), z.string()])),
  dynamic_masks: z.optional(
    z.array(zDynamicMask).register(z.globalRegistry, {
      description: "List of dynamic masks",
    }),
  ),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * Output
 */
export const zCogvideox5bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generating the video.",
  }),
  timings: z.record(z.string(), z.number()),
  seed: z.int().register(z.globalRegistry, {
    description:
      "\n            Seed of the generated video. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        ",
  }),
  video: zFile,
});

/**
 * ImageToVideoInput
 */
export const zCogvideox5bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  use_rife: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Use RIFE for video interpolation",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
  loras: z
    .optional(
      z.array(zLoraWeight).register(z.globalRegistry, {
        description:
          "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
      }),
    )
    .default([]),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
      }),
    )
    .default(7),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to perform.",
      }),
    )
    .default(50),
  export_fps: z
    .optional(
      z.int().gte(4).lte(32).register(z.globalRegistry, {
        description: "The target FPS of the video",
      }),
    )
    .default(16),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate video from",
      }),
    )
    .default(""),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
});

/**
 * Output
 */
export const zLtxVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for random number generation.",
  }),
  video: zFile,
});

/**
 * ImageToVideoInput
 */
export const zLtxVideoImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  guidance_scale: z
    .optional(
      z.number().lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for random number generation.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to take.",
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly",
    ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VLiveOutput
 */
export const zMinimaxVideo01LiveImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequest
 */
export const zMinimaxVideo01LiveImageToVideoInput = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * SadTalkerOutput
 */
export const zSadtalkerReferenceOutput = z.object({
  video: zFile,
});

/**
 * SadTalkerRefVideoInput
 */
export const zSadtalkerReferenceInput = z.object({
  pose_style: z
    .optional(
      z.int().gte(0).lte(45).register(z.globalRegistry, {
        description: "The style of the pose",
      }),
    )
    .default(0),
  source_image_url: z.union([z.string(), z.string()]),
  reference_pose_video_url: z.union([z.string(), z.string()]),
  driven_audio_url: z.union([z.string(), z.string()]),
  face_enhancer: z.optional(
    z.enum(["gfpgan"]).register(z.globalRegistry, {
      description: "The type of face enhancer to use",
    }),
  ),
  expression_scale: z
    .optional(
      z.number().gte(0).lte(3).register(z.globalRegistry, {
        description: "The scale of the expression",
      }),
    )
    .default(1),
  face_model_resolution: z.optional(
    z.enum(["256", "512"]).register(z.globalRegistry, {
      description: "The resolution of the face model",
    }),
  ),
  still_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
      }),
    )
    .default(false),
  preprocess: z.optional(
    z
      .enum(["crop", "extcrop", "resize", "full", "extfull"])
      .register(z.globalRegistry, {
        description: "The type of preprocessing to use",
      }),
  ),
});

/**
 * I2VOutput
 */
export const zKlingVideoV16StandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequest
 */
export const zKlingVideoV16StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * SubjectReferenceOutput
 */
export const zMinimaxVideo01SubjectReferenceOutput = z.object({
  video: zFile,
});

/**
 * SubjectReferenceRequest
 */
export const zMinimaxVideo01SubjectReferenceInput = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  subject_reference_image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VOutput
 */
export const zPixverseV35ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequest
 */
export const zPixverseV35ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * I2VOutput
 */
export const zPixverseV35ImageToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastImageToVideoRequest
 */
export const zPixverseV35ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Output
 */
export const zHunyuanVideoImg2VidLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * Input
 */
export const zHunyuanVideoImg2VidLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Ray2I2VOutput
 */
export const zLumaDreamMachineRay2ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Ray2ImageToVideoRequest
 */
export const zLumaDreamMachineRay2ImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(["16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  resolution: z.optional(
    z.enum(["540p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether the video should loop (end of video is blended with the beginning)",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["5s", "9s"]).register(z.globalRegistry, {
      description: "The duration of the generated video",
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * SkyreelsI2VResponse
 */
export const zSkyreelsI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation",
  }),
  video: zFile,
});

/**
 * SkyreelsI2VRequest
 */
export const zSkyreelsI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "Aspect ratio of the output video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description: "Guidance scale for generation (between 1.0 and 20.0)",
      }),
    )
    .default(6),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for generation. If not provided, a random seed will be used.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          "Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Negative prompt to guide generation away from certain attributes.",
    }),
  ),
});

/**
 * I2VDirectorOutput
 */
export const zMinimaxVideo01DirectorImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoDirectorRequest
 */
export const zMinimaxVideo01DirectorImageToVideoInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description:
      "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645",
  }),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * HunyuanI2VResponse
 */
export const zHunyuanVideoImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanVideoRequest
 */
export const zHunyuanVideoImageToVideoInput = z.object({
  prompt: z.string().max(1000).register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "The resolution of the video to generate.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_frames: z.optional(
    z.enum(["129"]).register(z.globalRegistry, {
      description: "The number of frames to generate.",
    }),
  ),
  i2v_stability: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Turning on I2V Stability reduces hallucination but also reduces motion.",
      }),
    )
    .default(false),
});

/**
 * WanI2VResponse
 */
export const zWanI2vLoraOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanLoRAI2VRequest
 */
export const zWanI2vLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, the video will be reversed.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoraWeightType2).register(z.globalRegistry, {
        description: "LoRA weights to be used in the inference.",
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
      }),
    )
    .default(true),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the output video.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
});

/**
 * TemplateToVideoOutput
 */
export const zViduTemplateToVideoOutput = z.object({
  video: zFile,
});

/**
 * TemplateToVideoRequest
 */
export const zViduTemplateToVideoInput = z.object({
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  template: z.optional(
    z
      .enum([
        "dreamy_wedding",
        "romantic_lift",
        "sweet_proposal",
        "couple_arrival",
        "cupid_arrow",
        "pet_lovers",
        "lunar_newyear",
        "hug",
        "kiss",
        "dynasty_dress",
        "wish_sender",
        "love_pose",
        "hair_swap",
        "youth_rewind",
        "morphlab",
        "live_photo",
        "emotionlab",
        "live_memory",
        "interaction",
        "christmas",
        "pet_finger",
        "eat_mushrooms",
        "beast_chase_library",
        "beast_chase_supermarket",
        "petal_scattered",
        "emoji_figure",
        "hair_color_change",
        "multiple_people_kissing",
        "beast_chase_amazon",
        "beast_chase_mountain",
        "balloonman_explodes_pro",
        "get_thinner",
        "jump2pool",
        "bodyshake",
        "jiggle_up",
        "shake_it_dance",
        "subject_3",
        "pubg_winner_hit",
        "shake_it_down",
        "blueprint_supreme",
        "hip_twist",
        "motor_dance",
        "rat_dance",
        "kwok_dance",
        "leg_sweep_dance",
        "heeseung_march",
        "shake_to_max",
        "dame_un_grrr",
        "i_know",
        "lit_bounce",
        "wave_dance",
        "chill_dance",
        "hip_flicking",
        "sakura_season",
        "zongzi_wrap",
        "zongzi_drop",
        "dragonboat_shot",
        "rain_kiss",
        "child_memory",
        "couple_drop",
        "couple_walk",
        "flower_receive",
        "love_drop",
        "cheek_kiss",
        "carry_me",
        "blow_kiss",
        "love_fall",
        "french_kiss_8s",
        "workday_feels",
        "love_story",
        "bloom_magic",
        "ghibli",
        "minecraft",
        "box_me",
        "claw_me",
        "clayshot",
        "manga_meme",
        "quad_meme",
        "pixel_me",
        "clayshot_duo",
        "irasutoya",
        "american_comic",
        "simpsons_comic",
        "yayoi_kusama_style",
        "pop_art",
        "jojo_style",
        "slice_therapy",
        "balloon_flyaway",
        "flying",
        "paperman",
        "pinch",
        "bloom_doorobear",
        "gender_swap",
        "nap_me",
        "sexy_me",
        "spin360",
        "smooth_shift",
        "paper_fall",
        "jump_to_cloud",
        "pilot",
        "sweet_dreams",
        "soul_depart",
        "punch_hit",
        "watermelon_hit",
        "split_stance_pet",
        "make_face",
        "break_glass",
        "split_stance_human",
        "covered_liquid_metal",
        "fluffy_plunge",
        "pet_belly_dance",
        "water_float",
        "relax_cut",
        "head_to_balloon",
        "cloning",
        "across_the_universe_jungle",
        "clothes_spinning_remnant",
        "across_the_universe_jurassic",
        "across_the_universe_moon",
        "fisheye_pet",
        "hitchcock_zoom",
        "cute_bangs",
        "earth_zoom_out",
        "fisheye_human",
        "drive_yacht",
        "virtual_singer",
        "earth_zoom_in",
        "aliens_coming",
        "drive_ferrari",
        "bjd_style",
        "virtual_fitting",
        "orbit",
        "zoom_in",
        "ai_outfit",
        "spin180",
        "orbit_dolly",
        "orbit_dolly_fast",
        "auto_spin",
        "walk_forward",
        "outfit_show",
        "zoom_in_fast",
        "zoom_out_image",
        "zoom_out_startend",
        "muscling",
        "captain_america",
        "hulk",
        "cap_walk",
        "hulk_dive",
        "exotic_princess",
        "beast_companion",
        "cartoon_doll",
        "golden_epoch",
        "oscar_gala",
        "fashion_stride",
        "star_carpet",
        "flame_carpet",
        "frost_carpet",
        "mecha_x",
        "style_me",
        "tap_me",
        "saber_warrior",
        "pet2human",
        "graduation",
        "fishermen",
        "happy_birthday",
        "fairy_me",
        "ladudu_me",
        "ladudu_me_random",
        "squid_game",
        "superman",
        "grow_wings",
        "clevage",
        "fly_with_doraemon",
        "creatice_product_down",
        "pole_dance",
        "hug_from_behind",
        "creatice_product_up_cybercity",
        "creatice_product_up_bluecircuit",
        "creatice_product_up",
        "run_fast",
        "background_explosion",
      ])
      .register(z.globalRegistry, {
        description:
          "AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.",
  }),
});

/**
 * StartEndToVideoOutput
 */
export const zViduStartEndToVideoOutput = z.object({
  video: zFile,
});

/**
 * StartEndToVideoRequest
 */
export const zViduStartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  end_image_url: z.union([z.string(), z.string()]),
  start_image_url: z.union([z.string(), z.string()]),
});

/**
 * ReferenceToVideoOutput
 */
export const zViduReferenceToVideoOutput = z.object({
  video: zFile,
});

/**
 * ReferenceToVideoRequest
 */
export const zViduReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the reference images to use for consistent subject appearance",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
});

/**
 * VideoOutput
 */
export const zViduImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequest
 */
export const zViduImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * TurboImageToVideoOutput
 *
 * Output model for all video generation endpoints
 */
export const zPikaV2TurboImageToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for all video generation endpoints",
  });

/**
 * ImageToVideoTurboInput
 *
 * Base request for image-to-video generation
 */
export const zPikaV2TurboImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: "The duration of the generated video in seconds",
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default(""),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Base request for image-to-video generation",
  });

/**
 * Pika22PikascenesOutput
 *
 * Output model for Pika 2.2 Pikascenes generation
 */
export const zPikaV22PikascenesOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for Pika 2.2 Pikascenes generation",
  });

/**
 * Pika22PikascenesRequest
 *
 * Request model for Pika 2.2 Pikascenes (collection-to-video) generation
 */
export const zPikaV22PikascenesInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt describing the desired video",
    }),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    aspect_ratio: z.optional(
      z
        .enum(["16:9", "9:16", "1:1", "4:5", "5:4", "3:2", "2:3"])
        .register(z.globalRegistry, {
          description: "The aspect ratio of the generated video",
        }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: "The duration of the generated video in seconds",
      }),
    ),
    ingredients_mode: z.optional(
      z.enum(["precise", "creative"]).register(z.globalRegistry, {
        description:
          "Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    image_urls: z.array(z.string()).register(z.globalRegistry, {
      description: "URLs of images to combine into a video",
    }),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default("ugly, bad, terrible"),
  })
  .register(z.globalRegistry, {
    description:
      "Request model for Pika 2.2 Pikascenes (collection-to-video) generation",
  });

/**
 * Pika22ImageToVideoOutput
 *
 * Output model for Pika 2.2 image-to-video generation
 */
export const zPikaV22ImageToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for Pika 2.2 image-to-video generation",
  });

/**
 * Pika22ImageToVideoRequest
 *
 * Request model for Pika 2.2 image-to-video generation
 */
export const zPikaV22ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    duration: z.optional(
      z.union([z.literal(5), z.literal(10)]).register(z.globalRegistry, {
        description: "The duration of the generated video in seconds",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default(""),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Request model for Pika 2.2 image-to-video generation",
  });

/**
 * ImageToVideoV21Output
 *
 * Output from image-to-video generation
 */
export const zPikaV21ImageToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output from image-to-video generation",
  });

/**
 * ImageToVideov21Input
 *
 * Base request for image-to-video generation
 */
export const zPikaV21ImageToVideoInput = z
  .object({
    prompt: z.string(),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "The resolution of the generated video",
      }),
    ),
    duration: z
      .optional(
        z.int().register(z.globalRegistry, {
          description: "The duration of the generated video in seconds",
        }),
      )
      .default(5),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "A negative prompt to guide the model",
        }),
      )
      .default(""),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Base request for image-to-video generation",
  });

/**
 * PikaffectsOutput
 *
 * Output from Pikaffects generation
 */
export const zPikaV15PikaffectsOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output from Pikaffects generation",
  });

/**
 * PikaffectsRequest
 *
 * Request model for Pikaffects endpoint
 */
export const zPikaV15PikaffectsInput = z
  .object({
    pikaffect: z
      .enum([
        "Cake-ify",
        "Crumble",
        "Crush",
        "Decapitate",
        "Deflate",
        "Dissolve",
        "Explode",
        "Eye-pop",
        "Inflate",
        "Levitate",
        "Melt",
        "Peel",
        "Poke",
        "Squish",
        "Ta-da",
        "Tear",
      ])
      .register(z.globalRegistry, {
        description: "The Pikaffect to apply",
      }),
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "Text prompt to guide the effect",
      }),
    ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator",
      }),
    ),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to guide the model",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
  })
  .register(z.globalRegistry, {
    description: "Request model for Pikaffects endpoint",
  });

/**
 * Ray2I2VOutput
 */
export const zLumaDreamMachineRay2FlashImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Ray2ImageToVideoRequest
 */
export const zLumaDreamMachineRay2FlashImageToVideoInput = z.object({
  prompt: z.string().min(3).max(5000),
  aspect_ratio: z.optional(
    z
      .enum(["16:9", "9:16", "4:3", "3:4", "21:9", "9:21"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  resolution: z.optional(
    z.enum(["540p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
    }),
  ),
  loop: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether the video should loop (end of video is blended with the beginning)",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["5s", "9s"]).register(z.globalRegistry, {
      description: "The duration of the generated video",
    }),
  ),
  image_url: z.optional(z.union([z.string(), z.string()])),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * TransitionOutput
 */
export const zPixverseV35TransitionOutput = z.object({
  video: zFile,
});

/**
 * TransitionRequest
 */
export const zPixverseV35TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt for the transition",
  }),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * EffectOutput
 */
export const zPixverseV35EffectsOutput = z.object({
  video: zFile,
});

/**
 * EffectInput
 */
export const zPixverseV35EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  effect: z
    .enum([
      "Kiss Me AI",
      "Kiss",
      "Muscle Surge",
      "Warmth of Jesus",
      "Anything, Robot",
      "The Tiger Touch",
      "Hug",
      "Holy Wings",
      "Microwave",
      "Zombie Mode",
      "Squid Game",
      "Baby Face",
      "Black Myth: Wukong",
      "Long Hair Magic",
      "Leggy Run",
      "Fin-tastic Mermaid",
      "Punch Face",
      "Creepy Devil Smile",
      "Thunder God",
      "Eye Zoom Challenge",
      "Who's Arrested?",
      "Baby Arrived",
      "Werewolf Rage",
      "Bald Swipe",
      "BOOM DROP",
      "Huge Cutie",
      "Liquid Metal",
      "Sharksnap!",
      "Dust Me Away",
      "3D Figurine Factor",
      "Bikini Up",
      "My Girlfriends",
      "My Boyfriends",
      "Subject 3 Fever",
      "Earth Zoom",
      "Pole Dance",
      "Vroom Dance",
      "GhostFace Terror",
      "Dragon Evoker",
      "Skeletal Bae",
      "Summoning succubus",
      "Halloween Voodoo Doll",
      "3D Naked-Eye AD",
      "Package Explosion",
      "Dishes Served",
      "Ocean ad",
      "Supermarket AD",
      "Tree doll",
      "Come Feel My Abs",
      "The Bicep Flex",
      "London Elite Vibe",
      "Flora Nymph Gown",
      "Christmas Costume",
      "It's Snowy",
      "Reindeer Cruiser",
      "Snow Globe Maker",
      "Pet Christmas Outfit",
      "Adopt a Polar Pal",
      "Cat Christmas Box",
      "Starlight Gift Box",
      "Xmas Poster",
      "Pet Christmas Tree",
      "City Santa Hat",
      "Stocking Sweetie",
      "Christmas Night",
      "Xmas Front Page Karma",
      "Grinch's Xmas Hijack",
      "Giant Product",
      "Truck Fashion Shoot",
      "Beach AD",
      "Shoal Surround",
      "Mechanical Assembly",
      "Lighting AD",
      "Billboard AD",
      "Product close-up",
      "Parachute Delivery",
      "Dreamlike Cloud",
      "Macaron Machine",
      "Poster AD",
      "Truck AD",
      "Graffiti AD",
      "3D Figurine Factory",
      "The Exclusive First Class",
      "Art Zoom Challenge",
      "I Quit",
      "Hitchcock Dolly Zoom",
      "Smell the Lens",
      "I believe I can fly",
      "Strikout Dance",
      "Pixel World",
      "Mint in Box",
      "Hands up, Hand",
      "Flora Nymph Go",
      "Somber Embrace",
      "Beam me up",
      "Suit Swagger",
    ])
    .register(z.globalRegistry, {
      description: "The effect to apply to the video",
    }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VOutputV4
 */
export const zPixverseV4ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequestV4
 */
export const zPixverseV4ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        "horizontal_left",
        "horizontal_right",
        "vertical_up",
        "vertical_down",
        "zoom_in",
        "zoom_out",
        "crane_up",
        "quickly_zoom_in",
        "quickly_zoom_out",
        "smooth_zoom_in",
        "camera_rotation",
        "robo_arm",
        "super_dolly_out",
        "whip_pan",
        "hitchcock",
        "left_follow",
        "right_follow",
        "pan_left",
        "pan_right",
        "fix_bg",
      ])
      .register(z.globalRegistry, {
        description: "The type of camera movement to apply to the video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * I2VOutputV4
 */
export const zPixverseV4ImageToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastImageToVideoRequestV4
 */
export const zPixverseV4ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        "horizontal_left",
        "horizontal_right",
        "vertical_up",
        "vertical_down",
        "zoom_in",
        "zoom_out",
        "crane_up",
        "quickly_zoom_in",
        "quickly_zoom_out",
        "smooth_zoom_in",
        "camera_rotation",
        "robo_arm",
        "super_dolly_out",
        "whip_pan",
        "hitchcock",
        "left_follow",
        "right_follow",
        "pan_left",
        "pan_right",
        "fix_bg",
      ])
      .register(z.globalRegistry, {
        description: "The type of camera movement to apply to the video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * FramePackResponse
 */
export const zFramepackOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * FramePackRequest
 */
export const zFramepackInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt for video generation (max 500 characters).",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["720p", "480p"]).register(z.globalRegistry, {
      description:
        "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(180),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: "Guidance scale for the generation.",
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: "Classifier-Free Guidance scale for the generation.",
      }),
    )
    .default(1),
});

/**
 * WanFLF2VResponse
 */
export const zWanFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanFLF2VRequest
 */
export const zWanFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(81),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
});

/**
 * FramePackFLF2VResponse
 */
export const zFramepackFlf2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * FramePackF2LFRequest
 */
export const zFramepackFlf2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt for video generation (max 500 characters).",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["720p", "480p"]).register(z.globalRegistry, {
      description:
        "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(1800).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(240),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.",
      }),
    )
    .default(0.8),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: "Guidance scale for the generation.",
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: "Classifier-Free Guidance scale for the generation.",
      }),
    )
    .default(1),
});

/**
 * MagiImageToVideoResponse
 */
export const zMagiDistilledImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiImageToVideoRequest
 */
export const zMagiDistilledImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(16), z.literal(32)])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * EffectOutput
 */
export const zPixverseV4EffectsOutput = z.object({
  video: zFile,
});

/**
 * EffectInput
 */
export const zPixverseV4EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  effect: z
    .enum([
      "Kiss Me AI",
      "Kiss",
      "Muscle Surge",
      "Warmth of Jesus",
      "Anything, Robot",
      "The Tiger Touch",
      "Hug",
      "Holy Wings",
      "Microwave",
      "Zombie Mode",
      "Squid Game",
      "Baby Face",
      "Black Myth: Wukong",
      "Long Hair Magic",
      "Leggy Run",
      "Fin-tastic Mermaid",
      "Punch Face",
      "Creepy Devil Smile",
      "Thunder God",
      "Eye Zoom Challenge",
      "Who's Arrested?",
      "Baby Arrived",
      "Werewolf Rage",
      "Bald Swipe",
      "BOOM DROP",
      "Huge Cutie",
      "Liquid Metal",
      "Sharksnap!",
      "Dust Me Away",
      "3D Figurine Factor",
      "Bikini Up",
      "My Girlfriends",
      "My Boyfriends",
      "Subject 3 Fever",
      "Earth Zoom",
      "Pole Dance",
      "Vroom Dance",
      "GhostFace Terror",
      "Dragon Evoker",
      "Skeletal Bae",
      "Summoning succubus",
      "Halloween Voodoo Doll",
      "3D Naked-Eye AD",
      "Package Explosion",
      "Dishes Served",
      "Ocean ad",
      "Supermarket AD",
      "Tree doll",
      "Come Feel My Abs",
      "The Bicep Flex",
      "London Elite Vibe",
      "Flora Nymph Gown",
      "Christmas Costume",
      "It's Snowy",
      "Reindeer Cruiser",
      "Snow Globe Maker",
      "Pet Christmas Outfit",
      "Adopt a Polar Pal",
      "Cat Christmas Box",
      "Starlight Gift Box",
      "Xmas Poster",
      "Pet Christmas Tree",
      "City Santa Hat",
      "Stocking Sweetie",
      "Christmas Night",
      "Xmas Front Page Karma",
      "Grinch's Xmas Hijack",
      "Giant Product",
      "Truck Fashion Shoot",
      "Beach AD",
      "Shoal Surround",
      "Mechanical Assembly",
      "Lighting AD",
      "Billboard AD",
      "Product close-up",
      "Parachute Delivery",
      "Dreamlike Cloud",
      "Macaron Machine",
      "Poster AD",
      "Truck AD",
      "Graffiti AD",
      "3D Figurine Factory",
      "The Exclusive First Class",
      "Art Zoom Challenge",
      "I Quit",
      "Hitchcock Dolly Zoom",
      "Smell the Lens",
      "I believe I can fly",
      "Strikout Dance",
      "Pixel World",
      "Mint in Box",
      "Hands up, Hand",
      "Flora Nymph Go",
      "Somber Embrace",
      "Beam me up",
      "Suit Swagger",
    ])
    .register(z.globalRegistry, {
      description: "The effect to apply to the video",
    }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * MagiImageToVideoResponse
 */
export const zMagiImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * MagiImageToVideoRequest
 */
export const zMagiImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_inference_steps: z.optional(
    z
      .union([
        z.literal(4),
        z.literal(8),
        z.literal(16),
        z.literal(32),
        z.literal(64),
      ])
      .register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(96).lte(192).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
      }),
    )
    .default(96),
});

/**
 * Q1ImageToVideoOutput
 */
export const zViduQ1ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q1ImageToVideoRequest
 */
export const zViduQ1ImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Seed for the random number generator",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Q1StartEndToVideoOutput
 */
export const zViduQ1StartEndToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q1StartEndToVideoRequest
 */
export const zViduQ1StartEndToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Seed for the random number generator",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  end_image_url: z.union([z.string(), z.string()]),
  start_image_url: z.union([z.string(), z.string()]),
});

/**
 * FramePackF1Response
 */
export const zFramepackF1Output = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFileType2,
});

/**
 * FramePackF1Request
 */
export const zFramepackF1Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt for video generation (max 500 characters).",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["720p", "480p"]).register(z.globalRegistry, {
      description:
        "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(30).lte(900).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(180),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(32).register(z.globalRegistry, {
        description: "Guidance scale for the generation.",
      }),
    )
    .default(10),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(7).register(z.globalRegistry, {
        description: "Classifier-Free Guidance scale for the generation.",
      }),
    )
    .default(1),
});

/**
 * HunyuanCustomResponse
 */
export const zHunyuanCustomOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generating the video.",
  }),
  video: zFile,
});

/**
 * HunyuanCustomRequest
 */
export const zHunyuanCustomInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt for video generation (max 500 characters).",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video to generate.",
    }),
  ),
  resolution: z.optional(
    z.enum(["512p", "720p"]).register(z.globalRegistry, {
      description:
        "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(81).lte(129).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(129),
  image_url: z.union([z.string(), z.string()]),
  fps: z
    .optional(
      z.int().gte(16).lte(30).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for generating the video.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(30).register(z.globalRegistry, {
        description:
          "The number of inference steps to run. Lower gets faster results, higher gets better results.",
      }),
    )
    .default(30),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion, blurring, text, subtitles, static, picture, black border.",
    ),
  cfg_scale: z
    .optional(
      z.number().gte(1.5).lte(13).register(z.globalRegistry, {
        description: "Classifier-Free Guidance scale for the generation.",
      }),
    )
    .default(7.5),
});

/**
 * EffectOutput
 */
export const zPixverseV45EffectsOutput = z.object({
  video: zFile,
});

/**
 * EffectInput
 */
export const zPixverseV45EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  effect: z
    .enum([
      "Kiss Me AI",
      "Kiss",
      "Muscle Surge",
      "Warmth of Jesus",
      "Anything, Robot",
      "The Tiger Touch",
      "Hug",
      "Holy Wings",
      "Microwave",
      "Zombie Mode",
      "Squid Game",
      "Baby Face",
      "Black Myth: Wukong",
      "Long Hair Magic",
      "Leggy Run",
      "Fin-tastic Mermaid",
      "Punch Face",
      "Creepy Devil Smile",
      "Thunder God",
      "Eye Zoom Challenge",
      "Who's Arrested?",
      "Baby Arrived",
      "Werewolf Rage",
      "Bald Swipe",
      "BOOM DROP",
      "Huge Cutie",
      "Liquid Metal",
      "Sharksnap!",
      "Dust Me Away",
      "3D Figurine Factor",
      "Bikini Up",
      "My Girlfriends",
      "My Boyfriends",
      "Subject 3 Fever",
      "Earth Zoom",
      "Pole Dance",
      "Vroom Dance",
      "GhostFace Terror",
      "Dragon Evoker",
      "Skeletal Bae",
      "Summoning succubus",
      "Halloween Voodoo Doll",
      "3D Naked-Eye AD",
      "Package Explosion",
      "Dishes Served",
      "Ocean ad",
      "Supermarket AD",
      "Tree doll",
      "Come Feel My Abs",
      "The Bicep Flex",
      "London Elite Vibe",
      "Flora Nymph Gown",
      "Christmas Costume",
      "It's Snowy",
      "Reindeer Cruiser",
      "Snow Globe Maker",
      "Pet Christmas Outfit",
      "Adopt a Polar Pal",
      "Cat Christmas Box",
      "Starlight Gift Box",
      "Xmas Poster",
      "Pet Christmas Tree",
      "City Santa Hat",
      "Stocking Sweetie",
      "Christmas Night",
      "Xmas Front Page Karma",
      "Grinch's Xmas Hijack",
      "Giant Product",
      "Truck Fashion Shoot",
      "Beach AD",
      "Shoal Surround",
      "Mechanical Assembly",
      "Lighting AD",
      "Billboard AD",
      "Product close-up",
      "Parachute Delivery",
      "Dreamlike Cloud",
      "Macaron Machine",
      "Poster AD",
      "Truck AD",
      "Graffiti AD",
      "3D Figurine Factory",
      "The Exclusive First Class",
      "Art Zoom Challenge",
      "I Quit",
      "Hitchcock Dolly Zoom",
      "Smell the Lens",
      "I believe I can fly",
      "Strikout Dance",
      "Pixel World",
      "Mint in Box",
      "Hands up, Hand",
      "Flora Nymph Go",
      "Somber Embrace",
      "Beam me up",
      "Suit Swagger",
    ])
    .register(z.globalRegistry, {
      description: "The effect to apply to the video",
    }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VOutputV4
 */
export const zPixverseV45ImageToVideoFastOutput = z.object({
  video: zFile,
});

/**
 * FastImageToVideoRequestV4
 */
export const zPixverseV45ImageToVideoFastInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        "horizontal_left",
        "horizontal_right",
        "vertical_up",
        "vertical_down",
        "zoom_in",
        "zoom_out",
        "crane_up",
        "quickly_zoom_in",
        "quickly_zoom_out",
        "smooth_zoom_in",
        "camera_rotation",
        "robo_arm",
        "super_dolly_out",
        "whip_pan",
        "hitchcock",
        "left_follow",
        "right_follow",
        "pan_left",
        "pan_right",
        "fix_bg",
      ])
      .register(z.globalRegistry, {
        description: "The type of camera movement to apply to the video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * TransitionOutput
 */
export const zPixverseV45TransitionOutput = z.object({
  video: zFile,
});

/**
 * TransitionRequest
 */
export const zPixverseV45TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt for the transition",
  }),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * ImageToVideoOutput
 */
export const zLtxVideoLoraImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * ImageToVideoInput
 *
 * Request model for image-to-video generation.
 */
export const zLtxVideoLoraImageToVideoInput = z
  .object({
    number_of_steps: z
      .optional(
        z.int().gte(1).lte(50).register(z.globalRegistry, {
          description: "The number of inference steps to use.",
        }),
      )
      .default(30),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "The resolution of the video.",
      }),
    ),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    aspect_ratio: z.optional(
      z.enum(["16:9", "1:1", "9:16", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(25),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using the LLM.",
        }),
      )
      .default(false),
    number_of_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(89),
    image_url: z.union([z.string(), z.string()]),
    loras: z
      .optional(
        z.array(zLoRaWeightType3).register(z.globalRegistry, {
          description: "The LoRA weights to use for generation.",
        }),
      )
      .default([]),
    prompt: z.string().register(z.globalRegistry, {
      description: "The prompt to generate the video from.",
    }),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed to use for generation.",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The negative prompt to use.",
        }),
      )
      .default(
        "blurry, low quality, low resolution, inconsistent motion, jittery, distorted",
      ),
  })
  .register(z.globalRegistry, {
    description: "Request model for image-to-video generation.",
  });

/**
 * ImageToVideoOutput
 */
export const zLtxVideo13bDevImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * ImageToVideoInput
 */
export const zLtxVideo13bDevImageToVideoInput = z.object({
  second_pass_skip_initial_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
      }),
    )
    .default(17),
  first_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the first pass.",
      }),
    )
    .default(30),
  frame_rate: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the video.",
      }),
    )
    .default(30),
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide generation",
  }),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to reverse the video.",
      }),
    )
    .default(false),
  expand_prompt: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to expand the prompt using a language model.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeight).register(z.globalRegistry, {
        description: "LoRA weights to use for generation",
      }),
    )
    .default([]),
  second_pass_num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description: "Number of inference steps during the second pass.",
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(9).lte(161).register(z.globalRegistry, {
        description: "The number of frames in the video.",
      }),
    )
    .default(121),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for generation",
      }),
    )
    .default("worst quality, inconsistent motion, blurry, jittery, distorted"),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  constant_rate_factor: z
    .optional(
      z.int().gte(20).lte(60).register(z.globalRegistry, {
        description:
          "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
      }),
    )
    .default(35),
  first_pass_skip_final_steps: z
    .optional(
      z.int().gte(0).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
      }),
    )
    .default(3),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
});

/**
 * ImageToVideoOutput
 */
export const zLtxVideo13bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zLtxVideo13bDistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(20).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(30),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(161).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(20).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video (480p or 720p).",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    constant_rate_factor: z
      .optional(
        z.int().gte(20).lte(60).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(35),
    first_pass_skip_final_steps: z
      .optional(
        z.int().gte(0).lte(20).register(z.globalRegistry, {
          description:
            "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
        }),
      )
      .default(1),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * ElementsOutput
 */
export const zKlingVideoV16ProElementsOutput = z.object({
  video: zFile,
});

/**
 * MultiImageToVideoRequest
 */
export const zKlingVideoV16ProElementsInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "List of image URLs to use for video generation. Supports up to 4 images.",
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
});

/**
 * ElementsOutput
 */
export const zKlingVideoV16StandardElementsOutput = z.object({
  video: zFile,
});

/**
 * MultiImageToVideoRequest
 */
export const zKlingVideoV16StandardElementsInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  input_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "List of image URLs to use for video generation. Supports up to 4 images.",
  }),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
});

/**
 * Output
 */
export const zHunyuanPortraitOutput = z.object({
  video: zFile,
});

/**
 * Input
 */
export const zHunyuanPortraitInput = z.object({
  video_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for generation. If None, a random seed will be used.",
    }),
  ),
  use_arcface: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use ArcFace for face recognition.",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoV21ProOutput
 */
export const zKlingVideoV21ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV21ProRequest
 */
export const zKlingVideoV21ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Output
 */
export const zHunyuanAvatarOutput = z.object({
  video: zFile,
});

/**
 * Input
 */
export const zHunyuanAvatarInput = z.object({
  text: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Text prompt describing the scene.",
      }),
    )
    .default("A cat is singing."),
  image_url: z.union([z.string(), z.string()]),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
      }),
    )
    .default(true),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(30).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  num_frames: z
    .optional(
      z.int().gte(129).lte(401).register(z.globalRegistry, {
        description:
          "Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.",
      }),
    )
    .default(129),
});

/**
 * SeedanceVideoOutput
 */
export const zBytedanceSeedanceV1LiteImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceImageToVideoInput
 */
export const zBytedanceSeedanceV1LiteImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "auto"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * ImageToVideoHailuo02Output
 */
export const zMinimaxHailuo02ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProImageToVideoHailuo02Input
 */
export const zMinimaxHailuo02ProImageToVideoInput = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * AvatarMultiAudioResponse
 */
export const zAiAvatarMultiOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * AvatarMultiAudioPersonRequest
 */
export const zAiAvatarMultiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  first_audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  second_audio_url: z.optional(z.union([z.string(), z.string()])),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(81),
  use_only_first_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use only the first audio file.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(181),
});

/**
 * AvatarMultiTextResponse
 */
export const zAiAvatarMultiTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * AvatarMultiTextRequest
 */
export const zAiAvatarMultiTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  second_text_input: z.string().register(z.globalRegistry, {
    description: "The text input to guide video generation.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  first_text_input: z.string().register(z.globalRegistry, {
    description: "The text input to guide video generation.",
  }),
  image_url: z.union([z.string(), z.string()]),
  voice2: z.optional(
    z
      .enum([
        "Aria",
        "Roger",
        "Sarah",
        "Laura",
        "Charlie",
        "George",
        "Callum",
        "River",
        "Liam",
        "Charlotte",
        "Alice",
        "Matilda",
        "Will",
        "Jessica",
        "Eric",
        "Chris",
        "Brian",
        "Daniel",
        "Lily",
        "Bill",
      ])
      .register(z.globalRegistry, {
        description: "The second person's voice to use for speech generation",
      }),
  ),
  voice1: z.optional(
    z
      .enum([
        "Aria",
        "Roger",
        "Sarah",
        "Laura",
        "Charlie",
        "George",
        "Callum",
        "River",
        "Liam",
        "Charlotte",
        "Alice",
        "Matilda",
        "Will",
        "Jessica",
        "Eric",
        "Chris",
        "Brian",
        "Daniel",
        "Lily",
        "Bill",
      ])
      .register(z.globalRegistry, {
        description: "The first person's voice to use for speech generation",
      }),
  ),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(81),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(191),
});

/**
 * AvatarSingleAudioResponse
 */
export const zAiAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * AvatarSingleAudioRequest
 */
export const zAiAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  audio_url: z.union([z.string(), z.string()]),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(145),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(42),
});

/**
 * AvatarSingleTextResponse
 */
export const zAiAvatarSingleTextOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * AvatarSingleTextRequest
 */
export const zAiAvatarSingleTextInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the video to generate. Must be either 480p or 720p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular", "high"]).register(z.globalRegistry, {
      description: "The acceleration level to use for generation.",
    }),
  ),
  text_input: z.string().register(z.globalRegistry, {
    description: "The text input to guide video generation.",
  }),
  image_url: z.union([z.string(), z.string()]),
  voice: z
    .enum([
      "Aria",
      "Roger",
      "Sarah",
      "Laura",
      "Charlie",
      "George",
      "Callum",
      "River",
      "Liam",
      "Charlotte",
      "Alice",
      "Matilda",
      "Will",
      "Jessica",
      "Eric",
      "Chris",
      "Brian",
      "Daniel",
      "Lily",
      "Bill",
    ])
    .register(z.globalRegistry, {
      description: "The voice to use for speech generation",
    }),
  seed: z
    .optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    )
    .default(42),
  num_frames: z
    .optional(
      z.int().gte(41).lte(241).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(136),
});

/**
 * Q1ReferenceToVideoOutput
 */
export const zViduQ1ReferenceToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q1ReferenceToVideoRequest
 */
export const zViduQ1ReferenceToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 1500 characters",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the output video",
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to add background music to the generated video",
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for generation",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
});

/**
 * Veo3ImageToVideoOutput
 */
export const zVeo3FastImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo3ImageToVideoInput
 */
export const zVeo3FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing how the image should be animated",
  }),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoOutput
 */
export const zLtxv13B098DistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * DistilledImageToVideoInput
 *
 * Distilled model input
 */
export const zLtxv13B098DistilledImageToVideoInput = z
  .object({
    second_pass_skip_initial_steps: z
      .optional(
        z.int().gte(1).lte(11).register(z.globalRegistry, {
          description:
            "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
        }),
      )
      .default(5),
    first_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the first pass.",
        }),
      )
      .default(8),
    frame_rate: z
      .optional(
        z.int().gte(1).lte(60).register(z.globalRegistry, {
          description: "The frame rate of the video.",
        }),
      )
      .default(24),
    reverse_video: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to reverse the video.",
        }),
      )
      .default(false),
    prompt: z.string().register(z.globalRegistry, {
      description: "Text prompt to guide generation",
    }),
    expand_prompt: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to expand the prompt using a language model.",
        }),
      )
      .default(false),
    temporal_adain_factor: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
        }),
      )
      .default(0.5),
    loras: z
      .optional(
        z.array(zLoRaWeight).register(z.globalRegistry, {
          description: "LoRA weights to use for generation",
        }),
      )
      .default([]),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable the safety checker.",
        }),
      )
      .default(true),
    num_frames: z
      .optional(
        z.int().gte(9).lte(1441).register(z.globalRegistry, {
          description: "The number of frames in the video.",
        }),
      )
      .default(121),
    second_pass_num_inference_steps: z
      .optional(
        z.int().gte(2).lte(12).register(z.globalRegistry, {
          description: "Number of inference steps during the second pass.",
        }),
      )
      .default(8),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Negative prompt for generation",
        }),
      )
      .default(
        "worst quality, inconsistent motion, blurry, jittery, distorted",
      ),
    enable_detail_pass: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
        }),
      )
      .default(false),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description: "Resolution of the generated video.",
      }),
    ),
    aspect_ratio: z.optional(
      z.enum(["9:16", "1:1", "16:9", "auto"]).register(z.globalRegistry, {
        description: "The aspect ratio of the video.",
      }),
    ),
    tone_map_compression_ratio: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
        }),
      )
      .default(0),
    image_url: z.union([z.string(), z.string()]),
    constant_rate_factor: z
      .optional(
        z.int().gte(0).lte(51).register(z.globalRegistry, {
          description:
            "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
        }),
      )
      .default(29),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for generation",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Distilled model input",
  });

/**
 * OmniHumanOutput
 */
export const zBytedanceOmnihumanOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of audio input/video output as used for billing.",
  }),
  video: zFile,
});

/**
 * OmniHumanInput
 */
export const zBytedanceOmnihumanInput = z.object({
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * WanI2VResponse
 */
export const zWanV22A14bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanI2VRequest
 */
export const zWanV22A14bImageToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(1),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
      }),
    )
    .default(3.5),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * WanSmallI2VResponse
 */
export const zWanV225bImageToVideoOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanSmallI2VRequest
 */
export const zWanV225bImageToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(0),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(24),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (580p or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(40),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

/**
 * WanTurboI2VResponse
 */
export const zWanV22A14bImageToVideoTurboOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanTurboI2VRequest
 */
export const zWanV22A14bImageToVideoTurboInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
});

/**
 * Veo3ImageToVideoOutput
 */
export const zVeo3ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo3ImageToVideoInput
 */
export const zVeo3ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing how the image should be animated",
  }),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoHailuo02FastOutput
 */
export const zMinimaxHailuo02FastImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * FastImageToVideoHailuo02Input
 */
export const zMinimaxHailuo02FastImageToVideoInput = z.object({
  prompt: z.string().max(2000),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * WanI2VResponse
 */
export const zWanV22A14bImageToVideoLoraOutput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The text prompt used for video generation.",
      }),
    )
    .default(""),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanLoRAI2VRequest
 */
export const zWanV22A14bImageToVideoLoraInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  num_interpolated_frames: z
    .optional(
      z.int().gte(0).lte(4).register(z.globalRegistry, {
        description:
          "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
      }),
    )
    .default(1),
  reverse_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If true, the video will be reversed.",
      }),
    )
    .default(false),
  loras: z
    .optional(
      z.array(zLoRaWeightType2).register(z.globalRegistry, {
        description: "LoRA weights to be used in the inference.",
      }),
    )
    .default([]),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(17).lte(161).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 17 to 161 (inclusive).",
      }),
    )
    .default(81),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  guidance_scale_2: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
      }),
    )
    .default(4),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  interpolator_model: z.optional(
    z.enum(["none", "film", "rife"]).register(z.globalRegistry, {
      description:
        "The model to use for frame interpolation. If None, no interpolation is applied.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  adjust_fps_for_interpolation: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
      }),
    )
    .default(true),
});

export const zBytedanceVideoStylizeOutput = z.unknown();

/**
 * StylizeInput
 */
export const zBytedanceVideoStylizeInput = z.object({
  style: z.string().max(100).register(z.globalRegistry, {
    description:
      "The style for your character in the video. Please use a short description.",
  }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * MareyOutput
 */
export const zMareyI2vOutput = z.object({
  video: zFileType2,
});

/**
 * MareyInputI2V
 */
export const zMareyI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate a video from",
  }),
  duration: z.optional(
    z.enum(["5s", "10s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  dimensions: z.optional(
    z
      .enum(["1920x1080", "1080x1920", "1152x1152", "1536x1152", "1152x1536"])
      .register(z.globalRegistry, {
        description:
          "The dimensions of the generated video in width x height format.",
      }),
  ),
  guidance_scale: z.optional(z.union([z.number(), z.unknown()])),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  negative_prompt: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * I2VOutputV5
 */
export const zPixverseV5ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequestV5
 */
export const zPixverseV5ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * EffectOutput
 */
export const zPixverseV5EffectsOutput = z.object({
  video: zFile,
});

/**
 * EffectInput
 */
export const zPixverseV5EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  effect: z
    .enum([
      "Kiss Me AI",
      "Kiss",
      "Muscle Surge",
      "Warmth of Jesus",
      "Anything, Robot",
      "The Tiger Touch",
      "Hug",
      "Holy Wings",
      "Microwave",
      "Zombie Mode",
      "Squid Game",
      "Baby Face",
      "Black Myth: Wukong",
      "Long Hair Magic",
      "Leggy Run",
      "Fin-tastic Mermaid",
      "Punch Face",
      "Creepy Devil Smile",
      "Thunder God",
      "Eye Zoom Challenge",
      "Who's Arrested?",
      "Baby Arrived",
      "Werewolf Rage",
      "Bald Swipe",
      "BOOM DROP",
      "Huge Cutie",
      "Liquid Metal",
      "Sharksnap!",
      "Dust Me Away",
      "3D Figurine Factor",
      "Bikini Up",
      "My Girlfriends",
      "My Boyfriends",
      "Subject 3 Fever",
      "Earth Zoom",
      "Pole Dance",
      "Vroom Dance",
      "GhostFace Terror",
      "Dragon Evoker",
      "Skeletal Bae",
      "Summoning succubus",
      "Halloween Voodoo Doll",
      "3D Naked-Eye AD",
      "Package Explosion",
      "Dishes Served",
      "Ocean ad",
      "Supermarket AD",
      "Tree doll",
      "Come Feel My Abs",
      "The Bicep Flex",
      "London Elite Vibe",
      "Flora Nymph Gown",
      "Christmas Costume",
      "It's Snowy",
      "Reindeer Cruiser",
      "Snow Globe Maker",
      "Pet Christmas Outfit",
      "Adopt a Polar Pal",
      "Cat Christmas Box",
      "Starlight Gift Box",
      "Xmas Poster",
      "Pet Christmas Tree",
      "City Santa Hat",
      "Stocking Sweetie",
      "Christmas Night",
      "Xmas Front Page Karma",
      "Grinch's Xmas Hijack",
      "Giant Product",
      "Truck Fashion Shoot",
      "Beach AD",
      "Shoal Surround",
      "Mechanical Assembly",
      "Lighting AD",
      "Billboard AD",
      "Product close-up",
      "Parachute Delivery",
      "Dreamlike Cloud",
      "Macaron Machine",
      "Poster AD",
      "Truck AD",
      "Graffiti AD",
      "3D Figurine Factory",
      "The Exclusive First Class",
      "Art Zoom Challenge",
      "I Quit",
      "Hitchcock Dolly Zoom",
      "Smell the Lens",
      "I believe I can fly",
      "Strikout Dance",
      "Pixel World",
      "Mint in Box",
      "Hands up, Hand",
      "Flora Nymph Go",
      "Somber Embrace",
      "Beam me up",
      "Suit Swagger",
    ])
    .register(z.globalRegistry, {
      description: "The effect to apply to the video",
    }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * TransitionOutputV5
 */
export const zPixverseV5TransitionOutput = z.object({
  video: zFile,
});

/**
 * TransitionRequest
 */
export const zPixverseV5TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt for the transition",
  }),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * ProcessOutput
 */
export const zDecartLucy5bImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProcessRequest
 */
export const zDecartLucy5bImageToVideoInput = z.object({
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * A coordinate point with x and y values for motion tracking
 */
export const zTrackPoint = z
  .object({
    x: z.number().register(z.globalRegistry, {
      description: "X coordinate",
    }),
    y: z.number().register(z.globalRegistry, {
      description: "Y coordinate",
    }),
  })
  .register(z.globalRegistry, {
    description: "A coordinate point with x and y values for motion tracking",
  });

/**
 * WanATIResponse
 */
export const zWanAtiOutput = z.object({
  video: zFile,
});

/**
 * WanATIRequest
 */
export const zWanAtiInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, 720p).",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  track: z.array(z.array(zTrackPoint)).register(z.globalRegistry, {
    description:
      "Motion tracks to guide video generation. Each track is a sequence of points defining a motion trajectory. Multiple tracks can control different elements or objects in the video. Expected format: array of tracks, where each track is an array of points with 'x' and 'y' coordinates (up to 121 points per track). Points will be automatically padded to 121 if fewer are provided. Coordinates should be within the image dimensions.",
  }),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
});

/**
 * SeedanceReferenceToVideoOutput
 */
export const zBytedanceSeedanceV1LiteReferenceToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceReferenceToVideoInput
 */
export const zBytedanceSeedanceV1LiteReferenceToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "auto"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  reference_image_urls: z.array(z.string()).register(z.globalRegistry, {
    description: "Reference images to generate the video with.",
  }),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * Lucy14BOutput
 */
export const zLucy14bImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Lucy14BImageToVideoInput
 */
export const zLucy14bImageToVideoInput = z.object({
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "\n            If set to true, the function will wait for the image to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the image directly\n            in the response without going through the CDN.\n        ",
      }),
    )
    .default(true),
  aspect_ratio: z.optional(
    z.enum(["9:16", "16:9"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video.",
    }),
  ),
  prompt: z.string().max(1500).register(z.globalRegistry, {
    description: "Text description of the desired video content",
  }),
  resolution: z.optional(
    z.enum(["720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * AIAvatarOutput
 */
export const zKlingVideoV1ProAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of the output video in seconds.",
  }),
  video: zFile,
});

/**
 * AIAvatarInput
 */
export const zKlingVideoV1ProAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to use for the video generation.",
      }),
    )
    .default("."),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * AIAvatarOutput
 */
export const zKlingVideoV1StandardAiAvatarOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of the output video in seconds.",
  }),
  video: zFile,
});

/**
 * AIAvatarInput
 */
export const zKlingVideoV1StandardAiAvatarInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to use for the video generation.",
      }),
    )
    .default("."),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * FabricOneOutput
 */
export const zFabric10Output = z.object({
  video: zFileType2,
});

/**
 * FabricOneLipsyncInput
 */
export const zFabric10Input = z.object({
  resolution: z.enum(["720p", "480p"]).register(z.globalRegistry, {
    description: "Resolution",
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * OmniHumanv15Output
 */
export const zBytedanceOmnihumanV15Output = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of audio input/video output as used for billing.",
  }),
  video: zFile,
});

/**
 * OmniHumanv15Input
 */
export const zBytedanceOmnihumanV15Input = z.object({
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Generate a video at a faster rate with a slight quality trade-off.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description:
        "The resolution of the generated video. Defaults to 1080p. 720p generation is faster and higher in quality. 1080p generation is limited to 30s audio and 720p generation is limited to 60s audio.",
    }),
  ),
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The text prompt used to guide the video generation.",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * FabricOneOutput
 */
export const zFabric10FastOutput = z.object({
  video: zFileType2,
});

/**
 * FabricOneLipsyncInput
 */
export const zFabric10FastInput = z.object({
  resolution: z.enum(["720p", "480p"]).register(z.globalRegistry, {
    description: "Resolution",
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * OviI2VResponse
 */
export const zOviImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: z.optional(z.union([zFileType2, z.unknown()])),
});

/**
 * OviI2VRequest
 */
export const zOviImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(30),
  audio_negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for audio generation.",
      }),
    )
    .default("robotic, muffled, echo, distorted"),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default("jitter, bad hands, blur, distortion"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoOutput
 */
export const zSora2ImageToVideoOutput = z.object({
  spritesheet: z.optional(zImageFile),
  thumbnail: z.optional(zImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: "The ID of the generated video",
  }),
  video: zVideoFileType2,
});

/**
 * ImageToVideoInput
 */
export const zSora2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: "Duration of the generated video in seconds",
      }),
  ),
  resolution: z.optional(
    z.enum(["auto", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "9:16", "16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  model: z.optional(
    z
      .enum(["sora-2", "sora-2-2025-12-08", "sora-2-2025-10-06"])
      .register(z.globalRegistry, {
        description:
          "The model to use for the generation. When the default model is selected, the latest snapshot of the model will be used - otherwise, select a specific snapshot of the model.",
      }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
      }),
    )
    .default(true),
});

/**
 * ProImageToVideoOutput
 */
export const zSora2ImageToVideoProOutput = z.object({
  spritesheet: z.optional(zImageFile),
  thumbnail: z.optional(zImageFile),
  video_id: z.string().register(z.globalRegistry, {
    description: "The ID of the generated video",
  }),
  video: zVideoFileType2,
});

/**
 * ProImageToVideoInput
 */
export const zSora2ImageToVideoProInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z
      .union([z.literal(4), z.literal(8), z.literal(12)])
      .register(z.globalRegistry, {
        description: "Duration of the generated video in seconds",
      }),
  ),
  resolution: z.optional(
    z.enum(["auto", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "9:16", "16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  delete_video: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Veo31ImageToVideoOutput
 */
export const zVeo31ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31ImageToVideoInput
 */
export const zVeo31ImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description:
        "The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * Veo31ImageToVideoOutput
 */
export const zVeo31FastImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31ImageToVideoInput
 */
export const zVeo31FastImageToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description:
        "The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * Veo31ReferenceToVideoOutput
 */
export const zVeo31ReferenceToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31ReferenceToVideoInput
 */
export const zVeo31ReferenceToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of the reference images to use for consistent subject appearance",
  }),
});

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zVeo31FirstLastFrameToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zVeo31FirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  first_frame_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  last_frame_url: z.union([z.string(), z.string()]),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * Veo31FirstLastFrameToVideoOutput
 */
export const zVeo31FastFirstLastFrameToVideoOutput = z.object({
  video: zFile,
});

/**
 * Veo31FirstLastFrameToVideoInput
 */
export const zVeo31FastFirstLastFrameToVideoInput = z.object({
  prompt: z.string().max(20000).register(z.globalRegistry, {
    description: "The text prompt describing the video you want to generate",
  }),
  duration: z.optional(
    z.enum(["4s", "6s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  auto_fix: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them.",
      }),
    )
    .default(false),
  resolution: z.optional(
    z.enum(["720p", "1080p", "4k"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  first_frame_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  last_frame_url: z.union([z.string(), z.string()]),
  negative_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A negative prompt to guide the video generation.",
    }),
  ),
});

/**
 * ImageToVideoV25StandardOutput
 */
export const zKlingVideoV25TurboStandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV25StandardRequest
 */
export const zKlingVideoV25TurboStandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Q2ImageToVideoOutput
 */
export const zViduQ2ImageToVideoProOutput = z.object({
  video: zFile,
});

/**
 * Q2ImageToVideoRequest
 */
export const zViduQ2ImageToVideoProInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 3000 characters",
  }),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to add background music to the video (only for 4-second videos)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * Q2ImageToVideoOutput
 */
export const zViduQ2ImageToVideoTurboOutput = z.object({
  video: zFile,
});

/**
 * Q2ImageToVideoRequest
 */
export const zViduQ2ImageToVideoTurboInput = z.object({
  prompt: z.string().max(3000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 3000 characters",
  }),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  duration: z.optional(
    z
      .union([
        z.literal(2),
        z.literal(3),
        z.literal(4),
        z.literal(5),
        z.literal(6),
        z.literal(7),
        z.literal(8),
      ])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to add background music to the video (only for 4-second videos)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * SeedanceFastI2VVideoOutput
 */
export const zBytedanceSeedanceV1ProFastImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProFastImageToVideoInput
 */
export const zBytedanceSeedanceV1ProFastImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "auto"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * ProFastImageToVideoHailuo23Output
 */
export const zMinimaxHailuo23FastProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProFastImageToVideoHailuo23Input
 */
export const zMinimaxHailuo23FastProImageToVideoInput = z.object({
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation",
  }),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * StandardImageToVideoHailuo23Output
 */
export const zMinimaxHailuo23StandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * StandardImageToVideoHailuo23Input
 */
export const zMinimaxHailuo23StandardImageToVideoInput = z.object({
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation",
  }),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description: "The duration of the video in seconds.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * StandardFastImageToVideoHailuo23Output
 */
export const zMinimaxHailuo23FastStandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * StandardFastImageToVideoHailuo23Input
 */
export const zMinimaxHailuo23FastStandardImageToVideoInput = z.object({
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation",
  }),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description: "The duration of the video in seconds.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * LongCatImageToVideoResponse
 */
export const zLongcatVideoDistilledImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCatImageToVideoRequest
 */
export const zLongcatVideoDistilledImageToVideo480pInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to guide the video generation.",
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(15),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
});

/**
 * LongCatImageToVideoResponse
 */
export const zLongcatVideoDistilledImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCat720PImageToVideoRequest
 */
export const zLongcatVideoDistilledImageToVideo720pInput = z.object({
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to guide the video generation.",
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(30),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use for refinement.",
      }),
    )
    .default(12),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(16).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(12),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
});

/**
 * LongCatImageToVideoResponse
 */
export const zLongcatVideoImageToVideo480pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCatCFGImageToVideoRequest
 */
export const zLongcatVideoImageToVideo480pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to guide the video generation.",
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "The acceleration level to use for the video generation.",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(15),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to use for the video generation.",
      }),
    )
    .default(
      "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
});

/**
 * LongCatImageToVideoResponse
 */
export const zLongcatVideoImageToVideo720pOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * LongCat720PCFGImageToVideoRequest
 */
export const zLongcatVideoImageToVideo720pInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to guide the video generation.",
      }),
    )
    .default(
      "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k",
    ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "The acceleration level to use for the video generation.",
    }),
  ),
  fps: z
    .optional(
      z.int().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frame rate of the generated video.",
      }),
    )
    .default(30),
  num_refine_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use for refinement.",
      }),
    )
    .default(40),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(4),
  num_frames: z
    .optional(
      z.int().gte(17).lte(961).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(162),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable safety checker.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to use for the video generation.",
      }),
    )
    .default(
      "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator.",
    }),
  ),
});

/**
 * KeyframeTransition
 *
 * Configuration for a transition between two keyframes
 */
export const zKeyframeTransition = z
  .object({
    prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Specific prompt for this transition. Overrides the global prompt if provided.",
      }),
    ),
    duration: z
      .optional(
        z.int().gte(1).lte(25).register(z.globalRegistry, {
          description: "Duration of this transition in seconds",
        }),
      )
      .default(5),
  })
  .register(z.globalRegistry, {
    description: "Configuration for a transition between two keyframes",
  });

/**
 * Pika22KeyframesToVideoOutput
 *
 * Output model for Pika 2.2 keyframes-to-video generation
 */
export const zPikaV22PikaframesOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output model for Pika 2.2 keyframes-to-video generation",
  });

/**
 * Pika22KeyframesToVideoRequest
 */
export const zPikaV22PikaframesInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Default prompt for all transitions. Individual transition prompts override this.",
    }),
  ),
  resolution: z.optional(
    z.enum(["720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  transitions: z.optional(
    z.array(zKeyframeTransition).register(z.globalRegistry, {
      description:
        "Configuration for each transition. Length must be len(image_urls) - 1. Total duration of all transitions must not exceed 25 seconds. If not provided, uses default 5-second transitions with the global prompt.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed for the random number generator",
    }),
  ),
  image_urls: z.array(z.string()).register(z.globalRegistry, {
    description:
      "URLs of keyframe images (2-5 images) to create transitions between",
  }),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "A negative prompt to guide the model",
      }),
    )
    .default(""),
});

/**
 * SwapOutput
 */
export const zPixverseSwapOutput = z.object({
  video: zFile,
});

/**
 * SwapRequest
 */
export const zPixverseSwapInput = z.object({
  original_sound_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to keep the original audio",
      }),
    )
    .default(true),
  video_url: z.union([z.string(), z.string()]),
  keyframe_id: z
    .optional(
      z.int().gte(1).register(z.globalRegistry, {
        description: "The keyframe ID (from 1 to the last frame position)",
      }),
    )
    .default(1),
  mode: z.optional(
    z.enum(["person", "object", "background"]).register(z.globalRegistry, {
      description: "The swap mode to use",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p"]).register(z.globalRegistry, {
      description: "The output resolution (1080p not supported)",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * LynxOutput
 */
export const zLynxOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation",
  }),
  video: zVideoFileType2,
});

/**
 * LynxInput
 */
export const zLynxInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide video generation",
  }),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p)",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the generated video (16:9, 9:16, or 1:1)",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(75).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(50),
  guidance_scale_2: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.",
      }),
    )
    .default(2),
  strength: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "Reference image scale. Controls the influence of the reference image on the generated video.",
      }),
    )
    .default(1),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(30).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 30.",
      }),
    )
    .default(16),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(20).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(81).register(z.globalRegistry, {
        description:
          "Number of frames in the generated video. Must be between 9 to 100.",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Negative prompt to guide what should not appear in the generated video",
      }),
    )
    .default(
      "Bright tones, overexposed, blurred background, static, subtitles, style, works, paintings, images, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
    ),
  ip_scale: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description:
          "Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.",
      }),
    )
    .default(1),
});

/**
 * LTXVImageToVideoResponse
 */
export const zLtx2ImageToVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LTXVImageToVideoRequest
 */
export const zLtx2ImageToVideoInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The prompt to generate the video from",
  }),
  resolution: z.optional(
    z.enum(["1080p", "1440p", "2160p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the generated video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .union([z.literal(6), z.literal(8), z.literal(10)])
      .register(z.globalRegistry, {
        description: "The duration of the generated video in seconds",
      }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: "The frames per second of the generated video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * LTXVImageToVideoResponse
 */
export const zLtx2ImageToVideoFastOutput = z.object({
  video: zVideoFileType2,
});

/**
 * LTXVImageToVideoFastRequest
 */
export const zLtx2ImageToVideoFastInput = z.object({
  prompt: z.string().min(1).max(5000).register(z.globalRegistry, {
    description: "The prompt to generate the video from",
  }),
  resolution: z.optional(
    z.enum(["1080p", "1440p", "2160p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the generated video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .union([
        z.literal(6),
        z.literal(8),
        z.literal(10),
        z.literal(12),
        z.literal(14),
        z.literal(16),
        z.literal(18),
        z.literal(20),
      ])
      .register(z.globalRegistry, {
        description:
          "The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.",
      }),
  ),
  fps: z.optional(
    z.union([z.literal(25), z.literal(50)]).register(z.globalRegistry, {
      description: "The frames per second of the generated video",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zKlingVideoO1ReferenceToVideoOutput = z.object({
  video: zFile,
});

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zKlingVideoO1ReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    aspect_ratio: z.optional(
      z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video frame.",
      }),
    ),
    duration: z.optional(
      z
        .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
        .register(z.globalRegistry, {
          description: "Video duration in seconds.",
        }),
    ),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      "Input for start-frame video generation with optional reference images and elements.",
  });

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zKlingVideoO1ImageToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output for Kling Omni Video generation.",
  });

/**
 * OmniVideoImageToVideoInput
 */
export const zKlingVideoO1ImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      "Use @Image1 to reference the start frame, @Image2 to reference the end frame.",
  }),
  duration: z.optional(
    z
      .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
      .register(z.globalRegistry, {
        description: "Video duration in seconds.",
      }),
  ),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * I2VOutputV5_5
 */
export const zPixverseV55ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequestV5_5
 */
export const zPixverseV55ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  generate_multi_clip_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable multi-clip generation with dynamic camera changes",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * TransitionOutputV5_5
 */
export const zPixverseV55TransitionOutput = z.object({
  video: zFile,
});

/**
 * TransitionRequestV5_5
 */
export const zPixverseV55TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt for the transition",
  }),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. Longer durations cost more. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * EffectOutput
 */
export const zPixverseV55EffectsOutput = z.object({
  video: zFile,
});

/**
 * EffectInputV5_5
 */
export const zPixverseV55EffectsInput = z.object({
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  effect: z
    .enum([
      "Kiss Me AI",
      "Kiss",
      "Muscle Surge",
      "Warmth of Jesus",
      "Anything, Robot",
      "The Tiger Touch",
      "Hug",
      "Holy Wings",
      "Microwave",
      "Zombie Mode",
      "Squid Game",
      "Baby Face",
      "Black Myth: Wukong",
      "Long Hair Magic",
      "Leggy Run",
      "Fin-tastic Mermaid",
      "Punch Face",
      "Creepy Devil Smile",
      "Thunder God",
      "Eye Zoom Challenge",
      "Who's Arrested?",
      "Baby Arrived",
      "Werewolf Rage",
      "Bald Swipe",
      "BOOM DROP",
      "Huge Cutie",
      "Liquid Metal",
      "Sharksnap!",
      "Dust Me Away",
      "3D Figurine Factor",
      "Bikini Up",
      "My Girlfriends",
      "My Boyfriends",
      "Subject 3 Fever",
      "Earth Zoom",
      "Pole Dance",
      "Vroom Dance",
      "GhostFace Terror",
      "Dragon Evoker",
      "Skeletal Bae",
      "Summoning succubus",
      "Halloween Voodoo Doll",
      "3D Naked-Eye AD",
      "Package Explosion",
      "Dishes Served",
      "Ocean ad",
      "Supermarket AD",
      "Tree doll",
      "Come Feel My Abs",
      "The Bicep Flex",
      "London Elite Vibe",
      "Flora Nymph Gown",
      "Christmas Costume",
      "It's Snowy",
      "Reindeer Cruiser",
      "Snow Globe Maker",
      "Pet Christmas Outfit",
      "Adopt a Polar Pal",
      "Cat Christmas Box",
      "Starlight Gift Box",
      "Xmas Poster",
      "Pet Christmas Tree",
      "City Santa Hat",
      "Stocking Sweetie",
      "Christmas Night",
      "Xmas Front Page Karma",
      "Grinch's Xmas Hijack",
      "Giant Product",
      "Truck Fashion Shoot",
      "Beach AD",
      "Shoal Surround",
      "Mechanical Assembly",
      "Lighting AD",
      "Billboard AD",
      "Product close-up",
      "Parachute Delivery",
      "Dreamlike Cloud",
      "Macaron Machine",
      "Poster AD",
      "Truck AD",
      "Graffiti AD",
      "3D Figurine Factory",
      "The Exclusive First Class",
      "Art Zoom Challenge",
      "I Quit",
      "Hitchcock Dolly Zoom",
      "Smell the Lens",
      "I believe I can fly",
      "Strikout Dance",
      "Pixel World",
      "Mint in Box",
      "Hands up, Hand",
      "Flora Nymph Go",
      "Somber Embrace",
      "Beam me up",
      "Suit Swagger",
    ])
    .register(z.globalRegistry, {
      description: "The effect to apply to the video",
    }),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoV26ProOutput
 */
export const zKlingVideoV26ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV26ProRequest
 */
export const zKlingVideoV26ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  voice_ids: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of voice IDs to use for voice control. Reference voices in the prompt using <<<voice_1>>>, <<<voice_2>>>. Maximum 2 voices allowed. When provided and referenced in prompt, enables voice control billing.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to generate native audio for the video. Supports Chinese and English voice output. Other languages are automatically translated to English. For English speech, use lowercase letters; for acronyms or proper nouns, use uppercase.",
      }),
    )
    .default(true),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
});

/**
 * AIAvatarOutput
 */
export const zKlingVideoAiAvatarV2StandardOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of the output video in seconds.",
  }),
  video: zFile,
});

/**
 * AIAvatarInput
 */
export const zKlingVideoAiAvatarV2StandardInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to use for the video generation.",
      }),
    )
    .default("."),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * AIAvatarOutput
 */
export const zKlingVideoAiAvatarV2ProOutput = z.object({
  duration: z.number().register(z.globalRegistry, {
    description: "Duration of the output video in seconds.",
  }),
  video: zFile,
});

/**
 * AIAvatarInput
 */
export const zKlingVideoAiAvatarV2ProInput = z.object({
  prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The prompt to use for the video generation.",
      }),
    )
    .default("."),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * AuroraOutputModel
 */
export const zCreatifyAuroraOutput = z.object({
  video: zVideoFileType2,
});

/**
 * AuroraInputModel
 */
export const zCreatifyAuroraInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description: "A text prompt to guide the video generation process.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: "Guidance scale to be used for text prompt adherence.",
      }),
    )
    .default(1),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(5).register(z.globalRegistry, {
        description: "Guidance scale to be used for audio adherence.",
      }),
    )
    .default(2),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * OmniVideoImageToVideoOutput
 *
 * Output for Kling Omni Video generation.
 */
export const zKlingVideoO1StandardImageToVideoOutput = z
  .object({
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output for Kling Omni Video generation.",
  });

/**
 * OmniVideoImageToVideoInput
 */
export const zKlingVideoO1StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500).register(z.globalRegistry, {
    description:
      "Use @Image1 to reference the start frame, @Image2 to reference the end frame.",
  }),
  duration: z.optional(
    z
      .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
      .register(z.globalRegistry, {
        description: "Video duration in seconds.",
      }),
  ),
  start_image_url: z.union([z.string(), z.string()]),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * OmniVideoReferenceToVideoOutput
 */
export const zKlingVideoO1StandardReferenceToVideoOutput = z.object({
  video: zFile,
});

/**
 * OmniVideoReferenceToVideoInput
 *
 * Input for start-frame video generation with optional reference images and elements.
 */
export const zKlingVideoO1StandardReferenceToVideoInput = z
  .object({
    prompt: z.string().max(2500).register(z.globalRegistry, {
      description:
        "Take @Element1, @Element2 to reference elements and @Image1, @Image2 to reference images in order.",
    }),
    aspect_ratio: z.optional(
      z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
        description: "The aspect ratio of the generated video frame.",
      }),
    ),
    duration: z.optional(
      z
        .enum(["3", "4", "5", "6", "7", "8", "9", "10"])
        .register(z.globalRegistry, {
          description: "Video duration in seconds.",
        }),
    ),
    elements: z.optional(
      z.array(zOmniVideoElementInput).register(z.globalRegistry, {
        description:
          "Elements (characters/objects) to include in the video. Reference in prompt as @Element1, @Element2, etc. Maximum 7 total (elements + reference images + start image).",
      }),
    ),
    image_urls: z.optional(
      z.array(z.string()).register(z.globalRegistry, {
        description:
          "Additional reference images for style/appearance. Reference in prompt as @Image1, @Image2, etc. Maximum 7 total (elements + reference images + start image).",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description:
      "Input for start-frame video generation with optional reference images and elements.",
  });

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zV26ImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output for image-to-video generation",
  });

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zV26ImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt describing the desired video motion. Max 800 characters.",
    }),
    duration: z.optional(
      z.enum(["5", "10", "15"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.",
      }),
    ),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "Video resolution. Valid values: 720p, 1080p",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.",
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Negative prompt to describe content to avoid. Max 500 characters.",
        }),
      )
      .default(""),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable prompt rewriting using LLM.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for Wan 2.6 image-to-video generation",
  });

/**
 * HunyuanVideo15Response
 */
export const zHunyuanVideoV15ImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * HunyuanVideo15I2VRequest
 */
export const zHunyuanVideoV15ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the video.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p"]).register(z.globalRegistry, {
      description: "The resolution of the video.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable prompt expansion to enhance the input prompt.",
      }),
    )
    .default(true),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for reproducibility.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(1).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps.",
      }),
    )
    .default(28),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to guide what not to generate.",
      }),
    )
    .default(""),
  num_frames: z
    .optional(
      z.int().gte(1).lte(121).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
});

/**
 * LiveAvatarResponse
 */
export const zLiveAvatarOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zVideoFileType2,
});

/**
 * LiveAvatarRequest
 */
export const zLiveAvatarInput = z.object({
  frames_per_clip: z
    .optional(
      z.int().gte(16).lte(80).register(z.globalRegistry, {
        description:
          "Number of frames per clip. Must be a multiple of 4. Higher values = smoother but slower generation.",
      }),
    )
    .default(48),
  prompt: z.string().register(z.globalRegistry, {
    description:
      "A text prompt describing the scene and character. Helps guide the video generation style and context.",
  }),
  acceleration: z.optional(
    z.enum(["none", "light", "regular", "high"]).register(z.globalRegistry, {
      description: "Acceleration level for faster video decoding ",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  num_clips: z
    .optional(
      z.int().gte(1).lte(100).register(z.globalRegistry, {
        description:
          "Number of video clips to generate. Each clip is approximately 3 seconds. Set higher for longer videos.",
      }),
    )
    .default(10),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "Random seed for reproducible generation.",
    }),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values follow the prompt more closely.",
      }),
    )
    .default(0),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable safety checker for content moderation.",
      }),
    )
    .default(true),
});

/**
 * SeedanceProv15I2VVideoOutput
 */
export const zBytedanceSeedanceV15ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProv15ImageToVideoInput
 */
export const zBytedanceSeedanceV15ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video",
      }),
    )
    .default(true),
  duration: z.optional(
    z
      .enum(["4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * KandinskyI2VResponse
 */
export const zKandinsky5ProImageToVideoOutput = z.object({
  video: z.optional(zFile),
});

/**
 * KandinskyI2VRequest
 */
export const zKandinsky5ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  resolution: z.optional(
    z.enum(["512P", "1024P"]).register(z.globalRegistry, {
      description: "Video resolution: 512p or 1024p.",
    }),
  ),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description: "Acceleration level for faster generation.",
    }),
  ),
  duration: z.optional(
    z.enum(["5s"]).register(z.globalRegistry, {
      description: "Video duration.",
    }),
  ),
  num_inference_steps: z.optional(z.int().gte(1).lte(40)).default(28),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)
 */
export const zTrajectoryPoint = z
  .record(z.string(), z.unknown())
  .register(z.globalRegistry, {
    description:
      "Schema referenced but not defined by fal.ai (missing from source OpenAPI spec)",
  });

/**
 * WanMoveOutput
 */
export const zWanMoveOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Random seed used for generation.",
  }),
  video: zVideoFileType2,
});

/**
 * WANMoveInput
 */
export const zWanMoveInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "Text prompt to guide the video generation.",
  }),
  trajectories: z.array(z.array(zTrajectoryPoint)).register(z.globalRegistry, {
    description:
      "A list of trajectories. Each trajectory list means the movement of one object.",
  }),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(50).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(40),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to guide the video generation.",
      }),
    )
    .default(
      "JPEG",
    ),
});

/**
 * LTX2ImageToVideoOutput
 */
export const zLtx219bImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2ImageToVideoInput
 */
export const zLtx219bImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  interpolation_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2ImageToVideoOutput
 */
export const zLtx219bImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRAImageToVideoInput
 */
export const zLtx219bImageToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  interpolation_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
});

/**
 * LTX2ImageToVideoOutput
 */
export const zLtx219bDistilledImageToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2DistilledImageToVideoInput
 */
export const zLtx219bDistilledImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  interpolation_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image.",
    }),
  ),
});

/**
 * LTX2ImageToVideoOutput
 */
export const zLtx219bDistilledImageToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRADistilledImageToVideoInput
 */
export const zLtx219bDistilledImageToVideoLoraInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  generate_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to generate audio for the video.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.union([z.string(), z.string()]),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  interpolation_direction: z.optional(
    z.enum(["forward", "backward"]).register(z.globalRegistry, {
      description:
        "The direction to interpolate the image sequence in. 'Forward' goes from the start image to the end image, 'Backward' goes from the end image to the start image.",
    }),
  ),
});

/**
 * ImageToVideoOutput
 *
 * Output for image-to-video generation
 */
export const zV26ImageToVideoFlashOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output for image-to-video generation",
  });

/**
 * ImageToVideoInput
 *
 * Input for Wan 2.6 image-to-video generation
 */
export const zV26ImageToVideoFlashInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt describing the desired video motion. Max 800 characters.",
    }),
    duration: z.optional(
      z.enum(["5", "10", "15"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. Choose between 5, 10 or 15 seconds.",
      }),
    ),
    resolution: z.optional(
      z.enum(["720p", "1080p"]).register(z.globalRegistry, {
        description: "Video resolution. Valid values: 720p, 1080p",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
    image_url: z.union([z.string(), z.string()]),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    multi_shots: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "When true, enables intelligent multi-shot segmentation. Only active when enable_prompt_expansion is True. Set to false for single-shot generation.",
        }),
      )
      .default(false),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description:
            "Negative prompt to describe content to avoid. Max 500 characters.",
        }),
      )
      .default(""),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable prompt rewriting using LLM.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for Wan 2.6 image-to-video generation",
  });

/**
 * Q2ProReferenceToVideoOutput
 */
export const zViduQ2ReferenceToVideoProOutput = z.object({
  video: zFile,
});

/**
 * Q2ProReferenceToVideoRequest
 */
export const zViduQ2ReferenceToVideoProInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 2000 characters",
  }),
  aspect_ratio: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Aspect ratio of the output video (e.g., auto, 16:9, 9:16, 1:1, or any W:H)",
      }),
    )
    .default("16:9"),
  resolution: z.optional(
    z.enum(["540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  duration: z
    .optional(
      z.int().gte(1).lte(8).register(z.globalRegistry, {
        description:
          "Duration of the video in seconds (0 for automatic duration)",
      }),
    )
    .default(4),
  reference_video_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs of the reference videos for video editing or motion reference. Supports up to 2 videos.",
    }),
  ),
  bgm: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to add background music to the generated video",
      }),
    )
    .default(false),
  reference_image_urls: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "URLs of the reference images for subject appearance. If videos are provided, up to 4 images are allowed; otherwise up to 7 images.",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  movement_amplitude: z.optional(
    z.enum(["auto", "small", "medium", "large"]).register(z.globalRegistry, {
      description: "The movement amplitude of objects in the frame",
    }),
  ),
});

/**
 * I2VOutputV5_5
 */
export const zPixverseV56ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequestV5_6
 */
export const zPixverseV56ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * TransitionOutputV5_5
 */
export const zPixverseV56TransitionOutput = z.object({
  video: zFile,
});

/**
 * TransitionRequestV5_6
 */
export const zPixverseV56TransitionInput = z.object({
  first_image_url: z.union([z.string(), z.string()]),
  aspect_ratio: z.optional(
    z.enum(["16:9", "4:3", "1:1", "3:4", "9:16"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video",
    }),
  ),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  thinking_type: z.optional(
    z.enum(["enabled", "disabled", "auto"]).register(z.globalRegistry, {
      description:
        "Prompt optimization mode: 'enabled' to optimize, 'disabled' to turn off, 'auto' for model decision",
    }),
  ),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt for the transition",
  }),
  duration: z.optional(
    z.enum(["5", "8", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 1080p videos are limited to 5 or 8 seconds",
    }),
  ),
  generate_audio_switch: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable audio generation (BGM, SFX, dialogue)",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * XAIImageToVideoOutput
 */
export const zGrokImagineVideoImageToVideoOutput = z.object({
  video: zVideoFileType2,
});

/**
 * XAIImageToVideoInput
 */
export const zGrokImagineVideoImageToVideoInput = z.object({
  prompt: z.string().max(4096).register(z.globalRegistry, {
    description: "Text description of desired changes or motion in the video.",
  }),
  duration: z
    .optional(
      z.int().gte(1).lte(15).register(z.globalRegistry, {
        description: "Video duration in seconds.",
      }),
    )
    .default(6),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the output video.",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["auto", "16:9", "4:3", "3:2", "1:1", "2:3", "3:4", "9:16"])
      .register(z.globalRegistry, {
        description: "Aspect ratio of the generated video.",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * Q3ImageToVideoOutput
 */
export const zViduQ3ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * Q3ImageToVideoRequest
 */
export const zViduQ3ImageToVideoInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation, max 2000 characters",
  }),
  duration: z
    .optional(
      z.int().gte(1).lte(16).register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
    )
    .default(5),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "Output video resolution",
    }),
  ),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use direct audio-video generation. When true, outputs video with sound.",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * WanI2VResponse
 */
export const zWanI2vOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for generation.",
  }),
  video: zFile,
});

/**
 * WanI2VRequest
 */
export const zWanI2vInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt to guide video generation.",
  }),
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift parameter for video generation.",
      }),
    )
    .default(5),
  acceleration: z.optional(
    z.enum(["none", "regular"]).register(z.globalRegistry, {
      description:
        "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
    }),
  ),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 5 to 24.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
      }),
    )
    .default(81),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(
      "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards",
    ),
  resolution: z.optional(
    z.enum(["480p", "720p"]).register(z.globalRegistry, {
      description:
        "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
    }),
  ),
  aspect_ratio: z.optional(
    z.enum(["auto", "16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description:
        "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
    }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(false),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  guide_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(5),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
});

/**
 * ImageToVideoV2MasterOutput
 */
export const zKlingVideoV2MasterImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV2MasterRequest
 */
export const zKlingVideoV2MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VOutputV4
 */
export const zPixverseV45ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequestV4
 */
export const zPixverseV45ImageToVideoInput = z.object({
  prompt: z.string(),
  resolution: z.optional(
    z.enum(["360p", "540p", "720p", "1080p"]).register(z.globalRegistry, {
      description: "The resolution of the generated video",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "8"]).register(z.globalRegistry, {
      description:
        "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
    }),
  ),
  style: z.optional(
    z
      .enum(["anime", "3d_animation", "clay", "comic", "cyberpunk"])
      .register(z.globalRegistry, {
        description: "The style of the generated video",
      }),
  ),
  camera_movement: z.optional(
    z
      .enum([
        "horizontal_left",
        "horizontal_right",
        "vertical_up",
        "vertical_down",
        "zoom_in",
        "zoom_out",
        "crane_up",
        "quickly_zoom_in",
        "quickly_zoom_out",
        "smooth_zoom_in",
        "camera_rotation",
        "robo_arm",
        "super_dolly_out",
        "whip_pan",
        "hitchcock",
        "left_follow",
        "right_follow",
        "pan_left",
        "pan_right",
        "fix_bg",
      ])
      .register(z.globalRegistry, {
        description: "The type of camera movement to apply to the video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
    }),
  ),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt to be used for the generation",
      }),
    )
    .default(""),
});

/**
 * ImageToVideoV21StandardOutput
 */
export const zKlingVideoV21StandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV21StandardRequest
 */
export const zKlingVideoV21StandardImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoV21MasterOutput
 */
export const zKlingVideoV21MasterImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV21MasterRequest
 */
export const zKlingVideoV21MasterImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * SeedanceProI2VVideoOutput
 */
export const zBytedanceSeedanceV1ProImageToVideoOutput = z.object({
  seed: z.int().register(z.globalRegistry, {
    description: "Seed used for generation",
  }),
  video: zFile,
});

/**
 * SeedanceProImageToVideoInput
 */
export const zBytedanceSeedanceV1ProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used to generate the video",
  }),
  resolution: z.optional(
    z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
      description:
        "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["21:9", "16:9", "4:3", "1:1", "3:4", "9:16", "auto"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  duration: z.optional(
    z
      .enum(["2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"])
      .register(z.globalRegistry, {
        description: "Duration of the video in seconds",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "If set to true, the safety checker will be enabled.",
      }),
    )
    .default(true),
  camera_fixed: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to fix the camera position",
      }),
    )
    .default(false),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed to control video generation. Use -1 for random.",
    }),
  ),
});

/**
 * ImageToVideoHailuo02Output
 */
export const zMinimaxHailuo02StandardImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * StandardImageToVideoHailuo02Input
 */
export const zMinimaxHailuo02StandardImageToVideoInput = z.object({
  prompt: z.string().max(2000),
  duration: z.optional(
    z.enum(["6", "10"]).register(z.globalRegistry, {
      description:
        "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
    }),
  ),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  resolution: z.optional(
    z.enum(["512P", "768P"]).register(z.globalRegistry, {
      description: "The resolution of the generated video.",
    }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoV25ProOutput
 */
export const zKlingVideoV25TurboProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoV25ProRequest
 */
export const zKlingVideoV25TurboProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * VideoOutput
 *
 * Base output for video generation
 */
export const zWan25PreviewImageToVideoOutput = z
  .object({
    actual_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description: "The actual prompt used if prompt rewriting was enabled",
      }),
    ),
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation",
    }),
    video: zVideoFileType2,
  })
  .register(z.globalRegistry, {
    description: "Base output for video generation",
  });

/**
 * ImageToVideoInput
 *
 * Input for image-to-video generation
 */
export const zWan25PreviewImageToVideoInput = z
  .object({
    prompt: z.string().min(1).register(z.globalRegistry, {
      description:
        "The text prompt describing the desired video motion. Max 800 characters.",
    }),
    duration: z.optional(
      z.enum(["5", "10"]).register(z.globalRegistry, {
        description:
          "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
      }),
    ),
    resolution: z.optional(
      z.enum(["480p", "720p", "1080p"]).register(z.globalRegistry, {
        description: "Video resolution. Valid values: 480p, 720p, 1080p",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description:
          "Random seed for reproducibility. If None, a random seed is chosen.",
      }),
    ),
    enable_prompt_expansion: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable prompt rewriting using LLM.",
        }),
      )
      .default(true),
    negative_prompt: z.optional(
      z.string().register(z.globalRegistry, {
        description:
          "Negative prompt to describe content to avoid. Max 500 characters.",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "If set to true, the safety checker will be enabled.",
        }),
      )
      .default(true),
  })
  .register(z.globalRegistry, {
    description: "Input for image-to-video generation",
  });

/**
 * ProImageToVideoHailuo23Output
 */
export const zMinimaxHailuo23ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProImageToVideoHailuo23Input
 */
export const zMinimaxHailuo23ProImageToVideoInput = z.object({
  prompt: z.string().min(1).max(2000).register(z.globalRegistry, {
    description: "Text prompt for video generation",
  }),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * VideoOutput
 */
export const zMinimaxVideo01ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoRequest
 */
export const zMinimaxVideo01ImageToVideoInput = z.object({
  prompt: z.string().max(2000),
  prompt_optimizer: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the model's prompt optimizer",
      }),
    )
    .default(true),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * I2VOutput
 */
export const zKlingVideoV16ProImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ProImageToVideoRequest
 */
export const zKlingVideoV16ProImageToVideoInput = z.object({
  prompt: z.string().max(2500),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "The aspect ratio of the generated video frame",
    }),
  ),
  duration: z.optional(
    z.enum(["5", "10"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  tail_image_url: z.optional(z.union([z.string(), z.string()])),
  image_url: z.union([z.string(), z.string()]),
  negative_prompt: z
    .optional(z.string().max(2500))
    .default("blur, distort, and low quality"),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
      }),
    )
    .default(0.5),
});

/**
 * WanProI2VResponse
 */
export const zWanProImageToVideoOutput = z.object({
  video: zFileType2,
});

/**
 * WanProI2VRequest
 */
export const zWanProImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video",
  }),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker",
      }),
    )
    .default(true),
  seed: z.optional(z.union([z.int(), z.unknown()])),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * ImageToVideoOutput
 */
export const zVeo2ImageToVideoOutput = z.object({
  video: zFile,
});

/**
 * ImageToVideoInput
 */
export const zVeo2ImageToVideoInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt describing how the image should be animated",
  }),
  duration: z.optional(
    z.enum(["5s", "6s", "7s", "8s"]).register(z.globalRegistry, {
      description: "The duration of the generated video in seconds",
    }),
  ),
  aspect_ratio: z.optional(
    z
      .enum(["auto", "auto_prefer_portrait", "16:9", "9:16"])
      .register(z.globalRegistry, {
        description: "The aspect ratio of the generated video",
      }),
  ),
  image_url: z.union([z.string(), z.string()]),
});

/**
 * WanEffectsOutput
 */
export const zWanEffectsOutput = z.object({
  seed: z.int(),
  video: zFile,
});

/**
 * BaseInput
 */
export const zWanEffectsInput = z.object({
  effect_type: z.optional(
    z
      .enum([
        "squish",
        "muscle",
        "inflate",
        "crush",
        "rotate",
        "gun-shooting",
        "deflate",
        "cakeify",
        "hulk",
        "baby",
        "bride",
        "classy",
        "puppy",
        "snow-white",
        "disney-princess",
        "mona-lisa",
        "painting",
        "pirate-captain",
        "princess",
        "jungle",
        "samurai",
        "vip",
        "warrior",
        "zen",
        "assassin",
        "timelapse",
        "tsunami",
        "fire",
        "zoom-call",
        "doom-fps",
        "fus-ro-dah",
        "hug-jesus",
        "robot-face-reveal",
        "super-saiyan",
        "jumpscare",
        "laughing",
        "cartoon-jaw-drop",
        "crying",
        "kissing",
        "angry-face",
        "selfie-younger-self",
        "animeify",
        "blast",
      ])
      .register(z.globalRegistry, {
        description: "The type of effect to apply to the video.",
      }),
  ),
  aspect_ratio: z.optional(
    z.enum(["16:9", "9:16", "1:1"]).register(z.globalRegistry, {
      description: "Aspect ratio of the output video.",
    }),
  ),
  subject: z.string().register(z.globalRegistry, {
    description:
      "The subject to insert into the predefined prompt template for the selected effect.",
  }),
  lora_scale: z
    .optional(
      z.number().gte(0.1).lte(2).register(z.globalRegistry, {
        description:
          "The scale of the LoRA weight. Used to adjust effect intensity.",
      }),
    )
    .default(1),
  image_url: z.union([z.string(), z.string()]),
  turbo_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use turbo mode. If True, the video will be generated faster but with lower quality.",
      }),
    )
    .default(false),
  frames_per_second: z
    .optional(
      z.int().gte(5).lte(24).register(z.globalRegistry, {
        description: "Frames per second of the generated video.",
      }),
    )
    .default(16),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(30),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
  num_frames: z
    .optional(
      z.int().gte(81).lte(100).register(z.globalRegistry, {
        description: "Number of frames to generate.",
      }),
    )
    .default(81),
});

/**
 * EchoMimicResponse
 */
export const zEchomimicV3Output = z.object({
  video: zFile,
});

/**
 * EchoMimicRequest
 */
export const zEchomimicV3Input = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to use for the video generation.",
  }),
  audio_url: z.union([z.string(), z.string()]),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(4.5),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "The audio guidance scale to use for the video generation.",
      }),
    )
    .default(2.5),
  num_frames_per_generation: z
    .optional(
      z.int().gte(49).lte(161).register(z.globalRegistry, {
        description: "The number of frames to generate at once.",
      }),
    )
    .default(121),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to use for the video generation.",
      }),
    )
    .default(""),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for the video generation.",
    }),
  ),
});

/**
 * StableAvatarResponse
 */
export const zStableAvatarOutput = z.object({
  video: zFile,
});

/**
 * StableAvatarRequest
 */
export const zStableAvatarInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to use for the video generation.",
  }),
  aspect_ratio: z.optional(
    z.enum(["16:9", "1:1", "9:16", "auto"]).register(z.globalRegistry, {
      description:
        "The aspect ratio of the video to generate. If 'auto', the aspect ratio will be determined by the reference image.",
    }),
  ),
  perturbation: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The amount of perturbation to use for the video generation. 0.0 means no perturbation, 1.0 means full perturbation.",
      }),
    )
    .default(0.1),
  image_url: z.union([z.string(), z.string()]),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use for the video generation.",
      }),
    )
    .default(5),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The seed to use for the video generation.",
    }),
  ),
  num_inference_steps: z
    .optional(
      z.int().gte(10).lte(50).register(z.globalRegistry, {
        description:
          "The number of inference steps to use for the video generation.",
      }),
    )
    .default(50),
  audio_url: z.union([z.string(), z.string()]),
  audio_guidance_scale: z
    .optional(
      z.number().gte(0).lte(10).register(z.globalRegistry, {
        description:
          "The audio guidance scale to use for the video generation.",
      }),
    )
    .default(4),
});

/**
 * WanS2VResponse
 */
export const zWanV2214bSpeechToVideoOutput = z.object({
  video: zFile,
});

/**
 * WanS2VRequest
 */
export const zWanV2214bSpeechToVideoInput = z.object({
  shift: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "Shift value for the video. Must be between 1.0 and 10.0.",
      }),
    )
    .default(5),
  prompt: z.string().register(z.globalRegistry, {
    description: "The text prompt used for video generation.",
  }),
  frames_per_second: z
    .optional(
      z.int().gte(4).lte(60).register(z.globalRegistry, {
        description:
          "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
      }),
    )
    .default(16),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, input data will be checked for safety before processing.",
      }),
    )
    .default(false),
  num_frames: z
    .optional(
      z.int().gte(40).lte(120).register(z.globalRegistry, {
        description:
          "Number of frames to generate. Must be between 40 to 120, (must be multiple of 4).",
      }),
    )
    .default(80),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description:
          "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
      }),
    )
    .default(3.5),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Negative prompt for video generation.",
      }),
    )
    .default(""),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description:
        "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
    }),
  ),
  resolution: z.optional(
    z.enum(["480p", "580p", "720p"]).register(z.globalRegistry, {
      description: "Resolution of the generated video (480p, 580p, or 720p).",
    }),
  ),
  enable_output_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If set to true, output video will be checked for safety after generation.",
      }),
    )
    .default(false),
  image_url: z.union([z.string(), z.string()]),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description:
        "The quality of the output video. Higher quality means better visual quality but larger file size.",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  num_inference_steps: z
    .optional(
      z.int().gte(2).lte(40).register(z.globalRegistry, {
        description:
          "Number of inference steps for sampling. Higher values give better quality but take longer.",
      }),
    )
    .default(27),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducibility. If None, a random seed is chosen.",
    }),
  ),
});

/**
 * AvatarsAppOutput
 */
export const zAvatarsAudioToVideoOutputType2 = z.object({
  video: zFileType2,
});

/**
 * InferenceResult
 */
export const zAvatarsAudioToVideoOutput = z.object({
  moderation_transcription: z.optional(z.union([z.string(), z.unknown()])),
  moderation_error: z.optional(z.union([z.string(), z.unknown()])),
  moderation_flagged: z.optional(z.boolean()).default(false),
  video: z.optional(z.union([zVideo, z.unknown()])),
});

/**
 * Audio2VideoInput
 */
export const zAvatarsAudioToVideoInputType2 = z.object({
  audio_url: z.union([z.string(), z.string()]),
  avatar_id: z
    .enum([
      "emily_vertical_primary",
      "emily_vertical_secondary",
      "marcus_vertical_primary",
      "marcus_vertical_secondary",
      "mira_vertical_primary",
      "mira_vertical_secondary",
      "jasmine_vertical_primary",
      "jasmine_vertical_secondary",
      "jasmine_vertical_walking",
      "aisha_vertical_walking",
      "elena_vertical_primary",
      "elena_vertical_secondary",
      "any_male_vertical_primary",
      "any_female_vertical_primary",
      "any_male_vertical_secondary",
      "any_female_vertical_secondary",
      "any_female_vertical_walking",
      "emily_primary",
      "emily_side",
      "marcus_primary",
      "marcus_side",
      "aisha_walking",
      "elena_primary",
      "elena_side",
      "any_male_primary",
      "any_female_primary",
      "any_male_side",
      "any_female_side",
    ])
    .register(z.globalRegistry, {
      description: "The avatar to use for the video",
    }),
});

/**
 * InferenceRequest
 */
export const zAvatarsAudioToVideoInput = z.object({
  avatar: z.enum([
    "Mia outdoor (UGC)",
    "Lara (Masterclass)",
    "Ines (UGC)",
    "Maria (Masterclass)",
    "Emma (UGC)",
    "Sienna (Masterclass)",
    "Elena (UGC)",
    "Jasmine (Masterclass)",
    "Amara (Masterclass)",
    "Ryan podcast (UGC)",
    "Tyler (Masterclass)",
    "Jayse (Masterclass)",
    "Paul (Masterclass)",
    "Matteo (UGC)",
    "Daniel car (UGC)",
    "Dario (Masterclass)",
    "Viva (Masterclass)",
    "Chen (Masterclass)",
    "Alex (Masterclass)",
    "Vanessa (UGC)",
    "Laurent (UGC)",
    "Noemie car (UGC)",
    "Brandon (UGC)",
    "Byron (Masterclass)",
    "Calista (Masterclass)",
    "Milo (Masterclass)",
    "Fabien (Masterclass)",
    "Rose (UGC)",
  ]),
  remove_background: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Enabling the remove background feature will result in a 50% increase in the price.",
      }),
    )
    .default(false),
  audio_url: z.union([z.string(), z.string()]),
});

/**
 * AudioToVideoResponse
 *
 * Response model for audio-to-video generation (no reference image).
 */
export const zLongcatSingleAvatarAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation.",
    }),
    video: zFile,
  })
  .register(z.globalRegistry, {
    description:
      "Response model for audio-to-video generation (no reference image).",
  });

/**
 * AudioToVideoRequest
 *
 * Request model for audio-to-video generation.
 */
export const zLongcatSingleAvatarAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The prompt to guide the video generation.",
        }),
      )
      .default(
        "A person is talking naturally with natural expressions and movements.",
      ),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description:
          "Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable safety checker.",
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "The audio guidance scale. Higher values may lead to exaggerated mouth movements.",
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.",
        }),
      )
      .default(1),
    audio_url: z.union([z.string(), z.string()]),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: "The number of inference steps to use.",
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator.",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The negative prompt to avoid in the video generation.",
        }),
      )
      .default(
        "Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: "The text guidance scale for classifier-free guidance.",
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: "Request model for audio-to-video generation.",
  });

/**
 * ImageAudioToVideoResponse
 *
 * Response model for image+audio to video generation.
 */
export const zLongcatSingleAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation.",
    }),
    video: zFile,
  })
  .register(z.globalRegistry, {
    description: "Response model for image+audio to video generation.",
  });

/**
 * ImageAudioToVideoRequest
 *
 * Request model for image+audio to video generation.
 */
export const zLongcatSingleAvatarImageAudioToVideoInput = z
  .object({
    prompt: z.string().register(z.globalRegistry, {
      description: "The prompt to guide the video generation.",
    }),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description:
          "Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.",
      }),
    ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable safety checker.",
        }),
      )
      .default(true),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "The audio guidance scale. Higher values may lead to exaggerated mouth movements.",
        }),
      )
      .default(4),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.",
        }),
      )
      .default(1),
    image_url: z.union([z.string(), z.string()]),
    audio_url: z.union([z.string(), z.string()]),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: "The number of inference steps to use.",
        }),
      )
      .default(30),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator.",
      }),
    ),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The negative prompt to avoid in the video generation.",
        }),
      )
      .default(
        "Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: "The text guidance scale for classifier-free guidance.",
        }),
      )
      .default(4),
  })
  .register(z.globalRegistry, {
    description: "Request model for image+audio to video generation.",
  });

/**
 * BoundingBox
 */
export const zBoundingBox = z.object({
  y: z.number().register(z.globalRegistry, {
    description: "Y-coordinate of the top-left corner",
  }),
  x: z.number().register(z.globalRegistry, {
    description: "X-coordinate of the top-left corner",
  }),
  h: z.number().register(z.globalRegistry, {
    description: "Height of the bounding box",
  }),
  w: z.number().register(z.globalRegistry, {
    description: "Width of the bounding box",
  }),
  label: z.string().register(z.globalRegistry, {
    description: "Label of the bounding box",
  }),
});

/**
 * MultiSpeakerImageAudioToVideoResponse
 *
 * Response model for multi-speaker image+audio to video generation.
 */
export const zLongcatMultiAvatarImageAudioToVideoOutput = z
  .object({
    seed: z.int().register(z.globalRegistry, {
      description: "The seed used for generation.",
    }),
    video: zFile,
  })
  .register(z.globalRegistry, {
    description:
      "Response model for multi-speaker image+audio to video generation.",
  });

/**
 * MultiSpeakerImageAudioToVideoRequest
 *
 * Request model for multi-speaker image+audio to video generation.
 */
export const zLongcatMultiAvatarImageAudioToVideoInput = z
  .object({
    prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The prompt to guide the video generation.",
        }),
      )
      .default(
        "Two people are having a conversation with natural expressions and movements.",
      ),
    num_inference_steps: z
      .optional(
        z.int().gte(10).lte(100).register(z.globalRegistry, {
          description: "The number of inference steps to use.",
        }),
      )
      .default(30),
    audio_url_person2: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The URL of the audio file for person 2 (right side).",
        }),
      )
      .default(
        "https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_woman.WAV",
      ),
    enable_safety_checker: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether to enable safety checker.",
        }),
      )
      .default(true),
    bbox_person1: z.optional(zBoundingBox),
    negative_prompt: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The negative prompt to avoid in the video generation.",
        }),
      )
      .default(
        "Close-up, Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards",
      ),
    text_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description: "The text guidance scale for classifier-free guidance.",
        }),
      )
      .default(4),
    resolution: z.optional(
      z.enum(["480p", "720p"]).register(z.globalRegistry, {
        description:
          "Resolution of the generated video (480p or 720p). Billing is per video-second (16 frames): 480p is 1 unit per second and 720p is 4 units per second.",
      }),
    ),
    audio_type: z.optional(
      z.enum(["para", "add"]).register(z.globalRegistry, {
        description:
          "How to combine the two audio tracks. 'para' (parallel) plays both simultaneously, 'add' (sequential) plays person 1 first then person 2.",
      }),
    ),
    image_url: z.union([z.string(), z.string()]),
    audio_url_person1: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "The URL of the audio file for person 1 (left side).",
        }),
      )
      .default(
        "https://raw.githubusercontent.com/meituan-longcat/LongCat-Video/refs/heads/main/assets/avatar/multi/sing_man.WAV",
      ),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "The seed for the random number generator.",
      }),
    ),
    audio_guidance_scale: z
      .optional(
        z.number().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "The audio guidance scale. Higher values may lead to exaggerated mouth movements.",
        }),
      )
      .default(4),
    bbox_person2: z.optional(zBoundingBox),
    num_segments: z
      .optional(
        z.int().gte(1).lte(10).register(z.globalRegistry, {
          description:
            "Number of video segments to generate. Each segment adds ~5 seconds of video. First segment is ~5.8s, additional segments are 5s each.",
        }),
      )
      .default(1),
  })
  .register(z.globalRegistry, {
    description:
      "Request model for multi-speaker image+audio to video generation.",
  });

/**
 * DubbingVideoOutput
 */
export const zElevenlabsDubbingOutput = z.object({
  target_lang: z.string().register(z.globalRegistry, {
    description: "The target language of the dubbed content",
  }),
  video: zFileType2,
});

/**
 * DubbingRequest
 */
export const zElevenlabsDubbingInput = z.object({
  video_url: z.optional(z.union([z.string(), z.unknown()])),
  highest_resolution: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to use the highest resolution for dubbing.",
      }),
    )
    .default(true),
  audio_url: z.optional(z.union([z.string(), z.unknown()])),
  target_lang: z.string().register(z.globalRegistry, {
    description: "Target language code for dubbing (ISO 639-1)",
  }),
  num_speakers: z.optional(z.union([z.int().gte(1).lte(50), z.unknown()])),
  source_lang: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * LTX2AudioToVideoOutput
 */
export const zLtx219bAudioToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2AudioToVideoInput
 */
export const zLtx219bAudioToVideoInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the audio before using it as conditioning.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2AudioToVideoOutput
 */
export const zLtx219bDistilledAudioToVideoOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2DistilledAudioToVideoInput
 */
export const zLtx219bDistilledAudioToVideoInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the audio before using it as conditioning.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2AudioToVideoOutput
 */
export const zLtx219bAudioToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRAAudioToVideoInput
 */
export const zLtx219bAudioToVideoLoraInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  num_inference_steps: z
    .optional(
      z.int().gte(8).lte(50).register(z.globalRegistry, {
        description: "The number of inference steps to use.",
      }),
    )
    .default(40),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  guidance_scale: z
    .optional(
      z.number().gte(1).lte(10).register(z.globalRegistry, {
        description: "The guidance scale to use.",
      }),
    )
    .default(3),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the audio before using it as conditioning.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

/**
 * LTX2AudioToVideoOutput
 */
export const zLtx219bDistilledAudioToVideoLoraOutput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt used for the generation.",
  }),
  seed: z.int().register(z.globalRegistry, {
    description: "The seed used for the random number generator.",
  }),
  video: zVideoFile,
});

/**
 * LTX2LoRADistilledAudioToVideoInput
 */
export const zLtx219bDistilledAudioToVideoLoraInput = z.object({
  match_audio_length: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "When enabled, the number of frames will be calculated based on the audio duration and FPS. When disabled, use the specified num_frames.",
      }),
    )
    .default(true),
  prompt: z.string().register(z.globalRegistry, {
    description: "The prompt to generate the video from.",
  }),
  acceleration: z.optional(
    z.enum(["none", "regular", "high", "full"]).register(z.globalRegistry, {
      description: "The acceleration level to use.",
    }),
  ),
  use_multiscale: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use multi-scale generation. If True, the model will generate the video at a smaller scale first, then use the smaller video to guide the generation of a video at or above your requested size. This results in better coherence and details.",
      }),
    )
    .default(true),
  fps: z
    .optional(
      z.number().gte(1).lte(60).register(z.globalRegistry, {
        description: "The frames per second of the generated video.",
      }),
    )
    .default(25),
  loras: z.array(zLoRaInput).register(z.globalRegistry, {
    description: "The LoRAs to use for the generation.",
  }),
  camera_lora: z.optional(
    z
      .enum([
        "dolly_in",
        "dolly_out",
        "dolly_left",
        "dolly_right",
        "jib_up",
        "jib_down",
        "static",
        "none",
      ])
      .register(z.globalRegistry, {
        description:
          "The camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
  ),
  video_size: z.optional(
    z.union([
      zImageSize,
      z.enum([
        "auto",
        "square_hd",
        "square",
        "portrait_4_3",
        "portrait_16_9",
        "landscape_4_3",
        "landscape_16_9",
      ]),
    ]),
  ),
  enable_safety_checker: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable the safety checker.",
      }),
    )
    .default(true),
  camera_lora_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The scale of the camera LoRA to use. This allows you to control the camera movement of the generated video more accurately than just prompting the model to move the camera.",
      }),
    )
    .default(1),
  image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the image to use for the video generation.",
      }),
    )
    .default(1),
  preprocess_audio: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to preprocess the audio before using it as conditioning.",
      }),
    )
    .default(true),
  negative_prompt: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The negative prompt to generate the video from.",
      }),
    )
    .default(
      "blurry, out of focus, overexposed, underexposed, low contrast, washed out colors, excessive noise, grainy texture, poor lighting, flickering, motion blur, distorted proportions, unnatural skin tones, deformed facial features, asymmetrical face, missing facial features, extra limbs, disfigured hands, wrong hand count, artifacts around text, inconsistent perspective, camera shake, incorrect depth of field, background too sharp, background clutter, distracting reflections, harsh shadows, inconsistent lighting direction, color banding, cartoonish rendering, 3D CGI look, unrealistic materials, uncanny valley effect, incorrect ethnicity, wrong gender, exaggerated expressions, wrong gaze direction, mismatched lip sync, silent or muted audio, distorted voice, robotic voice, echo, background noise, off-sync audio,incorrect dialogue, added dialogue, repetitive speech, jittery movement, awkward pauses, incorrect timing, unnatural transitions, inconsistent framing, tilted camera, flat lighting, inconsistent tone, cinematic oversaturation, stylized filters, or AI artifacts.",
    ),
  video_write_mode: z.optional(
    z.enum(["fast", "balanced", "small"]).register(z.globalRegistry, {
      description: "The write mode of the generated video.",
    }),
  ),
  video_output_type: z.optional(
    z
      .enum(["X264 (.mp4)", "VP9 (.webm)", "PRORES4444 (.mov)", "GIF (.gif)"])
      .register(z.globalRegistry, {
        description: "The output type of the generated video.",
      }),
  ),
  end_image_url: z.optional(z.union([z.string(), z.unknown()])),
  num_frames: z
    .optional(
      z.int().gte(9).lte(481).register(z.globalRegistry, {
        description: "The number of frames to generate.",
      }),
    )
    .default(121),
  image_url: z.optional(z.union([z.string(), z.unknown()])),
  sync_mode: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
      }),
    )
    .default(false),
  video_quality: z.optional(
    z.enum(["low", "medium", "high", "maximum"]).register(z.globalRegistry, {
      description: "The quality of the generated video.",
    }),
  ),
  enable_prompt_expansion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether to enable prompt expansion.",
      }),
    )
    .default(true),
  audio_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Audio conditioning strength. Values below 1.0 will allow the model to change the audio, while a value of exactly 1.0 will use the input audio without modification.",
      }),
    )
    .default(1),
  end_image_strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the end image to use for the video generation.",
      }),
    )
    .default(1),
  audio_url: z.union([z.string(), z.string()]),
  seed: z.optional(z.union([z.int(), z.unknown()])),
});

export const zQueueStatus = z.object({
  status: z.enum(["IN_QUEUE", "IN_PROGRESS", "COMPLETED"]),
  request_id: z.string().register(z.globalRegistry, {
    description: "The request id.",
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The response url.",
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The status url.",
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The cancel url.",
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: "The logs.",
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: "The metrics.",
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The queue position.",
    }),
  ),
});

export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledAudioToVideoLoraData = z.object({
  body: zLtx219bDistilledAudioToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledAudioToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoLoraRequestsByRequestIdResponse =
  zLtx219bDistilledAudioToVideoLoraOutput;

export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bAudioToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bAudioToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bAudioToVideoLoraData = z.object({
  body: zLtx219bAudioToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bAudioToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bAudioToVideoLoraRequestsByRequestIdResponse =
  zLtx219bAudioToVideoLoraOutput;

export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledAudioToVideoData = z.object({
  body: zLtx219bDistilledAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledAudioToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledAudioToVideoRequestsByRequestIdResponse =
  zLtx219bDistilledAudioToVideoOutput;

export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx219bAudioToVideoData = z.object({
  body: zLtx219bAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bAudioToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bAudioToVideoRequestsByRequestIdResponse =
  zLtx219bAudioToVideoOutput;

export const zGetFalAiElevenlabsDubbingRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiElevenlabsDubbingRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiElevenlabsDubbingRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiElevenlabsDubbingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiElevenlabsDubbingData = z.object({
  body: zElevenlabsDubbingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiElevenlabsDubbingResponse = zQueueStatus;

export const zGetFalAiElevenlabsDubbingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiElevenlabsDubbingRequestsByRequestIdResponse =
  zElevenlabsDubbingOutput;

export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatMultiAvatarImageAudioToVideoData = z.object({
  body: zLongcatMultiAvatarImageAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatMultiAvatarImageAudioToVideoResponse =
  zQueueStatus;

export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatMultiAvatarImageAudioToVideoRequestsByRequestIdResponse =
  zLongcatMultiAvatarImageAudioToVideoOutput;

export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatSingleAvatarImageAudioToVideoData = z.object({
  body: zLongcatSingleAvatarImageAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatSingleAvatarImageAudioToVideoResponse =
  zQueueStatus;

export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatSingleAvatarImageAudioToVideoRequestsByRequestIdResponse =
  zLongcatSingleAvatarImageAudioToVideoOutput;

export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatSingleAvatarAudioToVideoData = z.object({
  body: zLongcatSingleAvatarAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatSingleAvatarAudioToVideoResponse = zQueueStatus;

export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatSingleAvatarAudioToVideoRequestsByRequestIdResponse =
  zLongcatSingleAvatarAudioToVideoOutput;

export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutArgilAvatarsAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutArgilAvatarsAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostArgilAvatarsAudioToVideoData = z.object({
  body: zAvatarsAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostArgilAvatarsAudioToVideoResponse = zQueueStatus;

export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetArgilAvatarsAudioToVideoRequestsByRequestIdResponse =
  zAvatarsAudioToVideoOutput;

export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV2214bSpeechToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bSpeechToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV2214bSpeechToVideoData = z.object({
  body: zWanV2214bSpeechToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV2214bSpeechToVideoResponse = zQueueStatus;

export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bSpeechToVideoRequestsByRequestIdResponse =
  zWanV2214bSpeechToVideoOutput;

export const zGetFalAiStableAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiStableAvatarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiStableAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiStableAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiStableAvatarData = z.object({
  body: zStableAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiStableAvatarResponse = zQueueStatus;

export const zGetFalAiStableAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiStableAvatarRequestsByRequestIdResponse =
  zStableAvatarOutput;

export const zGetFalAiEchomimicV3RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiEchomimicV3RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiEchomimicV3RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiEchomimicV3RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiEchomimicV3Data = z.object({
  body: zEchomimicV3Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiEchomimicV3Response = zQueueStatus;

export const zGetFalAiEchomimicV3RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiEchomimicV3RequestsByRequestIdResponse =
  zEchomimicV3Output;

export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedAvatarsAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutVeedAvatarsAudioToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedAvatarsAudioToVideoData = z.object({
  body: zAvatarsAudioToVideoInputType2,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedAvatarsAudioToVideoResponse = zQueueStatus;

export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedAvatarsAudioToVideoRequestsByRequestIdResponse =
  zAvatarsAudioToVideoOutputType2;

export const zGetFalAiWanEffectsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanEffectsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanEffectsData = z.object({
  body: zWanEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanEffectsResponse = zQueueStatus;

export const zGetFalAiWanEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanEffectsRequestsByRequestIdResponse = zWanEffectsOutput;

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo2ImageToVideoData = z.object({
  body: zVeo2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo2ImageToVideoResponse = zQueueStatus;

export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo2ImageToVideoRequestsByRequestIdResponse =
  zVeo2ImageToVideoOutput;

export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanProImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanProImageToVideoData = z.object({
  body: zWanProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanProImageToVideoResponse = zQueueStatus;

export const zGetFalAiWanProImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanProImageToVideoRequestsByRequestIdResponse =
  zWanProImageToVideoOutput;

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16ProImageToVideoData = z.object({
  body: zKlingVideoV16ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV16ProImageToVideoOutput;

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxVideo01ImageToVideoData = z.object({
  body: zMinimaxVideo01ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01ImageToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01ImageToVideoRequestsByRequestIdResponse =
  zMinimaxVideo01ImageToVideoOutput;

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23ProImageToVideoData = z.object({
  body: zMinimaxHailuo23ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23ProImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23ProImageToVideoOutput;

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan25PreviewImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWan25PreviewImageToVideoData = z.object({
  body: zWan25PreviewImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan25PreviewImageToVideoResponse = zQueueStatus;

export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWan25PreviewImageToVideoRequestsByRequestIdResponse =
  zWan25PreviewImageToVideoOutput;

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV25TurboProImageToVideoData = z.object({
  body: zKlingVideoV25TurboProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboProImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV25TurboProImageToVideoOutput;

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo02StandardImageToVideoData = z.object({
  body: zMinimaxHailuo02StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02StandardImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02StandardImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo02StandardImageToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1ProImageToVideoData = z.object({
  body: zBytedanceSeedanceV1ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProImageToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1ProImageToVideoOutput;

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV21MasterImageToVideoData = z.object({
  body: zKlingVideoV21MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21MasterImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21MasterImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV21MasterImageToVideoOutput;

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV21StandardImageToVideoData = z.object({
  body: zKlingVideoV21StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21StandardImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21StandardImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV21StandardImageToVideoOutput;

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV45ImageToVideoData = z.object({
  body: zPixverseV45ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoRequestsByRequestIdResponse =
  zPixverseV45ImageToVideoOutput;

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV2MasterImageToVideoData = z.object({
  body: zKlingVideoV2MasterImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV2MasterImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV2MasterImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV2MasterImageToVideoOutput;

export const zGetFalAiWanI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanI2vRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanI2vData = z.object({
  body: zWanI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanI2vResponse = zQueueStatus;

export const zGetFalAiWanI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vRequestsByRequestIdResponse = zWanI2vOutput;

export const zGetFalAiViduQ3ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ3ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ3ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ3ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ3ImageToVideoData = z.object({
  body: zViduQ3ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ3ImageToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ3ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ3ImageToVideoRequestsByRequestIdResponse =
  zViduQ3ImageToVideoOutput;

export const zGetXaiGrokImagineVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetXaiGrokImagineVideoImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutXaiGrokImagineVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutXaiGrokImagineVideoImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostXaiGrokImagineVideoImageToVideoData = z.object({
  body: zGrokImagineVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostXaiGrokImagineVideoImageToVideoResponse = zQueueStatus;

export const zGetXaiGrokImagineVideoImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetXaiGrokImagineVideoImageToVideoRequestsByRequestIdResponse =
  zGrokImagineVideoImageToVideoOutput;

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV56TransitionData = z.object({
  body: zPixverseV56TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV56TransitionResponse = zQueueStatus;

export const zGetFalAiPixverseV56TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56TransitionRequestsByRequestIdResponse =
  zPixverseV56TransitionOutput;

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV56ImageToVideoData = z.object({
  body: zPixverseV56ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV56ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56ImageToVideoRequestsByRequestIdResponse =
  zPixverseV56ImageToVideoOutput;

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ReferenceToVideoProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiViduQ2ReferenceToVideoProData = z.object({
  body: zViduQ2ReferenceToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ2ReferenceToVideoProResponse = zQueueStatus;

export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ReferenceToVideoProRequestsByRequestIdResponse =
  zViduQ2ReferenceToVideoProOutput;

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoFlashRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostWanV26ImageToVideoFlashData = z.object({
  body: zV26ImageToVideoFlashInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoFlashResponse = zQueueStatus;

export const zGetWanV26ImageToVideoFlashRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoFlashRequestsByRequestIdResponse =
  zV26ImageToVideoFlashOutput;

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledImageToVideoLoraData = z.object({
  body: zLtx219bDistilledImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoLoraRequestsByRequestIdResponse =
  zLtx219bDistilledImageToVideoLoraOutput;

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledImageToVideoData = z.object({
  body: zLtx219bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledImageToVideoRequestsByRequestIdResponse =
  zLtx219bDistilledImageToVideoOutput;

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bImageToVideoLoraData = z.object({
  body: zLtx219bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoLoraRequestsByRequestIdResponse =
  zLtx219bImageToVideoLoraOutput;

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx219bImageToVideoData = z.object({
  body: zLtx219bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bImageToVideoRequestsByRequestIdResponse =
  zLtx219bImageToVideoOutput;

export const zGetFalAiWanMoveRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanMoveRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanMoveRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanMoveData = z.object({
  body: zWanMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanMoveResponse = zQueueStatus;

export const zGetFalAiWanMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanMoveRequestsByRequestIdResponse = zWanMoveOutput;

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKandinsky5ProImageToVideoData = z.object({
  body: zKandinsky5ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKandinsky5ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5ProImageToVideoRequestsByRequestIdResponse =
  zKandinsky5ProImageToVideoOutput;

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV15ProImageToVideoData = z.object({
  body: zBytedanceSeedanceV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV15ProImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV15ProImageToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV15ProImageToVideoOutput;

export const zGetFalAiLiveAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLiveAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLiveAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLiveAvatarData = z.object({
  body: zLiveAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLiveAvatarResponse = zQueueStatus;

export const zGetFalAiLiveAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLiveAvatarRequestsByRequestIdResponse = zLiveAvatarOutput;

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoV15ImageToVideoData = z.object({
  body: zHunyuanVideoV15ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoV15ImageToVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoV15ImageToVideoRequestsByRequestIdResponse =
  zHunyuanVideoV15ImageToVideoOutput;

export const zGetWanV26ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutWanV26ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutWanV26ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostWanV26ImageToVideoData = z.object({
  body: zV26ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostWanV26ImageToVideoResponse = zQueueStatus;

export const zGetWanV26ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetWanV26ImageToVideoRequestsByRequestIdResponse =
  zV26ImageToVideoOutput;

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1StandardReferenceToVideoData = z.object({
  body: zKlingVideoO1StandardReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardReferenceToVideoResponse =
  zQueueStatus;

export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardReferenceToVideoRequestsByRequestIdResponse =
  zKlingVideoO1StandardReferenceToVideoOutput;

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1StandardImageToVideoData = z.object({
  body: zKlingVideoO1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardImageToVideoRequestsByRequestIdResponse =
  zKlingVideoO1StandardImageToVideoOutput;

export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiCreatifyAuroraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiCreatifyAuroraData = z.object({
  body: zCreatifyAuroraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiCreatifyAuroraResponse = zQueueStatus;

export const zGetFalAiCreatifyAuroraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiCreatifyAuroraRequestsByRequestIdResponse =
  zCreatifyAuroraOutput;

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoAiAvatarV2ProData = z.object({
  body: zKlingVideoAiAvatarV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2ProResponse = zQueueStatus;

export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2ProRequestsByRequestIdResponse =
  zKlingVideoAiAvatarV2ProOutput;

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoAiAvatarV2StandardData = z.object({
  body: zKlingVideoAiAvatarV2StandardInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoAiAvatarV2StandardResponse = zQueueStatus;

export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoAiAvatarV2StandardRequestsByRequestIdResponse =
  zKlingVideoAiAvatarV2StandardOutput;

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV26ProImageToVideoData = z.object({
  body: zKlingVideoV26ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV26ProImageToVideoOutput;

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV55EffectsData = z.object({
  body: zPixverseV55EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV55EffectsResponse = zQueueStatus;

export const zGetFalAiPixverseV55EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55EffectsRequestsByRequestIdResponse =
  zPixverseV55EffectsOutput;

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV55TransitionData = z.object({
  body: zPixverseV55TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV55TransitionResponse = zQueueStatus;

export const zGetFalAiPixverseV55TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55TransitionRequestsByRequestIdResponse =
  zPixverseV55TransitionOutput;

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV55ImageToVideoData = z.object({
  body: zPixverseV55ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV55ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55ImageToVideoRequestsByRequestIdResponse =
  zPixverseV55ImageToVideoOutput;

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1ImageToVideoData = z.object({
  body: zKlingVideoO1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ImageToVideoRequestsByRequestIdResponse =
  zKlingVideoO1ImageToVideoOutput;

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1ReferenceToVideoData = z.object({
  body: zKlingVideoO1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1ReferenceToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1ReferenceToVideoRequestsByRequestIdResponse =
  zKlingVideoO1ReferenceToVideoOutput;

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx2ImageToVideoFastData = z.object({
  body: zLtx2ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoFastResponse = zQueueStatus;

export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoFastRequestsByRequestIdResponse =
  zLtx2ImageToVideoFastOutput;

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx2ImageToVideoData = z.object({
  body: zLtx2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx2ImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx2ImageToVideoRequestsByRequestIdResponse =
  zLtx2ImageToVideoOutput;

export const zGetBytedanceLynxRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetBytedanceLynxRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutBytedanceLynxRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutBytedanceLynxRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostBytedanceLynxData = z.object({
  body: zLynxInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBytedanceLynxResponse = zQueueStatus;

export const zGetBytedanceLynxRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBytedanceLynxRequestsByRequestIdResponse = zLynxOutput;

export const zGetFalAiPixverseSwapRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseSwapRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSwapRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseSwapData = z.object({
  body: zPixverseSwapInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseSwapResponse = zQueueStatus;

export const zGetFalAiPixverseSwapRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSwapRequestsByRequestIdResponse =
  zPixverseSwapOutput;

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikaframesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV22PikaframesData = z.object({
  body: zPikaV22PikaframesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikaframesResponse = zQueueStatus;

export const zGetFalAiPikaV22PikaframesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikaframesRequestsByRequestIdResponse =
  zPikaV22PikaframesOutput;

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoImageToVideo720pData = z.object({
  body: zLongcatVideoImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo720pResponse = zQueueStatus;

export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo720pRequestsByRequestIdResponse =
  zLongcatVideoImageToVideo720pOutput;

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoImageToVideo480pData = z.object({
  body: zLongcatVideoImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoImageToVideo480pResponse = zQueueStatus;

export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoImageToVideo480pRequestsByRequestIdResponse =
  zLongcatVideoImageToVideo480pOutput;

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoDistilledImageToVideo720pData = z.object({
  body: zLongcatVideoDistilledImageToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo720pResponse =
  zQueueStatus;

export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo720pRequestsByRequestIdResponse =
  zLongcatVideoDistilledImageToVideo720pOutput;

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoDistilledImageToVideo480pData = z.object({
  body: zLongcatVideoDistilledImageToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledImageToVideo480pResponse =
  zQueueStatus;

export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledImageToVideo480pRequestsByRequestIdResponse =
  zLongcatVideoDistilledImageToVideo480pOutput;

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoData = z.object({
  body: zMinimaxHailuo23FastStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastStandardImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastStandardImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23FastStandardImageToVideoOutput;

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23StandardImageToVideoData = z.object({
  body: zMinimaxHailuo23StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23StandardImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23StandardImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23StandardImageToVideoOutput;

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23FastProImageToVideoData = z.object({
  body: zMinimaxHailuo23FastProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23FastProImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23FastProImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23FastProImageToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoData = z.object({
  body: zBytedanceSeedanceV1ProFastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProFastImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastImageToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1ProFastImageToVideoOutput;

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiViduQ2ImageToVideoTurboData = z.object({
  body: zViduQ2ImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoTurboResponse = zQueueStatus;

export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoTurboRequestsByRequestIdResponse =
  zViduQ2ImageToVideoTurboOutput;

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ2ImageToVideoProData = z.object({
  body: zViduQ2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ2ImageToVideoProResponse = zQueueStatus;

export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2ImageToVideoProRequestsByRequestIdResponse =
  zViduQ2ImageToVideoProOutput;

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV25TurboStandardImageToVideoData = z.object({
  body: zKlingVideoV25TurboStandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboStandardImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboStandardImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV25TurboStandardImageToVideoOutput;

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiVeo31FastFirstLastFrameToVideoData = z.object({
  body: zVeo31FastFirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31FastFirstLastFrameToVideoResponse = zQueueStatus;

export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastFirstLastFrameToVideoRequestsByRequestIdResponse =
  zVeo31FastFirstLastFrameToVideoOutput;

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiVeo31FirstLastFrameToVideoData = z.object({
  body: zVeo31FirstLastFrameToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31FirstLastFrameToVideoResponse = zQueueStatus;

export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FirstLastFrameToVideoRequestsByRequestIdResponse =
  zVeo31FirstLastFrameToVideoOutput;

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31ReferenceToVideoData = z.object({
  body: zVeo31ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31ReferenceToVideoResponse = zQueueStatus;

export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ReferenceToVideoRequestsByRequestIdResponse =
  zVeo31ReferenceToVideoOutput;

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31FastImageToVideoData = z.object({
  body: zVeo31FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31FastImageToVideoResponse = zQueueStatus;

export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastImageToVideoRequestsByRequestIdResponse =
  zVeo31FastImageToVideoOutput;

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31ImageToVideoData = z.object({
  body: zVeo31ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31ImageToVideoResponse = zQueueStatus;

export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ImageToVideoRequestsByRequestIdResponse =
  zVeo31ImageToVideoOutput;

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSora2ImageToVideoProData = z.object({
  body: zSora2ImageToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoProResponse = zQueueStatus;

export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoProRequestsByRequestIdResponse =
  zSora2ImageToVideoProOutput;

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSora2ImageToVideoData = z.object({
  body: zSora2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSora2ImageToVideoResponse = zQueueStatus;

export const zGetFalAiSora2ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSora2ImageToVideoRequestsByRequestIdResponse =
  zSora2ImageToVideoOutput;

export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiOviImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiOviImageToVideoData = z.object({
  body: zOviImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiOviImageToVideoResponse = zQueueStatus;

export const zGetFalAiOviImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiOviImageToVideoRequestsByRequestIdResponse =
  zOviImageToVideoOutput;

export const zGetVeedFabric10FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetVeedFabric10FastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedFabric10FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedFabric10FastData = z.object({
  body: zFabric10FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedFabric10FastResponse = zQueueStatus;

export const zGetVeedFabric10FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedFabric10FastRequestsByRequestIdResponse =
  zFabric10FastOutput;

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanV15RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiBytedanceOmnihumanV15Data = z.object({
  body: zBytedanceOmnihumanV15Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanV15Response = zQueueStatus;

export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanV15RequestsByRequestIdResponse =
  zBytedanceOmnihumanV15Output;

export const zGetVeedFabric10RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetVeedFabric10RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutVeedFabric10RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedFabric10Data = z.object({
  body: zFabric10Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedFabric10Response = zQueueStatus;

export const zGetVeedFabric10RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedFabric10RequestsByRequestIdResponse = zFabric10Output;

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV1StandardAiAvatarData = z.object({
  body: zKlingVideoV1StandardAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardAiAvatarResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardAiAvatarRequestsByRequestIdResponse =
  zKlingVideoV1StandardAiAvatarOutput;

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV1ProAiAvatarData = z.object({
  body: zKlingVideoV1ProAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1ProAiAvatarResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1ProAiAvatarRequestsByRequestIdResponse =
  zKlingVideoV1ProAiAvatarOutput;

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutDecartLucy14bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostDecartLucy14bImageToVideoData = z.object({
  body: zLucy14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostDecartLucy14bImageToVideoResponse = zQueueStatus;

export const zGetDecartLucy14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetDecartLucy14bImageToVideoRequestsByRequestIdResponse =
  zLucy14bImageToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoData = z.object({
  body: zBytedanceSeedanceV1LiteReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteReferenceToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteReferenceToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1LiteReferenceToVideoOutput;

export const zGetFalAiWanAtiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanAtiRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanAtiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanAtiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanAtiData = z.object({
  body: zWanAtiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanAtiResponse = zQueueStatus;

export const zGetFalAiWanAtiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanAtiRequestsByRequestIdResponse = zWanAtiOutput;

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiDecartLucy5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiDecartLucy5bImageToVideoData = z.object({
  body: zDecartLucy5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiDecartLucy5bImageToVideoResponse = zQueueStatus;

export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiDecartLucy5bImageToVideoRequestsByRequestIdResponse =
  zDecartLucy5bImageToVideoOutput;

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV5TransitionData = z.object({
  body: zPixverseV5TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV5TransitionResponse = zQueueStatus;

export const zGetFalAiPixverseV5TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5TransitionRequestsByRequestIdResponse =
  zPixverseV5TransitionOutput;

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV5EffectsData = z.object({
  body: zPixverseV5EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV5EffectsResponse = zQueueStatus;

export const zGetFalAiPixverseV5EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5EffectsRequestsByRequestIdResponse =
  zPixverseV5EffectsOutput;

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV5ImageToVideoData = z.object({
  body: zPixverseV5ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV5ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5ImageToVideoRequestsByRequestIdResponse =
  zPixverseV5ImageToVideoOutput;

export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostMoonvalleyMareyI2vData = z.object({
  body: zMareyI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMoonvalleyMareyI2vResponse = zQueueStatus;

export const zGetMoonvalleyMareyI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyI2vRequestsByRequestIdResponse =
  zMareyI2vOutput;

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceVideoStylizeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiBytedanceVideoStylizeData = z.object({
  body: zBytedanceVideoStylizeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceVideoStylizeResponse = zQueueStatus;

export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceVideoStylizeRequestsByRequestIdResponse =
  zBytedanceVideoStylizeOutput;

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bImageToVideoLoraData = z.object({
  body: zWanV22A14bImageToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoLoraResponse = zQueueStatus;

export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoLoraRequestsByRequestIdResponse =
  zWanV22A14bImageToVideoLoraOutput;

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo02FastImageToVideoData = z.object({
  body: zMinimaxHailuo02FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02FastImageToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02FastImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo02FastImageToVideoOutput;

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo3ImageToVideoData = z.object({
  body: zVeo3ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo3ImageToVideoResponse = zQueueStatus;

export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo3ImageToVideoRequestsByRequestIdResponse =
  zVeo3ImageToVideoOutput;

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bImageToVideoTurboData = z.object({
  body: zWanV22A14bImageToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoTurboResponse = zQueueStatus;

export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoTurboRequestsByRequestIdResponse =
  zWanV22A14bImageToVideoTurboOutput;

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanV225bImageToVideoData = z.object({
  body: zWanV225bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV225bImageToVideoResponse = zQueueStatus;

export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bImageToVideoRequestsByRequestIdResponse =
  zWanV225bImageToVideoOutput;

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bImageToVideoData = z.object({
  body: zWanV22A14bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bImageToVideoResponse = zQueueStatus;

export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bImageToVideoRequestsByRequestIdResponse =
  zWanV22A14bImageToVideoOutput;

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceOmnihumanRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiBytedanceOmnihumanData = z.object({
  body: zBytedanceOmnihumanInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceOmnihumanResponse = zQueueStatus;

export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceOmnihumanRequestsByRequestIdResponse =
  zBytedanceOmnihumanOutput;

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxv13B098DistilledImageToVideoData = z.object({
  body: zLtxv13B098DistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledImageToVideoRequestsByRequestIdResponse =
  zLtxv13B098DistilledImageToVideoOutput;

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3FastImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo3FastImageToVideoData = z.object({
  body: zVeo3FastImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo3FastImageToVideoResponse = zQueueStatus;

export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo3FastImageToVideoRequestsByRequestIdResponse =
  zVeo3FastImageToVideoOutput;

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ReferenceToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiViduQ1ReferenceToVideoData = z.object({
  body: zViduQ1ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ1ReferenceToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ReferenceToVideoRequestsByRequestIdResponse =
  zViduQ1ReferenceToVideoOutput;

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarSingleTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAiAvatarSingleTextData = z.object({
  body: zAiAvatarSingleTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAiAvatarSingleTextResponse = zQueueStatus;

export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarSingleTextRequestsByRequestIdResponse =
  zAiAvatarSingleTextOutput;

export const zGetFalAiAiAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiAiAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAiAvatarData = z.object({
  body: zAiAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAiAvatarResponse = zQueueStatus;

export const zGetFalAiAiAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarRequestsByRequestIdResponse = zAiAvatarOutput;

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAiAvatarMultiTextData = z.object({
  body: zAiAvatarMultiTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiTextResponse = zQueueStatus;

export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiTextRequestsByRequestIdResponse =
  zAiAvatarMultiTextOutput;

export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiAiAvatarMultiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAiAvatarMultiData = z.object({
  body: zAiAvatarMultiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAiAvatarMultiResponse = zQueueStatus;

export const zGetFalAiAiAvatarMultiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAiAvatarMultiRequestsByRequestIdResponse =
  zAiAvatarMultiOutput;

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo02ProImageToVideoData = z.object({
  body: zMinimaxHailuo02ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02ProImageToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo02ProImageToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoData = z.object({
  body: zBytedanceSeedanceV1LiteImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteImageToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1LiteImageToVideoOutput;

export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanAvatarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanAvatarData = z.object({
  body: zHunyuanAvatarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanAvatarResponse = zQueueStatus;

export const zGetFalAiHunyuanAvatarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanAvatarRequestsByRequestIdResponse =
  zHunyuanAvatarOutput;

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV21ProImageToVideoData = z.object({
  body: zKlingVideoV21ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21ProImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV21ProImageToVideoOutput;

export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanPortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanPortraitData = z.object({
  body: zHunyuanPortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanPortraitResponse = zQueueStatus;

export const zGetFalAiHunyuanPortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanPortraitRequestsByRequestIdResponse =
  zHunyuanPortraitOutput;

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16StandardElementsData = z.object({
  body: zKlingVideoV16StandardElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardElementsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardElementsRequestsByRequestIdResponse =
  zKlingVideoV16StandardElementsOutput;

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProElementsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16ProElementsData = z.object({
  body: zKlingVideoV16ProElementsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProElementsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProElementsRequestsByRequestIdResponse =
  zKlingVideoV16ProElementsOutput;

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideo13bDistilledImageToVideoData = z.object({
  body: zLtxVideo13bDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledImageToVideoRequestsByRequestIdResponse =
  zLtxVideo13bDistilledImageToVideoOutput;

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideo13bDevImageToVideoData = z.object({
  body: zLtxVideo13bDevImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevImageToVideoRequestsByRequestIdResponse =
  zLtxVideo13bDevImageToVideoOutput;

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideoLoraImageToVideoData = z.object({
  body: zLtxVideoLoraImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraImageToVideoRequestsByRequestIdResponse =
  zLtxVideoLoraImageToVideoOutput;

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV45TransitionData = z.object({
  body: zPixverseV45TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TransitionResponse = zQueueStatus;

export const zGetFalAiPixverseV45TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TransitionRequestsByRequestIdResponse =
  zPixverseV45TransitionOutput;

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV45ImageToVideoFastData = z.object({
  body: zPixverseV45ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45ImageToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45ImageToVideoFastRequestsByRequestIdResponse =
  zPixverseV45ImageToVideoFastOutput;

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV45EffectsData = z.object({
  body: zPixverseV45EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45EffectsResponse = zQueueStatus;

export const zGetFalAiPixverseV45EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45EffectsRequestsByRequestIdResponse =
  zPixverseV45EffectsOutput;

export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanCustomRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanCustomData = z.object({
  body: zHunyuanCustomInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanCustomResponse = zQueueStatus;

export const zGetFalAiHunyuanCustomRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanCustomRequestsByRequestIdResponse =
  zHunyuanCustomOutput;

export const zGetFalAiFramepackF1RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFramepackF1RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackF1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFramepackF1Data = z.object({
  body: zFramepackF1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFramepackF1Response = zQueueStatus;

export const zGetFalAiFramepackF1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFramepackF1RequestsByRequestIdResponse =
  zFramepackF1Output;

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1StartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ1StartEndToVideoData = z.object({
  body: zViduQ1StartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ1StartEndToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1StartEndToVideoRequestsByRequestIdResponse =
  zViduQ1StartEndToVideoOutput;

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ1ImageToVideoData = z.object({
  body: zViduQ1ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ1ImageToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1ImageToVideoRequestsByRequestIdResponse =
  zViduQ1ImageToVideoOutput;

export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMagiImageToVideoData = z.object({
  body: zMagiImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiImageToVideoResponse = zQueueStatus;

export const zGetFalAiMagiImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMagiImageToVideoRequestsByRequestIdResponse =
  zMagiImageToVideoOutput;

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV4EffectsData = z.object({
  body: zPixverseV4EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV4EffectsResponse = zQueueStatus;

export const zGetFalAiPixverseV4EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4EffectsRequestsByRequestIdResponse =
  zPixverseV4EffectsOutput;

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMagiDistilledImageToVideoData = z.object({
  body: zMagiDistilledImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledImageToVideoResponse = zQueueStatus;

export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledImageToVideoRequestsByRequestIdResponse =
  zMagiDistilledImageToVideoOutput;

export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFramepackFlf2vData = z.object({
  body: zFramepackFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFramepackFlf2vResponse = zQueueStatus;

export const zGetFalAiFramepackFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFramepackFlf2vRequestsByRequestIdResponse =
  zFramepackFlf2vOutput;

export const zGetFalAiWanFlf2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanFlf2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFlf2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanFlf2vData = z.object({
  body: zWanFlf2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanFlf2vResponse = zQueueStatus;

export const zGetFalAiWanFlf2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanFlf2vRequestsByRequestIdResponse = zWanFlf2vOutput;

export const zGetFalAiFramepackRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFramepackRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiFramepackRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFramepackRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFramepackData = z.object({
  body: zFramepackInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFramepackResponse = zQueueStatus;

export const zGetFalAiFramepackRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFramepackRequestsByRequestIdResponse = zFramepackOutput;

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV4ImageToVideoFastData = z.object({
  body: zPixverseV4ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoFastRequestsByRequestIdResponse =
  zPixverseV4ImageToVideoFastOutput;

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV4ImageToVideoData = z.object({
  body: zPixverseV4ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV4ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4ImageToVideoRequestsByRequestIdResponse =
  zPixverseV4ImageToVideoOutput;

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35EffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV35EffectsData = z.object({
  body: zPixverseV35EffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35EffectsResponse = zQueueStatus;

export const zGetFalAiPixverseV35EffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35EffectsRequestsByRequestIdResponse =
  zPixverseV35EffectsOutput;

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TransitionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV35TransitionData = z.object({
  body: zPixverseV35TransitionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TransitionResponse = zQueueStatus;

export const zGetFalAiPixverseV35TransitionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TransitionRequestsByRequestIdResponse =
  zPixverseV35TransitionOutput;

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoData = z.object({
  body: zLumaDreamMachineRay2FlashImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashImageToVideoRequestsByRequestIdResponse =
  zLumaDreamMachineRay2FlashImageToVideoOutput;

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV15PikaffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV15PikaffectsData = z.object({
  body: zPikaV15PikaffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV15PikaffectsResponse = zQueueStatus;

export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV15PikaffectsRequestsByRequestIdResponse =
  zPikaV15PikaffectsOutput;

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV21ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV21ImageToVideoData = z.object({
  body: zPikaV21ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV21ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV21ImageToVideoRequestsByRequestIdResponse =
  zPikaV21ImageToVideoOutput;

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22ImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV22ImageToVideoData = z.object({
  body: zPikaV22ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV22ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22ImageToVideoRequestsByRequestIdResponse =
  zPikaV22ImageToVideoOutput;

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22PikascenesRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV22PikascenesData = z.object({
  body: zPikaV22PikascenesInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV22PikascenesResponse = zQueueStatus;

export const zGetFalAiPikaV22PikascenesRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22PikascenesRequestsByRequestIdResponse =
  zPikaV22PikascenesOutput;

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2TurboImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPikaV2TurboImageToVideoData = z.object({
  body: zPikaV2TurboImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV2TurboImageToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2TurboImageToVideoRequestsByRequestIdResponse =
  zPikaV2TurboImageToVideoOutput;

export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiViduImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduImageToVideoData = z.object({
  body: zViduImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduImageToVideoResponse = zQueueStatus;

export const zGetFalAiViduImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduImageToVideoRequestsByRequestIdResponse =
  zViduImageToVideoOutput;

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduReferenceToVideoData = z.object({
  body: zViduReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduReferenceToVideoResponse = zQueueStatus;

export const zGetFalAiViduReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduReferenceToVideoRequestsByRequestIdResponse =
  zViduReferenceToVideoOutput;

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduStartEndToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduStartEndToVideoData = z.object({
  body: zViduStartEndToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduStartEndToVideoResponse = zQueueStatus;

export const zGetFalAiViduStartEndToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduStartEndToVideoRequestsByRequestIdResponse =
  zViduStartEndToVideoOutput;

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduTemplateToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduTemplateToVideoData = z.object({
  body: zViduTemplateToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduTemplateToVideoResponse = zQueueStatus;

export const zGetFalAiViduTemplateToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduTemplateToVideoRequestsByRequestIdResponse =
  zViduTemplateToVideoOutput;

export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanI2vLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanI2vLoraData = z.object({
  body: zWanI2vLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanI2vLoraResponse = zQueueStatus;

export const zGetFalAiWanI2vLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanI2vLoraRequestsByRequestIdResponse = zWanI2vLoraOutput;

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoImageToVideoData = z.object({
  body: zHunyuanVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImageToVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImageToVideoRequestsByRequestIdResponse =
  zHunyuanVideoImageToVideoOutput;

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxVideo01DirectorImageToVideoData = z.object({
  body: zMinimaxVideo01DirectorImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01DirectorImageToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01DirectorImageToVideoRequestsByRequestIdResponse =
  zMinimaxVideo01DirectorImageToVideoOutput;

export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSkyreelsI2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSkyreelsI2vData = z.object({
  body: zSkyreelsI2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSkyreelsI2vResponse = zQueueStatus;

export const zGetFalAiSkyreelsI2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSkyreelsI2vRequestsByRequestIdResponse =
  zSkyreelsI2vOutput;

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2ImageToVideoData = z.object({
  body: zLumaDreamMachineRay2ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ImageToVideoResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ImageToVideoRequestsByRequestIdResponse =
  zLumaDreamMachineRay2ImageToVideoOutput;

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoImg2VidLoraData = z.object({
  body: zHunyuanVideoImg2VidLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoImg2VidLoraResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoImg2VidLoraRequestsByRequestIdResponse =
  zHunyuanVideoImg2VidLoraOutput;

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV35ImageToVideoFastData = z.object({
  body: zPixverseV35ImageToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoFastRequestsByRequestIdResponse =
  zPixverseV35ImageToVideoFastOutput;

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35ImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV35ImageToVideoData = z.object({
  body: zPixverseV35ImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35ImageToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35ImageToVideoRequestsByRequestIdResponse =
  zPixverseV35ImageToVideoOutput;

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxVideo01SubjectReferenceData = z.object({
  body: zMinimaxVideo01SubjectReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01SubjectReferenceResponse = zQueueStatus;

export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01SubjectReferenceRequestsByRequestIdResponse =
  zMinimaxVideo01SubjectReferenceOutput;

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16StandardImageToVideoData = z.object({
  body: zKlingVideoV16StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV16StandardImageToVideoOutput;

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerReferenceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSadtalkerReferenceData = z.object({
  body: zSadtalkerReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSadtalkerReferenceResponse = zQueueStatus;

export const zGetFalAiSadtalkerReferenceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerReferenceRequestsByRequestIdResponse =
  zSadtalkerReferenceOutput;

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxVideo01LiveImageToVideoData = z.object({
  body: zMinimaxVideo01LiveImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01LiveImageToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01LiveImageToVideoRequestsByRequestIdResponse =
  zMinimaxVideo01LiveImageToVideoOutput;

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoImageToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideoImageToVideoData = z.object({
  body: zLtxVideoImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoImageToVideoResponse = zQueueStatus;

export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoImageToVideoRequestsByRequestIdResponse =
  zLtxVideoImageToVideoOutput;

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiCogvideox5bImageToVideoData = z.object({
  body: zCogvideox5bImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bImageToVideoResponse = zQueueStatus;

export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bImageToVideoRequestsByRequestIdResponse =
  zCogvideox5bImageToVideoOutput;

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV15ProImageToVideoData = z.object({
  body: zKlingVideoV15ProImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV15ProImageToVideoOutput;

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV1StandardImageToVideoData = z.object({
  body: zKlingVideoV1StandardImageToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardImageToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardImageToVideoRequestsByRequestIdResponse =
  zKlingVideoV1StandardImageToVideoOutput;

export const zGetFalAiStableVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiStableVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiStableVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiStableVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiStableVideoData = z.object({
  body: zStableVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiStableVideoResponse = zQueueStatus;

export const zGetFalAiStableVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiStableVideoRequestsByRequestIdResponse =
  zStableVideoOutput;

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiAmtInterpolationFrameInterpolationData = z.object({
  body: zAmtInterpolationFrameInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationFrameInterpolationResponse =
  zQueueStatus;

export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationFrameInterpolationRequestsByRequestIdResponse =
  zAmtInterpolationFrameInterpolationOutput;

export const zGetFalAiLivePortraitRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLivePortraitRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLivePortraitRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLivePortraitData = z.object({
  body: zLivePortraitInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLivePortraitResponse = zQueueStatus;

export const zGetFalAiLivePortraitRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLivePortraitRequestsByRequestIdResponse =
  zLivePortraitOutput;

export const zGetFalAiMusetalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMusetalkRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMusetalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMusetalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMusetalkData = z.object({
  body: zMusetalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMusetalkResponse = zQueueStatus;

export const zGetFalAiMusetalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMusetalkRequestsByRequestIdResponse = zMusetalkOutput;

export const zGetFalAiSadtalkerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiSadtalkerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSadtalkerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSadtalkerData = z.object({
  body: zSadtalkerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSadtalkerResponse = zQueueStatus;

export const zGetFalAiSadtalkerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSadtalkerRequestsByRequestIdResponse = zSadtalkerOutput;

export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdLcmRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFastSvdLcmData = z.object({
  body: zFastSvdLcmInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastSvdLcmResponse = zQueueStatus;

export const zGetFalAiFastSvdLcmRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdLcmRequestsByRequestIdResponse = zFastSvdLcmOutput;

export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV25TurboProTextToVideoData = z.object({
  body: zKlingVideoV25TurboProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV25TurboProTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV25TurboProTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV25TurboProTextToVideoOutput;

export const zGetFalAiVeo3FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo3FastRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVeo3FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo3FastData = z.object({
  body: zVeo3FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo3FastResponse = zQueueStatus;

export const zGetFalAiVeo3FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo3FastRequestsByRequestIdResponse = zVeo3FastOutput;

export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo02StandardTextToVideoData = z.object({
  body: zMinimaxHailuo02StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02StandardTextToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02StandardTextToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo02StandardTextToVideoOutput;

export const zGetFalAiVeo3RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo3RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVeo3RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo3RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo3Data = z.object({
  body: zVeo3Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo3Response = zQueueStatus;

export const zGetFalAiVeo3RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo3RequestsByRequestIdResponse = zVeo3Output;

export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV2MasterTextToVideoData = z.object({
  body: zKlingVideoV2MasterTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV2MasterTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV2MasterTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV2MasterTextToVideoOutput;

export const zGetFalAiViduQ3TextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiViduQ3TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ3TextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ3TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ3TextToVideoData = z.object({
  body: zViduQ3TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ3TextToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ3TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ3TextToVideoRequestsByRequestIdResponse =
  zViduQ3TextToVideoOutput;

export const zGetXaiGrokImagineVideoTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetXaiGrokImagineVideoTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutXaiGrokImagineVideoTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutXaiGrokImagineVideoTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostXaiGrokImagineVideoTextToVideoData = z.object({
  body: zGrokImagineVideoTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostXaiGrokImagineVideoTextToVideoResponse = zQueueStatus;

export const zGetXaiGrokImagineVideoTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetXaiGrokImagineVideoTextToVideoRequestsByRequestIdResponse =
  zGrokImagineVideoTextToVideoOutput;

export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV56TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV56TextToVideoData = z.object({
  body: zPixverseV56TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV56TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV56TextToVideoRequestsByRequestIdResponse =
  zPixverseV56TextToVideoOutput;

export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledTextToVideoLoraData = z.object({
  body: zLtx219bDistilledTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledTextToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledTextToVideoLoraRequestsByRequestIdResponse =
  zLtx219bDistilledTextToVideoLoraOutput;

export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledTextToVideoData = z.object({
  body: zLtx219bDistilledTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledTextToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledTextToVideoRequestsByRequestIdResponse =
  zLtx219bDistilledTextToVideoOutput;

export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bTextToVideoLoraData = z.object({
  body: zLtx219bTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bTextToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bTextToVideoLoraRequestsByRequestIdResponse =
  zLtx219bTextToVideoLoraOutput;

export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx219bTextToVideoData = z.object({
  body: zLtx219bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bTextToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bTextToVideoRequestsByRequestIdResponse =
  zLtx219bTextToVideoOutput;

export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKandinsky5ProTextToVideoData = z.object({
  body: zKandinsky5ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKandinsky5ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5ProTextToVideoRequestsByRequestIdResponse =
  zKandinsky5ProTextToVideoOutput;

export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV15ProTextToVideoData = z.object({
  body: zBytedanceSeedanceV15ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV15ProTextToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV15ProTextToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV15ProTextToVideoOutput;

export const zGetWanV26TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetWanV26TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutWanV26TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutWanV26TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostWanV26TextToVideoData = z.object({
  body: zV26TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostWanV26TextToVideoResponse = zQueueStatus;

export const zGetWanV26TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetWanV26TextToVideoRequestsByRequestIdResponse =
  zV26TextToVideoOutput;

export const zGetVeedFabric10TextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetVeedFabric10TextRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedFabric10TextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutVeedFabric10TextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedFabric10TextData = z.object({
  body: zFabric10TextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedFabric10TextResponse = zQueueStatus;

export const zGetVeedFabric10TextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedFabric10TextRequestsByRequestIdResponse =
  zFabric10TextOutput;

export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV26ProTextToVideoData = z.object({
  body: zKlingVideoV26ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV26ProTextToVideoOutput;

export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV55TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV55TextToVideoData = z.object({
  body: zPixverseV55TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV55TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV55TextToVideoRequestsByRequestIdResponse =
  zPixverseV55TextToVideoOutput;

export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2TextToVideoFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx2TextToVideoFastData = z.object({
  body: zLtx2TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx2TextToVideoFastResponse = zQueueStatus;

export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx2TextToVideoFastRequestsByRequestIdResponse =
  zLtx2TextToVideoFastOutput;

export const zGetFalAiLtx2TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtx2TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx2TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx2TextToVideoData = z.object({
  body: zLtx2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx2TextToVideoResponse = zQueueStatus;

export const zGetFalAiLtx2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx2TextToVideoRequestsByRequestIdResponse =
  zLtx2TextToVideoOutput;

export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoV15TextToVideoData = z.object({
  body: zHunyuanVideoV15TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoV15TextToVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoV15TextToVideoRequestsByRequestIdResponse =
  zHunyuanVideoV15TextToVideoOutput;

export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinityStarTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiInfinityStarTextToVideoData = z.object({
  body: zInfinityStarTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiInfinityStarTextToVideoResponse = zQueueStatus;

export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiInfinityStarTextToVideoRequestsByRequestIdResponse =
  zInfinityStarTextToVideoOutput;

export const zGetFalAiSanaVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSanaVideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiSanaVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSanaVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSanaVideoData = z.object({
  body: zSanaVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSanaVideoResponse = zQueueStatus;

export const zGetFalAiSanaVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSanaVideoRequestsByRequestIdResponse = zSanaVideoOutput;

export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoTextToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoTextToVideo720pData = z.object({
  body: zLongcatVideoTextToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoTextToVideo720pResponse = zQueueStatus;

export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoTextToVideo720pRequestsByRequestIdResponse =
  zLongcatVideoTextToVideo720pOutput;

export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoTextToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoTextToVideo480pData = z.object({
  body: zLongcatVideoTextToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoTextToVideo480pResponse = zQueueStatus;

export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoTextToVideo480pRequestsByRequestIdResponse =
  zLongcatVideoTextToVideo480pOutput;

export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoDistilledTextToVideo720pData = z.object({
  body: zLongcatVideoDistilledTextToVideo720pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledTextToVideo720pResponse =
  zQueueStatus;

export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo720pRequestsByRequestIdResponse =
  zLongcatVideoDistilledTextToVideo720pOutput;

export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLongcatVideoDistilledTextToVideo480pData = z.object({
  body: zLongcatVideoDistilledTextToVideo480pInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLongcatVideoDistilledTextToVideo480pResponse =
  zQueueStatus;

export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLongcatVideoDistilledTextToVideo480pRequestsByRequestIdResponse =
  zLongcatVideoDistilledTextToVideo480pOutput;

export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23StandardTextToVideoData = z.object({
  body: zMinimaxHailuo23StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23StandardTextToVideoResponse =
  zQueueStatus;

export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23StandardTextToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23StandardTextToVideoOutput;

export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo23ProTextToVideoData = z.object({
  body: zMinimaxHailuo23ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo23ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo23ProTextToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo23ProTextToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1ProFastTextToVideoData = z.object({
  body: zBytedanceSeedanceV1ProFastTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProFastTextToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProFastTextToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1ProFastTextToVideoOutput;

export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ2TextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ2TextToVideoData = z.object({
  body: zViduQ2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ2TextToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2TextToVideoRequestsByRequestIdResponse =
  zViduQ2TextToVideoOutput;

export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKreaWan14bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiKreaWan14bTextToVideoData = z.object({
  body: zKreaWan14bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKreaWan14bTextToVideoResponse = zQueueStatus;

export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiKreaWan14bTextToVideoRequestsByRequestIdResponse =
  zKreaWan14bTextToVideoOutput;

export const zGetFalAiWanAlphaRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanAlphaRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanAlphaRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanAlphaRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanAlphaData = z.object({
  body: zWanAlphaInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanAlphaResponse = zQueueStatus;

export const zGetFalAiWanAlphaRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanAlphaRequestsByRequestIdResponse = zWanAlphaOutput;

export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5TextToVideoDistillRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKandinsky5TextToVideoDistillData = z.object({
  body: zKandinsky5TextToVideoDistillInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKandinsky5TextToVideoDistillResponse = zQueueStatus;

export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5TextToVideoDistillRequestsByRequestIdResponse =
  zKandinsky5TextToVideoDistillOutput;

export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKandinsky5TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiKandinsky5TextToVideoData = z.object({
  body: zKandinsky5TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKandinsky5TextToVideoResponse = zQueueStatus;

export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiKandinsky5TextToVideoRequestsByRequestIdResponse =
  zKandinsky5TextToVideoOutput;

export const zGetFalAiVeo31FastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo31FastRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVeo31FastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31FastData = z.object({
  body: zVeo31FastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31FastResponse = zQueueStatus;

export const zGetFalAiVeo31FastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastRequestsByRequestIdResponse = zVeo31FastOutput;

export const zGetFalAiVeo31RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo31RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVeo31RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31Data = z.object({
  body: zVeo31Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31Response = zQueueStatus;

export const zGetFalAiVeo31RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31RequestsByRequestIdResponse = zVeo31Output;

export const zGetFalAiSora2TextToVideoProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiSora2TextToVideoProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSora2TextToVideoProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2TextToVideoProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSora2TextToVideoProData = z.object({
  body: zSora2TextToVideoProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSora2TextToVideoProResponse = zQueueStatus;

export const zGetFalAiSora2TextToVideoProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSora2TextToVideoProRequestsByRequestIdResponse =
  zSora2TextToVideoProOutput;

export const zGetFalAiSora2TextToVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSora2TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSora2TextToVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSora2TextToVideoData = z.object({
  body: zSora2TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSora2TextToVideoResponse = zQueueStatus;

export const zGetFalAiSora2TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSora2TextToVideoRequestsByRequestIdResponse =
  zSora2TextToVideoOutput;

export const zGetFalAiOviRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiOviRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiOviRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiOviRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiOviData = z.object({
  body: zOviInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiOviResponse = zQueueStatus;

export const zGetFalAiOviRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiOviRequestsByRequestIdResponse = zOviOutput;

export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan25PreviewTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWan25PreviewTextToVideoData = z.object({
  body: zWan25PreviewTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan25PreviewTextToVideoResponse = zQueueStatus;

export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiWan25PreviewTextToVideoRequestsByRequestIdResponse =
  zWan25PreviewTextToVideoOutput;

export const zGetArgilAvatarsTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetArgilAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutArgilAvatarsTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutArgilAvatarsTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostArgilAvatarsTextToVideoData = z.object({
  body: zAvatarsTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostArgilAvatarsTextToVideoResponse = zQueueStatus;

export const zGetArgilAvatarsTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetArgilAvatarsTextToVideoRequestsByRequestIdResponse =
  zAvatarsTextToVideoOutput;

export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV5TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV5TextToVideoData = z.object({
  body: zPixverseV5TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV5TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV5TextToVideoRequestsByRequestIdResponse =
  zPixverseV5TextToVideoOutput;

export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiInfinitalkSingleTextRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkSingleTextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiInfinitalkSingleTextData = z.object({
  body: zInfinitalkSingleTextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiInfinitalkSingleTextResponse = zQueueStatus;

export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkSingleTextRequestsByRequestIdResponse =
  zInfinitalkSingleTextOutput;

export const zGetMoonvalleyMareyT2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetMoonvalleyMareyT2vRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMoonvalleyMareyT2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyT2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostMoonvalleyMareyT2vData = z.object({
  body: zMareyT2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMoonvalleyMareyT2vResponse = zQueueStatus;

export const zGetMoonvalleyMareyT2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyT2vRequestsByRequestIdResponse =
  zMareyT2vOutput;

export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bTextToVideoLoraData = z.object({
  body: zWanV22A14bTextToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoLoraResponse = zQueueStatus;

export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoLoraRequestsByRequestIdResponse =
  zWanV22A14bTextToVideoLoraOutput;

export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoDistillRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV225bTextToVideoDistillData = z.object({
  body: zWanV225bTextToVideoDistillInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoDistillResponse = zQueueStatus;

export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoDistillRequestsByRequestIdResponse =
  zWanV225bTextToVideoDistillOutput;

export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoFastWanRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV225bTextToVideoFastWanData = z.object({
  body: zWanV225bTextToVideoFastWanInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoFastWanResponse = zQueueStatus;

export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoFastWanRequestsByRequestIdResponse =
  zWanV225bTextToVideoFastWanOutput;

export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bTextToVideoTurboData = z.object({
  body: zWanV22A14bTextToVideoTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoTurboResponse = zQueueStatus;

export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoTurboRequestsByRequestIdResponse =
  zWanV22A14bTextToVideoTurboOutput;

export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV225bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV225bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanV225bTextToVideoData = z.object({
  body: zWanV225bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV225bTextToVideoResponse = zQueueStatus;

export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV225bTextToVideoRequestsByRequestIdResponse =
  zWanV225bTextToVideoOutput;

export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanV22A14bTextToVideoData = z.object({
  body: zWanV22A14bTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bTextToVideoResponse = zQueueStatus;

export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bTextToVideoRequestsByRequestIdResponse =
  zWanV22A14bTextToVideoOutput;

export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxv13B098DistilledRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxv13B098DistilledData = z.object({
  body: zLtxv13B098DistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledResponse = zQueueStatus;

export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledRequestsByRequestIdResponse =
  zLtxv13B098DistilledOutput;

export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxHailuo02ProTextToVideoData = z.object({
  body: zMinimaxHailuo02ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxHailuo02ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxHailuo02ProTextToVideoRequestsByRequestIdResponse =
  zMinimaxHailuo02ProTextToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1ProTextToVideoData = z.object({
  body: zBytedanceSeedanceV1ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1ProTextToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1ProTextToVideoOutput;

export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceSeedanceV1LiteTextToVideoData = z.object({
  body: zBytedanceSeedanceV1LiteTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceSeedanceV1LiteTextToVideoResponse =
  zQueueStatus;

export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceSeedanceV1LiteTextToVideoRequestsByRequestIdResponse =
  zBytedanceSeedanceV1LiteTextToVideoOutput;

export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV21MasterTextToVideoData = z.object({
  body: zKlingVideoV21MasterTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV21MasterTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV21MasterTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV21MasterTextToVideoOutput;

export const zGetVeedAvatarsTextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetVeedAvatarsTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedAvatarsTextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutVeedAvatarsTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedAvatarsTextToVideoData = z.object({
  body: zAvatarsTextToVideoInputType2,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedAvatarsTextToVideoResponse = zQueueStatus;

export const zGetVeedAvatarsTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedAvatarsTextToVideoRequestsByRequestIdResponse =
  zAvatarsTextToVideoOutputType2;

export const zGetFalAiLtxVideo13bDevRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDevRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideo13bDevData = z.object({
  body: zLtxVideo13bDevInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDevRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevRequestsByRequestIdResponse =
  zLtxVideo13bDevOutput;

export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideo13bDistilledData = z.object({
  body: zLtxVideo13bDistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledRequestsByRequestIdResponse =
  zLtxVideo13bDistilledOutput;

export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV45TextToVideoFastData = z.object({
  body: zPixverseV45TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TextToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TextToVideoFastRequestsByRequestIdResponse =
  zPixverseV45TextToVideoFastOutput;

export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV45TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV45TextToVideoData = z.object({
  body: zPixverseV45TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV45TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV45TextToVideoRequestsByRequestIdResponse =
  zPixverseV45TextToVideoOutput;

export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ1TextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ1TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiViduQ1TextToVideoData = z.object({
  body: zViduQ1TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ1TextToVideoResponse = zQueueStatus;

export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiViduQ1TextToVideoRequestsByRequestIdResponse =
  zViduQ1TextToVideoOutput;

export const zGetFalAiMagiRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMagiRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMagiRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMagiData = z.object({
  body: zMagiInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiResponse = zQueueStatus;

export const zGetFalAiMagiRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMagiRequestsByRequestIdResponse = zMagiOutput;

export const zGetFalAiMagiDistilledRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMagiDistilledRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMagiDistilledData = z.object({
  body: zMagiDistilledInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledResponse = zQueueStatus;

export const zGetFalAiMagiDistilledRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledRequestsByRequestIdResponse =
  zMagiDistilledOutput;

export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseV4TextToVideoData = z.object({
  body: zPixverseV4TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV4TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4TextToVideoRequestsByRequestIdResponse =
  zPixverseV4TextToVideoOutput;

export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV4TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV4TextToVideoFastData = z.object({
  body: zPixverseV4TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV4TextToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV4TextToVideoFastRequestsByRequestIdResponse =
  zPixverseV4TextToVideoFastOutput;

export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoLipsyncAudioToVideoData = z.object({
  body: zKlingVideoLipsyncAudioToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoLipsyncAudioToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoLipsyncAudioToVideoRequestsByRequestIdResponse =
  zKlingVideoLipsyncAudioToVideoOutput;

export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoLipsyncTextToVideoData = z.object({
  body: zKlingVideoLipsyncTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoLipsyncTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoLipsyncTextToVideoRequestsByRequestIdResponse =
  zKlingVideoLipsyncTextToVideoOutput;

export const zGetFalAiWanT2vLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanT2vLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanT2vLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanT2vLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanT2vLoraData = z.object({
  body: zWanT2vLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanT2vLoraResponse = zQueueStatus;

export const zGetFalAiWanT2vLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanT2vLoraRequestsByRequestIdResponse = zWanT2vLoraOutput;

export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2FlashData = z.object({
  body: zLumaDreamMachineRay2FlashInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashRequestsByRequestIdResponse =
  zLumaDreamMachineRay2FlashOutput;

export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV21TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV21TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV21TextToVideoData = z.object({
  body: zPikaV21TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV21TextToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV21TextToVideoRequestsByRequestIdResponse =
  zPikaV21TextToVideoOutput;

export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV22TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV22TextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV22TextToVideoData = z.object({
  body: zPikaV22TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV22TextToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV22TextToVideoRequestsByRequestIdResponse =
  zPikaV22TextToVideoOutput;

export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2TurboTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPikaV2TurboTextToVideoData = z.object({
  body: zPikaV2TurboTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV2TurboTextToVideoResponse = zQueueStatus;

export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2TurboTextToVideoRequestsByRequestIdResponse =
  zPikaV2TurboTextToVideoOutput;

export const zGetFalAiWanProTextToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiWanProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanProTextToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiWanProTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanProTextToVideoData = z.object({
  body: zWanProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanProTextToVideoResponse = zQueueStatus;

export const zGetFalAiWanProTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanProTextToVideoRequestsByRequestIdResponse =
  zWanProTextToVideoOutput;

export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16ProEffectsData = z.object({
  body: zKlingVideoV16ProEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProEffectsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProEffectsRequestsByRequestIdResponse =
  zKlingVideoV16ProEffectsOutput;

export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16StandardEffectsData = z.object({
  body: zKlingVideoV16StandardEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardEffectsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardEffectsRequestsByRequestIdResponse =
  zKlingVideoV16StandardEffectsOutput;

export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV15ProEffectsData = z.object({
  body: zKlingVideoV15ProEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProEffectsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProEffectsRequestsByRequestIdResponse =
  zKlingVideoV15ProEffectsOutput;

export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardEffectsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV1StandardEffectsData = z.object({
  body: zKlingVideoV1StandardEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardEffectsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardEffectsRequestsByRequestIdResponse =
  zKlingVideoV1StandardEffectsOutput;

export const zGetFalAiLtxVideoV095RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoV095RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideoV095Data = z.object({
  body: zLtxVideoV095Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095Response = zQueueStatus;

export const zGetFalAiLtxVideoV095RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095RequestsByRequestIdResponse =
  zLtxVideoV095Output;

export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16ProTextToVideoData = z.object({
  body: zKlingVideoV16ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16ProTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV16ProTextToVideoOutput;

export const zGetFalAiWanT2vRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanT2vRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanT2vRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanT2vRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanT2vData = z.object({
  body: zWanT2vInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanT2vResponse = zQueueStatus;

export const zGetFalAiWanT2vRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanT2vRequestsByRequestIdResponse = zWanT2vOutput;

export const zGetFalAiVeo2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo2RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVeo2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo2Data = z.object({
  body: zVeo2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo2Response = zQueueStatus;

export const zGetFalAiVeo2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo2RequestsByRequestIdResponse = zVeo2Output;

export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01DirectorRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxVideo01DirectorData = z.object({
  body: zMinimaxVideo01DirectorInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01DirectorResponse = zQueueStatus;

export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01DirectorRequestsByRequestIdResponse =
  zMinimaxVideo01DirectorOutput;

export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV35TextToVideoData = z.object({
  body: zPixverseV35TextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TextToVideoResponse = zQueueStatus;

export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TextToVideoRequestsByRequestIdResponse =
  zPixverseV35TextToVideoOutput;

export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseV35TextToVideoFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiPixverseV35TextToVideoFastData = z.object({
  body: zPixverseV35TextToVideoFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseV35TextToVideoFastResponse = zQueueStatus;

export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiPixverseV35TextToVideoFastRequestsByRequestIdResponse =
  zPixverseV35TextToVideoFastOutput;

export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLumaDreamMachineRay2Data = z.object({
  body: zLumaDreamMachineRay2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2Response = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2RequestsByRequestIdResponse =
  zLumaDreamMachineRay2Output;

export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoLoraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoLoraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanVideoLoraData = z.object({
  body: zHunyuanVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoLoraResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoLoraRequestsByRequestIdResponse =
  zHunyuanVideoLoraOutput;

export const zGetFalAiTranspixarRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiTranspixarRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiTranspixarRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiTranspixarRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiTranspixarData = z.object({
  body: zTranspixarInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiTranspixarResponse = zQueueStatus;

export const zGetFalAiTranspixarRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiTranspixarRequestsByRequestIdResponse = zTranspixarOutput;

export const zGetFalAiCogvideox5bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiCogvideox5bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiCogvideox5bData = z.object({
  body: zCogvideox5bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bResponse = zQueueStatus;

export const zGetFalAiCogvideox5bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bRequestsByRequestIdResponse =
  zCogvideox5bOutput;

export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV16StandardTextToVideoData = z.object({
  body: zKlingVideoV16StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV16StandardTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV16StandardTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV16StandardTextToVideoOutput;

export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01LiveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxVideo01LiveData = z.object({
  body: zMinimaxVideo01LiveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01LiveResponse = zQueueStatus;

export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01LiveRequestsByRequestIdResponse =
  zMinimaxVideo01LiveOutput;

export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV1StandardTextToVideoData = z.object({
  body: zKlingVideoV1StandardTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1StandardTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1StandardTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV1StandardTextToVideoOutput;

export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV15ProTextToVideoData = z.object({
  body: zKlingVideoV15ProTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV15ProTextToVideoResponse = zQueueStatus;

export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV15ProTextToVideoRequestsByRequestIdResponse =
  zKlingVideoV15ProTextToVideoOutput;

export const zGetFalAiMochiV1RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMochiV1RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMochiV1RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMochiV1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMochiV1Data = z.object({
  body: zMochiV1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMochiV1Response = zQueueStatus;

export const zGetFalAiMochiV1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMochiV1RequestsByRequestIdResponse = zMochiV1Output;

export const zGetFalAiHunyuanVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanVideoData = z.object({
  body: zHunyuanVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoRequestsByRequestIdResponse =
  zHunyuanVideoOutput;

export const zGetFalAiLtxVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtxVideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiLtxVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideoData = z.object({
  body: zLtxVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoResponse = zQueueStatus;

export const zGetFalAiLtxVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoRequestsByRequestIdResponse = zLtxVideoOutput;

export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastSvdTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFastSvdTextToVideoData = z.object({
  body: zFastSvdTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastSvdTextToVideoResponse = zQueueStatus;

export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdTextToVideoRequestsByRequestIdResponse =
  zFastSvdTextToVideoOutput;

export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastSvdLcmTextToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFastSvdLcmTextToVideoData = z.object({
  body: zFastSvdLcmTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastSvdLcmTextToVideoResponse = zQueueStatus;

export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFastSvdLcmTextToVideoRequestsByRequestIdResponse =
  zFastSvdLcmTextToVideoOutput;

export const zGetFalAiT2vTurboRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiT2vTurboRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiT2vTurboRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiT2vTurboRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiT2vTurboData = z.object({
  body: zT2vTurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiT2vTurboResponse = zQueueStatus;

export const zGetFalAiT2vTurboRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiT2vTurboRequestsByRequestIdResponse = zT2vTurboOutput;

export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiFastAnimatediffTextToVideoData = z.object({
  body: zFastAnimatediffTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTextToVideoResponse = zQueueStatus;

export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTextToVideoRequestsByRequestIdResponse =
  zFastAnimatediffTextToVideoOutput;

export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiFastAnimatediffTurboTextToVideoData = z.object({
  body: zFastAnimatediffTurboTextToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTurboTextToVideoResponse = zQueueStatus;

export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTurboTextToVideoRequestsByRequestIdResponse =
  zFastAnimatediffTurboTextToVideoOutput;

export const zGetFalAiMinimaxVideo01RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMinimaxVideo01RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVideo01RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVideo01RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxVideo01Data = z.object({
  body: zMinimaxVideo01Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVideo01Response = zQueueStatus;

export const zGetFalAiMinimaxVideo01RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVideo01RequestsByRequestIdResponse =
  zMinimaxVideo01Output;

export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiAnimatediffSparsectrlLcmRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiAnimatediffSparsectrlLcmData = z.object({
  body: zAnimatediffSparsectrlLcmInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAnimatediffSparsectrlLcmResponse = zQueueStatus;

export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiAnimatediffSparsectrlLcmRequestsByRequestIdResponse =
  zAnimatediffSparsectrlLcmOutput;

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostBriaVideoBackgroundRemovalData = z.object({
  body: zVideoBackgroundRemovalInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaVideoBackgroundRemovalResponse = zQueueStatus;

export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBriaVideoBackgroundRemovalRequestsByRequestIdResponse =
  zVideoBackgroundRemovalOutput;

export const zGetFalAiMmaudioV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMmaudioV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMmaudioV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMmaudioV2Data = z.object({
  body: zMmaudioV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMmaudioV2Response = zQueueStatus;

export const zGetFalAiMmaudioV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMmaudioV2RequestsByRequestIdResponse = zMmaudioV2Output;

export const zGetXaiGrokImagineVideoEditVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetXaiGrokImagineVideoEditVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutXaiGrokImagineVideoEditVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutXaiGrokImagineVideoEditVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostXaiGrokImagineVideoEditVideoData = z.object({
  body: zGrokImagineVideoEditVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostXaiGrokImagineVideoEditVideoResponse = zQueueStatus;

export const zGetXaiGrokImagineVideoEditVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetXaiGrokImagineVideoEditVideoRequestsByRequestIdResponse =
  zGrokImagineVideoEditVideoOutput;

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostHalfMoonAiAiFaceSwapFaceswapvideoData = z.object({
  body: zAiFaceSwapFaceswapvideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostHalfMoonAiAiFaceSwapFaceswapvideoResponse = zQueueStatus;

export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetHalfMoonAiAiFaceSwapFaceswapvideoRequestsByRequestIdResponse =
  zAiFaceSwapFaceswapvideoOutput;

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledVideoToVideoLoraData = z.object({
  body: zLtx219bDistilledVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoLoraRequestsByRequestIdResponse =
  zLtx219bDistilledVideoToVideoLoraOutput;

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledVideoToVideoData = z.object({
  body: zLtx219bDistilledVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledVideoToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledVideoToVideoRequestsByRequestIdResponse =
  zLtx219bDistilledVideoToVideoOutput;

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bVideoToVideoLoraData = z.object({
  body: zLtx219bVideoToVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoLoraRequestsByRequestIdResponse =
  zLtx219bVideoToVideoLoraOutput;

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bVideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx219bVideoToVideoData = z.object({
  body: zLtx219bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bVideoToVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bVideoToVideoRequestsByRequestIdResponse =
  zLtx219bVideoToVideoOutput;

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledExtendVideoLoraData = z.object({
  body: zLtx219bDistilledExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoLoraRequestsByRequestIdResponse =
  zLtx219bDistilledExtendVideoLoraOutput;

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bDistilledExtendVideoData = z.object({
  body: zLtx219bDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bDistilledExtendVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bDistilledExtendVideoRequestsByRequestIdResponse =
  zLtx219bDistilledExtendVideoOutput;

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoLoraRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtx219bExtendVideoLoraData = z.object({
  body: zLtx219bExtendVideoLoraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoLoraResponse = zQueueStatus;

export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoLoraRequestsByRequestIdResponse =
  zLtx219bExtendVideoLoraOutput;

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx219bExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx219bExtendVideoData = z.object({
  body: zLtx219bExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx219bExtendVideoResponse = zQueueStatus;

export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx219bExtendVideoRequestsByRequestIdResponse =
  zLtx219bExtendVideoOutput;

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseKeypointsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostBriaVideoEraseKeypointsData = z.object({
  body: zVideoEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaVideoEraseKeypointsResponse = zQueueStatus;

export const zGetBriaVideoEraseKeypointsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseKeypointsRequestsByRequestIdResponse =
  zVideoEraseKeypointsOutput;

export const zGetBriaVideoErasePromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaVideoErasePromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutBriaVideoErasePromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostBriaVideoErasePromptData = z.object({
  body: zVideoErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaVideoErasePromptResponse = zQueueStatus;

export const zGetBriaVideoErasePromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBriaVideoErasePromptRequestsByRequestIdResponse =
  zVideoErasePromptOutput;

export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutBriaVideoEraseMaskRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostBriaVideoEraseMaskData = z.object({
  body: zVideoEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaVideoEraseMaskResponse = zQueueStatus;

export const zGetBriaVideoEraseMaskRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBriaVideoEraseMaskRequestsByRequestIdResponse =
  zVideoEraseMaskOutput;

export const zGetFalAiLightxRelightRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLightxRelightRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRelightRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLightxRelightData = z.object({
  body: zLightxRelightInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLightxRelightResponse = zQueueStatus;

export const zGetFalAiLightxRelightRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLightxRelightRequestsByRequestIdResponse =
  zLightxRelightOutput;

export const zGetFalAiLightxRecameraRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLightxRecameraRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLightxRecameraRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLightxRecameraData = z.object({
  body: zLightxRecameraInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLightxRecameraResponse = zQueueStatus;

export const zGetFalAiLightxRecameraRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLightxRecameraRequestsByRequestIdResponse =
  zLightxRecameraOutput;

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV26StandardMotionControlData = z.object({
  body: zKlingVideoV26StandardMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26StandardMotionControlResponse =
  zQueueStatus;

export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26StandardMotionControlRequestsByRequestIdResponse =
  zKlingVideoV26StandardMotionControlOutput;

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV26ProMotionControlRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoV26ProMotionControlData = z.object({
  body: zKlingVideoV26ProMotionControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV26ProMotionControlResponse = zQueueStatus;

export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV26ProMotionControlRequestsByRequestIdResponse =
  zKlingVideoV26ProMotionControlOutput;

export const zGetDecartLucyRestyleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutDecartLucyRestyleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutDecartLucyRestyleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostDecartLucyRestyleData = z.object({
  body: zLucyRestyleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostDecartLucyRestyleResponse = zQueueStatus;

export const zGetDecartLucyRestyleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetDecartLucyRestyleRequestsByRequestIdResponse =
  zLucyRestyleOutput;

export const zGetFalAiScailRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiScailRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiScailRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiScailRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiScailData = z.object({
  body: zScailInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiScailResponse = zQueueStatus;

export const zGetFalAiScailRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiScailRequestsByRequestIdResponse = zScailOutput;

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutClarityaiCrystalVideoUpscalerRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostClarityaiCrystalVideoUpscalerData = z.object({
  body: zCrystalVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostClarityaiCrystalVideoUpscalerResponse = zQueueStatus;

export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetClarityaiCrystalVideoUpscalerRequestsByRequestIdResponse =
  zCrystalVideoUpscalerOutput;

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseMaskRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostBriaBriaVideoEraserEraseMaskData = z.object({
  body: zBriaVideoEraserEraseMaskInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseMaskResponse = zQueueStatus;

export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseMaskRequestsByRequestIdResponse =
  zBriaVideoEraserEraseMaskOutput;

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostBriaBriaVideoEraserEraseKeypointsData = z.object({
  body: zBriaVideoEraserEraseKeypointsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserEraseKeypointsResponse = zQueueStatus;

export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserEraseKeypointsRequestsByRequestIdResponse =
  zBriaVideoEraserEraseKeypointsOutput;

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaBriaVideoEraserErasePromptRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostBriaBriaVideoEraserErasePromptData = z.object({
  body: zBriaVideoEraserErasePromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaBriaVideoEraserErasePromptResponse = zQueueStatus;

export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetBriaBriaVideoEraserErasePromptRequestsByRequestIdResponse =
  zBriaVideoEraserErasePromptOutput;

export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutWanV26ReferenceToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostWanV26ReferenceToVideoData = z.object({
  body: zV26ReferenceToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostWanV26ReferenceToVideoResponse = zQueueStatus;

export const zGetWanV26ReferenceToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetWanV26ReferenceToVideoRequestsByRequestIdResponse =
  zV26ReferenceToVideoOutput;

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31FastExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31FastExtendVideoData = z.object({
  body: zVeo31FastExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31FastExtendVideoResponse = zQueueStatus;

export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31FastExtendVideoRequestsByRequestIdResponse =
  zVeo31FastExtendVideoOutput;

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVeo31ExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVeo31ExtendVideoData = z.object({
  body: zVeo31ExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVeo31ExtendVideoResponse = zQueueStatus;

export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVeo31ExtendVideoRequestsByRequestIdResponse =
  zVeo31ExtendVideoOutput;

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceData = z.object(
  {
    body: zKlingVideoO1StandardVideoToVideoReferenceInput,
    path: z.optional(z.never()),
    query: z.optional(z.never()),
  },
);

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoReferenceResponse =
  zQueueStatus;

export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoReferenceRequestsByRequestIdResponse =
  zKlingVideoO1StandardVideoToVideoReferenceOutput;

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1StandardVideoToVideoEditData = z.object({
  body: zKlingVideoO1StandardVideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1StandardVideoToVideoEditResponse =
  zQueueStatus;

export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1StandardVideoToVideoEditRequestsByRequestIdResponse =
  zKlingVideoO1StandardVideoToVideoEditOutput;

export const zGetFalAiSteadyDancerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSteadyDancerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSteadyDancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSteadyDancerData = z.object({
  body: zSteadyDancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSteadyDancerResponse = zQueueStatus;

export const zGetFalAiSteadyDancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSteadyDancerRequestsByRequestIdResponse =
  zSteadyDancerOutput;

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiOneToAllAnimation13bData = z.object({
  body: zOneToAllAnimation13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation13bResponse = zQueueStatus;

export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation13bRequestsByRequestIdResponse =
  zOneToAllAnimation13bOutput;

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiOneToAllAnimation14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiOneToAllAnimation14bData = z.object({
  body: zOneToAllAnimation14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiOneToAllAnimation14bResponse = zQueueStatus;

export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiOneToAllAnimation14bRequestsByRequestIdResponse =
  zOneToAllAnimation14bOutput;

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVisionEnhancerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVisionEnhancerData = z.object({
  body: zWanVisionEnhancerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVisionEnhancerResponse = zQueueStatus;

export const zGetFalAiWanVisionEnhancerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVisionEnhancerRequestsByRequestIdResponse =
  zWanVisionEnhancerOutput;

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncReact1RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSyncLipsyncReact1Data = z.object({
  body: zSyncLipsyncReact1Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncReact1Response = zQueueStatus;

export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncReact1RequestsByRequestIdResponse =
  zSyncLipsyncReact1Output;

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalFastRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostVeedVideoBackgroundRemovalFastData = z.object({
  body: zVideoBackgroundRemovalFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalFastResponse = zQueueStatus;

export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalFastRequestsByRequestIdResponse =
  zVideoBackgroundRemovalFastOutput;

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1VideoToVideoEditData = z.object({
  body: zKlingVideoO1VideoToVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoEditResponse = zQueueStatus;

export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoEditRequestsByRequestIdResponse =
  zKlingVideoO1VideoToVideoEditOutput;

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKlingVideoO1VideoToVideoReferenceData = z.object({
  body: zKlingVideoO1VideoToVideoReferenceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoO1VideoToVideoReferenceResponse = zQueueStatus;

export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoO1VideoToVideoReferenceRequestsByRequestIdResponse =
  zKlingVideoO1VideoToVideoReferenceOutput;

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedVideoBackgroundRemovalData = z.object({
  body: zVideoBackgroundRemovalInputType2,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalResponse = zQueueStatus;

export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalRequestsByRequestIdResponse =
  zVideoBackgroundRemovalOutputType2;

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostVeedVideoBackgroundRemovalGreenScreenData = z.object({
  body: zVideoBackgroundRemovalGreenScreenInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedVideoBackgroundRemovalGreenScreenResponse = zQueueStatus;

export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetVeedVideoBackgroundRemovalGreenScreenRequestsByRequestIdResponse =
  zVideoBackgroundRemovalGreenScreenOutput;

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLtx2RetakeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtx2RetakeVideoData = z.object({
  body: zLtx2RetakeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtx2RetakeVideoResponse = zQueueStatus;

export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtx2RetakeVideoRequestsByRequestIdResponse =
  zLtx2RetakeVideoOutput;

export const zGetDecartLucyEditFastRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutDecartLucyEditFastRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostDecartLucyEditFastData = z.object({
  body: zLucyEditFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostDecartLucyEditFastResponse = zQueueStatus;

export const zGetDecartLucyEditFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetDecartLucyEditFastRequestsByRequestIdResponse =
  zLucyEditFastOutput;

export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRleRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSam3VideoRleData = z.object({
  body: zSam3VideoRleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSam3VideoRleResponse = zQueueStatus;

export const zGetFalAiSam3VideoRleRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRleRequestsByRequestIdResponse =
  zSam3VideoRleOutput;

export const zGetFalAiSam3VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiSam3VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSam3VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSam3VideoData = z.object({
  body: zSam3VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSam3VideoResponse = zQueueStatus;

export const zGetFalAiSam3VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSam3VideoRequestsByRequestIdResponse = zSam3VideoOutput;

export const zGetFalAiEdittoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiEdittoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiEdittoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiEdittoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiEdittoData = z.object({
  body: zEdittoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiEdittoResponse = zQueueStatus;

export const zGetFalAiEdittoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiEdittoRequestsByRequestIdResponse = zEdittoOutput;

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFlashvsrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFlashvsrUpscaleVideoData = z.object({
  body: zFlashvsrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFlashvsrUpscaleVideoResponse = zQueueStatus;

export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFlashvsrUpscaleVideoRequestsByRequestIdResponse =
  zFlashvsrUpscaleVideoOutput;

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWorkflowUtilitiesAutoSubtitleData = z.object({
  body: zWorkflowUtilitiesAutoSubtitleInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWorkflowUtilitiesAutoSubtitleResponse = zQueueStatus;

export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWorkflowUtilitiesAutoSubtitleRequestsByRequestIdResponse =
  zWorkflowUtilitiesAutoSubtitleOutput;

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiBytedanceUpscalerUpscaleVideoData = z.object({
  body: zBytedanceUpscalerUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBytedanceUpscalerUpscaleVideoResponse = zQueueStatus;

export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiBytedanceUpscalerUpscaleVideoRequestsByRequestIdResponse =
  zBytedanceUpscalerUpscaleVideoOutput;

export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoAsPromptRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVideoAsPromptData = z.object({
  body: zVideoAsPromptInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVideoAsPromptResponse = zQueueStatus;

export const zGetFalAiVideoAsPromptRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVideoAsPromptRequestsByRequestIdResponse =
  zVideoAsPromptOutput;

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiBirefnetV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiBirefnetV2VideoData = z.object({
  body: zBirefnetV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBirefnetV2VideoResponse = zQueueStatus;

export const zGetFalAiBirefnetV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiBirefnetV2VideoRequestsByRequestIdResponse =
  zBirefnetV2VideoOutput;

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiViduQ2VideoExtensionProRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiViduQ2VideoExtensionProData = z.object({
  body: zViduQ2VideoExtensionProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiViduQ2VideoExtensionProResponse = zQueueStatus;

export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiViduQ2VideoExtensionProRequestsByRequestIdResponse =
  zViduQ2VideoExtensionProOutput;

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV15VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostMireloAiSfxV15VideoToVideoData = z.object({
  body: zSfxV15VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMireloAiSfxV15VideoToVideoResponse = zQueueStatus;

export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV15VideoToVideoRequestsByRequestIdResponse =
  zSfxV15VideoToVideoOutput;

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiKreaWan14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiKreaWan14bVideoToVideoData = z.object({
  body: zKreaWan14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKreaWan14bVideoToVideoResponse = zQueueStatus;

export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiKreaWan14bVideoToVideoRequestsByRequestIdResponse =
  zKreaWan14bVideoToVideoOutput;

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiSora2VideoToVideoRemixRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiSora2VideoToVideoRemixData = z.object({
  body: zSora2VideoToVideoRemixInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSora2VideoToVideoRemixResponse = zQueueStatus;

export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSora2VideoToVideoRemixRequestsByRequestIdResponse =
  zSora2VideoToVideoRemixOutput;

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsLongReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanVaceAppsLongReframeData = z.object({
  body: zWanVaceAppsLongReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsLongReframeResponse = zQueueStatus;

export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsLongReframeRequestsByRequestIdResponse =
  zWanVaceAppsLongReframeOutput;

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiInfinitalkVideoToVideoData = z.object({
  body: zInfinitalkVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiInfinitalkVideoToVideoResponse = zQueueStatus;

export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkVideoToVideoRequestsByRequestIdResponse =
  zInfinitalkVideoToVideoOutput;

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiSeedvrUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSeedvrUpscaleVideoData = z.object({
  body: zSeedvrUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSeedvrUpscaleVideoResponse = zQueueStatus;

export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSeedvrUpscaleVideoRequestsByRequestIdResponse =
  zSeedvrUpscaleVideoOutput;

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceAppsVideoEditRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVaceAppsVideoEditData = z.object({
  body: zWanVaceAppsVideoEditInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVaceAppsVideoEditResponse = zQueueStatus;

export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceAppsVideoEditRequestsByRequestIdResponse =
  zWanVaceAppsVideoEditOutput;

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateReplaceRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV2214bAnimateReplaceData = z.object({
  body: zWanV2214bAnimateReplaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateReplaceResponse = zQueueStatus;

export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateReplaceRequestsByRequestIdResponse =
  zWanV2214bAnimateReplaceOutput;

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV2214bAnimateMoveRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanV2214bAnimateMoveData = z.object({
  body: zWanV2214bAnimateMoveInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV2214bAnimateMoveResponse = zQueueStatus;

export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV2214bAnimateMoveRequestsByRequestIdResponse =
  zWanV2214bAnimateMoveOutput;

export const zGetDecartLucyEditProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetDecartLucyEditProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutDecartLucyEditProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostDecartLucyEditProData = z.object({
  body: zLucyEditProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostDecartLucyEditProResponse = zQueueStatus;

export const zGetDecartLucyEditProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetDecartLucyEditProRequestsByRequestIdResponse =
  zLucyEditProOutput;

export const zGetDecartLucyEditDevRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutDecartLucyEditDevRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutDecartLucyEditDevRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostDecartLucyEditDevData = z.object({
  body: zLucyEditDevInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostDecartLucyEditDevResponse = zQueueStatus;

export const zGetDecartLucyEditDevRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetDecartLucyEditDevRequestsByRequestIdResponse =
  zLucyEditDevOutput;

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWan22VaceFunA14bReframeData = z.object({
  body: zWan22VaceFunA14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bReframeResponse = zQueueStatus;

export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bReframeRequestsByRequestIdResponse =
  zWan22VaceFunA14bReframeOutput;

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWan22VaceFunA14bOutpaintingData = z.object({
  body: zWan22VaceFunA14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bOutpaintingResponse = zQueueStatus;

export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bOutpaintingRequestsByRequestIdResponse =
  zWan22VaceFunA14bOutpaintingOutput;

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWan22VaceFunA14bInpaintingData = z.object({
  body: zWan22VaceFunA14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bInpaintingResponse = zQueueStatus;

export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bInpaintingRequestsByRequestIdResponse =
  zWan22VaceFunA14bInpaintingOutput;

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWan22VaceFunA14bDepthData = z.object({
  body: zWan22VaceFunA14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bDepthResponse = zQueueStatus;

export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bDepthRequestsByRequestIdResponse =
  zWan22VaceFunA14bDepthOutput;

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWan22VaceFunA14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWan22VaceFunA14bPoseData = z.object({
  body: zWan22VaceFunA14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWan22VaceFunA14bPoseResponse = zQueueStatus;

export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWan22VaceFunA14bPoseRequestsByRequestIdResponse =
  zWan22VaceFunA14bPoseOutput;

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoFoleyRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiHunyuanVideoFoleyData = z.object({
  body: zHunyuanVideoFoleyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoFoleyResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoFoleyRequestsByRequestIdResponse =
  zHunyuanVideoFoleyOutput;

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2ProRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSyncLipsyncV2ProData = z.object({
  body: zSyncLipsyncV2ProInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2ProResponse = zQueueStatus;

export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2ProRequestsByRequestIdResponse =
  zSyncLipsyncV2ProOutput;

export const zGetFalAiWanFunControlRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanFunControlRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanFunControlRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanFunControlData = z.object({
  body: zWanFunControlInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanFunControlResponse = zQueueStatus;

export const zGetFalAiWanFunControlRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanFunControlRequestsByRequestIdResponse =
  zWanFunControlOutput;

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutBriaVideoIncreaseResolutionRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostBriaVideoIncreaseResolutionData = z.object({
  body: zVideoIncreaseResolutionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostBriaVideoIncreaseResolutionResponse = zQueueStatus;

export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetBriaVideoIncreaseResolutionRequestsByRequestIdResponse =
  zVideoIncreaseResolutionOutput;

export const zGetFalAiInfinitalkRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiInfinitalkRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiInfinitalkRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiInfinitalkData = z.object({
  body: zInfinitalkInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiInfinitalkResponse = zQueueStatus;

export const zGetFalAiInfinitalkRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiInfinitalkRequestsByRequestIdResponse = zInfinitalkOutput;

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutMireloAiSfxV1VideoToVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostMireloAiSfxV1VideoToVideoData = z.object({
  body: zSfxV1VideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMireloAiSfxV1VideoToVideoResponse = zQueueStatus;

export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetMireloAiSfxV1VideoToVideoRequestsByRequestIdResponse =
  zSfxV1VideoToVideoOutput;

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyPoseTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostMoonvalleyMareyPoseTransferData = z.object({
  body: zMareyPoseTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMoonvalleyMareyPoseTransferResponse = zQueueStatus;

export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyPoseTransferRequestsByRequestIdResponse =
  zMareyPoseTransferOutput;

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutMoonvalleyMareyMotionTransferRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostMoonvalleyMareyMotionTransferData = z.object({
  body: zMareyMotionTransferInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostMoonvalleyMareyMotionTransferResponse = zQueueStatus;

export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetMoonvalleyMareyMotionTransferRequestsByRequestIdResponse =
  zMareyMotionTransferOutput;

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeVideosRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFfmpegApiMergeVideosData = z.object({
  body: zFfmpegApiMergeVideosInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeVideosResponse = zQueueStatus;

export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeVideosRequestsByRequestIdResponse =
  zFfmpegApiMergeVideosOutput;

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanV22A14bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiWanV22A14bVideoToVideoData = z.object({
  body: zWanV22A14bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanV22A14bVideoToVideoResponse = zQueueStatus;

export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanV22A14bVideoToVideoRequestsByRequestIdResponse =
  zWanV22A14bVideoToVideoOutput;

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxv13B098DistilledExtendData = z.object({
  body: zLtxv13B098DistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledExtendResponse = zQueueStatus;

export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledExtendRequestsByRequestIdResponse =
  zLtxv13B098DistilledExtendOutput;

export const zGetFalAiRifeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiRifeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiRifeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiRifeVideoData = z.object({
  body: zRifeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiRifeVideoResponse = zQueueStatus;

export const zGetFalAiRifeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiRifeVideoRequestsByRequestIdResponse = zRifeVideoOutput;

export const zGetFalAiFilmVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiFilmVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFilmVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFilmVideoData = z.object({
  body: zFilmVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFilmVideoResponse = zQueueStatus;

export const zGetFalAiFilmVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFilmVideoRequestsByRequestIdResponse = zFilmVideoOutput;

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2FlashModifyData = z.object({
  body: zLumaDreamMachineRay2FlashModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashModifyResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashModifyRequestsByRequestIdResponse =
  zLumaDreamMachineRay2FlashModifyOutput;

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxv13B098DistilledMulticonditioningData = z.object({
  body: zLtxv13B098DistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxv13B098DistilledMulticonditioningResponse =
  zQueueStatus;

export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxv13B098DistilledMulticonditioningRequestsByRequestIdResponse =
  zLtxv13B098DistilledMulticonditioningOutput;

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseSoundEffectsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseSoundEffectsData = z.object({
  body: zPixverseSoundEffectsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseSoundEffectsResponse = zQueueStatus;

export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseSoundEffectsRequestsByRequestIdResponse =
  zPixverseSoundEffectsOutput;

export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundAudioRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiThinksoundAudioData = z.object({
  body: zThinksoundAudioInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiThinksoundAudioResponse = zQueueStatus;

export const zGetFalAiThinksoundAudioRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundAudioRequestsByRequestIdResponse =
  zThinksoundAudioOutput;

export const zGetFalAiThinksoundRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiThinksoundRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiThinksoundRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiThinksoundRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiThinksoundData = z.object({
  body: zThinksoundInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiThinksoundResponse = zQueueStatus;

export const zGetFalAiThinksoundRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiThinksoundRequestsByRequestIdResponse = zThinksoundOutput;

export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendFastRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseExtendFastData = z.object({
  body: zPixverseExtendFastInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendFastResponse = zQueueStatus;

export const zGetFalAiPixverseExtendFastRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendFastRequestsByRequestIdResponse =
  zPixverseExtendFastOutput;

export const zGetFalAiPixverseExtendRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseExtendRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseExtendData = z.object({
  body: zPixverseExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseExtendResponse = zQueueStatus;

export const zGetFalAiPixverseExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseExtendRequestsByRequestIdResponse =
  zPixverseExtendOutput;

export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiPixverseLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPixverseLipsyncData = z.object({
  body: zPixverseLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPixverseLipsyncResponse = zQueueStatus;

export const zGetFalAiPixverseLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPixverseLipsyncRequestsByRequestIdResponse =
  zPixverseLipsyncOutput;

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2ModifyData = z.object({
  body: zLumaDreamMachineRay2ModifyInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ModifyResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ModifyRequestsByRequestIdResponse =
  zLumaDreamMachineRay2ModifyOutput;

export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bReframeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bReframeData = z.object({
  body: zWanVace14bReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bReframeResponse = zQueueStatus;

export const zGetFalAiWanVace14bReframeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bReframeRequestsByRequestIdResponse =
  zWanVace14bReframeOutput;

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bOutpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bOutpaintingData = z.object({
  body: zWanVace14bOutpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bOutpaintingResponse = zQueueStatus;

export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bOutpaintingRequestsByRequestIdResponse =
  zWanVace14bOutpaintingOutput;

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bInpaintingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bInpaintingData = z.object({
  body: zWanVace14bInpaintingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bInpaintingResponse = zQueueStatus;

export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bInpaintingRequestsByRequestIdResponse =
  zWanVace14bInpaintingOutput;

export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bPoseRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bPoseData = z.object({
  body: zWanVace14bPoseInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bPoseResponse = zQueueStatus;

export const zGetFalAiWanVace14bPoseRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bPoseRequestsByRequestIdResponse =
  zWanVace14bPoseOutput;

export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bDepthRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bDepthData = z.object({
  body: zWanVace14bDepthInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bDepthResponse = zQueueStatus;

export const zGetFalAiWanVace14bDepthRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bDepthRequestsByRequestIdResponse =
  zWanVace14bDepthOutput;

export const zGetFalAiDwposeVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiDwposeVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiDwposeVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiDwposeVideoData = z.object({
  body: zDwposeVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiDwposeVideoResponse = zQueueStatus;

export const zGetFalAiDwposeVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiDwposeVideoRequestsByRequestIdResponse =
  zDwposeVideoOutput;

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiFfmpegApiMergeAudioVideoData = z.object({
  body: zFfmpegApiMergeAudioVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiMergeAudioVideoResponse = zQueueStatus;

export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiMergeAudioVideoRequestsByRequestIdResponse =
  zFfmpegApiMergeAudioVideoOutput;

export const zGetFalAiWanVace13bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace13bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace13bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace13bData = z.object({
  body: zWanVace13bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace13bResponse = zQueueStatus;

export const zGetFalAiWanVace13bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace13bRequestsByRequestIdResponse = zWanVace13bOutput;

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2FlashReframeData = z.object({
  body: zLumaDreamMachineRay2FlashReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2FlashReframeResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2FlashReframeRequestsByRequestIdResponse =
  zLumaDreamMachineRay2FlashReframeOutput;

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLumaDreamMachineRay2ReframeData = z.object({
  body: zLumaDreamMachineRay2ReframeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLumaDreamMachineRay2ReframeResponse = zQueueStatus;

export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLumaDreamMachineRay2ReframeRequestsByRequestIdResponse =
  zLumaDreamMachineRay2ReframeOutput;

export const zGetVeedLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetVeedLipsyncRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutVeedLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutVeedLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostVeedLipsyncData = z.object({
  body: zLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostVeedLipsyncResponse = zQueueStatus;

export const zGetVeedLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetVeedLipsyncRequestsByRequestIdResponse = zLipsyncOutput;

export const zGetFalAiWanVace14bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiWanVace14bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVace14bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVace14bData = z.object({
  body: zWanVace14bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVace14bResponse = zQueueStatus;

export const zGetFalAiWanVace14bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVace14bRequestsByRequestIdResponse = zWanVace14bOutput;

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledExtendRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideo13bDistilledExtendData = z.object({
  body: zLtxVideo13bDistilledExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledExtendResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledExtendRequestsByRequestIdResponse =
  zLtxVideo13bDistilledExtendOutput;

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideo13bDistilledMulticonditioningData = z.object({
  body: zLtxVideo13bDistilledMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDistilledMulticonditioningResponse =
  zQueueStatus;

export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDistilledMulticonditioningRequestsByRequestIdResponse =
  zLtxVideo13bDistilledMulticonditioningOutput;

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideo13bDevMulticonditioningData = z.object({
  body: zLtxVideo13bDevMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevMulticonditioningResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevMulticonditioningRequestsByRequestIdResponse =
  zLtxVideo13bDevMulticonditioningOutput;

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideo13bDevExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideo13bDevExtendData = z.object({
  body: zLtxVideo13bDevExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideo13bDevExtendResponse = zQueueStatus;

export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideo13bDevExtendRequestsByRequestIdResponse =
  zLtxVideo13bDevExtendOutput;

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideoLoraMulticonditioningData = z.object({
  body: zLtxVideoLoraMulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoLoraMulticonditioningResponse = zQueueStatus;

export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoLoraMulticonditioningRequestsByRequestIdResponse =
  zLtxVideoLoraMulticonditioningOutput;

export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiExtendVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMagiExtendVideoData = z.object({
  body: zMagiExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiExtendVideoResponse = zQueueStatus;

export const zGetFalAiMagiExtendVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMagiExtendVideoRequestsByRequestIdResponse =
  zMagiExtendVideoOutput;

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMagiDistilledExtendVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMagiDistilledExtendVideoData = z.object({
  body: zMagiDistilledExtendVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMagiDistilledExtendVideoResponse = zQueueStatus;

export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMagiDistilledExtendVideoRequestsByRequestIdResponse =
  zMagiDistilledExtendVideoOutput;

export const zGetFalAiWanVaceRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiWanVaceRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiWanVaceRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiWanVaceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiWanVaceData = z.object({
  body: zWanVaceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiWanVaceResponse = zQueueStatus;

export const zGetFalAiWanVaceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiWanVaceRequestsByRequestIdResponse = zWanVaceOutput;

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostCassetteaiVideoSoundEffectsGeneratorData = z.object({
  body: zVideoSoundEffectsGeneratorInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostCassetteaiVideoSoundEffectsGeneratorResponse = zQueueStatus;

export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetCassetteaiVideoSoundEffectsGeneratorRequestsByRequestIdResponse =
  zVideoSoundEffectsGeneratorOutput;

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncV2RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSyncLipsyncV2Data = z.object({
  body: zSyncLipsyncV2Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncV2Response = zQueueStatus;

export const zGetFalAiSyncLipsyncV2RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncV2RequestsByRequestIdResponse =
  zSyncLipsyncV2Output;

export const zGetFalAiLatentsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLatentsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiLatentsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLatentsyncData = z.object({
  body: zLatentsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLatentsyncResponse = zQueueStatus;

export const zGetFalAiLatentsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLatentsyncRequestsByRequestIdResponse = zLatentsyncOutput;

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiPikaV2PikadditionsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiPikaV2PikadditionsData = z.object({
  body: zPikaV2PikadditionsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiPikaV2PikadditionsResponse = zQueueStatus;

export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiPikaV2PikadditionsRequestsByRequestIdResponse =
  zPikaV2PikadditionsOutput;

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095ExtendRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiLtxVideoV095ExtendData = z.object({
  body: zLtxVideoV095ExtendInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095ExtendResponse = zQueueStatus;

export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095ExtendRequestsByRequestIdResponse =
  zLtxVideoV095ExtendOutput;

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiLtxVideoV095MulticonditioningRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiLtxVideoV095MulticonditioningData = z.object({
  body: zLtxVideoV095MulticonditioningInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiLtxVideoV095MulticonditioningResponse = zQueueStatus;

export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiLtxVideoV095MulticonditioningRequestsByRequestIdResponse =
  zLtxVideoV095MulticonditioningOutput;

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiTopazUpscaleVideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiTopazUpscaleVideoData = z.object({
  body: zTopazUpscaleVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiTopazUpscaleVideoResponse = zQueueStatus;

export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiTopazUpscaleVideoRequestsByRequestIdResponse =
  zTopazUpscaleVideoOutput;

export const zGetFalAiBenV2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiBenV2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiBenV2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiBenV2VideoData = z.object({
  body: zBenV2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiBenV2VideoResponse = zQueueStatus;

export const zGetFalAiBenV2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiBenV2VideoRequestsByRequestIdResponse = zBenV2VideoOutput;

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoLoraVideoToVideoData = z.object({
  body: zHunyuanVideoLoraVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoLoraVideoToVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoLoraVideoToVideoRequestsByRequestIdResponse =
  zHunyuanVideoLoraVideoToVideoOutput;

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiHunyuanVideoVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiHunyuanVideoVideoToVideoData = z.object({
  body: zHunyuanVideoVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiHunyuanVideoVideoToVideoResponse = zQueueStatus;

export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiHunyuanVideoVideoToVideoRequestsByRequestIdResponse =
  zHunyuanVideoVideoToVideoOutput;

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiFfmpegApiComposeRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiFfmpegApiComposeData = z.object({
  body: zFfmpegApiComposeInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFfmpegApiComposeResponse = zQueueStatus;

export const zGetFalAiFfmpegApiComposeRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiFfmpegApiComposeRequestsByRequestIdResponse =
  zFfmpegApiComposeOutput;

export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSyncLipsyncRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSyncLipsyncData = z.object({
  body: zSyncLipsyncInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSyncLipsyncResponse = zQueueStatus;

export const zGetFalAiSyncLipsyncRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSyncLipsyncRequestsByRequestIdResponse =
  zSyncLipsyncOutput;

export const zGetFalAiAutoCaptionRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAutoCaptionRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiAutoCaptionRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAutoCaptionData = z.object({
  body: zAutoCaptionInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAutoCaptionResponse = zQueueStatus;

export const zGetFalAiAutoCaptionRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAutoCaptionRequestsByRequestIdResponse =
  zAutoCaptionOutput;

export const zGetFalAiDubbingRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiDubbingRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiDubbingRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiDubbingRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiDubbingData = z.object({
  body: zDubbingInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiDubbingResponse = zQueueStatus;

export const zGetFalAiDubbingRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiDubbingRequestsByRequestIdResponse = zDubbingOutput;

export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVideoUpscalerRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVideoUpscalerData = z.object({
  body: zVideoUpscalerInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVideoUpscalerResponse = zQueueStatus;

export const zGetFalAiVideoUpscalerRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVideoUpscalerRequestsByRequestIdResponse =
  zVideoUpscalerOutput;

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiCogvideox5bVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiCogvideox5bVideoToVideoData = z.object({
  body: zCogvideox5bVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiCogvideox5bVideoToVideoResponse = zQueueStatus;

export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiCogvideox5bVideoToVideoRequestsByRequestIdResponse =
  zCogvideox5bVideoToVideoOutput;

export const zGetFalAiControlnextRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiControlnextRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiControlnextRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiControlnextRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiControlnextData = z.object({
  body: zControlnextInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiControlnextResponse = zQueueStatus;

export const zGetFalAiControlnextRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiControlnextRequestsByRequestIdResponse =
  zControlnextOutput;

export const zGetFalAiSam2VideoRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiSam2VideoRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiSam2VideoRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiSam2VideoData = z.object({
  body: zSam2VideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiSam2VideoResponse = zQueueStatus;

export const zGetFalAiSam2VideoRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiSam2VideoRequestsByRequestIdResponse = zSam2VideoOutput;

export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiAmtInterpolationRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiAmtInterpolationData = z.object({
  body: zAmtInterpolationInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiAmtInterpolationResponse = zQueueStatus;

export const zGetFalAiAmtInterpolationRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiAmtInterpolationRequestsByRequestIdResponse =
  zAmtInterpolationOutput;

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiFastAnimatediffTurboVideoToVideoData = z.object({
  body: zFastAnimatediffTurboVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffTurboVideoToVideoResponse = zQueueStatus;

export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffTurboVideoToVideoRequestsByRequestIdResponse =
  zFastAnimatediffTurboVideoToVideoOutput;

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiFastAnimatediffVideoToVideoRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiFastAnimatediffVideoToVideoData = z.object({
  body: zFastAnimatediffVideoToVideoInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiFastAnimatediffVideoToVideoResponse = zQueueStatus;

export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiFastAnimatediffVideoToVideoRequestsByRequestIdResponse =
  zFastAnimatediffVideoToVideoOutput;
