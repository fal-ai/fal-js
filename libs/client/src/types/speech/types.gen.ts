// This file is auto-generated by @hey-api/openapi-ts

export type ClientOptions = {
  baseUrl: "https://queue.fal.run" | (string & {});
};

/**
 * TTSOutput
 */
export type ElevenlabsTtsTurboV25Output = {
  audio: FileType2;
  /**
   * Timestamps
   *
   * Timestamps for each word in the generated speech. Only returned if `timestamps` is set to True in the request.
   */
  timestamps?: Array<unknown> | unknown;
};

/**
 * File
 */
export type FileType2 = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number | unknown;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string | unknown;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string | unknown;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
};

/**
 * TextToSpeechRequest
 */
export type ElevenlabsTtsTurboV25Input = {
  /**
   * Text
   *
   * The text to convert to speech
   */
  text: string;
  /**
   * Next Text
   *
   * The text that comes after the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  next_text?: string | unknown;
  /**
   * Speed
   *
   * Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.
   */
  speed?: number;
  /**
   * Style
   *
   * Style exaggeration (0-1)
   */
  style?: number;
  /**
   * Stability
   *
   * Voice stability (0-1)
   */
  stability?: number;
  /**
   * Timestamps
   *
   * Whether to return timestamps for each word in the generated speech
   */
  timestamps?: boolean;
  /**
   * Similarity Boost
   *
   * Similarity boost (0-1)
   */
  similarity_boost?: number;
  /**
   * Voice
   *
   * The voice to use for speech generation
   */
  voice?: string;
  /**
   * Language Code
   *
   * Language code (ISO 639-1) used to enforce a language for the model. An error will be returned if language code is not supported by the model.
   */
  language_code?: string | unknown;
  /**
   * Apply Text Normalization
   *
   * This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.
   */
  apply_text_normalization?: "auto" | "on" | "off";
  /**
   * Previous Text
   *
   * The text that came before the text of the current request. Can be used to improve the speech's continuity when concatenating together multiple generations or to influence the speech's continuity in the current generation.
   */
  previous_text?: string | unknown;
};

/**
 * OrpheusOutput
 */
export type OrpheusTtsOutput = {
  audio: FileType2;
};

/**
 * OrpheusRequest
 */
export type OrpheusTtsInput = {
  /**
   * Text
   *
   * The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>
   */
  text: string;
  /**
   * Voice
   *
   * Voice ID for the desired voice.
   */
  voice?: "tara" | "leah" | "jess" | "leo" | "dan" | "mia" | "zac" | "zoe";
  /**
   * Repetition Penalty
   *
   * Repetition penalty (>= 1.1 required for stable generations).
   */
  repetition_penalty?: number;
  /**
   * Temperature
   *
   * Temperature for generation (higher = more creative).
   */
  temperature?: number;
};

/**
 * DiaOutput
 */
export type DiaTtsOutput = {
  /**
   * The generated speech audio
   */
  audio: FileType2;
};

/**
 * DiaRequest
 */
export type DiaTtsInput = {
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string;
};

/**
 * TextToSpeechOutput
 */
export type MinimaxSpeech02HdOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * File
 */
export type File = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * TextToSpeechHDRequest
 */
export type MinimaxSpeech02HdInput = {
  /**
   * Text
   *
   * Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)
   */
  text: string;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * AudioSetting
 */
export type AudioSetting = {
  /**
   * Format
   *
   * Audio format
   */
  format?: "mp3" | "pcm" | "flac";
  /**
   * Sample Rate
   *
   * Sample rate of generated audio
   */
  sample_rate?: 8000 | 16000 | 22050 | 24000 | 32000 | 44100;
  /**
   * Channel
   *
   * Number of audio channels (1=mono, 2=stereo)
   */
  channel?: 1 | 2;
  /**
   * Bitrate
   *
   * Bitrate of generated audio
   */
  bitrate?: 32000 | 64000 | 128000 | 256000;
};

/**
 * PronunciationDict
 */
export type PronunciationDict = {
  /**
   * Tone List
   *
   * List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']
   */
  tone_list?: Array<string>;
};

/**
 * VoiceSetting
 */
export type VoiceSetting = {
  /**
   * Speed
   *
   * Speech speed (0.5-2.0)
   */
  speed?: number;
  /**
   * Vol
   *
   * Volume (0-10)
   */
  vol?: number;
  /**
   * Voice Id
   *
   * Predefined voice ID to use for synthesis
   */
  voice_id?: string;
  /**
   * Pitch
   *
   * Voice pitch (-12 to 12)
   */
  pitch?: number;
  /**
   * English Normalization
   *
   * Enables English text normalization to improve number reading performance, with a slight increase in latency
   */
  english_normalization?: boolean;
  /**
   * Emotion
   *
   * Emotion of the generated speech
   */
  emotion?:
    | "happy"
    | "sad"
    | "angry"
    | "fearful"
    | "disgusted"
    | "surprised"
    | "neutral";
};

/**
 * TextToSpeechOutput
 */
export type MinimaxSpeech02TurboOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * TextToSpeechTurboRequest
 */
export type MinimaxSpeech02TurboInput = {
  /**
   * Text
   *
   * Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)
   */
  text: string;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * VoiceCloneOutput
 */
export type MinimaxVoiceCloneOutput = {
  /**
   * Custom Voice Id
   *
   * The cloned voice ID for use with TTS
   */
  custom_voice_id: string;
  /**
   * Audio
   *
   * Preview audio generated with the cloned voice (if requested)
   */
  audio?: File;
};

/**
 * VoiceCloneRequest
 */
export type MinimaxVoiceCloneInput = {
  /**
   * Text
   *
   * Text to generate a TTS preview with the cloned voice (optional)
   */
  text?: string;
  /**
   * Model
   *
   * TTS model to use for preview. Options: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo
   */
  model?:
    | "speech-02-hd"
    | "speech-02-turbo"
    | "speech-01-hd"
    | "speech-01-turbo";
  /**
   * Accuracy
   *
   * Text validation accuracy threshold (0-1)
   */
  accuracy?: number;
  /**
   * Audio Url
   *
   *
   * URL of the input audio file for voice cloning. Should be at least 10 seconds
   * long. To retain the voice permanently, use it with a TTS (text-to-speech)
   * endpoint at least once within 7 days. Otherwise, it will be
   * automatically deleted.
   *
   */
  audio_url: string;
  /**
   * Noise Reduction
   *
   * Enable noise reduction for the cloned voice
   */
  noise_reduction?: boolean;
  /**
   * Need Volume Normalization
   *
   * Enable volume normalization for the cloned voice
   */
  need_volume_normalization?: boolean;
};

export type ChatterboxTextToSpeechOutput = unknown;

/**
 * ChatterboxRequest
 */
export type ChatterboxTextToSpeechInput = {
  /**
   * Text
   *
   * The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>
   */
  text: string;
  /**
   * Exaggeration
   *
   * Exaggeration factor for the generated speech (0.0 = no exaggeration, 1.0 = maximum exaggeration).
   */
  exaggeration?: number;
  /**
   * Audio Url
   *
   * Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.
   */
  audio_url?: string;
  /**
   * Temperature
   *
   * Temperature for generation (higher = more creative).
   */
  temperature?: number;
  /**
   * Seed
   *
   * Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed..
   */
  seed?: number;
  /**
   * Cfg
   */
  cfg?: number;
};

/**
 * TTSOutput
 *
 * Output parameters for the TTS request.
 */
export type ChatterboxhdTextToSpeechOutput = {
  /**
   * Audio
   *
   * The generated audio file.
   */
  audio: Audio;
};

/**
 * Audio
 */
export type Audio = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
};

/**
 * TTSInput
 *
 * Input parameters for the TTS request.
 */
export type ChatterboxhdTextToSpeechInput = {
  /**
   * Text
   *
   * Text to synthesize into speech.
   */
  text?: string;
  /**
   * Exaggeration
   *
   * Controls emotion exaggeration. Range typically 0.25 to 2.0.
   */
  exaggeration?: number;
  /**
   * High Quality Audio
   *
   * If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz.
   */
  high_quality_audio?: boolean;
  /**
   * Voice
   *
   * The voice to use for the TTS request. If neither voice nor audio are provided, a random voice will be used.
   */
  voice?:
    | "Aurora"
    | "Blade"
    | "Britney"
    | "Carl"
    | "Cliff"
    | "Richard"
    | "Rico"
    | "Siobhan"
    | "Vicky";
  /**
   * Audio Url
   *
   * URL to the audio sample to use as a voice prompt for zero-shot TTS voice cloning. Providing a audio sample will override the voice setting. If neither voice nor audio_url are provided, a random voice will be used.
   */
  audio_url?: string;
  /**
   * Temperature
   *
   * Controls the randomness of generation. Range typically 0.05 to 5.
   */
  temperature?: number;
  /**
   * Seed
   *
   * Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed.
   */
  seed?: number;
  /**
   * Cfg
   *
   * Classifier-free guidance scale (CFG) controls the conditioning factor. Range typically 0.2 to 1.0. For expressive or dramatic speech, try lower cfg values (e.g. ~0.3) and increase exaggeration to around 0.7 or higher. If the reference speaker has a fast speaking style, lowering cfg to around 0.3 can improve pacing.
   */
  cfg?: number;
};

/**
 * VoiceDesignOutput
 */
export type MinimaxVoiceDesignOutput = {
  /**
   * Custom Voice Id
   *
   * The voice_id of the generated voice
   */
  custom_voice_id: string;
  /**
   * Audio
   *
   * The preview audio using the generated voice
   */
  audio: File;
};

/**
 * VoiceDesignRequest
 */
export type MinimaxVoiceDesignInput = {
  /**
   * Prompt
   *
   * Voice description prompt for generating a personalized voice
   */
  prompt: string;
  /**
   * Preview Text
   *
   * Text for audio preview. Limited to 500 characters. A fee of $30 per 1M characters will be charged for the generation of the preview audio.
   */
  preview_text: string;
};

/**
 * TextToSpeechOutput
 */
export type MinimaxPreviewSpeech25TurboOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * TextToSpeechTurbov25Request
 */
export type MinimaxPreviewSpeech25TurboInput = {
  /**
   * Text
   *
   * Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)
   */
  text: string;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Persian"
    | "Filipino"
    | "Tamil"
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * TextToSpeechOutput
 */
export type MinimaxPreviewSpeech25HdOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * TextToSpeechHDv25Request
 */
export type MinimaxPreviewSpeech25HdInput = {
  /**
   * Text
   *
   * Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)
   */
  text: string;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Persian"
    | "Filipino"
    | "Tamil"
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export type VibevoiceOutput = {
  /**
   * Duration
   *
   * Duration of the generated audio in seconds
   */
  duration: number;
  /**
   * Rtf
   *
   * Real-time factor (generation_time / audio_duration). Lower is better.
   */
  rtf: number;
  /**
   * Sample Rate
   *
   * Sample rate of the generated audio
   */
  sample_rate: number;
  /**
   * Generation Time
   *
   * Time taken to generate the audio in seconds
   */
  generation_time: number;
  /**
   * Audio
   *
   * The generated audio file containing the speech
   */
  audio: File;
};

/**
 * VibeVoiceInput
 *
 * Input schema for VibeVoice TTS generation
 */
export type VibevoiceInput = {
  /**
   * Script
   *
   * The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.
   */
  script: string;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
  /**
   * Speakers
   *
   * List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.
   */
  speakers: Array<VibeVoiceSpeaker>;
  /**
   * CFG Scale
   *
   * CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.
   */
  cfg_scale?: number;
};

/**
 * VibeVoiceSpeaker
 */
export type VibeVoiceSpeaker = {
  /**
   * Preset
   *
   * Default voice preset to use for the speaker. Not used if `audio_url` is provided.
   */
  preset?:
    | "Alice [EN]"
    | "Carter [EN]"
    | "Frank [EN]"
    | "Mary [EN] (Background Music)"
    | "Maya [EN]"
    | "Anchen [ZH] (Background Music)"
    | "Bowen [ZH]"
    | "Xinran [ZH]";
  /**
   * Audio URL
   *
   * URL to a voice sample audio file. If provided, `preset` will be ignored.
   */
  audio_url?: string;
};

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export type Vibevoice7bOutput = {
  /**
   * Duration
   *
   * Duration of the generated audio in seconds
   */
  duration: number;
  /**
   * Rtf
   *
   * Real-time factor (generation_time / audio_duration). Lower is better.
   */
  rtf: number;
  /**
   * Sample Rate
   *
   * Sample rate of the generated audio
   */
  sample_rate: number;
  /**
   * Generation Time
   *
   * Time taken to generate the audio in seconds
   */
  generation_time: number;
  /**
   * Audio
   *
   * The generated audio file containing the speech
   */
  audio: File;
};

/**
 * VibeVoice7bInput
 *
 * Input schema for VibeVoice-7b TTS generation
 */
export type Vibevoice7bInput = {
  /**
   * Script
   *
   * The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.
   */
  script: string;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
  /**
   * Speakers
   *
   * List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.
   */
  speakers: Array<VibeVoiceSpeaker>;
  /**
   * CFG Scale
   *
   * CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.
   */
  cfg_scale?: number;
};

/**
 * ChatterboxMultilingualOutput
 */
export type ChatterboxTextToSpeechMultilingualOutput = {
  /**
   * Audio
   *
   * The generated multilingual speech audio file
   */
  audio: File;
};

/**
 * ChatterboxMultilingualRequest
 */
export type ChatterboxTextToSpeechMultilingualInput = {
  /**
   * Text
   *
   * The text to be converted to speech (maximum 300 characters). Supports 23 languages including English, French, German, Spanish, Italian, Portuguese, Hindi, Arabic, Chinese, Japanese, Korean, and more.
   */
  text: string;
  /**
   * Custom Audio Language
   *
   * If using a custom audio URL, specify the language of the audio here. Ignored if voice is not a custom url.
   */
  custom_audio_language?:
    | "english"
    | "arabic"
    | "danish"
    | "german"
    | "greek"
    | "spanish"
    | "finnish"
    | "french"
    | "hebrew"
    | "hindi"
    | "italian"
    | "japanese"
    | "korean"
    | "malay"
    | "dutch"
    | "norwegian"
    | "polish"
    | "portuguese"
    | "russian"
    | "swedish"
    | "swahili"
    | "turkish"
    | "chinese";
  /**
   * Exaggeration
   *
   * Controls speech expressiveness and emotional intensity (0.25-2.0). 0.5 is neutral, higher values increase expressiveness. Extreme values may be unstable.
   */
  exaggeration?: number;
  /**
   * Voice
   *
   * Language code for synthesis. In case using custom please provide audio url and select custom_audio_language.
   */
  voice?: string;
  /**
   * Temperature
   *
   * Controls randomness and variation in generation (0.05-5.0). Higher values create more varied speech patterns.
   */
  temperature?: number;
  /**
   * Seed
   *
   * Random seed for reproducible results. Set to 0 for random generation, or provide a specific number for consistent outputs.
   */
  seed?: number;
  /**
   * CFG Scale
   *
   * Configuration/pace weight controlling generation guidance (0.0-1.0). Use 0.0 for language transfer to mitigate accent inheritance.
   */
  cfg_scale?: number;
};

/**
 * TTSOutput
 */
export type KlingVideoV1TtsOutput = {
  /**
   * Audio
   *
   * The generated audio
   */
  audio: File;
};

/**
 * TTSInput
 */
export type KlingVideoV1TtsInput = {
  /**
   * Text
   *
   * The text to be converted to speech
   */
  text: string;
  /**
   * Voice Id
   *
   * The voice ID to use for speech synthesis
   */
  voice_id?:
    | "genshin_vindi2"
    | "zhinen_xuesheng"
    | "AOT"
    | "ai_shatang"
    | "genshin_klee2"
    | "genshin_kirara"
    | "ai_kaiya"
    | "oversea_male1"
    | "ai_chenjiahao_712"
    | "girlfriend_4_speech02"
    | "chat1_female_new-3"
    | "chat_0407_5-1"
    | "cartoon-boy-07"
    | "uk_boy1"
    | "cartoon-girl-01"
    | "PeppaPig_platform"
    | "ai_huangzhong_712"
    | "ai_huangyaoshi_712"
    | "ai_laoguowang_712"
    | "chengshu_jiejie"
    | "you_pingjing"
    | "calm_story1"
    | "uk_man2"
    | "laopopo_speech02"
    | "heainainai_speech02"
    | "reader_en_m-v1"
    | "commercial_lady_en_f-v1"
    | "tiyuxi_xuedi"
    | "tiexin_nanyou"
    | "girlfriend_1_speech02"
    | "girlfriend_2_speech02"
    | "zhuxi_speech02"
    | "uk_oldman3"
    | "dongbeilaotie_speech02"
    | "chongqingxiaohuo_speech02"
    | "chuanmeizi_speech02"
    | "chaoshandashu_speech02"
    | "ai_taiwan_man2_speech02"
    | "xianzhanggui_speech02"
    | "tianjinjiejie_speech02"
    | "diyinnansang_DB_CN_M_04-v2"
    | "yizhipiannan-v1"
    | "guanxiaofang-v2"
    | "tianmeixuemei-v1"
    | "daopianyansang-v1"
    | "mengwa-v1";
  /**
   * Voice Speed
   *
   * Rate of speech
   */
  voice_speed?: number;
};

/**
 * EmotionalStrengths
 */
export type EmotionalStrengths = {
  /**
   * Afraid
   *
   * Strength of fear emotion
   */
  afraid?: number;
  /**
   * Calm
   *
   * Strength of calm emotion
   */
  calm?: number;
  /**
   * Disgusted
   *
   * Strength of disgust emotion
   */
  disgusted?: number;
  /**
   * Angry
   *
   * Strength of anger emotion
   */
  angry?: number;
  /**
   * Sad
   *
   * Strength of sadness emotion
   */
  sad?: number;
  /**
   * Melancholic
   *
   * Strength of melancholic emotion
   */
  melancholic?: number;
  /**
   * Surprised
   *
   * Strength of surprise emotion
   */
  surprised?: number;
  /**
   * Happy
   *
   * Strength of happiness emotion
   */
  happy?: number;
};

/**
 * IndexTTS2Output
 */
export type IndexTts2TextToSpeechOutput = {
  /**
   * Audio
   *
   * The generated audio file in base64 format.
   */
  audio: File;
};

/**
 * IndexTTS2Input
 */
export type IndexTts2TextToSpeechInput = {
  /**
   * Prompt
   *
   * The speech prompt to generate
   */
  prompt: string;
  /**
   * Emotional Strengths
   *
   * The strengths of individual emotions for fine-grained control.
   */
  emotional_strengths?: EmotionalStrengths;
  /**
   * Strength
   *
   * The strength of the emotional style transfer. Higher values result in stronger emotional influence.
   */
  strength?: number;
  /**
   * Emotional Audio Url
   *
   * The emotional reference audio file to extract the style from.
   */
  emotional_audio_url?: string;
  /**
   * Audio Url
   *
   * The audio file to generate the speech from.
   */
  audio_url: string;
  /**
   * Emotion Prompt
   *
   * The emotional prompt to influence the emotional style. Must be used together with should_use_prompt_for_emotion.
   */
  emotion_prompt?: string;
  /**
   * Should Use Prompt For Emotion
   *
   * Whether to use the `prompt` to calculate emotional strengths, if enabled it will overwrite the `emotional_strengths` values. If `emotion_prompt` is provided, it will be used to instead of `prompt` to extract the emotional style.
   */
  should_use_prompt_for_emotion?: boolean;
};

/**
 * TextToSpeechHD26Output
 */
export type MinimaxSpeech26HdOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * TextToSpeechHD26Request
 */
export type MinimaxSpeech26HdInput = {
  /**
   * Prompt
   *
   * Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.
   */
  prompt: string;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Normalization Setting
   *
   * Loudness normalization settings for the audio
   */
  normalization_setting?: LoudnessNormalizationSetting;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * LoudnessNormalizationSetting
 */
export type LoudnessNormalizationSetting = {
  /**
   * Target Range
   *
   * Target loudness range in LU (default 8.0)
   */
  target_range?: number;
  /**
   * Target Loudness
   *
   * Target loudness in LUFS (default -18.0)
   */
  target_loudness?: number;
  /**
   * Enabled
   *
   * Enable loudness normalization for the audio
   */
  enabled?: boolean;
  /**
   * Target Peak
   *
   * Target peak level in dBTP (default -0.5).
   */
  target_peak?: number;
};

/**
 * TextToSpeechTurbo26Output
 */
export type MinimaxSpeech26TurboOutput = {
  /**
   * Duration Ms
   *
   * Duration of the audio in milliseconds
   */
  duration_ms: number;
  /**
   * Audio
   *
   * The generated audio file
   */
  audio: File;
};

/**
 * TextToSpeechTurbo26Request
 */
export type MinimaxSpeech26TurboInput = {
  /**
   * Prompt
   *
   * Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.
   */
  prompt: string;
  /**
   * Language Boost
   *
   * Enhance recognition of specified languages and dialects
   */
  language_boost?:
    | "Chinese"
    | "Chinese,Yue"
    | "English"
    | "Arabic"
    | "Russian"
    | "Spanish"
    | "French"
    | "Portuguese"
    | "German"
    | "Turkish"
    | "Dutch"
    | "Ukrainian"
    | "Vietnamese"
    | "Indonesian"
    | "Japanese"
    | "Italian"
    | "Korean"
    | "Thai"
    | "Polish"
    | "Romanian"
    | "Greek"
    | "Czech"
    | "Finnish"
    | "Hindi"
    | "Bulgarian"
    | "Danish"
    | "Hebrew"
    | "Malay"
    | "Slovak"
    | "Swedish"
    | "Croatian"
    | "Hungarian"
    | "Norwegian"
    | "Slovenian"
    | "Catalan"
    | "Nynorsk"
    | "Afrikaans"
    | "auto";
  /**
   * Output Format
   *
   * Format of the output content (non-streaming only)
   */
  output_format?: "url" | "hex";
  /**
   * Pronunciation Dict
   *
   * Custom pronunciation dictionary for text replacement
   */
  pronunciation_dict?: PronunciationDict;
  /**
   * Voice Setting
   *
   * Voice configuration settings
   */
  voice_setting?: VoiceSetting;
  /**
   * Normalization Setting
   *
   * Loudness normalization settings for the audio
   */
  normalization_setting?: LoudnessNormalizationSetting;
  /**
   * Audio Setting
   *
   * Audio configuration settings
   */
  audio_setting?: AudioSetting;
};

/**
 * MayaVoiceOutput
 *
 * Output schema for Maya-1-Voice TTS generation
 */
export type MayaOutput = {
  /**
   * Rtf
   *
   * Real-time factor (generation_time / audio_duration). Lower is better.
   */
  rtf: number;
  /**
   * Duration
   *
   * Duration of the generated audio in seconds
   */
  duration: number;
  /**
   * Sample Rate
   *
   * Sample rate of the generated audio
   */
  sample_rate: string;
  /**
   * Generation Time
   *
   * Time taken to generate the audio in seconds
   */
  generation_time: number;
  audio: FileType2;
};

/**
 * MayaVoiceInput
 *
 * Input schema for Maya-1-Voice TTS generation
 */
export type MayaInput = {
  /**
   * Repetition Penalty
   *
   * Penalty for repeating tokens. Higher values reduce repetition artifacts.
   */
  repetition_penalty?: number;
  /**
   * Prompt
   *
   * Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.
   */
  prompt: string;
  /**
   * Top P
   *
   * Nucleus sampling parameter. Controls diversity of token selection.
   */
  top_p?: number;
  /**
   * Text
   *
   * The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'
   */
  text: string;
  /**
   * Output Format
   *
   * Output audio format for the generated speech
   */
  output_format?: "wav" | "mp3";
  /**
   * Max Tokens
   *
   * Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.
   */
  max_tokens?: number;
  /**
   * Temperature
   *
   * Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.
   */
  temperature?: number;
  /**
   * Sample Rate
   *
   * Output audio sample rate. 48 kHz provides higher quality audio, 24 kHz is faster.
   */
  sample_rate?: "48 kHz" | "24 kHz";
};

export type MayaStreamOutput = unknown;

/**
 * MayaVoiceStreamingInput
 *
 * Input schema for Maya-1-Voice streaming TTS generation
 */
export type MayaStreamInput = {
  /**
   * Repetition Penalty
   *
   * Penalty for repeating tokens. Higher values reduce repetition artifacts.
   */
  repetition_penalty?: number;
  /**
   * Prompt
   *
   * Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.
   */
  prompt: string;
  /**
   * Top P
   *
   * Nucleus sampling parameter. Controls diversity of token selection.
   */
  top_p?: number;
  /**
   * Text
   *
   * The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'
   */
  text: string;
  /**
   * Output Format
   *
   * Output audio format. 'mp3' for browser-playable audio, 'wav' for uncompressed audio, 'pcm' for raw PCM (lowest latency, requires client-side decoding).
   */
  output_format?: "mp3" | "wav" | "pcm";
  /**
   * Max Tokens
   *
   * Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.
   */
  max_tokens?: number;
  /**
   * Temperature
   *
   * Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.
   */
  temperature?: number;
  /**
   * Sample Rate
   *
   * Output audio sample rate. 48 kHz uses upsampling for higher quality audio, 24 kHz is native SNAC output (faster, lower latency).
   */
  sample_rate?: "48 kHz" | "24 kHz";
};

/**
 * MayaVoiceBatchOutput
 *
 * Output schema for batch Maya-1-Voice TTS generation
 */
export type MayaBatchOutput = {
  /**
   * Average Rtf
   *
   * Average real-time factor across all generations
   */
  average_rtf: number;
  /**
   * Sample Rate
   *
   * Sample rate of all generated audio files
   */
  sample_rate: string;
  /**
   * Total Generation Time
   *
   * Total time taken to generate all audio files in seconds
   */
  total_generation_time: number;
  /**
   * Audios
   *
   * List of generated audio files
   */
  audios: Array<FileType2>;
  /**
   * Durations
   *
   * Duration of each generated audio in seconds
   */
  durations: Array<number>;
};

/**
 * MayaVoiceBatchInput
 *
 * Input schema for batch Maya-1-Voice TTS generation
 */
export type MayaBatchInput = {
  /**
   * Repetition Penalty
   *
   * Repetition penalty for all generations.
   */
  repetition_penalty?: number;
  /**
   * Top P
   *
   * Nucleus sampling parameter for all generations.
   */
  top_p?: number;
  /**
   * Output Format
   *
   * Output audio format for all generated speech files
   */
  output_format?: "wav" | "mp3";
  /**
   * Texts
   *
   * List of texts to synthesize into speech. You can embed emotion tags in each text using the format <emotion_name>.
   */
  texts: Array<string>;
  /**
   * Prompts
   *
   * List of voice descriptions for each text. Must match the length of texts list. Each describes the voice/character attributes.
   */
  prompts: Array<string>;
  /**
   * Max Tokens
   *
   * Maximum SNAC tokens per generation.
   */
  max_tokens?: number;
  /**
   * Temperature
   *
   * Sampling temperature for all generations.
   */
  temperature?: number;
  /**
   * Sample Rate
   *
   * Output audio sample rate for all generations. 48 kHz provides higher quality, 24 kHz is faster.
   */
  sample_rate?: "48 kHz" | "24 kHz";
};

/**
 * VibeVoice_0_5BOutput
 *
 * Output schema for VibeVoice-0.5b TTS generation
 */
export type Vibevoice05bOutput = {
  /**
   * Duration
   *
   * Duration of the generated audio in seconds
   */
  duration: number;
  /**
   * Rtf
   *
   * Real-time factor (generation_time / audio_duration). Lower is better.
   */
  rtf: number;
  /**
   * Sample Rate
   *
   * Sample rate of the generated audio
   */
  sample_rate: number;
  /**
   * Generation Time
   *
   * Time taken to generate the audio in seconds
   */
  generation_time: number;
  /**
   * Audio
   *
   * The generated audio file containing the speech
   */
  audio: File;
};

/**
 * VibeVoice0_5bInput
 *
 * Input schema for VibeVoice-0.5b TTS generation
 */
export type Vibevoice05bInput = {
  /**
   * Script
   *
   * The script to convert to speech.
   */
  script: string;
  /**
   * Seed
   *
   * Random seed for reproducible generation.
   */
  seed?: number;
  /**
   * Speaker
   *
   * Voice to use for speaking.
   */
  speaker: "Frank" | "Wayne" | "Carter" | "Emma" | "Grace" | "Mike";
  /**
   * CFG Scale
   *
   * CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.
   */
  cfg_scale?: number;
};

/**
 * Qwen3TTSOutput06b
 */
export type Qwen3TtsTextToSpeech06bOutput = {
  /**
   * Audio
   *
   * The generated speech audio file.
   */
  audio: AudioFile;
};

/**
 * AudioFile
 */
export type AudioFile = {
  /**
   * File Size
   *
   * The size of the file in bytes.
   */
  file_size?: number;
  /**
   * Duration
   *
   * The duration of the audio
   */
  duration?: number;
  /**
   * File Data
   *
   * File data
   */
  file_data?: Blob | File;
  /**
   * Channels
   *
   * The number of channels in the audio
   */
  channels?: number;
  /**
   * Url
   *
   * The URL where the file can be downloaded from.
   */
  url: string;
  /**
   * File Name
   *
   * The name of the file. It will be auto-generated if not provided.
   */
  file_name?: string;
  /**
   * Sample Rate
   *
   * The sample rate of the audio
   */
  sample_rate?: number;
  /**
   * Content Type
   *
   * The mime type of the file.
   */
  content_type?: string;
  /**
   * Bitrate
   *
   * The bitrate of the audio (e.g., '192k' or 192000)
   */
  bitrate?: string | number;
};

/**
 * Qwen3TTSInput06b
 */
export type Qwen3TtsTextToSpeech06bInput = {
  /**
   * Prompt
   *
   * Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided.
   */
  prompt?: string;
  /**
   * Speaker Voice Embedding File Url
   *
   * URL to a speaker embedding file in safetensors format, from `fal-ai/qwen-3-tts/clone-voice/0.6b` endpoint. If provided, the TTS model will use the cloned voice for synthesis instead of the predefined voices.
   */
  speaker_voice_embedding_file_url?: string;
  /**
   * Top P
   *
   * Top-p sampling parameter.
   */
  top_p?: number;
  /**
   * Repetition Penalty
   *
   * Penalty to reduce repeated tokens/codes.
   */
  repetition_penalty?: number;
  /**
   * Subtalker Temperature
   *
   * Temperature for sub-talker sampling.
   */
  subtalker_temperature?: number;
  /**
   * Top K
   *
   * Top-k sampling parameter.
   */
  top_k?: number;
  /**
   * Voice
   *
   * The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support.
   */
  voice?:
    | "Vivian"
    | "Serena"
    | "Uncle_Fu"
    | "Dylan"
    | "Eric"
    | "Ryan"
    | "Aiden"
    | "Ono_Anna"
    | "Sohee";
  /**
   * Reference Text
   *
   * Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice.
   */
  reference_text?: string;
  /**
   * Temperature
   *
   * Sampling temperature; higher => more random.
   */
  temperature?: number;
  /**
   * Language
   *
   * The language of the voice.
   */
  language?:
    | "Auto"
    | "English"
    | "Chinese"
    | "Spanish"
    | "French"
    | "German"
    | "Italian"
    | "Japanese"
    | "Korean"
    | "Portuguese"
    | "Russian";
  /**
   * Subtalker Top K
   *
   * Top-k for sub-talker sampling.
   */
  subtalker_top_k?: number;
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string;
  /**
   * Max New Tokens
   *
   * Maximum number of new codec tokens to generate.
   */
  max_new_tokens?: number;
  /**
   * Subtalker Dosample
   *
   * Sampling switch for the sub-talker.
   */
  subtalker_dosample?: boolean;
  /**
   * Subtalker Top P
   *
   * Top-p for sub-talker sampling.
   */
  subtalker_top_p?: number;
};

/**
 * Qwen3TTSOutput
 */
export type Qwen3TtsTextToSpeech17bOutput = {
  /**
   * Audio
   *
   * The generated speech audio file.
   */
  audio: AudioFile;
};

/**
 * Qwen3TTSInput
 */
export type Qwen3TtsTextToSpeech17bInput = {
  /**
   * Prompt
   *
   * Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided.
   */
  prompt?: string;
  /**
   * Speaker Voice Embedding File Url
   *
   * URL to a speaker embedding file in safetensors format, from `fal-ai/qwen-3-tts/clone-voice` endpoint. If provided, the TTS model will use the cloned voice for synthesis instead of the predefined voices.
   */
  speaker_voice_embedding_file_url?: string;
  /**
   * Top P
   *
   * Top-p sampling parameter.
   */
  top_p?: number;
  /**
   * Repetition Penalty
   *
   * Penalty to reduce repeated tokens/codes.
   */
  repetition_penalty?: number;
  /**
   * Subtalker Temperature
   *
   * Temperature for sub-talker sampling.
   */
  subtalker_temperature?: number;
  /**
   * Top K
   *
   * Top-k sampling parameter.
   */
  top_k?: number;
  /**
   * Voice
   *
   * The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support.
   */
  voice?:
    | "Vivian"
    | "Serena"
    | "Uncle_Fu"
    | "Dylan"
    | "Eric"
    | "Ryan"
    | "Aiden"
    | "Ono_Anna"
    | "Sohee";
  /**
   * Reference Text
   *
   * Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice.
   */
  reference_text?: string;
  /**
   * Temperature
   *
   * Sampling temperature; higher => more random.
   */
  temperature?: number;
  /**
   * Language
   *
   * The language of the voice.
   */
  language?:
    | "Auto"
    | "English"
    | "Chinese"
    | "Spanish"
    | "French"
    | "German"
    | "Italian"
    | "Japanese"
    | "Korean"
    | "Portuguese"
    | "Russian";
  /**
   * Subtalker Top K
   *
   * Top-k for sub-talker sampling.
   */
  subtalker_top_k?: number;
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string;
  /**
   * Max New Tokens
   *
   * Maximum number of new codec tokens to generate.
   */
  max_new_tokens?: number;
  /**
   * Subtalker Dosample
   *
   * Sampling switch for the sub-talker.
   */
  subtalker_dosample?: boolean;
  /**
   * Subtalker Top P
   *
   * Top-p for sub-talker sampling.
   */
  subtalker_top_p?: number;
};

/**
 * Qwen3DesignVoiceOutput
 */
export type Qwen3TtsVoiceDesign17bOutput = {
  /**
   * Audio
   *
   * The generated speech audio file.
   */
  audio: AudioFile;
};

/**
 * Qwen3DesignVoiceInput
 */
export type Qwen3TtsVoiceDesign17bInput = {
  /**
   * Repetition Penalty
   *
   * Penalty to reduce repeated tokens/codes.
   */
  repetition_penalty?: number;
  /**
   * Subtalker Top K
   *
   * Top-k for sub-talker sampling.
   */
  subtalker_top_k?: number;
  /**
   * Top P
   *
   * Top-p sampling parameter.
   */
  top_p?: number;
  /**
   * Prompt
   *
   * Optional prompt to guide the style of the generated speech.
   */
  prompt: string;
  /**
   * Max New Tokens
   *
   * Maximum number of new codec tokens to generate.
   */
  max_new_tokens?: number;
  /**
   * Text
   *
   * The text to be converted to speech.
   */
  text: string;
  /**
   * Language
   *
   * The language of the voice to be designed.
   */
  language?:
    | "Auto"
    | "English"
    | "Chinese"
    | "Spanish"
    | "French"
    | "German"
    | "Italian"
    | "Japanese"
    | "Korean"
    | "Portuguese"
    | "Russian";
  /**
   * Top K
   *
   * Top-k sampling parameter.
   */
  top_k?: number;
  /**
   * Subtalker Dosample
   *
   * Sampling switch for the sub-talker.
   */
  subtalker_dosample?: boolean;
  /**
   * Subtalker Temperature
   *
   * Temperature for sub-talker sampling.
   */
  subtalker_temperature?: number;
  /**
   * Subtalker Top P
   *
   * Top-p for sub-talker sampling.
   */
  subtalker_top_p?: number;
  /**
   * Temperature
   *
   * Sampling temperature; higher => more random.
   */
  temperature?: number;
};

/**
 * ChatterboxOutput
 */
export type ChatterboxSpeechToSpeechOutput = {
  /**
   * Audio
   *
   * The generated speech audio
   */
  audio: File;
};

/**
 * ChatterboxVCRequest
 */
export type ChatterboxSpeechToSpeechInput = {
  /**
   * Source Audio Url
   */
  source_audio_url: string;
  /**
   * Target Voice Audio Url
   *
   * Optional URL to an audio file to use as a reference for the generated speech. If provided, the model will try to match the style and tone of the reference audio.
   */
  target_voice_audio_url?: string;
};

/**
 * STSOutput
 *
 * Output parameters for the speech-to-speech request.
 */
export type ChatterboxhdSpeechToSpeechOutput = {
  /**
   * Audio
   *
   * The generated voice-converted audio file.
   */
  audio: Audio;
};

/**
 * STSInput
 *
 * Input parameters for the speech-to-speech request.
 */
export type ChatterboxhdSpeechToSpeechInput = {
  /**
   * High Quality Audio
   *
   * If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz.
   */
  high_quality_audio?: boolean;
  /**
   * Target Voice Audio Url
   *
   * URL to the audio file which represents the voice of the output audio. If provided, this will override the target_voice setting. If neither target_voice nor target_voice_audio_url are provided, the default target voice will be used.
   */
  target_voice_audio_url?: string;
  /**
   * Source Audio Url
   *
   * URL to the source audio file to be voice-converted.
   */
  source_audio_url: string;
  /**
   * Target Voice
   *
   * The voice to use for the speech-to-speech request. If neither target_voice nor target_voice_audio_url are provided, a random target voice will be used.
   */
  target_voice?:
    | "Aurora"
    | "Blade"
    | "Britney"
    | "Carl"
    | "Cliff"
    | "Richard"
    | "Rico"
    | "Siobhan"
    | "Vicky";
};

export type QueueStatus = {
  status: "IN_QUEUE" | "IN_PROGRESS" | "COMPLETED";
  /**
   * The request id.
   */
  request_id: string;
  /**
   * The response url.
   */
  response_url?: string;
  /**
   * The status url.
   */
  status_url?: string;
  /**
   * The cancel url.
   */
  cancel_url?: string;
  /**
   * The logs.
   */
  logs?: {
    [key: string]: unknown;
  };
  /**
   * The metrics.
   */
  metrics?: {
    [key: string]: unknown;
  };
  /**
   * The queue position.
   */
  queue_position?: number;
};

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/resemble-ai/chatterboxhd/speech-to-speech/requests/{request_id}/status";
  };

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusResponse =
  GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusResponses[keyof GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusResponses];

export type PutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/resemble-ai/chatterboxhd/speech-to-speech/requests/{request_id}/cancel";
  };

export type PutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelResponse =
  PutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelResponses[keyof PutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelResponses];

export type PostResembleAiChatterboxhdSpeechToSpeechData = {
  body: ChatterboxhdSpeechToSpeechInput;
  path?: never;
  query?: never;
  url: "/resemble-ai/chatterboxhd/speech-to-speech";
};

export type PostResembleAiChatterboxhdSpeechToSpeechResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostResembleAiChatterboxhdSpeechToSpeechResponse =
  PostResembleAiChatterboxhdSpeechToSpeechResponses[keyof PostResembleAiChatterboxhdSpeechToSpeechResponses];

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/resemble-ai/chatterboxhd/speech-to-speech/requests/{request_id}";
};

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ChatterboxhdSpeechToSpeechOutput;
  };

export type GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdResponse =
  GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdResponses[keyof GetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdResponses];

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/chatterbox/speech-to-speech/requests/{request_id}/status";
};

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusResponse =
  GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusResponses[keyof GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusResponses];

export type PutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chatterbox/speech-to-speech/requests/{request_id}/cancel";
};

export type PutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelResponse =
  PutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelResponses[keyof PutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelResponses];

export type PostFalAiChatterboxSpeechToSpeechData = {
  body: ChatterboxSpeechToSpeechInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chatterbox/speech-to-speech";
};

export type PostFalAiChatterboxSpeechToSpeechResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChatterboxSpeechToSpeechResponse =
  PostFalAiChatterboxSpeechToSpeechResponses[keyof PostFalAiChatterboxSpeechToSpeechResponses];

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chatterbox/speech-to-speech/requests/{request_id}";
};

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ChatterboxSpeechToSpeechOutput;
};

export type GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdResponse =
  GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdResponses[keyof GetFalAiChatterboxSpeechToSpeechRequestsByRequestIdResponses];

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-3-tts/voice-design/1.7b/requests/{request_id}/status";
};

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusResponse =
  GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusResponses[keyof GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusResponses];

export type PutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/voice-design/1.7b/requests/{request_id}/cancel";
};

export type PutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelResponse =
  PutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelResponses[keyof PutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelResponses];

export type PostFalAiQwen3TtsVoiceDesign17bData = {
  body: Qwen3TtsVoiceDesign17bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-3-tts/voice-design/1.7b";
};

export type PostFalAiQwen3TtsVoiceDesign17bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwen3TtsVoiceDesign17bResponse =
  PostFalAiQwen3TtsVoiceDesign17bResponses[keyof PostFalAiQwen3TtsVoiceDesign17bResponses];

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/voice-design/1.7b/requests/{request_id}";
};

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Qwen3TtsVoiceDesign17bOutput;
};

export type GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdResponse =
  GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdResponses[keyof GetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdResponses];

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-3-tts/text-to-speech/1.7b/requests/{request_id}/status";
};

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusResponse =
  GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusResponses[keyof GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusResponses];

export type PutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/1.7b/requests/{request_id}/cancel";
};

export type PutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelResponse =
  PutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelResponses[keyof PutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelResponses];

export type PostFalAiQwen3TtsTextToSpeech17bData = {
  body: Qwen3TtsTextToSpeech17bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/1.7b";
};

export type PostFalAiQwen3TtsTextToSpeech17bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwen3TtsTextToSpeech17bResponse =
  PostFalAiQwen3TtsTextToSpeech17bResponses[keyof PostFalAiQwen3TtsTextToSpeech17bResponses];

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/1.7b/requests/{request_id}";
};

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Qwen3TtsTextToSpeech17bOutput;
};

export type GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdResponse =
  GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdResponses[keyof GetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdResponses];

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/qwen-3-tts/text-to-speech/0.6b/requests/{request_id}/status";
};

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusResponse =
  GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusResponses[keyof GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusResponses];

export type PutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/0.6b/requests/{request_id}/cancel";
};

export type PutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelResponse =
  PutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelResponses[keyof PutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelResponses];

export type PostFalAiQwen3TtsTextToSpeech06bData = {
  body: Qwen3TtsTextToSpeech06bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/0.6b";
};

export type PostFalAiQwen3TtsTextToSpeech06bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiQwen3TtsTextToSpeech06bResponse =
  PostFalAiQwen3TtsTextToSpeech06bResponses[keyof PostFalAiQwen3TtsTextToSpeech06bResponses];

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/qwen-3-tts/text-to-speech/0.6b/requests/{request_id}";
};

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Qwen3TtsTextToSpeech06bOutput;
};

export type GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdResponse =
  GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdResponses[keyof GetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdResponses];

export type GetFalAiVibevoice05bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vibevoice/0.5b/requests/{request_id}/status";
};

export type GetFalAiVibevoice05bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiVibevoice05bRequestsByRequestIdStatusResponse =
  GetFalAiVibevoice05bRequestsByRequestIdStatusResponses[keyof GetFalAiVibevoice05bRequestsByRequestIdStatusResponses];

export type PutFalAiVibevoice05bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/0.5b/requests/{request_id}/cancel";
};

export type PutFalAiVibevoice05bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiVibevoice05bRequestsByRequestIdCancelResponse =
  PutFalAiVibevoice05bRequestsByRequestIdCancelResponses[keyof PutFalAiVibevoice05bRequestsByRequestIdCancelResponses];

export type PostFalAiVibevoice05bData = {
  body: Vibevoice05bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vibevoice/0.5b";
};

export type PostFalAiVibevoice05bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiVibevoice05bResponse =
  PostFalAiVibevoice05bResponses[keyof PostFalAiVibevoice05bResponses];

export type GetFalAiVibevoice05bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/0.5b/requests/{request_id}";
};

export type GetFalAiVibevoice05bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Vibevoice05bOutput;
};

export type GetFalAiVibevoice05bRequestsByRequestIdResponse =
  GetFalAiVibevoice05bRequestsByRequestIdResponses[keyof GetFalAiVibevoice05bRequestsByRequestIdResponses];

export type GetFalAiMayaBatchRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/maya/batch/requests/{request_id}/status";
};

export type GetFalAiMayaBatchRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMayaBatchRequestsByRequestIdStatusResponse =
  GetFalAiMayaBatchRequestsByRequestIdStatusResponses[keyof GetFalAiMayaBatchRequestsByRequestIdStatusResponses];

export type PutFalAiMayaBatchRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/batch/requests/{request_id}/cancel";
};

export type PutFalAiMayaBatchRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMayaBatchRequestsByRequestIdCancelResponse =
  PutFalAiMayaBatchRequestsByRequestIdCancelResponses[keyof PutFalAiMayaBatchRequestsByRequestIdCancelResponses];

export type PostFalAiMayaBatchData = {
  body: MayaBatchInput;
  path?: never;
  query?: never;
  url: "/fal-ai/maya/batch";
};

export type PostFalAiMayaBatchResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMayaBatchResponse =
  PostFalAiMayaBatchResponses[keyof PostFalAiMayaBatchResponses];

export type GetFalAiMayaBatchRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/batch/requests/{request_id}";
};

export type GetFalAiMayaBatchRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MayaBatchOutput;
};

export type GetFalAiMayaBatchRequestsByRequestIdResponse =
  GetFalAiMayaBatchRequestsByRequestIdResponses[keyof GetFalAiMayaBatchRequestsByRequestIdResponses];

export type GetFalAiMayaStreamRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/maya/stream/requests/{request_id}/status";
};

export type GetFalAiMayaStreamRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMayaStreamRequestsByRequestIdStatusResponse =
  GetFalAiMayaStreamRequestsByRequestIdStatusResponses[keyof GetFalAiMayaStreamRequestsByRequestIdStatusResponses];

export type PutFalAiMayaStreamRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/stream/requests/{request_id}/cancel";
};

export type PutFalAiMayaStreamRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMayaStreamRequestsByRequestIdCancelResponse =
  PutFalAiMayaStreamRequestsByRequestIdCancelResponses[keyof PutFalAiMayaStreamRequestsByRequestIdCancelResponses];

export type PostFalAiMayaStreamData = {
  body: MayaStreamInput;
  path?: never;
  query?: never;
  url: "/fal-ai/maya/stream";
};

export type PostFalAiMayaStreamResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMayaStreamResponse =
  PostFalAiMayaStreamResponses[keyof PostFalAiMayaStreamResponses];

export type GetFalAiMayaStreamRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/stream/requests/{request_id}";
};

export type GetFalAiMayaStreamRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MayaStreamOutput;
};

export type GetFalAiMayaStreamRequestsByRequestIdResponse =
  GetFalAiMayaStreamRequestsByRequestIdResponses[keyof GetFalAiMayaStreamRequestsByRequestIdResponses];

export type GetFalAiMayaRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/maya/requests/{request_id}/status";
};

export type GetFalAiMayaRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMayaRequestsByRequestIdStatusResponse =
  GetFalAiMayaRequestsByRequestIdStatusResponses[keyof GetFalAiMayaRequestsByRequestIdStatusResponses];

export type PutFalAiMayaRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/requests/{request_id}/cancel";
};

export type PutFalAiMayaRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMayaRequestsByRequestIdCancelResponse =
  PutFalAiMayaRequestsByRequestIdCancelResponses[keyof PutFalAiMayaRequestsByRequestIdCancelResponses];

export type PostFalAiMayaData = {
  body: MayaInput;
  path?: never;
  query?: never;
  url: "/fal-ai/maya";
};

export type PostFalAiMayaResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMayaResponse =
  PostFalAiMayaResponses[keyof PostFalAiMayaResponses];

export type GetFalAiMayaRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/maya/requests/{request_id}";
};

export type GetFalAiMayaRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MayaOutput;
};

export type GetFalAiMayaRequestsByRequestIdResponse =
  GetFalAiMayaRequestsByRequestIdResponses[keyof GetFalAiMayaRequestsByRequestIdResponses];

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/speech-2.6-turbo/requests/{request_id}/status";
};

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-turbo/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxSpeech26TurboData = {
  body: MinimaxSpeech26TurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-turbo";
};

export type PostFalAiMinimaxSpeech26TurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxSpeech26TurboResponse =
  PostFalAiMinimaxSpeech26TurboResponses[keyof PostFalAiMinimaxSpeech26TurboResponses];

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-turbo/requests/{request_id}";
};

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxSpeech26TurboOutput;
};

export type GetFalAiMinimaxSpeech26TurboRequestsByRequestIdResponse =
  GetFalAiMinimaxSpeech26TurboRequestsByRequestIdResponses[keyof GetFalAiMinimaxSpeech26TurboRequestsByRequestIdResponses];

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/speech-2.6-hd/requests/{request_id}/status";
};

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-hd/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxSpeech26HdData = {
  body: MinimaxSpeech26HdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-hd";
};

export type PostFalAiMinimaxSpeech26HdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxSpeech26HdResponse =
  PostFalAiMinimaxSpeech26HdResponses[keyof PostFalAiMinimaxSpeech26HdResponses];

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-2.6-hd/requests/{request_id}";
};

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxSpeech26HdOutput;
};

export type GetFalAiMinimaxSpeech26HdRequestsByRequestIdResponse =
  GetFalAiMinimaxSpeech26HdRequestsByRequestIdResponses[keyof GetFalAiMinimaxSpeech26HdRequestsByRequestIdResponses];

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/index-tts-2/text-to-speech/requests/{request_id}/status";
};

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusResponse =
  GetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusResponses[keyof GetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusResponses];

export type PutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/index-tts-2/text-to-speech/requests/{request_id}/cancel";
};

export type PutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelResponse =
  PutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelResponses[keyof PutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelResponses];

export type PostFalAiIndexTts2TextToSpeechData = {
  body: IndexTts2TextToSpeechInput;
  path?: never;
  query?: never;
  url: "/fal-ai/index-tts-2/text-to-speech";
};

export type PostFalAiIndexTts2TextToSpeechResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiIndexTts2TextToSpeechResponse =
  PostFalAiIndexTts2TextToSpeechResponses[keyof PostFalAiIndexTts2TextToSpeechResponses];

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/index-tts-2/text-to-speech/requests/{request_id}";
};

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: IndexTts2TextToSpeechOutput;
};

export type GetFalAiIndexTts2TextToSpeechRequestsByRequestIdResponse =
  GetFalAiIndexTts2TextToSpeechRequestsByRequestIdResponses[keyof GetFalAiIndexTts2TextToSpeechRequestsByRequestIdResponses];

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/kling-video/v1/tts/requests/{request_id}/status";
};

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdStatusResponse =
  GetFalAiKlingVideoV1TtsRequestsByRequestIdStatusResponses[keyof GetFalAiKlingVideoV1TtsRequestsByRequestIdStatusResponses];

export type PutFalAiKlingVideoV1TtsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/v1/tts/requests/{request_id}/cancel";
};

export type PutFalAiKlingVideoV1TtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiKlingVideoV1TtsRequestsByRequestIdCancelResponse =
  PutFalAiKlingVideoV1TtsRequestsByRequestIdCancelResponses[keyof PutFalAiKlingVideoV1TtsRequestsByRequestIdCancelResponses];

export type PostFalAiKlingVideoV1TtsData = {
  body: KlingVideoV1TtsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/kling-video/v1/tts";
};

export type PostFalAiKlingVideoV1TtsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiKlingVideoV1TtsResponse =
  PostFalAiKlingVideoV1TtsResponses[keyof PostFalAiKlingVideoV1TtsResponses];

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/kling-video/v1/tts/requests/{request_id}";
};

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: KlingVideoV1TtsOutput;
};

export type GetFalAiKlingVideoV1TtsRequestsByRequestIdResponse =
  GetFalAiKlingVideoV1TtsRequestsByRequestIdResponses[keyof GetFalAiKlingVideoV1TtsRequestsByRequestIdResponses];

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/fal-ai/chatterbox/text-to-speech/multilingual/requests/{request_id}/status";
  };

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusResponse =
  GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusResponses[keyof GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusResponses];

export type PutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/chatterbox/text-to-speech/multilingual/requests/{request_id}/cancel";
  };

export type PutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelResponse =
  PutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelResponses[keyof PutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelResponses];

export type PostFalAiChatterboxTextToSpeechMultilingualData = {
  body: ChatterboxTextToSpeechMultilingualInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chatterbox/text-to-speech/multilingual";
};

export type PostFalAiChatterboxTextToSpeechMultilingualResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChatterboxTextToSpeechMultilingualResponse =
  PostFalAiChatterboxTextToSpeechMultilingualResponses[keyof PostFalAiChatterboxTextToSpeechMultilingualResponses];

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/fal-ai/chatterbox/text-to-speech/multilingual/requests/{request_id}";
  };

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ChatterboxTextToSpeechMultilingualOutput;
  };

export type GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdResponse =
  GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdResponses[keyof GetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdResponses];

export type GetFalAiVibevoice7bRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vibevoice/7b/requests/{request_id}/status";
};

export type GetFalAiVibevoice7bRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiVibevoice7bRequestsByRequestIdStatusResponse =
  GetFalAiVibevoice7bRequestsByRequestIdStatusResponses[keyof GetFalAiVibevoice7bRequestsByRequestIdStatusResponses];

export type PutFalAiVibevoice7bRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/7b/requests/{request_id}/cancel";
};

export type PutFalAiVibevoice7bRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiVibevoice7bRequestsByRequestIdCancelResponse =
  PutFalAiVibevoice7bRequestsByRequestIdCancelResponses[keyof PutFalAiVibevoice7bRequestsByRequestIdCancelResponses];

export type PostFalAiVibevoice7bData = {
  body: Vibevoice7bInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vibevoice/7b";
};

export type PostFalAiVibevoice7bResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiVibevoice7bResponse =
  PostFalAiVibevoice7bResponses[keyof PostFalAiVibevoice7bResponses];

export type GetFalAiVibevoice7bRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/7b/requests/{request_id}";
};

export type GetFalAiVibevoice7bRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: Vibevoice7bOutput;
};

export type GetFalAiVibevoice7bRequestsByRequestIdResponse =
  GetFalAiVibevoice7bRequestsByRequestIdResponses[keyof GetFalAiVibevoice7bRequestsByRequestIdResponses];

export type GetFalAiVibevoiceRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/vibevoice/requests/{request_id}/status";
};

export type GetFalAiVibevoiceRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiVibevoiceRequestsByRequestIdStatusResponse =
  GetFalAiVibevoiceRequestsByRequestIdStatusResponses[keyof GetFalAiVibevoiceRequestsByRequestIdStatusResponses];

export type PutFalAiVibevoiceRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/requests/{request_id}/cancel";
};

export type PutFalAiVibevoiceRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiVibevoiceRequestsByRequestIdCancelResponse =
  PutFalAiVibevoiceRequestsByRequestIdCancelResponses[keyof PutFalAiVibevoiceRequestsByRequestIdCancelResponses];

export type PostFalAiVibevoiceData = {
  body: VibevoiceInput;
  path?: never;
  query?: never;
  url: "/fal-ai/vibevoice";
};

export type PostFalAiVibevoiceResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiVibevoiceResponse =
  PostFalAiVibevoiceResponses[keyof PostFalAiVibevoiceResponses];

export type GetFalAiVibevoiceRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/vibevoice/requests/{request_id}";
};

export type GetFalAiVibevoiceRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: VibevoiceOutput;
};

export type GetFalAiVibevoiceRequestsByRequestIdResponse =
  GetFalAiVibevoiceRequestsByRequestIdResponses[keyof GetFalAiVibevoiceRequestsByRequestIdResponses];

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/preview/speech-2.5-hd/requests/{request_id}/status";
};

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-hd/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxPreviewSpeech25HdData = {
  body: MinimaxPreviewSpeech25HdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-hd";
};

export type PostFalAiMinimaxPreviewSpeech25HdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxPreviewSpeech25HdResponse =
  PostFalAiMinimaxPreviewSpeech25HdResponses[keyof PostFalAiMinimaxPreviewSpeech25HdResponses];

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-hd/requests/{request_id}";
};

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxPreviewSpeech25HdOutput;
};

export type GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdResponse =
  GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdResponses[keyof GetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdResponses];

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/preview/speech-2.5-turbo/requests/{request_id}/status";
};

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-turbo/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxPreviewSpeech25TurboData = {
  body: MinimaxPreviewSpeech25TurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-turbo";
};

export type PostFalAiMinimaxPreviewSpeech25TurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxPreviewSpeech25TurboResponse =
  PostFalAiMinimaxPreviewSpeech25TurboResponses[keyof PostFalAiMinimaxPreviewSpeech25TurboResponses];

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/preview/speech-2.5-turbo/requests/{request_id}";
};

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxPreviewSpeech25TurboOutput;
};

export type GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdResponse =
  GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdResponses[keyof GetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdResponses];

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/voice-design/requests/{request_id}/status";
};

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/voice-design/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxVoiceDesignData = {
  body: MinimaxVoiceDesignInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/voice-design";
};

export type PostFalAiMinimaxVoiceDesignResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxVoiceDesignResponse =
  PostFalAiMinimaxVoiceDesignResponses[keyof PostFalAiMinimaxVoiceDesignResponses];

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/voice-design/requests/{request_id}";
};

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxVoiceDesignOutput;
};

export type GetFalAiMinimaxVoiceDesignRequestsByRequestIdResponse =
  GetFalAiMinimaxVoiceDesignRequestsByRequestIdResponses[keyof GetFalAiMinimaxVoiceDesignRequestsByRequestIdResponses];

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: {
      /**
       * Whether to include logs (`1`) in the response or not (`0`).
       */
      logs?: number;
    };
    url: "/resemble-ai/chatterboxhd/text-to-speech/requests/{request_id}/status";
  };

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusResponses =
  {
    /**
     * The request status.
     */
    200: QueueStatus;
  };

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusResponse =
  GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusResponses[keyof GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusResponses];

export type PutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelData =
  {
    body?: never;
    path: {
      /**
       * Request ID
       */
      request_id: string;
    };
    query?: never;
    url: "/resemble-ai/chatterboxhd/text-to-speech/requests/{request_id}/cancel";
  };

export type PutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelResponses =
  {
    /**
     * The request was cancelled.
     */
    200: {
      /**
       * Whether the request was cancelled successfully.
       */
      success?: boolean;
    };
  };

export type PutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelResponse =
  PutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelResponses[keyof PutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelResponses];

export type PostResembleAiChatterboxhdTextToSpeechData = {
  body: ChatterboxhdTextToSpeechInput;
  path?: never;
  query?: never;
  url: "/resemble-ai/chatterboxhd/text-to-speech";
};

export type PostResembleAiChatterboxhdTextToSpeechResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostResembleAiChatterboxhdTextToSpeechResponse =
  PostResembleAiChatterboxhdTextToSpeechResponses[keyof PostResembleAiChatterboxhdTextToSpeechResponses];

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/resemble-ai/chatterboxhd/text-to-speech/requests/{request_id}";
};

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdResponses =
  {
    /**
     * Result of the request.
     */
    200: ChatterboxhdTextToSpeechOutput;
  };

export type GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdResponse =
  GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdResponses[keyof GetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdResponses];

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/chatterbox/text-to-speech/requests/{request_id}/status";
};

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusResponse =
  GetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusResponses[keyof GetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusResponses];

export type PutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chatterbox/text-to-speech/requests/{request_id}/cancel";
};

export type PutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelResponse =
  PutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelResponses[keyof PutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelResponses];

export type PostFalAiChatterboxTextToSpeechData = {
  body: ChatterboxTextToSpeechInput;
  path?: never;
  query?: never;
  url: "/fal-ai/chatterbox/text-to-speech";
};

export type PostFalAiChatterboxTextToSpeechResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiChatterboxTextToSpeechResponse =
  PostFalAiChatterboxTextToSpeechResponses[keyof PostFalAiChatterboxTextToSpeechResponses];

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/chatterbox/text-to-speech/requests/{request_id}";
};

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ChatterboxTextToSpeechOutput;
};

export type GetFalAiChatterboxTextToSpeechRequestsByRequestIdResponse =
  GetFalAiChatterboxTextToSpeechRequestsByRequestIdResponses[keyof GetFalAiChatterboxTextToSpeechRequestsByRequestIdResponses];

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/voice-clone/requests/{request_id}/status";
};

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/voice-clone/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxVoiceCloneData = {
  body: MinimaxVoiceCloneInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/voice-clone";
};

export type PostFalAiMinimaxVoiceCloneResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxVoiceCloneResponse =
  PostFalAiMinimaxVoiceCloneResponses[keyof PostFalAiMinimaxVoiceCloneResponses];

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/voice-clone/requests/{request_id}";
};

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxVoiceCloneOutput;
};

export type GetFalAiMinimaxVoiceCloneRequestsByRequestIdResponse =
  GetFalAiMinimaxVoiceCloneRequestsByRequestIdResponses[keyof GetFalAiMinimaxVoiceCloneRequestsByRequestIdResponses];

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/speech-02-turbo/requests/{request_id}/status";
};

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-02-turbo/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxSpeech02TurboData = {
  body: MinimaxSpeech02TurboInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/speech-02-turbo";
};

export type PostFalAiMinimaxSpeech02TurboResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxSpeech02TurboResponse =
  PostFalAiMinimaxSpeech02TurboResponses[keyof PostFalAiMinimaxSpeech02TurboResponses];

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-02-turbo/requests/{request_id}";
};

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxSpeech02TurboOutput;
};

export type GetFalAiMinimaxSpeech02TurboRequestsByRequestIdResponse =
  GetFalAiMinimaxSpeech02TurboRequestsByRequestIdResponses[keyof GetFalAiMinimaxSpeech02TurboRequestsByRequestIdResponses];

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/minimax/speech-02-hd/requests/{request_id}/status";
};

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusResponse =
  GetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusResponses[keyof GetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusResponses];

export type PutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-02-hd/requests/{request_id}/cancel";
};

export type PutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelResponse =
  PutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelResponses[keyof PutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelResponses];

export type PostFalAiMinimaxSpeech02HdData = {
  body: MinimaxSpeech02HdInput;
  path?: never;
  query?: never;
  url: "/fal-ai/minimax/speech-02-hd";
};

export type PostFalAiMinimaxSpeech02HdResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiMinimaxSpeech02HdResponse =
  PostFalAiMinimaxSpeech02HdResponses[keyof PostFalAiMinimaxSpeech02HdResponses];

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/minimax/speech-02-hd/requests/{request_id}";
};

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: MinimaxSpeech02HdOutput;
};

export type GetFalAiMinimaxSpeech02HdRequestsByRequestIdResponse =
  GetFalAiMinimaxSpeech02HdRequestsByRequestIdResponses[keyof GetFalAiMinimaxSpeech02HdRequestsByRequestIdResponses];

export type GetFalAiDiaTtsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/dia-tts/requests/{request_id}/status";
};

export type GetFalAiDiaTtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiDiaTtsRequestsByRequestIdStatusResponse =
  GetFalAiDiaTtsRequestsByRequestIdStatusResponses[keyof GetFalAiDiaTtsRequestsByRequestIdStatusResponses];

export type PutFalAiDiaTtsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dia-tts/requests/{request_id}/cancel";
};

export type PutFalAiDiaTtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiDiaTtsRequestsByRequestIdCancelResponse =
  PutFalAiDiaTtsRequestsByRequestIdCancelResponses[keyof PutFalAiDiaTtsRequestsByRequestIdCancelResponses];

export type PostFalAiDiaTtsData = {
  body: DiaTtsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/dia-tts";
};

export type PostFalAiDiaTtsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiDiaTtsResponse =
  PostFalAiDiaTtsResponses[keyof PostFalAiDiaTtsResponses];

export type GetFalAiDiaTtsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/dia-tts/requests/{request_id}";
};

export type GetFalAiDiaTtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: DiaTtsOutput;
};

export type GetFalAiDiaTtsRequestsByRequestIdResponse =
  GetFalAiDiaTtsRequestsByRequestIdResponses[keyof GetFalAiDiaTtsRequestsByRequestIdResponses];

export type GetFalAiOrpheusTtsRequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/orpheus-tts/requests/{request_id}/status";
};

export type GetFalAiOrpheusTtsRequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiOrpheusTtsRequestsByRequestIdStatusResponse =
  GetFalAiOrpheusTtsRequestsByRequestIdStatusResponses[keyof GetFalAiOrpheusTtsRequestsByRequestIdStatusResponses];

export type PutFalAiOrpheusTtsRequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/orpheus-tts/requests/{request_id}/cancel";
};

export type PutFalAiOrpheusTtsRequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiOrpheusTtsRequestsByRequestIdCancelResponse =
  PutFalAiOrpheusTtsRequestsByRequestIdCancelResponses[keyof PutFalAiOrpheusTtsRequestsByRequestIdCancelResponses];

export type PostFalAiOrpheusTtsData = {
  body: OrpheusTtsInput;
  path?: never;
  query?: never;
  url: "/fal-ai/orpheus-tts";
};

export type PostFalAiOrpheusTtsResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiOrpheusTtsResponse =
  PostFalAiOrpheusTtsResponses[keyof PostFalAiOrpheusTtsResponses];

export type GetFalAiOrpheusTtsRequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/orpheus-tts/requests/{request_id}";
};

export type GetFalAiOrpheusTtsRequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: OrpheusTtsOutput;
};

export type GetFalAiOrpheusTtsRequestsByRequestIdResponse =
  GetFalAiOrpheusTtsRequestsByRequestIdResponses[keyof GetFalAiOrpheusTtsRequestsByRequestIdResponses];

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: {
    /**
     * Whether to include logs (`1`) in the response or not (`0`).
     */
    logs?: number;
  };
  url: "/fal-ai/elevenlabs/tts/turbo-v2.5/requests/{request_id}/status";
};

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusResponses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusResponse =
  GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusResponses[keyof GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusResponses];

export type PutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/turbo-v2.5/requests/{request_id}/cancel";
};

export type PutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelResponses = {
  /**
   * The request was cancelled.
   */
  200: {
    /**
     * Whether the request was cancelled successfully.
     */
    success?: boolean;
  };
};

export type PutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelResponse =
  PutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelResponses[keyof PutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelResponses];

export type PostFalAiElevenlabsTtsTurboV25Data = {
  body: ElevenlabsTtsTurboV25Input;
  path?: never;
  query?: never;
  url: "/fal-ai/elevenlabs/tts/turbo-v2.5";
};

export type PostFalAiElevenlabsTtsTurboV25Responses = {
  /**
   * The request status.
   */
  200: QueueStatus;
};

export type PostFalAiElevenlabsTtsTurboV25Response =
  PostFalAiElevenlabsTtsTurboV25Responses[keyof PostFalAiElevenlabsTtsTurboV25Responses];

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdData = {
  body?: never;
  path: {
    /**
     * Request ID
     */
    request_id: string;
  };
  query?: never;
  url: "/fal-ai/elevenlabs/tts/turbo-v2.5/requests/{request_id}";
};

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdResponses = {
  /**
   * Result of the request.
   */
  200: ElevenlabsTtsTurboV25Output;
};

export type GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdResponse =
  GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdResponses[keyof GetFalAiElevenlabsTtsTurboV25RequestsByRequestIdResponses];
