// This file is auto-generated by @hey-api/openapi-ts

import { z } from "zod";

/**
 * File
 */
export const zFileType2 = z.object({
  file_size: z.optional(z.union([z.int(), z.unknown()])),
  file_name: z.optional(z.union([z.string(), z.unknown()])),
  content_type: z.optional(z.union([z.string(), z.unknown()])),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
});

/**
 * TTSOutput
 */
export const zElevenlabsTtsTurboV25Output = z.object({
  audio: zFileType2,
  timestamps: z.optional(z.union([z.array(z.unknown()), z.unknown()])),
});

/**
 * TextToSpeechRequest
 */
export const zElevenlabsTtsTurboV25Input = z.object({
  text: z.string().min(1).register(z.globalRegistry, {
    description: "The text to convert to speech",
  }),
  next_text: z.optional(z.union([z.string(), z.unknown()])),
  speed: z
    .optional(
      z.number().gte(0.7).lte(1.2).register(z.globalRegistry, {
        description:
          "Speech speed (0.7-1.2). Values below 1.0 slow down the speech, above 1.0 speed it up. Extreme values may affect quality.",
      }),
    )
    .default(1),
  style: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Style exaggeration (0-1)",
      }),
    )
    .default(0),
  stability: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Voice stability (0-1)",
      }),
    )
    .default(0.5),
  timestamps: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to return timestamps for each word in the generated speech",
      }),
    )
    .default(false),
  similarity_boost: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Similarity boost (0-1)",
      }),
    )
    .default(0.75),
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "The voice to use for speech generation",
      }),
    )
    .default("Rachel"),
  language_code: z.optional(z.union([z.string(), z.unknown()])),
  apply_text_normalization: z.optional(
    z.enum(["auto", "on", "off"]).register(z.globalRegistry, {
      description:
        "This parameter controls text normalization with three modes: 'auto', 'on', and 'off'. When set to 'auto', the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With 'on', text normalization will always be applied, while with 'off', it will be skipped.",
    }),
  ),
  previous_text: z.optional(z.union([z.string(), z.unknown()])),
});

/**
 * OrpheusOutput
 */
export const zOrpheusTtsOutput = z.object({
  audio: zFileType2,
});

/**
 * OrpheusRequest
 */
export const zOrpheusTtsInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description:
      "The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>",
  }),
  voice: z.optional(
    z
      .enum(["tara", "leah", "jess", "leo", "dan", "mia", "zac", "zoe"])
      .register(z.globalRegistry, {
        description: "Voice ID for the desired voice.",
      }),
  ),
  repetition_penalty: z
    .optional(
      z.number().gte(1.1).lte(2).register(z.globalRegistry, {
        description:
          "Repetition penalty (>= 1.1 required for stable generations).",
      }),
    )
    .default(1.2),
  temperature: z
    .optional(
      z.number().gte(0).lte(2).register(z.globalRegistry, {
        description: "Temperature for generation (higher = more creative).",
      }),
    )
    .default(0.7),
});

/**
 * DiaOutput
 */
export const zDiaTtsOutput = z.object({
  audio: zFileType2,
});

/**
 * DiaRequest
 */
export const zDiaTtsInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description: "The text to be converted to speech.",
  }),
});

/**
 * File
 */
export const zFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
});

/**
 * TextToSpeechOutput
 */
export const zMinimaxSpeech02HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * AudioSetting
 */
export const zAudioSetting = z.object({
  format: z.optional(
    z.enum(["mp3", "pcm", "flac"]).register(z.globalRegistry, {
      description: "Audio format",
    }),
  ),
  sample_rate: z.optional(
    z
      .union([
        z.literal(8000),
        z.literal(16000),
        z.literal(22050),
        z.literal(24000),
        z.literal(32000),
        z.literal(44100),
      ])
      .register(z.globalRegistry, {
        description: "Sample rate of generated audio",
      }),
  ),
  channel: z.optional(
    z.union([z.literal(1), z.literal(2)]).register(z.globalRegistry, {
      description: "Number of audio channels (1=mono, 2=stereo)",
    }),
  ),
  bitrate: z.optional(
    z
      .union([
        z.literal(32000),
        z.literal(64000),
        z.literal(128000),
        z.literal(256000),
      ])
      .register(z.globalRegistry, {
        description: "Bitrate of generated audio",
      }),
  ),
});

/**
 * PronunciationDict
 */
export const zPronunciationDict = z.object({
  tone_list: z.optional(
    z.array(z.string()).register(z.globalRegistry, {
      description:
        "List of pronunciation replacements in format ['text/(pronunciation)', ...]. For Chinese, tones are 1-5. Example: ['燕少飞/(yan4)(shao3)(fei1)']",
    }),
  ),
});

/**
 * VoiceSetting
 */
export const zVoiceSetting = z.object({
  speed: z
    .optional(
      z.number().gte(0.5).lte(2).register(z.globalRegistry, {
        description: "Speech speed (0.5-2.0)",
      }),
    )
    .default(1),
  vol: z
    .optional(
      z.number().gte(0.01).lte(10).register(z.globalRegistry, {
        description: "Volume (0-10)",
      }),
    )
    .default(1),
  voice_id: z
    .optional(
      z.string().register(z.globalRegistry, {
        description: "Predefined voice ID to use for synthesis",
      }),
    )
    .default("Wise_Woman"),
  pitch: z
    .optional(
      z.int().gte(-12).lte(12).register(z.globalRegistry, {
        description: "Voice pitch (-12 to 12)",
      }),
    )
    .default(0),
  english_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Enables English text normalization to improve number reading performance, with a slight increase in latency",
      }),
    )
    .default(false),
  emotion: z.optional(
    z
      .enum([
        "happy",
        "sad",
        "angry",
        "fearful",
        "disgusted",
        "surprised",
        "neutral",
      ])
      .register(z.globalRegistry, {
        description: "Emotion of the generated speech",
      }),
  ),
});

/**
 * TextToSpeechHDRequest
 */
export const zMinimaxSpeech02HdInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
  }),
  voice_setting: z.optional(zVoiceSetting),
  language_boost: z.optional(
    z
      .enum([
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * TextToSpeechOutput
 */
export const zMinimaxSpeech02TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * TextToSpeechTurboRequest
 */
export const zMinimaxSpeech02TurboInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
  }),
  voice_setting: z.optional(zVoiceSetting),
  language_boost: z.optional(
    z
      .enum([
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * VoiceCloneOutput
 */
export const zMinimaxVoiceCloneOutput = z.object({
  custom_voice_id: z.string().register(z.globalRegistry, {
    description: "The cloned voice ID for use with TTS",
  }),
  audio: z.optional(zFile),
});

/**
 * VoiceCloneRequest
 */
export const zMinimaxVoiceCloneInput = z.object({
  text: z
    .optional(
      z.string().max(1000).register(z.globalRegistry, {
        description:
          "Text to generate a TTS preview with the cloned voice (optional)",
      }),
    )
    .default(
      "Hello, this is a preview of your cloned voice! I hope you like it!",
    ),
  model: z.optional(
    z
      .enum([
        "speech-02-hd",
        "speech-02-turbo",
        "speech-01-hd",
        "speech-01-turbo",
      ])
      .register(z.globalRegistry, {
        description:
          "TTS model to use for preview. Options: speech-02-hd, speech-02-turbo, speech-01-hd, speech-01-turbo",
      }),
  ),
  accuracy: z.optional(
    z.number().gte(0).lte(1).register(z.globalRegistry, {
      description: "Text validation accuracy threshold (0-1)",
    }),
  ),
  audio_url: z.union([z.string(), z.string()]),
  noise_reduction: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable noise reduction for the cloned voice",
      }),
    )
    .default(false),
  need_volume_normalization: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable volume normalization for the cloned voice",
      }),
    )
    .default(false),
});

export const zChatterboxTextToSpeechOutput = z.unknown();

/**
 * ChatterboxRequest
 */
export const zChatterboxTextToSpeechInput = z.object({
  text: z.string().register(z.globalRegistry, {
    description:
      "The text to be converted to speech. You can additionally add the following emotive tags: <laugh>, <chuckle>, <sigh>, <cough>, <sniffle>, <groan>, <yawn>, <gasp>",
  }),
  exaggeration: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Exaggeration factor for the generated speech (0.0 = no exaggeration, 1.0 = maximum exaggeration).",
      }),
    )
    .default(0.25),
  audio_url: z.optional(z.union([z.string(), z.string()])),
  temperature: z
    .optional(
      z.number().gte(0.05).lte(2).register(z.globalRegistry, {
        description: "Temperature for generation (higher = more creative).",
      }),
    )
    .default(0.7),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed..",
    }),
  ),
  cfg: z.optional(z.number().gte(0.1).lte(1)).default(0.5),
});

/**
 * Audio
 */
export const zAudio = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
});

/**
 * TTSOutput
 *
 * Output parameters for the TTS request.
 */
export const zChatterboxhdTextToSpeechOutput = z
  .object({
    audio: zAudio,
  })
  .register(z.globalRegistry, {
    description: "Output parameters for the TTS request.",
  });

/**
 * TTSInput
 *
 * Input parameters for the TTS request.
 */
export const zChatterboxhdTextToSpeechInput = z
  .object({
    text: z
      .optional(
        z.string().register(z.globalRegistry, {
          description: "Text to synthesize into speech.",
        }),
      )
      .default(
        "My name is Maximus Decimus Meridius, commander of the Armies of the North, General of the Felix Legions and loyal servant to the true emperor, Marcus Aurelius. Father to a murdered son, husband to a murdered wife. And I will have my vengeance, in this life or the next.",
      ),
    exaggeration: z
      .optional(
        z.number().gte(0.25).lte(2).register(z.globalRegistry, {
          description:
            "Controls emotion exaggeration. Range typically 0.25 to 2.0.",
        }),
      )
      .default(0.5),
    high_quality_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz. ",
        }),
      )
      .default(false),
    voice: z.optional(
      z
        .enum([
          "Aurora",
          "Blade",
          "Britney",
          "Carl",
          "Cliff",
          "Richard",
          "Rico",
          "Siobhan",
          "Vicky",
        ])
        .register(z.globalRegistry, {
          description:
            "The voice to use for the TTS request. If neither voice nor audio are provided, a random voice will be used.",
        }),
    ),
    audio_url: z.optional(z.union([z.string(), z.string()])),
    temperature: z
      .optional(
        z.number().gte(0.05).lte(5).register(z.globalRegistry, {
          description:
            "Controls the randomness of generation. Range typically 0.05 to 5.",
        }),
      )
      .default(0.8),
    seed: z
      .optional(
        z.int().gte(0).register(z.globalRegistry, {
          description:
            "Useful to control the reproducibility of the generated audio. Assuming all other properties didn't change, a fixed seed should always generate the exact same audio file. Set to 0 for random seed.",
        }),
      )
      .default(0),
    cfg: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "Classifier-free guidance scale (CFG) controls the conditioning factor. Range typically 0.2 to 1.0. For expressive or dramatic speech, try lower cfg values (e.g. ~0.3) and increase exaggeration to around 0.7 or higher. If the reference speaker has a fast speaking style, lowering cfg to around 0.3 can improve pacing.",
        }),
      )
      .default(0.5),
  })
  .register(z.globalRegistry, {
    description: "Input parameters for the TTS request.",
  });

/**
 * VoiceDesignOutput
 */
export const zMinimaxVoiceDesignOutput = z.object({
  custom_voice_id: z.string().register(z.globalRegistry, {
    description: "The voice_id of the generated voice",
  }),
  audio: zFile,
});

/**
 * VoiceDesignRequest
 */
export const zMinimaxVoiceDesignInput = z.object({
  prompt: z.string().max(2000).register(z.globalRegistry, {
    description: "Voice description prompt for generating a personalized voice",
  }),
  preview_text: z.string().max(500).register(z.globalRegistry, {
    description:
      "Text for audio preview. Limited to 500 characters. A fee of $30 per 1M characters will be charged for the generation of the preview audio.",
  }),
});

/**
 * TextToSpeechOutput
 */
export const zMinimaxPreviewSpeech25TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * TextToSpeechTurbov25Request
 */
export const zMinimaxPreviewSpeech25TurboInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
  }),
  voice_setting: z.optional(zVoiceSetting),
  language_boost: z.optional(
    z
      .enum([
        "Persian",
        "Filipino",
        "Tamil",
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * TextToSpeechOutput
 */
export const zMinimaxPreviewSpeech25HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * TextToSpeechHDv25Request
 */
export const zMinimaxPreviewSpeech25HdInput = z.object({
  text: z.string().min(1).max(5000).register(z.globalRegistry, {
    description:
      "Text to convert to speech (max 5000 characters, minimum 1 non-whitespace character)",
  }),
  voice_setting: z.optional(zVoiceSetting),
  language_boost: z.optional(
    z
      .enum([
        "Persian",
        "Filipino",
        "Tamil",
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export const zVibevoiceOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: "Duration of the generated audio in seconds",
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        "Real-time factor (generation_time / audio_duration). Lower is better.",
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: "Sample rate of the generated audio",
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: "Time taken to generate the audio in seconds",
    }),
    audio: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output schema for VibeVoice TTS generation",
  });

/**
 * VibeVoiceSpeaker
 */
export const zVibeVoiceSpeaker = z.object({
  preset: z.optional(
    z
      .enum([
        "Alice [EN]",
        "Carter [EN]",
        "Frank [EN]",
        "Mary [EN] (Background Music)",
        "Maya [EN]",
        "Anchen [ZH] (Background Music)",
        "Bowen [ZH]",
        "Xinran [ZH]",
      ])
      .register(z.globalRegistry, {
        description:
          "Default voice preset to use for the speaker. Not used if `audio_url` is provided.",
      }),
  ),
  audio_url: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "URL to a voice sample audio file. If provided, `preset` will be ignored.",
    }),
  ),
});

/**
 * VibeVoiceInput
 *
 * Input schema for VibeVoice TTS generation
 */
export const zVibevoiceInput = z
  .object({
    script: z.string().max(90000).register(z.globalRegistry, {
      description:
        "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for reproducible generation.",
      }),
    ),
    speakers: z.array(zVibeVoiceSpeaker).register(z.globalRegistry, {
      description:
        "List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.",
    }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.",
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: "Input schema for VibeVoice TTS generation",
  });

/**
 * VibeVoiceOutput
 *
 * Output schema for VibeVoice TTS generation
 */
export const zVibevoice7bOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: "Duration of the generated audio in seconds",
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        "Real-time factor (generation_time / audio_duration). Lower is better.",
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: "Sample rate of the generated audio",
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: "Time taken to generate the audio in seconds",
    }),
    audio: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output schema for VibeVoice TTS generation",
  });

/**
 * VibeVoice7bInput
 *
 * Input schema for VibeVoice-7b TTS generation
 */
export const zVibevoice7bInput = z
  .object({
    script: z.string().max(30000).register(z.globalRegistry, {
      description:
        "The script to convert to speech. Can be formatted with 'Speaker X:' prefixes for multi-speaker dialogues.",
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for reproducible generation.",
      }),
    ),
    speakers: z.array(zVibeVoiceSpeaker).register(z.globalRegistry, {
      description:
        "List of speakers to use for the script. If not provided, will be inferred from the script or voice samples.",
    }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.",
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: "Input schema for VibeVoice-7b TTS generation",
  });

/**
 * ChatterboxMultilingualOutput
 */
export const zChatterboxTextToSpeechMultilingualOutput = z.object({
  audio: zFile,
});

/**
 * ChatterboxMultilingualRequest
 */
export const zChatterboxTextToSpeechMultilingualInput = z.object({
  text: z.string().max(300).register(z.globalRegistry, {
    description:
      "The text to be converted to speech (maximum 300 characters). Supports 23 languages including English, French, German, Spanish, Italian, Portuguese, Hindi, Arabic, Chinese, Japanese, Korean, and more.",
  }),
  custom_audio_language: z.optional(
    z
      .enum([
        "english",
        "arabic",
        "danish",
        "german",
        "greek",
        "spanish",
        "finnish",
        "french",
        "hebrew",
        "hindi",
        "italian",
        "japanese",
        "korean",
        "malay",
        "dutch",
        "norwegian",
        "polish",
        "portuguese",
        "russian",
        "swedish",
        "swahili",
        "turkish",
        "chinese",
      ])
      .register(z.globalRegistry, {
        description:
          "If using a custom audio URL, specify the language of the audio here. Ignored if voice is not a custom url.",
      }),
  ),
  exaggeration: z
    .optional(
      z.number().gte(0.25).lte(2).register(z.globalRegistry, {
        description:
          "Controls speech expressiveness and emotional intensity (0.25-2.0). 0.5 is neutral, higher values increase expressiveness. Extreme values may be unstable.",
      }),
    )
    .default(0.5),
  voice: z
    .optional(
      z.string().register(z.globalRegistry, {
        description:
          "Language code for synthesis. In case using custom please provide audio url and select custom_audio_language. ",
      }),
    )
    .default("english"),
  temperature: z
    .optional(
      z.number().gte(0.05).lte(5).register(z.globalRegistry, {
        description:
          "Controls randomness and variation in generation (0.05-5.0). Higher values create more varied speech patterns.",
      }),
    )
    .default(0.8),
  seed: z.optional(
    z.int().register(z.globalRegistry, {
      description:
        "Random seed for reproducible results. Set to 0 for random generation, or provide a specific number for consistent outputs.",
    }),
  ),
  cfg_scale: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "Configuration/pace weight controlling generation guidance (0.0-1.0). Use 0.0 for language transfer to mitigate accent inheritance.",
      }),
    )
    .default(0.5),
});

/**
 * TTSOutput
 */
export const zKlingVideoV1TtsOutput = z.object({
  audio: zFile,
});

/**
 * TTSInput
 */
export const zKlingVideoV1TtsInput = z.object({
  text: z.string().max(500).register(z.globalRegistry, {
    description: "The text to be converted to speech",
  }),
  voice_id: z.optional(
    z
      .enum([
        "genshin_vindi2",
        "zhinen_xuesheng",
        "AOT",
        "ai_shatang",
        "genshin_klee2",
        "genshin_kirara",
        "ai_kaiya",
        "oversea_male1",
        "ai_chenjiahao_712",
        "girlfriend_4_speech02",
        "chat1_female_new-3",
        "chat_0407_5-1",
        "cartoon-boy-07",
        "uk_boy1",
        "cartoon-girl-01",
        "PeppaPig_platform",
        "ai_huangzhong_712",
        "ai_huangyaoshi_712",
        "ai_laoguowang_712",
        "chengshu_jiejie",
        "you_pingjing",
        "calm_story1",
        "uk_man2",
        "laopopo_speech02",
        "heainainai_speech02",
        "reader_en_m-v1",
        "commercial_lady_en_f-v1",
        "tiyuxi_xuedi",
        "tiexin_nanyou",
        "girlfriend_1_speech02",
        "girlfriend_2_speech02",
        "zhuxi_speech02",
        "uk_oldman3",
        "dongbeilaotie_speech02",
        "chongqingxiaohuo_speech02",
        "chuanmeizi_speech02",
        "chaoshandashu_speech02",
        "ai_taiwan_man2_speech02",
        "xianzhanggui_speech02",
        "tianjinjiejie_speech02",
        "diyinnansang_DB_CN_M_04-v2",
        "yizhipiannan-v1",
        "guanxiaofang-v2",
        "tianmeixuemei-v1",
        "daopianyansang-v1",
        "mengwa-v1",
      ])
      .register(z.globalRegistry, {
        description: "The voice ID to use for speech synthesis",
      }),
  ),
  voice_speed: z
    .optional(
      z.number().gte(0.8).lte(2).register(z.globalRegistry, {
        description: "Rate of speech",
      }),
    )
    .default(1),
});

/**
 * EmotionalStrengths
 */
export const zEmotionalStrengths = z.object({
  afraid: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of fear emotion",
      }),
    )
    .default(0),
  calm: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of calm emotion",
      }),
    )
    .default(0),
  disgusted: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of disgust emotion",
      }),
    )
    .default(0),
  angry: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of anger emotion",
      }),
    )
    .default(0),
  sad: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of sadness emotion",
      }),
    )
    .default(0),
  melancholic: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of melancholic emotion",
      }),
    )
    .default(0),
  surprised: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of surprise emotion",
      }),
    )
    .default(0),
  happy: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Strength of happiness emotion",
      }),
    )
    .default(0),
});

/**
 * IndexTTS2Output
 */
export const zIndexTts2TextToSpeechOutput = z.object({
  audio: zFile,
});

/**
 * IndexTTS2Input
 */
export const zIndexTts2TextToSpeechInput = z.object({
  prompt: z.string().register(z.globalRegistry, {
    description: "The speech prompt to generate",
  }),
  emotional_strengths: z.optional(zEmotionalStrengths),
  strength: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description:
          "The strength of the emotional style transfer. Higher values result in stronger emotional influence.",
      }),
    )
    .default(1),
  emotional_audio_url: z.optional(z.union([z.string(), z.string()])),
  audio_url: z.union([z.string(), z.string()]),
  emotion_prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The emotional prompt to influence the emotional style. Must be used together with should_use_prompt_for_emotion.",
    }),
  ),
  should_use_prompt_for_emotion: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description:
          "Whether to use the `prompt` to calculate emotional strengths, if enabled it will overwrite the `emotional_strengths` values. If `emotion_prompt` is provided, it will be used to instead of `prompt` to extract the emotional style.",
      }),
    )
    .default(false),
});

/**
 * TextToSpeechHD26Output
 */
export const zMinimaxSpeech26HdOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * LoudnessNormalizationSetting
 */
export const zLoudnessNormalizationSetting = z.object({
  target_range: z
    .optional(
      z.number().gte(0).lte(20).register(z.globalRegistry, {
        description: "Target loudness range in LU (default 8.0)",
      }),
    )
    .default(8),
  target_loudness: z
    .optional(
      z.number().gte(-70).lte(-10).register(z.globalRegistry, {
        description: "Target loudness in LUFS (default -18.0)",
      }),
    )
    .default(-18),
  enabled: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Enable loudness normalization for the audio",
      }),
    )
    .default(true),
  target_peak: z
    .optional(
      z.number().gte(-3).lte(0).register(z.globalRegistry, {
        description: "Target peak level in dBTP (default -0.5).",
      }),
    )
    .default(-0.5),
});

/**
 * TextToSpeechHD26Request
 */
export const zMinimaxSpeech26HdInput = z.object({
  prompt: z.string().min(1).max(10000).register(z.globalRegistry, {
    description:
      "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.",
  }),
  language_boost: z.optional(
    z
      .enum([
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  voice_setting: z.optional(zVoiceSetting),
  normalization_setting: z.optional(zLoudnessNormalizationSetting),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * TextToSpeechTurbo26Output
 */
export const zMinimaxSpeech26TurboOutput = z.object({
  duration_ms: z.int().register(z.globalRegistry, {
    description: "Duration of the audio in milliseconds",
  }),
  audio: zFile,
});

/**
 * TextToSpeechTurbo26Request
 */
export const zMinimaxSpeech26TurboInput = z.object({
  prompt: z.string().min(1).max(10000).register(z.globalRegistry, {
    description:
      "Text to convert to speech. Paragraph breaks should be marked with newline characters. **NOTE**: You can customize speech pauses by adding markers in the form `<#x#>`, where `x` is the pause duration in seconds. Valid range: `[0.01, 99.99]`, up to two decimal places. Pause markers must be placed between speakable text segments and cannot be used consecutively.",
  }),
  language_boost: z.optional(
    z
      .enum([
        "Chinese",
        "Chinese,Yue",
        "English",
        "Arabic",
        "Russian",
        "Spanish",
        "French",
        "Portuguese",
        "German",
        "Turkish",
        "Dutch",
        "Ukrainian",
        "Vietnamese",
        "Indonesian",
        "Japanese",
        "Italian",
        "Korean",
        "Thai",
        "Polish",
        "Romanian",
        "Greek",
        "Czech",
        "Finnish",
        "Hindi",
        "Bulgarian",
        "Danish",
        "Hebrew",
        "Malay",
        "Slovak",
        "Swedish",
        "Croatian",
        "Hungarian",
        "Norwegian",
        "Slovenian",
        "Catalan",
        "Nynorsk",
        "Afrikaans",
        "auto",
      ])
      .register(z.globalRegistry, {
        description: "Enhance recognition of specified languages and dialects",
      }),
  ),
  output_format: z.optional(
    z.enum(["url", "hex"]).register(z.globalRegistry, {
      description: "Format of the output content (non-streaming only)",
    }),
  ),
  pronunciation_dict: z.optional(zPronunciationDict),
  voice_setting: z.optional(zVoiceSetting),
  normalization_setting: z.optional(zLoudnessNormalizationSetting),
  audio_setting: z.optional(zAudioSetting),
});

/**
 * MayaVoiceOutput
 *
 * Output schema for Maya-1-Voice TTS generation
 */
export const zMayaOutput = z
  .object({
    rtf: z.number().register(z.globalRegistry, {
      description:
        "Real-time factor (generation_time / audio_duration). Lower is better.",
    }),
    duration: z.number().register(z.globalRegistry, {
      description: "Duration of the generated audio in seconds",
    }),
    sample_rate: z.string().register(z.globalRegistry, {
      description: "Sample rate of the generated audio",
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: "Time taken to generate the audio in seconds",
    }),
    audio: zFileType2,
  })
  .register(z.globalRegistry, {
    description: "Output schema for Maya-1-Voice TTS generation",
  });

/**
 * MayaVoiceInput
 *
 * Input schema for Maya-1-Voice TTS generation
 */
export const zMayaInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            "Penalty for repeating tokens. Higher values reduce repetition artifacts.",
        }),
      )
      .default(1.1),
    prompt: z.string().max(500).register(z.globalRegistry, {
      description:
        "Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.",
    }),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "Nucleus sampling parameter. Controls diversity of token selection.",
        }),
      )
      .default(0.9),
    text: z.string().max(5000).register(z.globalRegistry, {
      description:
        "The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'",
    }),
    output_format: z.optional(
      z.enum(["wav", "mp3"]).register(z.globalRegistry, {
        description: "Output audio format for the generated speech",
      }),
    ),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description:
            "Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.",
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            "Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.",
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(["48 kHz", "24 kHz"]).register(z.globalRegistry, {
        description:
          "Output audio sample rate. 48 kHz provides higher quality audio, 24 kHz is faster.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input schema for Maya-1-Voice TTS generation",
  });

export const zMayaStreamOutput = z.unknown();

/**
 * MayaVoiceStreamingInput
 *
 * Input schema for Maya-1-Voice streaming TTS generation
 */
export const zMayaStreamInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            "Penalty for repeating tokens. Higher values reduce repetition artifacts.",
        }),
      )
      .default(1.1),
    prompt: z.string().max(500).register(z.globalRegistry, {
      description:
        "Description of the voice/character. Includes attributes like age, accent, pitch, timbre, pacing, tone, and intensity. See examples for format.",
    }),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description:
            "Nucleus sampling parameter. Controls diversity of token selection.",
        }),
      )
      .default(0.9),
    text: z.string().max(5000).register(z.globalRegistry, {
      description:
        "The text to synthesize into speech. You can embed emotion tags anywhere in the text using the format <emotion_name>. Available emotions: laugh, laugh_harder, sigh, chuckle, gasp, angry, excited, whisper, cry, scream, sing, snort, exhale, gulp, giggle, sarcastic, curious. Example: 'Hello world! <excited> This is amazing!' or 'I can't believe this <sigh> happened again.'",
    }),
    output_format: z.optional(
      z.enum(["mp3", "wav", "pcm"]).register(z.globalRegistry, {
        description:
          "Output audio format. 'mp3' for browser-playable audio, 'wav' for uncompressed audio, 'pcm' for raw PCM (lowest latency, requires client-side decoding).",
      }),
    ),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description:
            "Maximum number of SNAC tokens to generate (7 tokens per frame). Controls maximum audio length.",
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description:
            "Sampling temperature. Lower values (0.2-0.5) produce more stable/consistent audio. Higher values add variation.",
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(["48 kHz", "24 kHz"]).register(z.globalRegistry, {
        description:
          "Output audio sample rate. 48 kHz uses upsampling for higher quality audio, 24 kHz is native SNAC output (faster, lower latency).",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input schema for Maya-1-Voice streaming TTS generation",
  });

/**
 * MayaVoiceBatchOutput
 *
 * Output schema for batch Maya-1-Voice TTS generation
 */
export const zMayaBatchOutput = z
  .object({
    average_rtf: z.number().register(z.globalRegistry, {
      description: "Average real-time factor across all generations",
    }),
    sample_rate: z.string().register(z.globalRegistry, {
      description: "Sample rate of all generated audio files",
    }),
    total_generation_time: z.number().register(z.globalRegistry, {
      description: "Total time taken to generate all audio files in seconds",
    }),
    audios: z.array(zFileType2).register(z.globalRegistry, {
      description: "List of generated audio files",
    }),
    durations: z.array(z.number()).register(z.globalRegistry, {
      description: "Duration of each generated audio in seconds",
    }),
  })
  .register(z.globalRegistry, {
    description: "Output schema for batch Maya-1-Voice TTS generation",
  });

/**
 * MayaVoiceBatchInput
 *
 * Input schema for batch Maya-1-Voice TTS generation
 */
export const zMayaBatchInput = z
  .object({
    repetition_penalty: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description: "Repetition penalty for all generations.",
        }),
      )
      .default(1.1),
    top_p: z
      .optional(
        z.number().gte(0).lte(1).register(z.globalRegistry, {
          description: "Nucleus sampling parameter for all generations.",
        }),
      )
      .default(0.9),
    output_format: z.optional(
      z.enum(["wav", "mp3"]).register(z.globalRegistry, {
        description: "Output audio format for all generated speech files",
      }),
    ),
    texts: z.array(z.string()).min(1).max(100).register(z.globalRegistry, {
      description:
        "List of texts to synthesize into speech. You can embed emotion tags in each text using the format <emotion_name>.",
    }),
    prompts: z.array(z.string()).min(1).max(100).register(z.globalRegistry, {
      description:
        "List of voice descriptions for each text. Must match the length of texts list. Each describes the voice/character attributes.",
    }),
    max_tokens: z
      .optional(
        z.int().gte(28).lte(4000).register(z.globalRegistry, {
          description: "Maximum SNAC tokens per generation.",
        }),
      )
      .default(2000),
    temperature: z
      .optional(
        z.number().gte(0).lte(2).register(z.globalRegistry, {
          description: "Sampling temperature for all generations.",
        }),
      )
      .default(0.4),
    sample_rate: z.optional(
      z.enum(["48 kHz", "24 kHz"]).register(z.globalRegistry, {
        description:
          "Output audio sample rate for all generations. 48 kHz provides higher quality, 24 kHz is faster.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input schema for batch Maya-1-Voice TTS generation",
  });

/**
 * VibeVoice_0_5BOutput
 *
 * Output schema for VibeVoice-0.5b TTS generation
 */
export const zVibevoice05bOutput = z
  .object({
    duration: z.number().register(z.globalRegistry, {
      description: "Duration of the generated audio in seconds",
    }),
    rtf: z.number().register(z.globalRegistry, {
      description:
        "Real-time factor (generation_time / audio_duration). Lower is better.",
    }),
    sample_rate: z.int().register(z.globalRegistry, {
      description: "Sample rate of the generated audio",
    }),
    generation_time: z.number().register(z.globalRegistry, {
      description: "Time taken to generate the audio in seconds",
    }),
    audio: zFile,
  })
  .register(z.globalRegistry, {
    description: "Output schema for VibeVoice-0.5b TTS generation",
  });

/**
 * VibeVoice0_5bInput
 *
 * Input schema for VibeVoice-0.5b TTS generation
 */
export const zVibevoice05bInput = z
  .object({
    script: z.string().max(90000).register(z.globalRegistry, {
      description: "The script to convert to speech.",
    }),
    seed: z.optional(
      z.int().register(z.globalRegistry, {
        description: "Random seed for reproducible generation.",
      }),
    ),
    speaker: z
      .enum(["Frank", "Wayne", "Carter", "Emma", "Grace", "Mike"])
      .register(z.globalRegistry, {
        description: "Voice to use for speaking.",
      }),
    cfg_scale: z
      .optional(
        z.number().gte(1).lte(2).register(z.globalRegistry, {
          description:
            "CFG (Classifier-Free Guidance) scale for generation. Higher values increase adherence to text.",
        }),
      )
      .default(1.3),
  })
  .register(z.globalRegistry, {
    description: "Input schema for VibeVoice-0.5b TTS generation",
  });

/**
 * AudioFile
 */
export const zAudioFile = z.object({
  file_size: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The size of the file in bytes.",
    }),
  ),
  duration: z.optional(
    z.number().register(z.globalRegistry, {
      description: "The duration of the audio",
    }),
  ),
  file_data: z.optional(
    z.string().register(z.globalRegistry, {
      description: "File data",
    }),
  ),
  channels: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The number of channels in the audio",
    }),
  ),
  url: z.string().register(z.globalRegistry, {
    description: "The URL where the file can be downloaded from.",
  }),
  file_name: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "The name of the file. It will be auto-generated if not provided.",
    }),
  ),
  sample_rate: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The sample rate of the audio",
    }),
  ),
  content_type: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The mime type of the file.",
    }),
  ),
  bitrate: z.optional(z.union([z.string(), z.int()])),
});

/**
 * Qwen3TTSOutput06b
 */
export const zQwen3TtsTextToSpeech06bOutput = z.object({
  audio: zAudioFile,
});

/**
 * Qwen3TTSInput06b
 */
export const zQwen3TtsTextToSpeech06bInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided.",
    }),
  ),
  speaker_voice_embedding_file_url: z.optional(
    z.union([z.string(), z.string()]),
  ),
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p sampling parameter.",
      }),
    )
    .default(1),
  repetition_penalty: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description: "Penalty to reduce repeated tokens/codes.",
      }),
    )
    .default(1.05),
  subtalker_temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Temperature for sub-talker sampling.",
      }),
    )
    .default(0.9),
  top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k sampling parameter.",
      }),
    )
    .default(50),
  voice: z.optional(
    z
      .enum([
        "Vivian",
        "Serena",
        "Uncle_Fu",
        "Dylan",
        "Eric",
        "Ryan",
        "Aiden",
        "Ono_Anna",
        "Sohee",
      ])
      .register(z.globalRegistry, {
        description:
          "The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support.",
      }),
  ),
  reference_text: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice.",
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Sampling temperature; higher => more random.",
      }),
    )
    .default(0.9),
  language: z.optional(
    z
      .enum([
        "Auto",
        "English",
        "Chinese",
        "Spanish",
        "French",
        "German",
        "Italian",
        "Japanese",
        "Korean",
        "Portuguese",
        "Russian",
      ])
      .register(z.globalRegistry, {
        description: "The language of the voice.",
      }),
  ),
  subtalker_top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k for sub-talker sampling.",
      }),
    )
    .default(50),
  text: z.string().register(z.globalRegistry, {
    description: "The text to be converted to speech.",
  }),
  max_new_tokens: z
    .optional(
      z.int().gte(1).lte(8192).register(z.globalRegistry, {
        description: "Maximum number of new codec tokens to generate.",
      }),
    )
    .default(200),
  subtalker_dosample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Sampling switch for the sub-talker.",
      }),
    )
    .default(true),
  subtalker_top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p for sub-talker sampling.",
      }),
    )
    .default(1),
});

/**
 * Qwen3TTSOutput
 */
export const zQwen3TtsTextToSpeech17bOutput = z.object({
  audio: zAudioFile,
});

/**
 * Qwen3TTSInput
 */
export const zQwen3TtsTextToSpeech17bInput = z.object({
  prompt: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Optional prompt to guide the style of the generated speech. This prompt will be ignored if a speaker embedding is provided.",
    }),
  ),
  speaker_voice_embedding_file_url: z.optional(
    z.union([z.string(), z.string()]),
  ),
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p sampling parameter.",
      }),
    )
    .default(1),
  repetition_penalty: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description: "Penalty to reduce repeated tokens/codes.",
      }),
    )
    .default(1.05),
  subtalker_temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Temperature for sub-talker sampling.",
      }),
    )
    .default(0.9),
  top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k sampling parameter.",
      }),
    )
    .default(50),
  voice: z.optional(
    z
      .enum([
        "Vivian",
        "Serena",
        "Uncle_Fu",
        "Dylan",
        "Eric",
        "Ryan",
        "Aiden",
        "Ono_Anna",
        "Sohee",
      ])
      .register(z.globalRegistry, {
        description:
          "The voice to be used for speech synthesis, will be ignored if a speaker embedding is provided. Check out the **[documentation](https://github.com/QwenLM/Qwen3-TTS/tree/main?tab=readme-ov-file#custom-voice-generate)** for each voice's details and which language they primarily support.",
      }),
  ),
  reference_text: z.optional(
    z.string().register(z.globalRegistry, {
      description:
        "Optional reference text that was used when creating the speaker embedding. Providing this can improve synthesis quality when using a cloned voice.",
    }),
  ),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Sampling temperature; higher => more random.",
      }),
    )
    .default(0.9),
  language: z.optional(
    z
      .enum([
        "Auto",
        "English",
        "Chinese",
        "Spanish",
        "French",
        "German",
        "Italian",
        "Japanese",
        "Korean",
        "Portuguese",
        "Russian",
      ])
      .register(z.globalRegistry, {
        description: "The language of the voice.",
      }),
  ),
  subtalker_top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k for sub-talker sampling.",
      }),
    )
    .default(50),
  text: z.string().register(z.globalRegistry, {
    description: "The text to be converted to speech.",
  }),
  max_new_tokens: z
    .optional(
      z.int().gte(1).lte(8192).register(z.globalRegistry, {
        description: "Maximum number of new codec tokens to generate.",
      }),
    )
    .default(200),
  subtalker_dosample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Sampling switch for the sub-talker.",
      }),
    )
    .default(true),
  subtalker_top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p for sub-talker sampling.",
      }),
    )
    .default(1),
});

/**
 * Qwen3DesignVoiceOutput
 */
export const zQwen3TtsVoiceDesign17bOutput = z.object({
  audio: zAudioFile,
});

/**
 * Qwen3DesignVoiceInput
 */
export const zQwen3TtsVoiceDesign17bInput = z.object({
  repetition_penalty: z
    .optional(
      z.number().gte(0).register(z.globalRegistry, {
        description: "Penalty to reduce repeated tokens/codes.",
      }),
    )
    .default(1.05),
  subtalker_top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k for sub-talker sampling.",
      }),
    )
    .default(50),
  top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p sampling parameter.",
      }),
    )
    .default(1),
  prompt: z.string().register(z.globalRegistry, {
    description: "Optional prompt to guide the style of the generated speech.",
  }),
  max_new_tokens: z
    .optional(
      z.int().gte(1).lte(8192).register(z.globalRegistry, {
        description: "Maximum number of new codec tokens to generate.",
      }),
    )
    .default(200),
  text: z.string().register(z.globalRegistry, {
    description: "The text to be converted to speech.",
  }),
  language: z.optional(
    z
      .enum([
        "Auto",
        "English",
        "Chinese",
        "Spanish",
        "French",
        "German",
        "Italian",
        "Japanese",
        "Korean",
        "Portuguese",
        "Russian",
      ])
      .register(z.globalRegistry, {
        description: "The language of the voice to be designed.",
      }),
  ),
  top_k: z
    .optional(
      z.int().gte(0).register(z.globalRegistry, {
        description: "Top-k sampling parameter.",
      }),
    )
    .default(50),
  subtalker_dosample: z
    .optional(
      z.boolean().register(z.globalRegistry, {
        description: "Sampling switch for the sub-talker.",
      }),
    )
    .default(true),
  subtalker_temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Temperature for sub-talker sampling.",
      }),
    )
    .default(0.9),
  subtalker_top_p: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Top-p for sub-talker sampling.",
      }),
    )
    .default(1),
  temperature: z
    .optional(
      z.number().gte(0).lte(1).register(z.globalRegistry, {
        description: "Sampling temperature; higher => more random.",
      }),
    )
    .default(0.9),
});

/**
 * ChatterboxOutput
 */
export const zChatterboxSpeechToSpeechOutput = z.object({
  audio: zFile,
});

/**
 * ChatterboxVCRequest
 */
export const zChatterboxSpeechToSpeechInput = z.object({
  source_audio_url: z.union([z.string(), z.string()]),
  target_voice_audio_url: z.optional(z.union([z.string(), z.string()])),
});

/**
 * STSOutput
 *
 * Output parameters for the speech-to-speech request.
 */
export const zChatterboxhdSpeechToSpeechOutput = z
  .object({
    audio: zAudio,
  })
  .register(z.globalRegistry, {
    description: "Output parameters for the speech-to-speech request.",
  });

/**
 * STSInput
 *
 * Input parameters for the speech-to-speech request.
 */
export const zChatterboxhdSpeechToSpeechInput = z
  .object({
    high_quality_audio: z
      .optional(
        z.boolean().register(z.globalRegistry, {
          description:
            "If True, the generated audio will be upscaled to 48kHz. The generation of the audio will take longer, but the quality will be higher. If False, the generated audio will be 24kHz. ",
        }),
      )
      .default(false),
    target_voice_audio_url: z.optional(z.union([z.string(), z.string()])),
    source_audio_url: z.union([z.string(), z.string()]),
    target_voice: z.optional(
      z
        .enum([
          "Aurora",
          "Blade",
          "Britney",
          "Carl",
          "Cliff",
          "Richard",
          "Rico",
          "Siobhan",
          "Vicky",
        ])
        .register(z.globalRegistry, {
          description:
            "The voice to use for the speech-to-speech request. If neither target_voice nor target_voice_audio_url are provided, a random target voice will be used.",
        }),
    ),
  })
  .register(z.globalRegistry, {
    description: "Input parameters for the speech-to-speech request.",
  });

export const zQueueStatus = z.object({
  status: z.enum(["IN_QUEUE", "IN_PROGRESS", "COMPLETED"]),
  request_id: z.string().register(z.globalRegistry, {
    description: "The request id.",
  }),
  response_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The response url.",
    }),
  ),
  status_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The status url.",
    }),
  ),
  cancel_url: z.optional(
    z.string().register(z.globalRegistry, {
      description: "The cancel url.",
    }),
  ),
  logs: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: "The logs.",
    }),
  ),
  metrics: z.optional(
    z.record(z.string(), z.unknown()).register(z.globalRegistry, {
      description: "The metrics.",
    }),
  ),
  queue_position: z.optional(
    z.int().register(z.globalRegistry, {
      description: "The queue position.",
    }),
  ),
});

export const zGetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostResembleAiChatterboxhdSpeechToSpeechData = z.object({
  body: zChatterboxhdSpeechToSpeechInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostResembleAiChatterboxhdSpeechToSpeechResponse = zQueueStatus;

export const zGetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetResembleAiChatterboxhdSpeechToSpeechRequestsByRequestIdResponse =
  zChatterboxhdSpeechToSpeechOutput;

export const zGetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiChatterboxSpeechToSpeechRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiChatterboxSpeechToSpeechRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiChatterboxSpeechToSpeechData = z.object({
  body: zChatterboxSpeechToSpeechInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiChatterboxSpeechToSpeechResponse = zQueueStatus;

export const zGetFalAiChatterboxSpeechToSpeechRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiChatterboxSpeechToSpeechRequestsByRequestIdResponse =
  zChatterboxSpeechToSpeechOutput;

export const zGetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiQwen3TtsVoiceDesign17bData = z.object({
  body: zQwen3TtsVoiceDesign17bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiQwen3TtsVoiceDesign17bResponse = zQueueStatus;

export const zGetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiQwen3TtsVoiceDesign17bRequestsByRequestIdResponse =
  zQwen3TtsVoiceDesign17bOutput;

export const zGetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiQwen3TtsTextToSpeech17bData = z.object({
  body: zQwen3TtsTextToSpeech17bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiQwen3TtsTextToSpeech17bResponse = zQueueStatus;

export const zGetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiQwen3TtsTextToSpeech17bRequestsByRequestIdResponse =
  zQwen3TtsTextToSpeech17bOutput;

export const zGetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiQwen3TtsTextToSpeech06bData = z.object({
  body: zQwen3TtsTextToSpeech06bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiQwen3TtsTextToSpeech06bResponse = zQueueStatus;

export const zGetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * Result of the request.
 */
export const zGetFalAiQwen3TtsTextToSpeech06bRequestsByRequestIdResponse =
  zQwen3TtsTextToSpeech06bOutput;

export const zGetFalAiVibevoice05bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVibevoice05bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVibevoice05bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVibevoice05bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVibevoice05bData = z.object({
  body: zVibevoice05bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVibevoice05bResponse = zQueueStatus;

export const zGetFalAiVibevoice05bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVibevoice05bRequestsByRequestIdResponse =
  zVibevoice05bOutput;

export const zGetFalAiMayaBatchRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMayaBatchRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMayaBatchRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMayaBatchRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMayaBatchData = z.object({
  body: zMayaBatchInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMayaBatchResponse = zQueueStatus;

export const zGetFalAiMayaBatchRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMayaBatchRequestsByRequestIdResponse = zMayaBatchOutput;

export const zGetFalAiMayaStreamRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMayaStreamRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMayaStreamRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMayaStreamRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMayaStreamData = z.object({
  body: zMayaStreamInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMayaStreamResponse = zQueueStatus;

export const zGetFalAiMayaStreamRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMayaStreamRequestsByRequestIdResponse = zMayaStreamOutput;

export const zGetFalAiMayaRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiMayaRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiMayaRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiMayaRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMayaData = z.object({
  body: zMayaInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMayaResponse = zQueueStatus;

export const zGetFalAiMayaRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMayaRequestsByRequestIdResponse = zMayaOutput;

export const zGetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxSpeech26TurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxSpeech26TurboRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxSpeech26TurboData = z.object({
  body: zMinimaxSpeech26TurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxSpeech26TurboResponse = zQueueStatus;

export const zGetFalAiMinimaxSpeech26TurboRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxSpeech26TurboRequestsByRequestIdResponse =
  zMinimaxSpeech26TurboOutput;

export const zGetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiMinimaxSpeech26HdRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxSpeech26HdRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxSpeech26HdData = z.object({
  body: zMinimaxSpeech26HdInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxSpeech26HdResponse = zQueueStatus;

export const zGetFalAiMinimaxSpeech26HdRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxSpeech26HdRequestsByRequestIdResponse =
  zMinimaxSpeech26HdOutput;

export const zGetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiIndexTts2TextToSpeechRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiIndexTts2TextToSpeechRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiIndexTts2TextToSpeechData = z.object({
  body: zIndexTts2TextToSpeechInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiIndexTts2TextToSpeechResponse = zQueueStatus;

export const zGetFalAiIndexTts2TextToSpeechRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiIndexTts2TextToSpeechRequestsByRequestIdResponse =
  zIndexTts2TextToSpeechOutput;

export const zGetFalAiKlingVideoV1TtsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiKlingVideoV1TtsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiKlingVideoV1TtsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiKlingVideoV1TtsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiKlingVideoV1TtsData = z.object({
  body: zKlingVideoV1TtsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiKlingVideoV1TtsResponse = zQueueStatus;

export const zGetFalAiKlingVideoV1TtsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiKlingVideoV1TtsRequestsByRequestIdResponse =
  zKlingVideoV1TtsOutput;

export const zGetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiChatterboxTextToSpeechMultilingualData = z.object({
  body: zChatterboxTextToSpeechMultilingualInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiChatterboxTextToSpeechMultilingualResponse =
  zQueueStatus;

export const zGetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiChatterboxTextToSpeechMultilingualRequestsByRequestIdResponse =
  zChatterboxTextToSpeechMultilingualOutput;

export const zGetFalAiVibevoice7bRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVibevoice7bRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiVibevoice7bRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVibevoice7bRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVibevoice7bData = z.object({
  body: zVibevoice7bInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVibevoice7bResponse = zQueueStatus;

export const zGetFalAiVibevoice7bRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVibevoice7bRequestsByRequestIdResponse =
  zVibevoice7bOutput;

export const zGetFalAiVibevoiceRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiVibevoiceRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiVibevoiceRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiVibevoiceRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiVibevoiceData = z.object({
  body: zVibevoiceInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiVibevoiceResponse = zQueueStatus;

export const zGetFalAiVibevoiceRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiVibevoiceRequestsByRequestIdResponse = zVibevoiceOutput;

export const zGetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxPreviewSpeech25HdData = z.object({
  body: zMinimaxPreviewSpeech25HdInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxPreviewSpeech25HdResponse = zQueueStatus;

export const zGetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxPreviewSpeech25HdRequestsByRequestIdResponse =
  zMinimaxPreviewSpeech25HdOutput;

export const zGetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiMinimaxPreviewSpeech25TurboData = z.object({
  body: zMinimaxPreviewSpeech25TurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxPreviewSpeech25TurboResponse = zQueueStatus;

export const zGetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxPreviewSpeech25TurboRequestsByRequestIdResponse =
  zMinimaxPreviewSpeech25TurboOutput;

export const zGetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxVoiceDesignRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVoiceDesignRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxVoiceDesignData = z.object({
  body: zMinimaxVoiceDesignInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVoiceDesignResponse = zQueueStatus;

export const zGetFalAiMinimaxVoiceDesignRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVoiceDesignRequestsByRequestIdResponse =
  zMinimaxVoiceDesignOutput;

export const zGetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutResembleAiChatterboxhdTextToSpeechRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostResembleAiChatterboxhdTextToSpeechData = z.object({
  body: zChatterboxhdTextToSpeechInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostResembleAiChatterboxhdTextToSpeechResponse = zQueueStatus;

export const zGetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * Result of the request.
 */
export const zGetResembleAiChatterboxhdTextToSpeechRequestsByRequestIdResponse =
  zChatterboxhdTextToSpeechOutput;

export const zGetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiChatterboxTextToSpeechRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiChatterboxTextToSpeechRequestsByRequestIdCancelResponse =
  z
    .object({
      success: z.optional(
        z.boolean().register(z.globalRegistry, {
          description: "Whether the request was cancelled successfully.",
        }),
      ),
    })
    .register(z.globalRegistry, {
      description: "The request was cancelled.",
    });

export const zPostFalAiChatterboxTextToSpeechData = z.object({
  body: zChatterboxTextToSpeechInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiChatterboxTextToSpeechResponse = zQueueStatus;

export const zGetFalAiChatterboxTextToSpeechRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiChatterboxTextToSpeechRequestsByRequestIdResponse =
  zChatterboxTextToSpeechOutput;

export const zGetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiMinimaxVoiceCloneRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxVoiceCloneRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxVoiceCloneData = z.object({
  body: zMinimaxVoiceCloneInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxVoiceCloneResponse = zQueueStatus;

export const zGetFalAiMinimaxVoiceCloneRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxVoiceCloneRequestsByRequestIdResponse =
  zMinimaxVoiceCloneOutput;

export const zGetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiMinimaxSpeech02TurboRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxSpeech02TurboRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxSpeech02TurboData = z.object({
  body: zMinimaxSpeech02TurboInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxSpeech02TurboResponse = zQueueStatus;

export const zGetFalAiMinimaxSpeech02TurboRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxSpeech02TurboRequestsByRequestIdResponse =
  zMinimaxSpeech02TurboOutput;

export const zGetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  },
);

/**
 * The request status.
 */
export const zGetFalAiMinimaxSpeech02HdRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelData = z.object(
  {
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  },
);

/**
 * The request was cancelled.
 */
export const zPutFalAiMinimaxSpeech02HdRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiMinimaxSpeech02HdData = z.object({
  body: zMinimaxSpeech02HdInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiMinimaxSpeech02HdResponse = zQueueStatus;

export const zGetFalAiMinimaxSpeech02HdRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiMinimaxSpeech02HdRequestsByRequestIdResponse =
  zMinimaxSpeech02HdOutput;

export const zGetFalAiDiaTtsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiDiaTtsRequestsByRequestIdStatusResponse = zQueueStatus;

export const zPutFalAiDiaTtsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiDiaTtsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiDiaTtsData = z.object({
  body: zDiaTtsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiDiaTtsResponse = zQueueStatus;

export const zGetFalAiDiaTtsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiDiaTtsRequestsByRequestIdResponse = zDiaTtsOutput;

export const zGetFalAiOrpheusTtsRequestsByRequestIdStatusData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(
    z.object({
      logs: z.optional(
        z.number().register(z.globalRegistry, {
          description:
            "Whether to include logs (`1`) in the response or not (`0`).",
        }),
      ),
    }),
  ),
});

/**
 * The request status.
 */
export const zGetFalAiOrpheusTtsRequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiOrpheusTtsRequestsByRequestIdCancelData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * The request was cancelled.
 */
export const zPutFalAiOrpheusTtsRequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiOrpheusTtsData = z.object({
  body: zOrpheusTtsInput,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiOrpheusTtsResponse = zQueueStatus;

export const zGetFalAiOrpheusTtsRequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiOrpheusTtsRequestsByRequestIdResponse = zOrpheusTtsOutput;

export const zGetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(
      z.object({
        logs: z.optional(
          z.number().register(z.globalRegistry, {
            description:
              "Whether to include logs (`1`) in the response or not (`0`).",
          }),
        ),
      }),
    ),
  });

/**
 * The request status.
 */
export const zGetFalAiElevenlabsTtsTurboV25RequestsByRequestIdStatusResponse =
  zQueueStatus;

export const zPutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelData =
  z.object({
    body: z.optional(z.never()),
    path: z.object({
      request_id: z.string().register(z.globalRegistry, {
        description: "Request ID",
      }),
    }),
    query: z.optional(z.never()),
  });

/**
 * The request was cancelled.
 */
export const zPutFalAiElevenlabsTtsTurboV25RequestsByRequestIdCancelResponse = z
  .object({
    success: z.optional(
      z.boolean().register(z.globalRegistry, {
        description: "Whether the request was cancelled successfully.",
      }),
    ),
  })
  .register(z.globalRegistry, {
    description: "The request was cancelled.",
  });

export const zPostFalAiElevenlabsTtsTurboV25Data = z.object({
  body: zElevenlabsTtsTurboV25Input,
  path: z.optional(z.never()),
  query: z.optional(z.never()),
});

/**
 * The request status.
 */
export const zPostFalAiElevenlabsTtsTurboV25Response = zQueueStatus;

export const zGetFalAiElevenlabsTtsTurboV25RequestsByRequestIdData = z.object({
  body: z.optional(z.never()),
  path: z.object({
    request_id: z.string().register(z.globalRegistry, {
      description: "Request ID",
    }),
  }),
  query: z.optional(z.never()),
});

/**
 * Result of the request.
 */
export const zGetFalAiElevenlabsTtsTurboV25RequestsByRequestIdResponse =
  zElevenlabsTtsTurboV25Output;
